/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "/";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./src/index.ts");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/array_util.js":
/*!************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/array_util.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Inserts a value into a sorted array. This method allows duplicate, meaning it\n * allows inserting duplicate value, in which case, the element will be inserted\n * at the lowest index of the value.\n * @param arr The array to modify.\n * @param element The element to insert.\n * @param comparator Optional. If no comparator is specified, elements are\n * compared using array_util.defaultComparator, which is suitable for Strings\n * and Numbers in ascending arrays. If the array contains multiple instances of\n * the target value, the left-most instance will be returned. To provide a\n * comparator, it should take 2 arguments to compare and return a negative,\n * zero, or a positive number.\n */\nfunction binaryInsert(arr, element, comparator) {\n    var index = binarySearch(arr, element, comparator);\n    var insertionPoint = index < 0 ? -(index + 1) : index;\n    arr.splice(insertionPoint, 0, element);\n}\nexports.binaryInsert = binaryInsert;\n/**\n * Searches the array for the target using binary search, returns the index\n * of the found element, or position to insert if element not found. If no\n * comparator is specified, elements are compared using array_\n * util.defaultComparator, which is suitable for Strings and Numbers in\n * ascending arrays. If the array contains multiple instances of the target\n * value, the left-most instance will be returned.\n * @param arr The array to be searched in.\n * @param target The target to be searched for.\n * @param comparator Should take 2 arguments to compare and return a negative,\n *    zero, or a positive number.\n * @return Lowest index of the target value if found, otherwise the insertion\n *    point where the target should be inserted, in the form of\n *    (-insertionPoint - 1).\n */\nfunction binarySearch(arr, target, comparator) {\n    return binarySearch_(arr, target, comparator || defaultComparator);\n}\nexports.binarySearch = binarySearch;\n/**\n * Compares its two arguments for order.\n * @param a The first element to be compared.\n * @param b The second element to be compared.\n * @return A negative number, zero, or a positive number as the first\n *     argument is less than, equal to, or greater than the second.\n */\nfunction defaultComparator(a, b) {\n    return a > b ? 1 : a < b ? -1 : 0;\n}\nfunction binarySearch_(arr, target, comparator) {\n    var left = 0;\n    var right = arr.length;\n    var middle = 0;\n    var found = false;\n    while (left < right) {\n        middle = left + ((right - left) >>> 1);\n        var compareResult = comparator(target, arr[middle]);\n        if (compareResult > 0) {\n            left = middle + 1;\n        }\n        else {\n            right = middle;\n            // If compareResult is 0, the value is found. We record it is found,\n            // and then keep looking because there may be duplicate.\n            found = !compareResult;\n        }\n    }\n    return found ? left : -left - 1;\n}\n//# sourceMappingURL=array_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/array_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/backend.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/backend.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EPSILON_FLOAT32 = 1e-7;\nexports.EPSILON_FLOAT16 = 1e-4;\n/** Convenient class for storing tensor-related data. */\nvar DataStorage = /** @class */ (function () {\n    function DataStorage(backend, dataMover) {\n        this.backend = backend;\n        this.dataMover = dataMover;\n        this.data = new WeakMap();\n        this.dataIdsCount = 0;\n    }\n    DataStorage.prototype.get = function (dataId) {\n        if (!this.data.has(dataId)) {\n            this.dataMover.moveData(this.backend, dataId);\n        }\n        return this.data.get(dataId);\n    };\n    DataStorage.prototype.set = function (dataId, value) {\n        this.dataIdsCount++;\n        this.data.set(dataId, value);\n    };\n    DataStorage.prototype.has = function (dataId) {\n        return this.data.has(dataId);\n    };\n    DataStorage.prototype.delete = function (dataId) {\n        this.dataIdsCount--;\n        return this.data.delete(dataId);\n    };\n    DataStorage.prototype.numDataIds = function () {\n        return this.dataIdsCount;\n    };\n    return DataStorage;\n}());\nexports.DataStorage = DataStorage;\n/**\n * The interface that defines the kernels that should be implemented when\n * adding a new backend. New backends don't need to implement every one of the\n * methods, this can be done gradually (throw an error for unimplemented\n * methods).\n */\nvar KernelBackend = /** @class */ (function () {\n    function KernelBackend() {\n    }\n    KernelBackend.prototype.time = function (f) {\n        return notYetImplemented('time');\n    };\n    KernelBackend.prototype.read = function (dataId) {\n        return notYetImplemented('read');\n    };\n    KernelBackend.prototype.readSync = function (dataId) {\n        return notYetImplemented('readSync');\n    };\n    KernelBackend.prototype.numDataIds = function () {\n        return notYetImplemented('numDataIds');\n    };\n    KernelBackend.prototype.disposeData = function (dataId) {\n        return notYetImplemented('disposeData');\n    };\n    KernelBackend.prototype.write = function (values, shape, dtype) {\n        return notYetImplemented('write');\n    };\n    KernelBackend.prototype.move = function (dataId, values, shape, dtype) {\n        return notYetImplemented('move');\n    };\n    KernelBackend.prototype.memory = function () {\n        return notYetImplemented('memory');\n    };\n    /** Returns the highest precision for floats in bits (e.g. 16 or 32) */\n    KernelBackend.prototype.floatPrecision = function () {\n        return notYetImplemented('floatPrecision');\n    };\n    /** Returns the smallest representable number.  */\n    KernelBackend.prototype.epsilon = function () {\n        return this.floatPrecision() === 32 ? exports.EPSILON_FLOAT32 : exports.EPSILON_FLOAT16;\n    };\n    KernelBackend.prototype.batchMatMul = function (a, b, transposeA, transposeB) {\n        return notYetImplemented('batchMatMul');\n    };\n    KernelBackend.prototype.fusedBatchMatMul = function (_a) {\n        var a = _a.a, b = _a.b, transposeA = _a.transposeA, transposeB = _a.transposeB, bias = _a.bias, activation = _a.activation, preluActivationWeights = _a.preluActivationWeights;\n        return notYetImplemented('fusedBatchMatMul');\n    };\n    KernelBackend.prototype.slice = function (x, begin, size) {\n        return notYetImplemented('slice');\n    };\n    KernelBackend.prototype.stridedSlice = function (x, begin, end, strides) {\n        return notYetImplemented('stridedSlice');\n    };\n    KernelBackend.prototype.unstack = function (x, axis) {\n        return notYetImplemented('unstack');\n    };\n    KernelBackend.prototype.reverse = function (a, axis) {\n        return notYetImplemented('reverse');\n    };\n    KernelBackend.prototype.concat = function (tensors, axis) {\n        return notYetImplemented('concat');\n    };\n    KernelBackend.prototype.neg = function (a) {\n        return notYetImplemented('neg');\n    };\n    KernelBackend.prototype.add = function (a, b) {\n        return notYetImplemented('add');\n    };\n    KernelBackend.prototype.addN = function (tensors) {\n        return notYetImplemented('addN');\n    };\n    KernelBackend.prototype.subtract = function (a, b) {\n        return notYetImplemented('subtract');\n    };\n    KernelBackend.prototype.multiply = function (a, b) {\n        return notYetImplemented('multiply');\n    };\n    KernelBackend.prototype.realDivide = function (a, b) {\n        return notYetImplemented('realDivide');\n    };\n    KernelBackend.prototype.floorDiv = function (a, b) {\n        return notYetImplemented('floorDiv');\n    };\n    KernelBackend.prototype.sum = function (x, axes) {\n        return notYetImplemented('sum');\n    };\n    KernelBackend.prototype.prod = function (x, axes) {\n        return notYetImplemented('prod');\n    };\n    KernelBackend.prototype.unsortedSegmentSum = function (x, segmentIds, numSegments) {\n        return notYetImplemented('unsortedSegmentSum');\n    };\n    KernelBackend.prototype.argMin = function (x, axis) {\n        return notYetImplemented('argMin');\n    };\n    KernelBackend.prototype.argMax = function (x, axis) {\n        return notYetImplemented('argMax');\n    };\n    KernelBackend.prototype.equal = function (a, b) {\n        return notYetImplemented('equal');\n    };\n    KernelBackend.prototype.notEqual = function (a, b) {\n        return notYetImplemented('notEqual');\n    };\n    KernelBackend.prototype.less = function (a, b) {\n        return notYetImplemented('less');\n    };\n    KernelBackend.prototype.lessEqual = function (a, b) {\n        return notYetImplemented('lessEqual');\n    };\n    KernelBackend.prototype.greater = function (a, b) {\n        return notYetImplemented('greater');\n    };\n    KernelBackend.prototype.greaterEqual = function (a, b) {\n        return notYetImplemented('greaterEqual');\n    };\n    KernelBackend.prototype.logicalNot = function (a) {\n        return notYetImplemented('logicalNot');\n    };\n    KernelBackend.prototype.logicalAnd = function (a, b) {\n        return notYetImplemented('logicalAnd');\n    };\n    KernelBackend.prototype.logicalOr = function (a, b) {\n        return notYetImplemented('logicalOr');\n    };\n    KernelBackend.prototype.where = function (condition) {\n        return notYetImplemented('where');\n    };\n    KernelBackend.prototype.select = function (condition, a, b) {\n        return notYetImplemented('select');\n    };\n    KernelBackend.prototype.topk = function (x, k, sorted) {\n        return notYetImplemented('topk');\n    };\n    KernelBackend.prototype.min = function (x, axes) {\n        return notYetImplemented('min');\n    };\n    KernelBackend.prototype.minimum = function (a, b) {\n        return notYetImplemented('minimum');\n    };\n    KernelBackend.prototype.mod = function (a, b) {\n        return notYetImplemented('mod');\n    };\n    KernelBackend.prototype.max = function (x, axes) {\n        return notYetImplemented('max');\n    };\n    KernelBackend.prototype.maximum = function (a, b) {\n        return notYetImplemented('maximum');\n    };\n    KernelBackend.prototype.all = function (x, axes) {\n        return notYetImplemented('all');\n    };\n    KernelBackend.prototype.any = function (x, axes) {\n        return notYetImplemented('any');\n    };\n    KernelBackend.prototype.squaredDifference = function (a, b) {\n        return notYetImplemented('squaredDifference');\n    };\n    KernelBackend.prototype.ceil = function (x) {\n        return notYetImplemented('ceil');\n    };\n    KernelBackend.prototype.floor = function (x) {\n        return notYetImplemented('floor');\n    };\n    KernelBackend.prototype.round = function (x) {\n        return notYetImplemented('round');\n    };\n    KernelBackend.prototype.sign = function (x) {\n        return notYetImplemented('sign');\n    };\n    KernelBackend.prototype.isNaN = function (x) {\n        return notYetImplemented('isNaN');\n    };\n    KernelBackend.prototype.isInf = function (x) {\n        return notYetImplemented('isInf');\n    };\n    KernelBackend.prototype.isFinite = function (x) {\n        return notYetImplemented('isFinite');\n    };\n    KernelBackend.prototype.pow = function (a, b) {\n        return notYetImplemented('pow');\n    };\n    KernelBackend.prototype.exp = function (x) {\n        return notYetImplemented('exp');\n    };\n    KernelBackend.prototype.expm1 = function (x) {\n        return notYetImplemented('expm1');\n    };\n    KernelBackend.prototype.softmax = function (x, dim) {\n        return notYetImplemented('softmax');\n    };\n    KernelBackend.prototype.log = function (x) {\n        return notYetImplemented('log');\n    };\n    KernelBackend.prototype.log1p = function (x) {\n        return notYetImplemented('log1p');\n    };\n    KernelBackend.prototype.sqrt = function (x) {\n        return notYetImplemented('sqrt');\n    };\n    KernelBackend.prototype.rsqrt = function (x) {\n        return notYetImplemented('rsqrt');\n    };\n    KernelBackend.prototype.square = function (x) {\n        return notYetImplemented('square');\n    };\n    KernelBackend.prototype.reciprocal = function (x) {\n        return notYetImplemented('reciprocal');\n    };\n    KernelBackend.prototype.relu = function (x) {\n        return notYetImplemented('relu');\n    };\n    KernelBackend.prototype.relu6 = function (x) {\n        return notYetImplemented('relu6');\n    };\n    KernelBackend.prototype.prelu = function (x, a) {\n        return notYetImplemented('prelu');\n    };\n    KernelBackend.prototype.elu = function (x) {\n        return notYetImplemented('elu');\n    };\n    KernelBackend.prototype.eluDer = function (dy, y) {\n        return notYetImplemented('eluDer');\n    };\n    KernelBackend.prototype.selu = function (x) {\n        return notYetImplemented('selu');\n    };\n    KernelBackend.prototype.int = function (x) {\n        return notYetImplemented('int');\n    };\n    KernelBackend.prototype.clip = function (x, min, max) {\n        return notYetImplemented('clip');\n    };\n    KernelBackend.prototype.abs = function (x) {\n        return notYetImplemented('abs');\n    };\n    KernelBackend.prototype.complexAbs = function (x) {\n        return notYetImplemented('complexAbs');\n    };\n    KernelBackend.prototype.sigmoid = function (x) {\n        return notYetImplemented('sigmoid');\n    };\n    KernelBackend.prototype.softplus = function (x) {\n        return notYetImplemented('softplus');\n    };\n    KernelBackend.prototype.sin = function (x) {\n        return notYetImplemented('sin');\n    };\n    KernelBackend.prototype.cos = function (x) {\n        return notYetImplemented('cos');\n    };\n    KernelBackend.prototype.tan = function (x) {\n        return notYetImplemented('tan');\n    };\n    KernelBackend.prototype.asin = function (x) {\n        return notYetImplemented('asin');\n    };\n    KernelBackend.prototype.acos = function (x) {\n        return notYetImplemented('acos');\n    };\n    KernelBackend.prototype.atan = function (x) {\n        return notYetImplemented('atan');\n    };\n    KernelBackend.prototype.atan2 = function (a, b) {\n        return notYetImplemented('atan2');\n    };\n    KernelBackend.prototype.sinh = function (x) {\n        return notYetImplemented('sinh');\n    };\n    KernelBackend.prototype.cosh = function (x) {\n        return notYetImplemented('cosh');\n    };\n    KernelBackend.prototype.tanh = function (x) {\n        return notYetImplemented('tanh');\n    };\n    KernelBackend.prototype.asinh = function (x) {\n        return notYetImplemented('asinh');\n    };\n    KernelBackend.prototype.acosh = function (x) {\n        return notYetImplemented('acosh');\n    };\n    KernelBackend.prototype.atanh = function (x) {\n        return notYetImplemented('atanh');\n    };\n    KernelBackend.prototype.erf = function (x) {\n        return notYetImplemented('erf');\n    };\n    KernelBackend.prototype.step = function (x, alpha) {\n        return notYetImplemented('step');\n    };\n    KernelBackend.prototype.fusedConv2d = function (_a) {\n        var input = _a.input, filter = _a.filter, convInfo = _a.convInfo, bias = _a.bias, activation = _a.activation, preluActivationWeights = _a.preluActivationWeights;\n        return notYetImplemented('fusedConv2d');\n    };\n    KernelBackend.prototype.conv2d = function (x, filter, convInfo) {\n        return notYetImplemented('conv2d');\n    };\n    KernelBackend.prototype.conv2dDerInput = function (dy, filter, convInfo) {\n        return notYetImplemented('conv2dDerInput');\n    };\n    KernelBackend.prototype.conv2dDerFilter = function (x, dY, convInfo) {\n        return notYetImplemented('conv2dDerFilter');\n    };\n    KernelBackend.prototype.fusedDepthwiseConv2D = function (_a) {\n        var input = _a.input, filter = _a.filter, convInfo = _a.convInfo, bias = _a.bias, activation = _a.activation, preluActivationWeights = _a.preluActivationWeights;\n        return notYetImplemented('fusedDepthwiseConv2D');\n    };\n    KernelBackend.prototype.depthwiseConv2D = function (input, filter, convInfo) {\n        return notYetImplemented('depthwiseConv2D');\n    };\n    KernelBackend.prototype.depthwiseConv2DDerInput = function (dy, filter, convInfo) {\n        return notYetImplemented('depthwiseConv2DDerInput');\n    };\n    KernelBackend.prototype.depthwiseConv2DDerFilter = function (x, dY, convInfo) {\n        return notYetImplemented('depthwiseConv2DDerFilter');\n    };\n    KernelBackend.prototype.conv3d = function (x, filter, convInfo) {\n        return notYetImplemented('conv3d');\n    };\n    KernelBackend.prototype.conv3dDerInput = function (dy, filter, convInfo) {\n        return notYetImplemented('conv3dDerInput');\n    };\n    KernelBackend.prototype.conv3dDerFilter = function (x, dY, convInfo) {\n        return notYetImplemented('conv3dDerFilter');\n    };\n    KernelBackend.prototype.maxPool = function (x, convInfo) {\n        return notYetImplemented('maxPool');\n    };\n    KernelBackend.prototype.maxPoolBackprop = function (dy, x, y, convInfo) {\n        return notYetImplemented('maxPoolBackprop');\n    };\n    KernelBackend.prototype.avgPool = function (x, convInfo) {\n        return notYetImplemented('avgPool');\n    };\n    KernelBackend.prototype.avgPoolBackprop = function (dy, x, convInfo) {\n        return notYetImplemented('avgPoolBackprop');\n    };\n    KernelBackend.prototype.avgPool3d = function (x, convInfo) {\n        return notYetImplemented('avgPool3d');\n    };\n    KernelBackend.prototype.avgPool3dBackprop = function (dy, x, convInfo) {\n        return notYetImplemented('avgPool3dBackprop');\n    };\n    KernelBackend.prototype.maxPool3d = function (x, convInfo) {\n        return notYetImplemented('maxPool3d');\n    };\n    KernelBackend.prototype.maxPool3dBackprop = function (dy, x, y, convInfo) {\n        return notYetImplemented('maxPool3dBackprop');\n    };\n    KernelBackend.prototype.reshape = function (x, shape) {\n        return notYetImplemented('reshape');\n    };\n    KernelBackend.prototype.cast = function (x, dtype) {\n        return notYetImplemented('cast');\n    };\n    KernelBackend.prototype.tile = function (x, reps) {\n        return notYetImplemented('tile');\n    };\n    KernelBackend.prototype.pad = function (x, paddings, constantValue) {\n        return notYetImplemented('pad');\n    };\n    KernelBackend.prototype.transpose = function (x, perm) {\n        return notYetImplemented('transpose');\n    };\n    KernelBackend.prototype.gather = function (x, indices, axis) {\n        return notYetImplemented('gather');\n    };\n    KernelBackend.prototype.gatherND = function (x, indices) {\n        return notYetImplemented('gatherND');\n    };\n    KernelBackend.prototype.scatterND = function (indices, updates, shape) {\n        return notYetImplemented('scatterND');\n    };\n    KernelBackend.prototype.batchToSpaceND = function (x, blockShape, crops) {\n        return notYetImplemented('batchToSpaceND');\n    };\n    KernelBackend.prototype.spaceToBatchND = function (x, blockShape, paddings) {\n        return notYetImplemented('spaceToBatchND');\n    };\n    KernelBackend.prototype.resizeBilinear = function (x, newHeight, newWidth, alignCorners) {\n        return notYetImplemented('resizeBilinear');\n    };\n    KernelBackend.prototype.resizeBilinearBackprop = function (dy, x, alignCorners) {\n        return notYetImplemented('resizeBilinearBackprop');\n    };\n    KernelBackend.prototype.resizeNearestNeighbor = function (x, newHEight, newWidth, alignCorners) {\n        return notYetImplemented('resizeNearestNeighbor');\n    };\n    KernelBackend.prototype.resizeNearestNeighborBackprop = function (dy, x, alignCorners) {\n        return notYetImplemented('resizeNearestNeighborBackprop');\n    };\n    KernelBackend.prototype.batchNormalization = function (x, mean, variance, varianceEpsilon, scale, offset) {\n        return notYetImplemented('batchNormalization');\n    };\n    KernelBackend.prototype.localResponseNormalization4D = function (x, radius, bias, alpha, beta) {\n        return notYetImplemented('localResponseNormalization4D');\n    };\n    KernelBackend.prototype.LRNGrad = function (dy, inputImage, outputImage, radius, bias, alpha, beta) {\n        return notYetImplemented('LRNGrad');\n    };\n    KernelBackend.prototype.multinomial = function (logits, normalized, numSamples, seed) {\n        return notYetImplemented('multinomial');\n    };\n    KernelBackend.prototype.oneHot = function (indices, depth, onValue, offValue) {\n        return notYetImplemented('oneHot');\n    };\n    KernelBackend.prototype.cumsum = function (x, axis, exclusive, reverse) {\n        return notYetImplemented('cumsum');\n    };\n    KernelBackend.prototype.nonMaxSuppression = function (boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n        return notYetImplemented('nonMaxSuppression');\n    };\n    KernelBackend.prototype.fft = function (x) {\n        return notYetImplemented('fft');\n    };\n    KernelBackend.prototype.ifft = function (x) {\n        return notYetImplemented('ifft');\n    };\n    KernelBackend.prototype.complex = function (real, imag) {\n        return notYetImplemented('complex');\n    };\n    KernelBackend.prototype.real = function (input) {\n        return notYetImplemented('real');\n    };\n    KernelBackend.prototype.imag = function (input) {\n        return notYetImplemented('imag');\n    };\n    KernelBackend.prototype.cropAndResize = function (image, boxes, boxIndex, cropSize, method, extrapolationValue) {\n        return notYetImplemented('cropAndResize');\n    };\n    KernelBackend.prototype.depthToSpace = function (x, blockSize, dataFormat) {\n        return notYetImplemented('depthToSpace');\n    };\n    // Aligns with the \"SplitV\" kernel in TensorFlow.\n    KernelBackend.prototype.split = function (value, sizeSplits, axis) {\n        return notYetImplemented('split');\n    };\n    KernelBackend.prototype.sparseToDense = function (sparseIndices, sparseValues, outputShape, defaultValue) {\n        return notYetImplemented('sparseToDense');\n    };\n    KernelBackend.prototype.diag = function (x) {\n        return notYetImplemented('diag');\n    };\n    KernelBackend.prototype.fill = function (shape, value, dtype) {\n        return notYetImplemented('fill');\n    };\n    KernelBackend.prototype.onesLike = function (x) {\n        return notYetImplemented('onesLike');\n    };\n    KernelBackend.prototype.zerosLike = function (x) {\n        return notYetImplemented('zerosLike');\n    };\n    KernelBackend.prototype.linspace = function (start, stop, num) {\n        return notYetImplemented('linspace');\n    };\n    KernelBackend.prototype.dispose = function () {\n        return notYetImplemented('dispose');\n    };\n    return KernelBackend;\n}());\nexports.KernelBackend = KernelBackend;\nfunction notYetImplemented(kernelName) {\n    throw new Error(\"'\" + kernelName + \"' not yet implemented or not found in the registry. \" +\n        \"Did you forget to import the kernel?\");\n}\n//# sourceMappingURL=backend.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/backend.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction __export(m) {\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n}\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ../ops/tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n// Utilities needed by backend consumers of tf-core.\n__export(__webpack_require__(/*! ../ops/axis_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js\"));\n__export(__webpack_require__(/*! ../ops/broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\"));\n__export(__webpack_require__(/*! ../ops/concat_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js\"));\n__export(__webpack_require__(/*! ../ops/conv_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js\"));\n__export(__webpack_require__(/*! ../ops/reduce_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js\"));\nvar types_1 = __webpack_require__(/*! ../types */ \"./node_modules/@tensorflow/tfjs-core/dist/types.js\");\nexports.upcastType = types_1.upcastType;\nfunction castTensor(x, dtype, backend) {\n    if (dtype === 'complex64') {\n        if (x.dtype === 'complex64') {\n            return x.clone();\n        }\n        var zerosTensor = tensor_ops_1.zeros(x.shape);\n        var floatX = x.toFloat();\n        var result = backend.complex(floatX, zerosTensor);\n        zerosTensor.dispose();\n        floatX.dispose();\n        return result;\n    }\n    if (!util_1.hasEncodingLoss(x.dtype, dtype)) {\n        // We don't change the underlying data, since we cast to higher\n        // precision.\n        return engine_1.ENGINE.makeTensorFromDataId(x.dataId, x.shape, dtype);\n    }\n    if (x.dtype === 'complex64') {\n        var real = backend.real(x);\n        var result = real.cast(dtype);\n        real.dispose();\n        return result;\n    }\n    if (dtype === 'int32') {\n        return backend.int(x);\n    }\n    else if (dtype === 'bool') {\n        var zero = tensor_ops_1.scalar(0, x.dtype);\n        var result = backend.notEqual(x, zero);\n        zero.dispose();\n        return result;\n    }\n    else {\n        throw new Error(\"Error in Cast: failed to cast \" + x.dtype + \" to \" + dtype);\n    }\n}\nexports.castTensor = castTensor;\nfunction reshapeTensor(x, shape) {\n    return engine_1.ENGINE.makeTensorFromDataId(x.dataId, shape, x.dtype);\n}\nexports.reshapeTensor = reshapeTensor;\nfunction linspaceImpl(start, stop, num) {\n    var step = (stop - start) / (num - 1);\n    var values = util_1.makeZerosTypedArray(num, 'float32');\n    values[0] = start;\n    for (var i = 1; i < values.length; i++) {\n        values[i] = values[i - 1] + step;\n    }\n    return tensor_ops_1.tensor1d(values, 'float32');\n}\nexports.linspaceImpl = linspaceImpl;\n//# sourceMappingURL=backend_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Merges real and imaginary Float32Arrays into a single complex Float32Array.\n *\n * The memory layout is interleaved as follows:\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n * complex: [r0, i0, r1, i1, r2, i2]\n *\n * This is the inverse of splitRealAndImagArrays.\n *\n * @param real The real values of the complex tensor values.\n * @param imag The imag values of the complex tensor values.\n * @returns A complex tensor as a Float32Array with merged values.\n */\nfunction mergeRealAndImagArrays(real, imag) {\n    if (real.length !== imag.length) {\n        throw new Error(\"Cannot merge real and imag arrays of different lengths. real:\" +\n            (real.length + \", imag: \" + imag.length + \".\"));\n    }\n    var result = new Float32Array(real.length * 2);\n    for (var i = 0; i < result.length; i += 2) {\n        result[i] = real[i / 2];\n        result[i + 1] = imag[i / 2];\n    }\n    return result;\n}\nexports.mergeRealAndImagArrays = mergeRealAndImagArrays;\n/**\n * Splits a complex Float32Array into real and imag parts.\n *\n * The memory layout is interleaved as follows:\n * complex: [r0, i0, r1, i1, r2, i2]\n * real: [r0, r1, r2]\n * imag: [i0, i1, i2]\n *\n * This is the inverse of mergeRealAndImagArrays.\n *\n * @param complex The complex tensor values.\n * @returns An object with real and imag Float32Array components of the complex\n *     tensor.\n */\nfunction splitRealAndImagArrays(complex) {\n    var real = new Float32Array(complex.length / 2);\n    var imag = new Float32Array(complex.length / 2);\n    for (var i = 0; i < complex.length; i += 2) {\n        real[i / 2] = complex[i];\n        imag[i / 2] = complex[i + 1];\n    }\n    return { real: real, imag: imag };\n}\nexports.splitRealAndImagArrays = splitRealAndImagArrays;\n/**\n * Extracts even indexed complex values in the given array.\n * @param complex The complex tensor values\n */\nfunction complexWithEvenIndex(complex) {\n    var len = Math.ceil(complex.length / 4);\n    var real = new Float32Array(len);\n    var imag = new Float32Array(len);\n    for (var i = 0; i < complex.length; i += 4) {\n        real[Math.floor(i / 4)] = complex[i];\n        imag[Math.floor(i / 4)] = complex[i + 1];\n    }\n    return { real: real, imag: imag };\n}\nexports.complexWithEvenIndex = complexWithEvenIndex;\n/**\n * Extracts odd indexed comple values in the given array.\n * @param complex The complex tensor values\n */\nfunction complexWithOddIndex(complex) {\n    var len = Math.floor(complex.length / 4);\n    var real = new Float32Array(len);\n    var imag = new Float32Array(len);\n    for (var i = 2; i < complex.length; i += 4) {\n        real[Math.floor(i / 4)] = complex[i];\n        imag[Math.floor(i / 4)] = complex[i + 1];\n    }\n    return { real: real, imag: imag };\n}\nexports.complexWithOddIndex = complexWithOddIndex;\n/**\n * Get the map representing a complex value in the given array.\n * @param complex The complex tensor values.\n * @param index An index of the target complex value.\n */\nfunction getComplexWithIndex(complex, index) {\n    var real = complex[index * 2];\n    var imag = complex[index * 2 + 1];\n    return { real: real, imag: imag };\n}\nexports.getComplexWithIndex = getComplexWithIndex;\n/**\n * Insert a given complex value into the TypedArray.\n * @param data The array in which the complex value is inserted.\n * @param c The complex value to be inserted.\n * @param index An index of the target complex value.\n */\nfunction assignToTypedArray(data, real, imag, index) {\n    data[index * 2] = real;\n    data[index * 2 + 1] = imag;\n}\nexports.assignToTypedArray = assignToTypedArray;\n/**\n * Make the list of exponent terms used by FFT.\n */\nfunction exponents(n, inverse) {\n    var real = new Float32Array(n / 2);\n    var imag = new Float32Array(n / 2);\n    for (var i = 0; i < Math.ceil(n / 2); i++) {\n        var x = (inverse ? 2 : -2) * Math.PI * (i / n);\n        real[i] = Math.cos(x);\n        imag[i] = Math.sin(x);\n    }\n    return { real: real, imag: imag };\n}\nexports.exponents = exponents;\n/**\n * Make the exponent term used by FFT.\n */\nfunction exponent(k, n, inverse) {\n    var x = (inverse ? 2 : -2) * Math.PI * (k / n);\n    var real = Math.cos(x);\n    var imag = Math.sin(x);\n    return { real: real, imag: imag };\n}\nexports.exponent = exponent;\n//# sourceMappingURL=complex_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/backend_cpu.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/backend_cpu.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar seedrandom = __webpack_require__(/*! seedrandom */ \"./node_modules/seedrandom/index.js\");\nvar engine_1 = __webpack_require__(/*! ../../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar environment_1 = __webpack_require__(/*! ../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar log_1 = __webpack_require__(/*! ../../log */ \"./node_modules/@tensorflow/tfjs-core/dist/log.js\");\nvar array_ops_util = __webpack_require__(/*! ../../ops/array_ops_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js\");\nvar axis_util = __webpack_require__(/*! ../../ops/axis_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js\");\nvar broadcast_util = __webpack_require__(/*! ../../ops/broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar complex_ops_1 = __webpack_require__(/*! ../../ops/complex_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/complex_ops.js\");\nvar concat_util = __webpack_require__(/*! ../../ops/concat_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js\");\nvar erf_util = __webpack_require__(/*! ../../ops/erf_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js\");\nvar gather_nd_util = __webpack_require__(/*! ../../ops/gather_nd_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js\");\nvar ops = __webpack_require__(/*! ../../ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\nvar ops_1 = __webpack_require__(/*! ../../ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\nvar scatter_nd_util = __webpack_require__(/*! ../../ops/scatter_nd_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js\");\nvar selu_util = __webpack_require__(/*! ../../ops/selu_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js\");\nvar slice_util_1 = __webpack_require__(/*! ../../ops/slice_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js\");\nvar tensor_1 = __webpack_require__(/*! ../../tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nvar types_1 = __webpack_require__(/*! ../../types */ \"./node_modules/@tensorflow/tfjs-core/dist/types.js\");\nvar util = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar util_1 = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar backend_1 = __webpack_require__(/*! ../backend */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/backend.js\");\nvar backend_util = __webpack_require__(/*! ../backend_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js\");\nvar complex_util = __webpack_require__(/*! ../complex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js\");\nvar non_max_suppression_impl_1 = __webpack_require__(/*! ../non_max_suppression_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js\");\nvar split_shared_1 = __webpack_require__(/*! ../split_shared */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/split_shared.js\");\nvar tile_impl_1 = __webpack_require__(/*! ../tile_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/tile_impl.js\");\nvar topk_impl_1 = __webpack_require__(/*! ../topk_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/topk_impl.js\");\nvar where_impl_1 = __webpack_require__(/*! ../where_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js\");\nvar cpu_util_1 = __webpack_require__(/*! ./cpu_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/cpu_util.js\");\nfunction mapActivation(backend, x, activation, preluActivationWeights) {\n    if (activation === 'linear') {\n        return backend.linear(x);\n    }\n    else if (activation === 'relu') {\n        return backend.relu(x);\n    }\n    else if (activation === 'elu') {\n        return backend.elu(x);\n    }\n    else if (activation === 'relu6') {\n        return backend.relu6(x);\n    }\n    else if (activation === 'prelu') {\n        return backend.prelu(x, preluActivationWeights);\n    }\n    throw new Error(\"Activation \" + activation + \" has not been implemented for the CPU backend.\");\n}\nvar MathBackendCPU = /** @class */ (function (_super) {\n    __extends(MathBackendCPU, _super);\n    function MathBackendCPU() {\n        var _this = _super.call(this) || this;\n        _this.blockSize = 48;\n        _this.firstUse = true;\n        _this.data = new backend_1.DataStorage(_this, engine_1.ENGINE);\n        return _this;\n    }\n    MathBackendCPU.prototype.write = function (values, shape, dtype) {\n        if (this.firstUse) {\n            this.firstUse = false;\n            if (environment_1.env().get('IS_NODE')) {\n                log_1.warn('\\n============================\\n' +\n                    'Hi there 👋. Looks like you are running TensorFlow.js in ' +\n                    'Node.js. To speed things up dramatically, install our node ' +\n                    'backend, which binds to TensorFlow C++, by running ' +\n                    'npm i @tensorflow/tfjs-node, ' +\n                    'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n                    'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n                    'suffix for CUDA) at the start of your program. ' +\n                    'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n                    '\\n============================');\n            }\n        }\n        var dataId = {};\n        this.data.set(dataId, { values: values, dtype: dtype });\n        return dataId;\n    };\n    MathBackendCPU.prototype.move = function (dataId, values, shape, dtype) {\n        this.data.set(dataId, { values: values, dtype: dtype });\n    };\n    MathBackendCPU.prototype.numDataIds = function () {\n        return this.data.numDataIds();\n    };\n    MathBackendCPU.prototype.read = function (dataId) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.readSync(dataId)];\n            });\n        });\n    };\n    MathBackendCPU.prototype.readSync = function (dataId) {\n        var _a = this.data.get(dataId), dtype = _a.dtype, complexTensors = _a.complexTensors;\n        if (dtype === 'complex64') {\n            var realValues = this.readSync(complexTensors.real.dataId);\n            var imagValues = this.readSync(complexTensors.imag.dataId);\n            return complex_util.mergeRealAndImagArrays(realValues, imagValues);\n        }\n        return this.data.get(dataId).values;\n    };\n    MathBackendCPU.prototype.bufferSync = function (t) {\n        var data = this.readSync(t.dataId);\n        var decodedData = data;\n        if (t.dtype === 'string') {\n            try {\n                // Decode the bytes into string.\n                decodedData = data.map(function (d) { return util.decodeString(d); });\n            }\n            catch (_a) {\n                throw new Error('Failed to decode encoded string bytes into utf-8');\n            }\n        }\n        return ops_1.buffer(t.shape, t.dtype, decodedData);\n    };\n    MathBackendCPU.prototype.makeOutput = function (values, shape, dtype) {\n        var dataId = this.write(values, shape, dtype);\n        return engine_1.ENGINE.makeTensorFromDataId(dataId, shape, dtype, this);\n    };\n    MathBackendCPU.prototype.disposeData = function (dataId) {\n        if (this.data.has(dataId)) {\n            var complexTensors = this.data.get(dataId).complexTensors;\n            if (complexTensors != null) {\n                complexTensors.real.dispose();\n                complexTensors.imag.dispose();\n            }\n            this.data.delete(dataId);\n        }\n    };\n    MathBackendCPU.prototype.time = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            var start, kernelMs;\n            return __generator(this, function (_a) {\n                start = util_1.now();\n                f();\n                kernelMs = util_1.now() - start;\n                return [2 /*return*/, { kernelMs: kernelMs }];\n            });\n        });\n    };\n    MathBackendCPU.prototype.memory = function () {\n        return {\n            // Unreliable due to automatic gc. The numbers above are cumulative.\n            unreliable: true,\n            reasons: ['The reported memory is an upper bound. Due to automatic garbage ' +\n                    'collection, the true allocated memory may be less.']\n        };\n    };\n    MathBackendCPU.prototype.complex = function (real, imag) {\n        var result = this.makeOutput(null, real.shape, 'complex64');\n        var resultData = this.data.get(result.dataId);\n        // The backend owns the reference to the underlying real and imaginary\n        // clones. These will explicitly get disposed when the complex tensor is\n        // disposed.\n        resultData.complexTensors = {\n            real: engine_1.ENGINE.keep(real.clone()),\n            imag: engine_1.ENGINE.keep(imag.clone())\n        };\n        return result;\n    };\n    MathBackendCPU.prototype.real = function (input) {\n        var resultData = this.data.get(input.dataId);\n        return resultData.complexTensors.real.clone();\n    };\n    MathBackendCPU.prototype.imag = function (input) {\n        var resultData = this.data.get(input.dataId);\n        return resultData.complexTensors.imag.clone();\n    };\n    MathBackendCPU.prototype.slice = function (x, begin, size) {\n        cpu_util_1.assertNotComplex(x, 'slice');\n        var isContinous = slice_util_1.isSliceContinous(x.shape, begin, size);\n        if (isContinous) {\n            var flatOffset = slice_util_1.computeFlatOffset(begin, x.strides);\n            var length_1 = util.sizeFromShape(size);\n            var vals = this.readSync(x.dataId);\n            return ops_1.tensor(vals.subarray(flatOffset, flatOffset + length_1), size, x.dtype);\n        }\n        var buffer = ops.buffer(size, x.dtype);\n        var xBuf = this.bufferSync(x);\n        for (var i = 0; i < buffer.size; ++i) {\n            var loc = buffer.indexToLoc(i);\n            var xLoc = loc.map(function (idx, j) { return idx + begin[j]; });\n            buffer.values[i] = xBuf.get.apply(xBuf, xLoc);\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.stridedSlice = function (x, begin, end, strides) {\n        cpu_util_1.assertNotComplex(x, 'stridedSlice');\n        var outShape = slice_util_1.computeOutShape(begin, end, strides);\n        if (outShape.some(function (axis) { return axis === 0; })) {\n            return ops.tensor([], outShape);\n        }\n        var buffer = ops.buffer(outShape, x.dtype);\n        var xBuf = this.bufferSync(x);\n        for (var i = 0; i < buffer.size; i++) {\n            var loc = buffer.indexToLoc(i);\n            var newLoc = new Array(loc.length);\n            for (var j = 0; j < newLoc.length; j++) {\n                newLoc[j] = loc[j] * strides[j] + begin[j];\n            }\n            buffer.set.apply(buffer, [xBuf.get.apply(xBuf, newLoc)].concat(loc));\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.diag = function (x) {\n        var xVals = this.readSync(x.dataId);\n        var buffer = ops.buffer([x.size, x.size], x.dtype);\n        var vals = buffer.values;\n        for (var i = 0; i < xVals.length; i++) {\n            vals[i * x.size + i] = xVals[i];\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.unstack = function (x, axis) {\n        var num = x.shape[axis];\n        var outShape = new Array(x.rank - 1);\n        var outIndex = 0;\n        for (var i = 0; i < x.rank; i++) {\n            if (i !== axis) {\n                outShape[outIndex++] = x.shape[i];\n            }\n        }\n        var begin = new Array(x.rank).fill(0);\n        var size = x.shape.slice();\n        size[axis] = 1;\n        var res = new Array(num);\n        for (var i = 0; i < res.length; i++) {\n            begin[axis] = i;\n            res[i] = this.slice(x, begin, size).reshape(outShape);\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.reverse = function (x, axis) {\n        cpu_util_1.assertNotComplex(x, 'reverse');\n        var buffer = ops.buffer(x.shape, x.dtype);\n        var xBuf = this.bufferSync(x);\n        var _loop_1 = function (i) {\n            var outLoc = buffer.indexToLoc(i);\n            var inLoc = outLoc.slice();\n            axis.forEach(function (ax) { return inLoc[ax] = x.shape[ax] - 1 - inLoc[ax]; });\n            buffer.set.apply(buffer, [xBuf.get.apply(xBuf, inLoc)].concat(outLoc));\n        };\n        for (var i = 0; i < buffer.size; i++) {\n            _loop_1(i);\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.concat = function (tensors, axis) {\n        var _this = this;\n        if (tensors[0].dtype === 'complex64') {\n            var reals = tensors.map(function (t) { return complex_ops_1.real(t); });\n            var imags = tensors.map(function (t) { return complex_ops_1.imag(t); });\n            return complex_ops_1.complex(this.concat(reals, axis), this.concat(imags, axis));\n        }\n        var tensors2D = tensors.map(function (t) {\n            var innerSize = util.sizeFromShape(t.shape.slice(axis));\n            return t.as2D(-1, innerSize);\n        });\n        var outShape = concat_util.computeOutShape(tensors2D.map(function (t) { return t.shape; }), 1 /* axis */);\n        var values = ops.buffer(outShape, tensors[0].dtype)\n            .values;\n        if (tensors2D[0].shape[0] === 1) {\n            // Use built-in TypedArray.set() method for speed.\n            var offset_1 = 0;\n            tensors2D.forEach(function (t) {\n                values.set(_this.readSync(t.dataId), offset_1);\n                offset_1 += t.size;\n            });\n        }\n        else {\n            var colOffset_1 = 0;\n            tensors2D.forEach(function (t) {\n                var tVals = _this.readSync(t.dataId);\n                var tIdx = 0;\n                for (var row = 0; row < t.shape[0]; ++row) {\n                    var resIdx = row * outShape[1] + colOffset_1;\n                    for (var col = 0; col < t.shape[1]; ++col) {\n                        values[resIdx + col] = tVals[tIdx++];\n                    }\n                }\n                colOffset_1 += t.shape[1];\n            });\n        }\n        var finalOutShape = concat_util.computeOutShape(tensors.map(function (t) { return t.shape; }), axis);\n        return ops_1.tensor(values, finalOutShape, tensors[0].dtype);\n    };\n    MathBackendCPU.prototype.neg = function (x) {\n        cpu_util_1.assertNotComplex(x, 'neg');\n        return this.multiply(ops.scalar(-1), x);\n    };\n    MathBackendCPU.prototype.add = function (a, b) {\n        if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n            return this.broadcastedBinaryComplexOp(a.cast('complex64'), b.cast('complex64'), function (aReal, aImag, bReal, bImag) {\n                return { real: aReal + bReal, imag: aImag + bImag };\n            });\n        }\n        return this.broadcastedBinaryOp(a, b, types_1.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue + bValue; });\n    };\n    MathBackendCPU.prototype.addN = function (tensors) {\n        var _this = this;\n        cpu_util_1.assertNotComplex(tensors, 'addN');\n        var vals = tensors.map(function (t) { return _this.readSync(t.dataId); });\n        var result = ops.buffer(tensors[0].shape, tensors[0].dtype);\n        var resultVals = result.values;\n        for (var i = 0; i < tensors.length; i++) {\n            var currVals = vals[i];\n            for (var j = 0; j < resultVals.length; j++) {\n                resultVals[j] += currVals[j];\n            }\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.softmax = function (logits, dim) {\n        var axes = util.parseAxisParam([dim], logits.shape);\n        var maxLogit = this.max(logits, axes);\n        var expandedShape = axis_util.expandShapeToKeepDim(maxLogit.shape, axes);\n        var a = this.subtract(logits, maxLogit.reshape(expandedShape));\n        var b = this.exp(a);\n        var sumExp = this.sum(b, axes).reshape(expandedShape);\n        return this.realDivide(b, sumExp);\n    };\n    MathBackendCPU.prototype.subtract = function (a, b) {\n        if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n            return this.broadcastedBinaryComplexOp(a.cast('complex64'), b.cast('complex64'), function (aReal, aImag, bReal, bImag) {\n                return { real: aReal - bReal, imag: aImag - bImag };\n            });\n        }\n        return this.broadcastedBinaryOp(a, b, types_1.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue - bValue; });\n    };\n    MathBackendCPU.prototype.pow = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'pow');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aValue, bValue) { return Math.pow(aValue, bValue); });\n    };\n    MathBackendCPU.prototype.batchMatMul = function (a, b, transposeA, transposeB) {\n        cpu_util_1.assertNotComplex([a, b], 'matMul');\n        var sharedDim = transposeA ? a.shape[1] : a.shape[2];\n        var leftDim = transposeA ? a.shape[2] : a.shape[1];\n        var rightDim = transposeB ? b.shape[1] : b.shape[2];\n        var batchDim = a.shape[0];\n        var aValues = this.readSync(a.dataId);\n        var bValues = this.readSync(b.dataId);\n        var _a = transposeA ?\n            [a.strides[0], 1, a.strides[1]] :\n            [a.strides[0], a.strides[1], 1], aBatch = _a[0], aOuterStep = _a[1], aInnerStep = _a[2];\n        var _b = transposeB ?\n            [1, b.strides[1], b.strides[0]] :\n            [b.strides[1], 1, b.strides[0]], bInnerStep = _b[0], bOuterStep = _b[1], bBatch = _b[2];\n        var size = leftDim * rightDim;\n        var result = ops_1.buffer([batchDim, leftDim, rightDim], a.dtype);\n        var resVals = result.values;\n        var blockSize = this.blockSize;\n        for (var b_1 = 0; b_1 < batchDim; b_1++) {\n            for (var i0 = 0; i0 < leftDim; i0 += blockSize) {\n                for (var j0 = 0; j0 < rightDim; j0 += blockSize) {\n                    for (var k0 = 0; k0 < sharedDim; k0 += blockSize) {\n                        // for when blockSize doesn't evenly divide the input\n                        var iBlock = Math.min(i0 + blockSize, leftDim);\n                        var jBlock = Math.min(j0 + blockSize, rightDim);\n                        var kBlock = Math.min(k0 + blockSize, sharedDim);\n                        for (var i = i0; i < iBlock; i++) {\n                            for (var j = j0; j < jBlock; j++) {\n                                var sum = 0.0;\n                                for (var k = k0; k < kBlock; k++) {\n                                    sum += aValues[b_1 * aBatch + i * aOuterStep + k * aInnerStep] *\n                                        bValues[k * bInnerStep + j * bOuterStep + b_1 * bBatch];\n                                }\n                                resVals[b_1 * size + (i * rightDim + j)] += sum;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.fusedBatchMatMul = function (_a) {\n        var a = _a.a, b = _a.b, transposeA = _a.transposeA, transposeB = _a.transposeB, bias = _a.bias, activation = _a.activation, preluActivationWeights = _a.preluActivationWeights;\n        var result = this.batchMatMul(a, b, transposeA, transposeB);\n        if (bias) {\n            result = this.add(result, bias);\n        }\n        if (activation) {\n            result =\n                mapActivation(this, result, activation, preluActivationWeights);\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.multiply = function (a, b) {\n        if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n            return this.broadcastedBinaryComplexOp(a.cast('complex64'), b.cast('complex64'), function (aReal, aImag, bReal, bImag) {\n                return {\n                    real: aReal * bReal - aImag * bImag,\n                    imag: aReal * bImag + aImag * bReal\n                };\n            });\n        }\n        return this.broadcastedBinaryOp(a, b, types_1.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue * bValue; });\n    };\n    MathBackendCPU.prototype.realDivide = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'realDivide');\n        var op = function (a, b) { return a / b; };\n        var outputDtype = 'float32';\n        return this.broadcastedBinaryOp(a, b, outputDtype, op);\n    };\n    MathBackendCPU.prototype.floorDiv = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'floorDiv');\n        var op = function (a, b) { return Math.floor(a / b); };\n        var outputDtype = 'int32';\n        return this.broadcastedBinaryOp(a, b, outputDtype, op);\n    };\n    MathBackendCPU.prototype.sum = function (x, axes) {\n        cpu_util_1.assertNotComplex(x, 'sum');\n        axis_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var resultDtype = types_1.upcastType(x.dtype, 'int32');\n        var result = ops.zeros(outShape, resultDtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var sum = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                sum += aVals[offset + j];\n            }\n            vals[i] = sum;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.prod = function (x, axes) {\n        cpu_util_1.assertNotComplex(x, 'sum');\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var resultDtype = types_1.upcastType(x.dtype, 'int32');\n        var result = ops.zeros(outShape, resultDtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var prod = 1;\n            for (var j = 0; j < reduceSize; ++j) {\n                prod *= aVals[offset + j];\n            }\n            vals[i] = prod;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.unsortedSegmentSum = function (x, segmentIds, numSegments) {\n        cpu_util_1.assertNotComplex(x, 'unsortedSegmentSum');\n        var res = [];\n        // Reshape the segment id's so that they can be broadcast with\n        // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n        var numIters = x.rank - segmentIds.rank;\n        for (var i = 0; i < numIters; ++i) {\n            segmentIds = segmentIds.expandDims(i + 1);\n        }\n        for (var i = 0; i < numSegments; ++i) {\n            var segmentId = ops.scalar(i, 'int32');\n            var mask = ops.equal(segmentId, segmentIds).asType('float32');\n            var sum = mask.mul(x).sum(0);\n            res.push(sum);\n        }\n        return ops.stack(res);\n    };\n    MathBackendCPU.prototype.argMin = function (x, axis) {\n        cpu_util_1.assertNotComplex(x, 'argMin');\n        var axes = [axis];\n        axis_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, 'int32');\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var min = aVals[offset];\n            var minIndex = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value < min) {\n                    min = value;\n                    minIndex = j;\n                }\n            }\n            vals[i] = minIndex;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.argMax = function (x, axis) {\n        cpu_util_1.assertNotComplex(x, 'argMax');\n        var axes = [axis];\n        axis_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, 'int32');\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var max = aVals[offset];\n            var maxIndex = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value > max) {\n                    max = value;\n                    maxIndex = j;\n                }\n            }\n            vals[i] = maxIndex;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.cumsum = function (x, axis, exclusive, reverse) {\n        cpu_util_1.assertNotComplex(x, 'cumsum');\n        if (axis !== x.rank - 1) {\n            throw new Error(\"backend.cumsum in CPU expects an inner-most axis=\" + (x.rank - 1) + \" \" +\n                (\"but got axis=\" + axis));\n        }\n        var resultDtype = types_1.upcastType(x.dtype, 'int32');\n        var result = ops.zeros(x.shape, resultDtype);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        var finalDim = x.shape[x.rank - 1];\n        var indexAdjuster = reverse ?\n            function (i, j) { return i + finalDim - j - 1; } :\n            function (i, j) { return i + j; };\n        for (var i = 0; i < aVals.length; i += finalDim) {\n            for (var j = 0; j < finalDim; j++) {\n                var idx = indexAdjuster(i, j);\n                if (j === 0) {\n                    vals[idx] = exclusive ? 0 : aVals[idx];\n                }\n                else {\n                    var prevIdx = indexAdjuster(i, j - 1);\n                    vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                        aVals[idx] + vals[prevIdx];\n                }\n            }\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.equal = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'equal');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal === bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.notEqual = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'notEqual');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal !== bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.less = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'less');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal < bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.lessEqual = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'lessEqual');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal <= bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.greater = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'greater');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal > bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.greaterEqual = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'greaterEqual');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return (aVal >= bVal) ? 1 : 0;\n        });\n    };\n    MathBackendCPU.prototype.logicalNot = function (x) {\n        cpu_util_1.assertNotComplex(x, 'logicalNot');\n        var values = this.readSync(x.dataId);\n        var newValues = new Uint8Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = values[i] ? 0 : 1;\n        }\n        return this.makeOutput(newValues, x.shape, 'bool');\n    };\n    MathBackendCPU.prototype.logicalAnd = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'logicalAnd');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return aVal && bVal;\n        });\n    };\n    MathBackendCPU.prototype.logicalOr = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'logicalOr');\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            return aVal || bVal;\n        });\n    };\n    MathBackendCPU.prototype.select = function (condition, a, b) {\n        cpu_util_1.assertNotComplex([condition, a, b], 'select');\n        var values = this.readSync(condition.dataId);\n        var aValues = this.readSync(a.dataId);\n        var bValues = this.readSync(b.dataId);\n        var result = ops.zeros(a.shape, types_1.upcastType(a.dtype, b.dtype));\n        var newValues = this.readSync(result.dataId);\n        var index = 0;\n        var offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ?\n            1 :\n            util.sizeFromShape(a.shape.slice(1));\n        for (var i = 0; i < values.length; i++) {\n            for (var j = 0; j < offset; j++) {\n                if (values[i] === 1) {\n                    newValues[index++] = aValues[i];\n                }\n                else {\n                    newValues[index++] = bValues[i];\n                }\n            }\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.where = function (condition) {\n        cpu_util_1.assertNotComplex([condition], 'where');\n        var condVals = this.readSync(condition.dataId);\n        return where_impl_1.whereImpl(condition.shape, condVals);\n    };\n    MathBackendCPU.prototype.topk = function (x, k, sorted) {\n        cpu_util_1.assertNotComplex(x, 'topk');\n        var xVals = this.readSync(x.dataId);\n        return topk_impl_1.topkImpl(xVals, x.shape, x.dtype, k, sorted);\n    };\n    MathBackendCPU.prototype.min = function (x, axes) {\n        cpu_util_1.assertNotComplex(x, 'min');\n        axis_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var min = aVals[offset];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value < min) {\n                    min = value;\n                }\n            }\n            vals[i] = min;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.minimum = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'minimum');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) { return Math.min(aVal, bVal); });\n    };\n    MathBackendCPU.prototype.mod = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'mod');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) {\n            var rem = aVal % bVal;\n            if ((aVal < 0 && bVal < 0) || (aVal >= 0 && bVal >= 0)) {\n                return rem;\n            }\n            else {\n                return (rem + bVal) % bVal;\n            }\n        });\n    };\n    MathBackendCPU.prototype.max = function (x, axes) {\n        cpu_util_1.assertNotComplex(x, 'max');\n        axis_util.assertAxesAreInnerMostDims('max', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var max = aVals[offset];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (value > max) {\n                    max = value;\n                }\n            }\n            vals[i] = max;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.maximum = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'maximum');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) { return Math.max(aVal, bVal); });\n    };\n    MathBackendCPU.prototype.all = function (x, axes) {\n        cpu_util_1.assertNotComplex(x, 'all');\n        axis_util.assertAxesAreInnerMostDims('all', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var all = aVals[offset];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                all = all && value;\n            }\n            vals[i] = all;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.any = function (x, axes) {\n        cpu_util_1.assertNotComplex(x, 'any');\n        axis_util.assertAxesAreInnerMostDims('any', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = this.readSync(result.dataId);\n        var aVals = this.readSync(x.dataId);\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var anyVal = aVals[offset];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                anyVal = anyVal || value;\n            }\n            vals[i] = anyVal;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.squaredDifference = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'squaredDifference');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) {\n            var diff = aVal - bVal;\n            return diff * diff;\n        });\n    };\n    MathBackendCPU.prototype.ceil = function (x) {\n        cpu_util_1.assertNotComplex(x, 'ceil');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.ceil(values[i]);\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.floor = function (x) {\n        cpu_util_1.assertNotComplex(x, 'floor');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.floor(values[i]);\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.sign = function (x) {\n        cpu_util_1.assertNotComplex(x, 'x');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            if (values[i] < 0) {\n                newValues[i] = -1;\n            }\n            else if (values[i] > 0) {\n                newValues[i] = 1;\n            }\n            else {\n                newValues[i] = 0;\n            }\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.isNaN = function (x) {\n        cpu_util_1.assertNotComplex(x, 'x');\n        var values = this.readSync(x.dataId);\n        var newValues = new Uint8Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            if (Number.isNaN(values[i])) {\n                newValues[i] = 1;\n            }\n        }\n        return this.makeOutput(newValues, x.shape, 'bool');\n    };\n    MathBackendCPU.prototype.isInf = function (x) {\n        cpu_util_1.assertNotComplex(x, 'x');\n        var values = this.readSync(x.dataId);\n        var newValues = new Uint8Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            if (Math.abs(values[i]) === Infinity) {\n                newValues[i] = 1;\n            }\n        }\n        return this.makeOutput(newValues, x.shape, 'bool');\n    };\n    MathBackendCPU.prototype.isFinite = function (x) {\n        cpu_util_1.assertNotComplex(x, 'x');\n        var values = this.readSync(x.dataId);\n        var newValues = new Uint8Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            if (Number.isFinite(values[i])) {\n                newValues[i] = 1;\n            }\n        }\n        return this.makeOutput(newValues, x.shape, 'bool');\n    };\n    MathBackendCPU.prototype.round = function (x) {\n        cpu_util_1.assertNotComplex(x, 'round');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            // The algorithm is based on banker's rounding.\n            var base = Math.floor(values[i]);\n            if (values[i] - base < 0.5) {\n                newValues[i] = Math.floor(values[i]);\n            }\n            else if (values[i] - base > 0.5) {\n                newValues[i] = Math.ceil(values[i]);\n            }\n            else {\n                if (base % 2.0 === 0.0) {\n                    newValues[i] = base;\n                }\n                else {\n                    newValues[i] = base + 1.0;\n                }\n            }\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.exp = function (x) {\n        cpu_util_1.assertNotComplex(x, 'exp');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.exp(values[i]);\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.expm1 = function (x) {\n        cpu_util_1.assertNotComplex(x, 'expm1');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.expm1(values[i]);\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.log = function (x) {\n        cpu_util_1.assertNotComplex(x, 'log');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.log(value);\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.log1p = function (x) {\n        cpu_util_1.assertNotComplex(x, 'log1p');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.log1p(value);\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.sqrt = function (x) {\n        cpu_util_1.assertNotComplex(x, 'sqrt');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.sqrt(value);\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.rsqrt = function (x) {\n        cpu_util_1.assertNotComplex(x, 'rsqrt');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = 1 / Math.sqrt(value);\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.reciprocal = function (x) {\n        cpu_util_1.assertNotComplex(x, 'reciprocal');\n        var values = this.readSync(x.dataId);\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = 1 / values[i];\n        }\n        return this.makeOutput(newValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.linear = function (x) {\n        return x;\n    };\n    MathBackendCPU.prototype.relu = function (x) {\n        cpu_util_1.assertNotComplex(x, 'relu');\n        var res = ops.zeros(x.shape, x.dtype);\n        var resVals = this.readSync(res.dataId);\n        var inVals = this.readSync(x.dataId);\n        for (var i = 0; i < inVals.length; ++i) {\n            resVals[i] = Math.max(0, inVals[i]);\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.relu6 = function (x) {\n        cpu_util_1.assertNotComplex(x, 'relu');\n        var res = ops.zeros(x.shape, x.dtype);\n        var resVals = this.readSync(res.dataId);\n        var inVals = this.readSync(x.dataId);\n        for (var i = 0; i < inVals.length; ++i) {\n            resVals[i] = Math.min(Math.max(0, inVals[i]), 6);\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.prelu = function (x, a) {\n        cpu_util_1.assertNotComplex([x, a], 'prelu');\n        return this.broadcastedBinaryOp(x, a, x.dtype, function (xValue, aValue) { return xValue < 0 ? aValue * xValue : xValue; });\n    };\n    MathBackendCPU.prototype.elu = function (x) {\n        cpu_util_1.assertNotComplex(x, 'elu');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = v;\n            }\n            else {\n                resultValues[i] = (Math.exp(v) - 1);\n            }\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.eluDer = function (dy, y) {\n        cpu_util_1.assertNotComplex([dy, y], 'eluDer');\n        var resultValues = new Float32Array(y.size);\n        var values = this.readSync(y.dataId);\n        var dyValues = this.readSync(dy.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 1) {\n                resultValues[i] = dyValues[i];\n            }\n            else {\n                resultValues[i] = dyValues[i] * (v + 1);\n            }\n        }\n        return this.makeOutput(resultValues, y.shape, 'float32');\n    };\n    MathBackendCPU.prototype.selu = function (x) {\n        cpu_util_1.assertNotComplex(x, 'selu');\n        // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n        // see: https://arxiv.org/abs/1706.02515\n        var scaleAlpha = selu_util.SELU_SCALEALPHA;\n        var scale = selu_util.SELU_SCALE;\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = scale * v;\n            }\n            else {\n                resultValues[i] = scaleAlpha * (Math.exp(v) - 1);\n            }\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.clip = function (x, min, max) {\n        cpu_util_1.assertNotComplex(x, 'clip');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            resultValues[i] = v > max ? max : (v < min ? min : v);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.abs = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.abs(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.complexAbs = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < x.size; ++i) {\n            var real_1 = values[i * 2];\n            var imag_1 = values[i * 2 + 1];\n            resultValues[i] = Math.hypot(real_1, imag_1);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.int = function (x) {\n        cpu_util_1.assertNotComplex(x, 'int');\n        var resultValues = new Int32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = values[i];\n        }\n        return this.makeOutput(resultValues, x.shape, 'int32');\n    };\n    MathBackendCPU.prototype.sigmoid = function (x) {\n        cpu_util_1.assertNotComplex(x, 'sigmoid');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = 1 / (1 + Math.exp(-values[i]));\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.softplus = function (x) {\n        cpu_util_1.assertNotComplex(x, 'softplus');\n        // mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n        // epsilon is the difference between 1.0 and the next representable float.\n        // For a single precision 32 bit float this should be 2^-23, see:\n        // https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\n        var epsilon = 1.1920928955078125e-7;\n        var threshold = Math.log(epsilon) + 2.0;\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            // Value above which exp(x) may overflow, but softplus(x) == x\n            // is within machine epsilon.\n            var tooLarge = values[i] > -threshold;\n            // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n            // is within machine epsilon.\n            var tooSmall = values[i] < threshold;\n            var expX = Math.exp(values[i]);\n            var result = void 0;\n            if (tooSmall) {\n                result = expX;\n            }\n            else if (tooLarge) {\n                result = values[i];\n            }\n            else {\n                result = Math.log(1.0 + expX);\n            }\n            resultValues[i] = result;\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.sin = function (x) {\n        cpu_util_1.assertNotComplex(x, 'sin');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.sin(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.cos = function (x) {\n        cpu_util_1.assertNotComplex(x, 'cos');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.cos(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.tan = function (x) {\n        cpu_util_1.assertNotComplex(x, 'tan');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.tan(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.asin = function (x) {\n        cpu_util_1.assertNotComplex(x, 'asin');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.asin(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.acos = function (x) {\n        cpu_util_1.assertNotComplex(x, 'acos');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.acos(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.atan = function (x) {\n        cpu_util_1.assertNotComplex(x, 'atan');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.atan(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.atan2 = function (a, b) {\n        cpu_util_1.assertNotComplex([a, b], 'atan2');\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aValue, bValue) { return Math.atan2(aValue, bValue); });\n    };\n    MathBackendCPU.prototype.sinh = function (x) {\n        cpu_util_1.assertNotComplex(x, 'sinh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.sinh(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.cosh = function (x) {\n        cpu_util_1.assertNotComplex(x, 'cosh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.cosh(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.tanh = function (x) {\n        cpu_util_1.assertNotComplex(x, 'tanh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = util.tanh(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.asinh = function (x) {\n        cpu_util_1.assertNotComplex(x, 'asinh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.asinh(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.acosh = function (x) {\n        cpu_util_1.assertNotComplex(x, 'acosh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.acosh(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.atanh = function (x) {\n        cpu_util_1.assertNotComplex(x, 'atanh');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.atanh(values[i]);\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.erf = function (x) {\n        cpu_util_1.assertNotComplex(x, 'erf');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        var p = erf_util.ERF_P;\n        var a1 = erf_util.ERF_A1;\n        var a2 = erf_util.ERF_A2;\n        var a3 = erf_util.ERF_A3;\n        var a4 = erf_util.ERF_A4;\n        var a5 = erf_util.ERF_A5;\n        for (var i = 0; i < values.length; ++i) {\n            var sign = Math.sign(values[i]);\n            var v = Math.abs(values[i]);\n            var t = 1.0 / (1.0 + p * v);\n            resultValues[i] = sign *\n                (1.0 -\n                    (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n                        Math.exp(-v * v));\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.step = function (x, alpha) {\n        if (alpha === void 0) { alpha = 0; }\n        cpu_util_1.assertNotComplex(x, 'step');\n        var resultValues = new Float32Array(x.size);\n        var values = this.readSync(x.dataId);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            if (isNaN(value)) {\n                resultValues[i] = NaN;\n            }\n            else {\n                resultValues[i] = value > 0 ? 1 : alpha;\n            }\n        }\n        return this.makeOutput(resultValues, x.shape, 'float32');\n    };\n    MathBackendCPU.prototype.fusedConv2d = function (_a) {\n        var input = _a.input, filter = _a.filter, convInfo = _a.convInfo, bias = _a.bias, activation = _a.activation, preluActivationWeights = _a.preluActivationWeights;\n        var result = this.conv2d(input, filter, convInfo);\n        if (bias) {\n            result = this.add(result, bias);\n        }\n        if (activation) {\n            result =\n                mapActivation(this, result, activation, preluActivationWeights);\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.conv2d = function (x, filter, convInfo) {\n        cpu_util_1.assertNotComplex([x, filter], 'conv2d');\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var padLeft = convInfo.padInfo.left;\n        var padTop = convInfo.padInfo.top;\n        var isChannelsLast = convInfo.dataFormat === 'channelsLast';\n        var y = ops.buffer(convInfo.outShape, x.dtype);\n        var xBatchStride = x.strides[0];\n        var xRowStride = isChannelsLast ? x.strides[1] : x.strides[2];\n        var xColStride = isChannelsLast ? x.strides[2] : 1;\n        var xChannelStride = isChannelsLast ? 1 : x.strides[1];\n        var yBatchStride = y.strides[0];\n        var yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];\n        var yColStride = isChannelsLast ? y.strides[2] : 1;\n        var yChannelStride = isChannelsLast ? 1 : y.strides[1];\n        var xVals = this.readSync(x.dataId);\n        var wVals = this.readSync(filter.dataId);\n        var yVals = y.values;\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            var xOffset1 = b * xBatchStride;\n            var yOffset1 = b * yBatchStride;\n            for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                var yOffset2 = yOffset1 + yR * yRowStride;\n                var xRCorner = yR * convInfo.strideHeight - padTop;\n                for (var wR = 0; wR < filterHeight; wR++) {\n                    var xR = xRCorner + wR * dilationHeight;\n                    if (xR < 0 || xR >= convInfo.inHeight) {\n                        continue;\n                    }\n                    var wOffset1 = wR * filter.strides[0];\n                    var xOffset2 = xOffset1 + xR * xRowStride;\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var yOffset3 = yOffset2 + yC * yColStride;\n                        var xCCorner = yC * convInfo.strideWidth - padLeft;\n                        for (var wC = 0; wC < filterWidth; wC++) {\n                            var xC = xCCorner + wC * dilationWidth;\n                            if (xC < 0 || xC >= convInfo.inWidth) {\n                                continue;\n                            }\n                            var wOffset2 = wOffset1 + wC * filter.strides[1];\n                            var xOffset3 = xOffset2 + xC * xColStride;\n                            var wOffset3 = wOffset2;\n                            for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                                var xVal = xVals[xOffset3 + d1 * xChannelStride];\n                                for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                                    yVals[yOffset3 + d2 * yChannelStride] +=\n                                        xVal * wVals[wOffset3 + d2];\n                                }\n                                wOffset3 += convInfo.outChannels;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.conv3d = function (x, filter, convInfo) {\n        var filterDepth = convInfo.filterDepth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var padFront = convInfo.padInfo.front;\n        var padLeft = convInfo.padInfo.left;\n        var padTop = convInfo.padInfo.top;\n        var y = ops.buffer(convInfo.outShape, x.dtype);\n        var xVals = this.readSync(x.dataId);\n        var wVals = this.readSync(filter.dataId);\n        var yVals = y.values;\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            var xOffset1 = b * x.strides[0];\n            var yOffset1 = b * y.strides[0];\n            for (var yF = 0; yF < convInfo.outDepth; ++yF) {\n                var yOffset2 = yOffset1 + yF * y.strides[1];\n                var xFCorner = yF * convInfo.strideDepth - padFront;\n                for (var wF = 0; wF < filterDepth; wF++) {\n                    var xF = xFCorner + wF * dilationDepth;\n                    if (xF < 0 || xF >= convInfo.inDepth) {\n                        continue;\n                    }\n                    var wOffset1 = wF * filter.strides[0];\n                    var xOffset2 = xOffset1 + xF * x.strides[1];\n                    for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                        var yOffset3 = yOffset2 + yR * y.strides[2];\n                        var xRCorner = yR * convInfo.strideHeight - padTop;\n                        for (var wR = 0; wR < filterHeight; wR++) {\n                            var xR = xRCorner + wR * dilationHeight;\n                            if (xR < 0 || xR >= convInfo.inHeight) {\n                                continue;\n                            }\n                            var wOffset2 = wOffset1 + wR * filter.strides[1];\n                            var xOffset3 = xOffset2 + xR * x.strides[2];\n                            for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                                var yOffset4 = yOffset3 + yC * convInfo.outChannels;\n                                var xCCorner = yC * convInfo.strideWidth - padLeft;\n                                for (var wC = 0; wC < filterWidth; wC++) {\n                                    var xC = xCCorner + wC * dilationWidth;\n                                    if (xC < 0 || xC >= convInfo.inWidth) {\n                                        continue;\n                                    }\n                                    var wOffset3 = wOffset2 + wC * filter.strides[2];\n                                    var xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                                    var wOffset4 = wOffset3;\n                                    for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                                        var xVal = xVals[xOffset4 + d1];\n                                        for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                                            yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                                        }\n                                        wOffset4 += convInfo.outChannels;\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.conv2dDerInput = function (dy, filter, convInfo) {\n        cpu_util_1.assertNotComplex([dy, filter], 'conv2dDerInput');\n        var dx = ops.buffer(convInfo.inShape, 'float32');\n        var dxValues = dx.values;\n        var dyValues = this.readSync(dy.dataId);\n        var fltValues = this.readSync(filter.dataId);\n        var _a = filter.strides, fltS0 = _a[0], fltS1 = _a[1], fltS2 = _a[2];\n        var batchSize = convInfo.batchSize, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth, dataFormat = convInfo.dataFormat;\n        var topPad = filterHeight - 1 - convInfo.padInfo.top;\n        var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n        var isChannelsLast = dataFormat === 'channelsLast';\n        var xBatchStride = dx.strides[0];\n        var xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];\n        var xColStride = isChannelsLast ? dx.strides[2] : 1;\n        var xChannelStride = isChannelsLast ? 1 : dx.strides[1];\n        var yBatchStride = dy.strides[0];\n        var yRowStride = isChannelsLast ? dy.strides[1] : dy.strides[2];\n        var yColStride = isChannelsLast ? dy.strides[2] : 1;\n        var yChannelStride = isChannelsLast ? 1 : dy.strides[1];\n        for (var b = 0; b < batchSize; ++b) {\n            for (var d1 = 0; d1 < inChannels; ++d1) {\n                for (var xR = 0; xR < inHeight; ++xR) {\n                    var xRCorner = xR - topPad;\n                    var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                    var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n                    for (var xC = 0; xC < inWidth; ++xC) {\n                        var xCCorner = xC - leftPad;\n                        var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                        var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n                        var dotProd = 0;\n                        for (var yR = xRMin; yR < yRMax; ++yR) {\n                            var wR = yR * strideHeight - xRCorner;\n                            for (var yC = xCMin; yC < yCMax; ++yC) {\n                                var wC = yC * strideWidth - xCCorner;\n                                var dyOffset = yBatchStride * b + yRowStride * yR + yColStride * yC;\n                                var fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n                                for (var d2 = 0; d2 < outChannels; ++d2) {\n                                    var pixel = dyValues[dyOffset + yChannelStride * d2];\n                                    var weight = fltValues[fltOffset + d2];\n                                    dotProd += pixel * weight;\n                                }\n                            }\n                        }\n                        var dxOffset = xBatchStride * b + xRowStride * xR +\n                            xColStride * xC + xChannelStride * d1;\n                        dxValues[dxOffset] = dotProd;\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.conv3dDerInput = function (dy, filter, convInfo) {\n        var dx = ops.buffer(convInfo.inShape, 'float32');\n        var dxValues = dx.values;\n        var _a = dx.strides, dxS0 = _a[0], dxS1 = _a[1], dxS2 = _a[2], dxS3 = _a[3];\n        var dyValues = this.readSync(dy.dataId);\n        var _b = dy.strides, dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2], dyS3 = _b[3];\n        var fltValues = this.readSync(filter.dataId);\n        var _c = filter.strides, fltS0 = _c[0], fltS1 = _c[1], fltS2 = _c[2], fltS3 = _c[3];\n        var batchSize = convInfo.batchSize, filterDepth = convInfo.filterDepth, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inDepth = convInfo.inDepth, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outDepth = convInfo.outDepth, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideDepth = convInfo.strideDepth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;\n        var frontPad = filterDepth - 1 - convInfo.padInfo.front;\n        var topPad = filterHeight - 1 - convInfo.padInfo.top;\n        var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n        for (var b = 0; b < batchSize; ++b) {\n            for (var d1 = 0; d1 < inChannels; ++d1) {\n                // Frames of depth\n                for (var xF = 0; xF < inDepth; ++xF) {\n                    var xFCorner = xF - frontPad;\n                    var xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n                    var yFMax = Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n                    // Rows as per standard 2d matrix notation\n                    for (var xR = 0; xR < inHeight; ++xR) {\n                        var xRCorner = xR - topPad;\n                        var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                        var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n                        // Columns as per standard 2d matrix notation\n                        for (var xC = 0; xC < inWidth; ++xC) {\n                            var xCCorner = xC - leftPad;\n                            var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                            var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n                            var dotProd = 0;\n                            for (var yF = xFMin; yF < yFMax; ++yF) {\n                                var wF = yF * strideDepth - xFCorner;\n                                for (var yR = xRMin; yR < yRMax; ++yR) {\n                                    var wR = yR * strideHeight - xRCorner;\n                                    for (var yC = xCMin; yC < yCMax; ++yC) {\n                                        var wC = yC * strideWidth - xCCorner;\n                                        var dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                                        var fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                                            fltS1 * (filterHeight - 1 - wR) +\n                                            fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n                                        for (var d2 = 0; d2 < outChannels; ++d2) {\n                                            var pixel = dyValues[dyOffset + d2];\n                                            var weight = fltValues[fltOffset + d2];\n                                            dotProd += pixel * weight;\n                                        }\n                                    }\n                                }\n                            }\n                            dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                                dotProd;\n                        }\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.conv2dDerFilter = function (x, dy, convInfo) {\n        cpu_util_1.assertNotComplex([x, dy], 'conv2dDerFilter');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var isChannelsLast = convInfo.dataFormat === 'channelsLast';\n        var dW = ops.buffer(convInfo.filterShape, 'float32');\n        var leftPad = convInfo.padInfo.left;\n        var topPad = convInfo.padInfo.top;\n        var xBuf = this.bufferSync(x);\n        var dyBuf = this.bufferSync(dy);\n        for (var wR = 0; wR < filterHeight; ++wR) {\n            var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n            var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n            for (var wC = 0; wC < filterWidth; ++wC) {\n                var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n                var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                    for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                        // Need to convolve.\n                        var dotProd = 0;\n                        for (var b = 0; b < convInfo.batchSize; ++b) {\n                            for (var yR = yRMin; yR < yRMax; ++yR) {\n                                var xR = wR + yR * strideHeight - topPad;\n                                for (var yC = yCMin; yC < yCMax; ++yC) {\n                                    var xC = wC + yC * strideWidth - leftPad;\n                                    if (isChannelsLast) {\n                                        dotProd +=\n                                            xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n                                    }\n                                    else {\n                                        dotProd +=\n                                            xBuf.get(b, d1, xR, xC) * dyBuf.get(b, d2, yR, yC);\n                                    }\n                                }\n                            }\n                        }\n                        dW.set(dotProd, wR, wC, d1, d2);\n                    }\n                }\n            }\n        }\n        return dW.toTensor();\n    };\n    MathBackendCPU.prototype.conv3dDerFilter = function (x, dy, convInfo) {\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterDepth = convInfo.filterDepth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dw = ops.buffer(convInfo.filterShape, 'float32');\n        var dwValues = dw.values;\n        var _a = dw.strides, dwS0 = _a[0], dwS1 = _a[1], dwS2 = _a[2], dwS3 = _a[3];\n        var dyValues = this.readSync(dy.dataId);\n        var _b = dy.strides, dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2], dyS3 = _b[3];\n        var xValues = this.readSync(x.dataId);\n        var _c = x.strides, xS0 = _c[0], xS1 = _c[1], xS2 = _c[2], xS3 = _c[3];\n        var frontPad = convInfo.padInfo.front;\n        var leftPad = convInfo.padInfo.left;\n        var topPad = convInfo.padInfo.top;\n        for (var wF = 0; wF < filterDepth; ++wF) {\n            var yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n            var yFMax = Math.min(convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n            var wOffset1 = wF * dwS0;\n            for (var wR = 0; wR < filterHeight; ++wR) {\n                var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n                var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n                var wOffset2 = wR * dwS1 + wOffset1;\n                for (var wC = 0; wC < filterWidth; ++wC) {\n                    var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n                    var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n                    var wOffset3 = wC * dwS2 + wOffset2;\n                    for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                        var wOffset4 = d1 * dwS3 + wOffset3;\n                        for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                            var dotProd = 0;\n                            for (var b = 0; b < convInfo.batchSize; ++b) {\n                                var xOffset1 = b * xS0;\n                                var yOffset1 = b * dyS0;\n                                for (var yF = yFMin; yF < yFMax; ++yF) {\n                                    var xF = wF + yF * strideDepth - frontPad;\n                                    var xOffset2 = xF * xS1 + xOffset1;\n                                    var yOffset2 = yF * dyS1 + yOffset1;\n                                    for (var yR = yRMin; yR < yRMax; ++yR) {\n                                        var xR = wR + yR * strideHeight - topPad;\n                                        var xOffset3 = xR * xS2 + xOffset2;\n                                        var yOffset3 = yR * dyS2 + yOffset2;\n                                        for (var yC = yCMin; yC < yCMax; ++yC) {\n                                            var xC = wC + yC * strideWidth - leftPad;\n                                            var xOffset4 = xC * xS3 + xOffset3;\n                                            var yOffset4 = yC * dyS3 + yOffset3;\n                                            dotProd +=\n                                                xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                                        }\n                                    }\n                                }\n                            }\n                            dwValues[wOffset4 + d2] = dotProd;\n                        }\n                    }\n                }\n            }\n        }\n        return dw.toTensor();\n    };\n    MathBackendCPU.prototype.fusedDepthwiseConv2D = function (_a) {\n        var input = _a.input, filter = _a.filter, convInfo = _a.convInfo, bias = _a.bias, activation = _a.activation, preluActivationWeights = _a.preluActivationWeights;\n        var result = this.depthwiseConv2D(input, filter, convInfo);\n        if (bias) {\n            result = this.add(result, bias);\n        }\n        if (activation) {\n            result =\n                mapActivation(this, result, activation, preluActivationWeights);\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.depthwiseConv2D = function (x, filter, convInfo) {\n        cpu_util_1.assertNotComplex([x, filter], 'depthwiseConv2D');\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var padLeft = convInfo.padInfo.left;\n        var padTop = convInfo.padInfo.top;\n        var chMul = convInfo.outChannels / convInfo.inChannels;\n        var y = ops.buffer(convInfo.outShape, x.dtype);\n        var xVals = this.readSync(x.dataId);\n        var wVals = this.readSync(filter.dataId);\n        var yVals = y.values;\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            var xOffset1 = b * x.strides[0];\n            var yOffset1 = b * y.strides[0];\n            for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                var yOffset2 = yOffset1 + yR * y.strides[1];\n                var xRCorner = yR * convInfo.strideHeight - padLeft;\n                for (var wR = 0; wR < filterHeight; ++wR) {\n                    var xR = xRCorner + wR * dilationHeight;\n                    if (xR < 0 || xR >= convInfo.inHeight) {\n                        continue;\n                    }\n                    var wOffset1 = wR * filter.strides[0];\n                    var xOffset2 = xOffset1 + xR * x.strides[1];\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var yOffset3 = yOffset2 + yC * y.strides[2];\n                        var xCCorner = yC * convInfo.strideWidth - padTop;\n                        for (var wC = 0; wC < filterWidth; ++wC) {\n                            var xC = xCCorner + wC * dilationWidth;\n                            if (xC < 0 || xC >= convInfo.inWidth) {\n                                continue;\n                            }\n                            var wOffset2 = wOffset1 + wC * filter.strides[1];\n                            var xOffset3 = xOffset2 + xC * convInfo.inChannels;\n                            var yOffset4 = yOffset3;\n                            var wOffset3 = wOffset2;\n                            for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                                var xVal = xVals[xOffset3 + d1];\n                                for (var q = 0; q < chMul; ++q) {\n                                    yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n                                }\n                                yOffset4 += chMul;\n                                wOffset3 += chMul;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.depthwiseConv2DDerInput = function (dy, filter, convInfo) {\n        cpu_util_1.assertNotComplex([dy, filter], 'depthwiseConv2DDerInput');\n        var dx = ops.buffer(convInfo.inShape, 'float32');\n        var dxValues = dx.values;\n        var _a = dx.strides, dxS0 = _a[0], dxS1 = _a[1], dxS2 = _a[2];\n        var dyValues = this.readSync(dy.dataId);\n        var _b = dy.strides, dyS0 = _b[0], dyS1 = _b[1], dyS2 = _b[2];\n        var fltValues = this.readSync(filter.dataId);\n        var _c = filter.strides, fltS0 = _c[0], fltS1 = _c[1], fltS2 = _c[2];\n        var batchSize = convInfo.batchSize, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;\n        var topPad = filterHeight - 1 - convInfo.padInfo.top;\n        var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n        var chMul = outChannels / inChannels;\n        for (var b = 0; b < batchSize; ++b) {\n            for (var d1 = 0; d1 < inChannels; ++d1) {\n                for (var xR = 0; xR < inHeight; ++xR) {\n                    var xRCorner = xR - topPad;\n                    var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                    var yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n                    for (var xC = 0; xC < inWidth; ++xC) {\n                        var xCCorner = xC - leftPad;\n                        var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                        var yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n                        var dotProd = 0;\n                        for (var yR = xRMin; yR < yRMax; ++yR) {\n                            var wR = yR * strideHeight - xRCorner;\n                            for (var yC = xCMin; yC < yCMax; ++yC) {\n                                var wC = yC * strideWidth - xCCorner;\n                                var dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n                                var fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                                    fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n                                for (var dm = 0; dm < chMul; ++dm) {\n                                    var d2 = d1 * chMul + dm;\n                                    var pixel = dyValues[dyOffset + d2];\n                                    var weight = fltValues[fltOffset + dm];\n                                    dotProd += pixel * weight;\n                                }\n                            }\n                        }\n                        dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.depthwiseConv2DDerFilter = function (x, dy, convInfo) {\n        cpu_util_1.assertNotComplex([x, dy], 'depthwiseConv2DDerFilter');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dW = ops.buffer(convInfo.filterShape, 'float32');\n        var leftPad = convInfo.padInfo.left;\n        var topPad = convInfo.padInfo.top;\n        var chMul = convInfo.outChannels / convInfo.inChannels;\n        var xBuf = this.bufferSync(x);\n        var dyBuf = this.bufferSync(dy);\n        for (var wR = 0; wR < filterHeight; ++wR) {\n            var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n            var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n            for (var wC = 0; wC < filterWidth; ++wC) {\n                var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n                var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n                for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                    var d1 = Math.trunc(d2 / chMul);\n                    var dm = d2 % chMul;\n                    var dotProd = 0;\n                    for (var b = 0; b < convInfo.batchSize; ++b) {\n                        for (var yR = yRMin; yR < yRMax; ++yR) {\n                            var xR = wR + yR * strideHeight - topPad;\n                            for (var yC = yCMin; yC < yCMax; ++yC) {\n                                var xC = wC + yC * strideWidth - leftPad;\n                                dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);\n                            }\n                        }\n                    }\n                    dW.set(dotProd, wR, wC, d1, dm);\n                }\n            }\n        }\n        return dW.toTensor();\n    };\n    MathBackendCPU.prototype.tile = function (x, reps) {\n        cpu_util_1.assertNotComplex(x, 'tile');\n        return tile_impl_1.tile(this.bufferSync(x), reps);\n    };\n    MathBackendCPU.prototype.pad = function (x, paddings, constantValue) {\n        cpu_util_1.assertNotComplex(x, 'pad');\n        var outShape = paddings.map(function (p, i) { return p[0] /* beforePad */ + x.shape[i] + p[1]; } /* afterPad */);\n        var start = paddings.map(function (p) { return p[0]; });\n        var xBuffer = this.bufferSync(x);\n        var buffer = ops.buffer(outShape, x.dtype);\n        if (constantValue !== 0) {\n            buffer.values.fill(constantValue);\n        }\n        for (var i = 0; i < x.size; i++) {\n            var coords = xBuffer.indexToLoc(i);\n            var outCoords = coords.map(function (c, i) { return c + start[i]; });\n            buffer.set.apply(buffer, [xBuffer.get.apply(xBuffer, coords)].concat(outCoords));\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.transpose = function (x, perm) {\n        cpu_util_1.assertNotComplex(x, 'transpose');\n        var newShape = new Array(x.rank);\n        for (var i = 0; i < newShape.length; i++) {\n            newShape[i] = x.shape[perm[i]];\n        }\n        var values = this.readSync(x.dataId);\n        var result = ops_1.buffer(newShape, x.dtype);\n        var xBuf = this.bufferSync(x);\n        for (var i = 0; i < x.size; ++i) {\n            var loc = xBuf.indexToLoc(i);\n            // Permute location.\n            var newLoc = new Array(loc.length);\n            for (var i_1 = 0; i_1 < newLoc.length; i_1++) {\n                newLoc[i_1] = loc[perm[i_1]];\n            }\n            var newIndex = result.locToIndex(newLoc);\n            result.values[newIndex] = values[i];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.gather = function (x, indices, axis) {\n        cpu_util_1.assertNotComplex([x, indices], 'gather');\n        var newShape = x.shape.slice();\n        var indicesValues = this.readSync(indices.dataId);\n        newShape[axis] = indicesValues.length;\n        var result = ops_1.buffer(newShape, x.dtype);\n        var xBuf = this.bufferSync(x);\n        for (var i = 0; i < result.size; ++i) {\n            var newLoc = result.indexToLoc(i);\n            var originalLoc = newLoc.slice();\n            originalLoc[axis] = indicesValues[newLoc[axis]];\n            var originalIndex = xBuf.locToIndex(originalLoc);\n            result.values[i] = xBuf.values[originalIndex];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.batchToSpaceND = function (x, blockShape, crops) {\n        cpu_util_1.assertNotComplex([x], 'batchToSpaceND');\n        var prod = blockShape.reduce(function (a, b) { return a * b; });\n        var reshaped = array_ops_util.getReshaped(x.shape, blockShape, prod);\n        var permuted = array_ops_util.getPermuted(reshaped.length, blockShape.length);\n        var reshapedPermuted = array_ops_util.getReshapedPermuted(x.shape, blockShape, prod);\n        var sliceBeginCoords = array_ops_util.getSliceBeginCoords(crops, blockShape.length);\n        var sliceSize = array_ops_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n        return x.reshape(reshaped)\n            .transpose(permuted)\n            .reshape(reshapedPermuted)\n            .slice(sliceBeginCoords, sliceSize);\n    };\n    MathBackendCPU.prototype.spaceToBatchND = function (x, blockShape, paddings) {\n        cpu_util_1.assertNotComplex([x], 'spaceToBatchND');\n        var prod = blockShape.reduce(function (a, b) { return a * b; });\n        var completePaddings = [[0, 0]];\n        completePaddings.push.apply(completePaddings, paddings);\n        for (var i = 1 + blockShape.length; i < x.shape.length; ++i) {\n            completePaddings.push([0, 0]);\n        }\n        var paddedX = x.pad(completePaddings);\n        var reshapedPaddedShape = array_ops_util.getReshaped(paddedX.shape, blockShape, prod, false);\n        var permutedReshapedPaddedPermutation = array_ops_util.getPermuted(reshapedPaddedShape.length, blockShape.length, false);\n        var flattenShape = array_ops_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n        return paddedX.reshape(reshapedPaddedShape)\n            .transpose(permutedReshapedPaddedPermutation)\n            .reshape(flattenShape);\n    };\n    MathBackendCPU.prototype.pool = function (x, convInfo, poolType) {\n        cpu_util_1.assertNotComplex(x, 'pool');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var initialValue = (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n            Number.POSITIVE_INFINITY);\n        var xValues = this.readSync(x.dataId);\n        var output = ops.buffer(convInfo.outShape, x.dtype);\n        var outputVals = output.values;\n        var outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n        var outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n        var outputColStrides = convInfo.outShape[3];\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            var outputBatchOffset = b * outputBatchStrides;\n            var inputBatchOffset = b * x.strides[0];\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * strideHeight - padTop;\n                    var xRMin = Math.max(0, xRCorner);\n                    var xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n                    var outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * strideWidth - padLeft;\n                        var xCMin = Math.max(0, xCCorner);\n                        var xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n                        var minMaxValue = initialValue;\n                        var avgValue = 0;\n                        var count = 0;\n                        for (var xR = xRMin; xR < xRMax; xR += dilationHeight) {\n                            var xROffset = inputBatchOffset + xR * x.strides[1];\n                            for (var xC = xCMin; xC < xCMax; xC += dilationWidth) {\n                                var xCOffset = xROffset + xC * x.strides[2];\n                                var pixel = xValues[xCOffset + d];\n                                if ((poolType === 'max' && pixel > minMaxValue)) {\n                                    minMaxValue = pixel;\n                                }\n                                else if (poolType === 'avg') {\n                                    avgValue += pixel;\n                                    count++;\n                                }\n                            }\n                            if (isNaN(minMaxValue)) {\n                                break;\n                            }\n                        }\n                        var outputOffset = outputRowOffset + yC * outputColStrides + d;\n                        outputVals[outputOffset] =\n                            poolType === 'avg' ? avgValue / count : minMaxValue;\n                    }\n                }\n            }\n        }\n        return output.toTensor();\n    };\n    MathBackendCPU.prototype.maxPool = function (x, convInfo) {\n        return this.pool(x, convInfo, 'max');\n    };\n    MathBackendCPU.prototype.maxPoolPositions = function (x, convInfo) {\n        var maxPositions = ops.buffer(convInfo.outShape, 'int32');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var xBuf = this.bufferSync(x);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * strideHeight - padTop;\n                    var xRMin = xRCorner;\n                    while (xRMin < 0) {\n                        xRMin += dilationHeight;\n                    }\n                    // const xRMin = Math.max(0, xRCorner);\n                    var xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * strideWidth - padLeft;\n                        var xCMin = xCCorner;\n                        while (xCMin < 0) {\n                            xCMin += dilationWidth;\n                        }\n                        var xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n                        var maxValue = Number.NEGATIVE_INFINITY;\n                        var maxPosition = -1;\n                        for (var xR = xRMin; xR < xRMax; xR += dilationHeight) {\n                            var wR = xR - xRCorner;\n                            for (var xC = xCMin; xC < xCMax; xC += dilationWidth) {\n                                var wC = xC - xCCorner;\n                                var pixel = xBuf.get(b, xR, xC, d);\n                                if (pixel > maxValue) {\n                                    maxValue = pixel;\n                                    maxPosition = wR * effectiveFilterWidth + wC;\n                                }\n                            }\n                        }\n                        maxPositions.set(maxPosition, b, yR, yC, d);\n                    }\n                }\n            }\n        }\n        return maxPositions.toTensor();\n    };\n    MathBackendCPU.prototype.maxPoolBackprop = function (dy, x, y, convInfo) {\n        cpu_util_1.assertNotComplex([x, y], 'maxPoolBackprop');\n        var maxPositions = this.maxPoolPositions(x, convInfo);\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var dx = ops.buffer(x.shape, 'float32');\n        var maxPosBuf = this.bufferSync(maxPositions);\n        var dyBuf = this.bufferSync(dy);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n                    for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n                        // Shader code begins.\n                        var dyRCorner = dxR - padTop;\n                        var dyCCorner = dxC - padLeft;\n                        var dotProd = 0;\n                        for (var wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n                            var dyR = (dyRCorner + wR) / strideHeight;\n                            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                                Math.floor(dyR) !== dyR) {\n                                continue;\n                            }\n                            for (var wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n                                var dyC = (dyCCorner + wC) / strideWidth;\n                                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                                    Math.floor(dyC) !== dyC) {\n                                    continue;\n                                }\n                                var maxPos = effectiveFilterHeight * effectiveFilterWidth -\n                                    1 - maxPosBuf.get(b, dyR, dyC, d);\n                                var curPos = wR * effectiveFilterWidth + wC;\n                                var mask = maxPos === curPos ? 1 : 0;\n                                if (mask === 0) {\n                                    continue;\n                                }\n                                var pixel = dyBuf.get(b, dyR, dyC, d);\n                                dotProd += pixel * mask;\n                            }\n                        }\n                        dx.set(dotProd, b, dxR, dxC, d);\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.avgPoolBackprop = function (dy, x, convInfo) {\n        cpu_util_1.assertNotComplex([dy, x], 'avgPoolBackprop');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var dx = ops.buffer(x.shape, 'float32');\n        var avgMultiplier = 1 / (filterHeight * filterWidth);\n        var dyBuf = this.bufferSync(dy);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n                    for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n                        // Shader code begins.\n                        var dyRCorner = dxR - padTop;\n                        var dyCCorner = dxC - padLeft;\n                        var dotProd = 0;\n                        for (var wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n                            var dyR = (dyRCorner + wR) / strideHeight;\n                            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                                Math.floor(dyR) !== dyR) {\n                                continue;\n                            }\n                            for (var wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n                                var dyC = (dyCCorner + wC) / strideWidth;\n                                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                                    Math.floor(dyC) !== dyC) {\n                                    continue;\n                                }\n                                var pixel = dyBuf.get(b, dyR, dyC, d);\n                                dotProd += pixel;\n                            }\n                        }\n                        dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.pool3d = function (x, convInfo, poolType) {\n        cpu_util_1.assertNotComplex(x, 'pool3d');\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padFront = convInfo.padInfo.front;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var initialValue = (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n            Number.POSITIVE_INFINITY);\n        var xValues = this.readSync(x.dataId);\n        var output = ops.buffer(convInfo.outShape, x.dtype);\n        var outputVals = output.values;\n        var outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] *\n            convInfo.outShape[3] * convInfo.outShape[4];\n        var outputDepthStrides = convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];\n        var outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];\n        var outputColStrides = convInfo.outShape[4];\n        for (var batch = 0; batch < convInfo.batchSize; ++batch) {\n            var outputBatchOffset = batch * outputBatchStrides;\n            var inputBatchOffset = batch * x.strides[0];\n            for (var channel = 0; channel < convInfo.inChannels; ++channel) {\n                for (var yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n                    var xDepthCorner = yDepth * strideDepth - padFront;\n                    var xDepthMin = xDepthCorner;\n                    while (xDepthMin < 0) {\n                        xDepthMin += dilationDepth;\n                    }\n                    var xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n                    var outputDepthOffset = outputBatchOffset + yDepth * outputDepthStrides;\n                    for (var yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n                        var xRowCorner = yRow * strideHeight - padTop;\n                        var xRowMin = xRowCorner;\n                        while (xRowMin < 0) {\n                            xRowMin += dilationHeight;\n                        }\n                        var xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n                        var outputRowOffset = outputDepthOffset + yRow * outputRowStrides;\n                        for (var yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n                            var xColCorner = yCol * strideWidth - padLeft;\n                            var xColMin = xColCorner;\n                            while (xColMin < 0) {\n                                xColMin += dilationWidth;\n                            }\n                            var xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n                            // Shader code begins\n                            var outputColOffset = outputRowOffset + yCol * outputColStrides;\n                            var minMaxValue = initialValue;\n                            var avgValue = 0;\n                            var count = 0;\n                            for (var xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {\n                                var xDepthOffset = inputBatchOffset + xDepth * x.strides[1];\n                                for (var xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {\n                                    var xRowOffset = xDepthOffset + xRow * x.strides[2];\n                                    for (var xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {\n                                        var xColOffset = xRowOffset + xCol * x.strides[3];\n                                        var pixel = xValues[xColOffset + channel];\n                                        if ((poolType === 'max' && pixel > minMaxValue)) {\n                                            minMaxValue = pixel;\n                                        }\n                                        else if (poolType === 'avg') {\n                                            avgValue += pixel;\n                                            count++;\n                                        }\n                                        if (isNaN(minMaxValue)) {\n                                            break;\n                                        }\n                                    }\n                                    if (isNaN(minMaxValue)) {\n                                        break;\n                                    }\n                                }\n                                if (isNaN(minMaxValue)) {\n                                    break;\n                                }\n                            }\n                            var outputOffset = outputColOffset + channel;\n                            outputVals[outputOffset] =\n                                poolType === 'avg' ? avgValue / count : minMaxValue;\n                        }\n                    }\n                }\n            }\n        }\n        return output.toTensor();\n    };\n    MathBackendCPU.prototype.avgPool3d = function (x, convInfo) {\n        cpu_util_1.assertNotComplex(x, 'avgPool3d');\n        return this.pool3d(x, convInfo, 'avg').toFloat();\n    };\n    MathBackendCPU.prototype.avgPool3dBackprop = function (dy, x, convInfo) {\n        cpu_util_1.assertNotComplex([dy, x], 'avgPool3dBackprop');\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterDepth = convInfo.filterDepth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var dx = ops.buffer(x.shape, 'float32');\n        var avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n        var dyBuf = this.bufferSync(dy);\n        for (var batch = 0; batch < convInfo.batchSize; ++batch) {\n            for (var channel = 0; channel < convInfo.inChannels; ++channel) {\n                for (var dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n                    for (var dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n                        for (var dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n                            // Shader code begins.\n                            var dyDepthCorner = dxDepth - padFront;\n                            var dyRowCorner = dxRow - padTop;\n                            var dyColCorner = dxCol - padLeft;\n                            var dotProd = 0;\n                            for (var wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {\n                                var dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                                    Math.floor(dyDepth) !== dyDepth) {\n                                    continue;\n                                }\n                                for (var wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {\n                                    var dyRow = (dyRowCorner + wRow) / strideHeight;\n                                    if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                                        Math.floor(dyRow) !== dyRow) {\n                                        continue;\n                                    }\n                                    for (var wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {\n                                        var dyCol = (dyColCorner + wCol) / strideWidth;\n                                        if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                                            Math.floor(dyCol) !== dyCol) {\n                                            continue;\n                                        }\n                                        var pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                                        dotProd += pixel;\n                                    }\n                                }\n                            }\n                            dx.set(dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol, channel);\n                        }\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.maxPool3d = function (x, convInfo) {\n        cpu_util_1.assertNotComplex(x, 'maxPool3d');\n        return this.pool3d(x, convInfo, 'max').toFloat();\n    };\n    MathBackendCPU.prototype.maxPool3dPositions = function (x, convInfo) {\n        var maxPositions = ops.buffer(convInfo.outShape, 'int32');\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padFront = convInfo.padInfo.front;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var xBuf = this.bufferSync(x);\n        for (var batch = 0; batch < convInfo.batchSize; ++batch) {\n            for (var channel = 0; channel < convInfo.inChannels; ++channel) {\n                for (var yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n                    var xDepthCorner = yDepth * strideDepth - padFront;\n                    var xDepthMin = xDepthCorner;\n                    while (xDepthMin < 0) {\n                        xDepthMin += dilationDepth;\n                    }\n                    var xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n                    for (var yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n                        var xRowCorner = yRow * strideHeight - padTop;\n                        var xRowMin = xRowCorner;\n                        while (xRowMin < 0) {\n                            xRowMin += dilationHeight;\n                        }\n                        var xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n                        for (var yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n                            var xColCorner = yCol * strideWidth - padLeft;\n                            var xColMin = xColCorner;\n                            while (xColMin < 0) {\n                                xColMin += dilationWidth;\n                            }\n                            var xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n                            // Shader code begins\n                            var maxValue = Number.NEGATIVE_INFINITY;\n                            var maxPosition = -1;\n                            for (var xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {\n                                var wDepth = xDepth - xDepthCorner;\n                                for (var xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {\n                                    var wRow = xRow - xRowCorner;\n                                    for (var xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {\n                                        var wCol = xCol - xColCorner;\n                                        var pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);\n                                        if (pixel >= maxValue) {\n                                            maxValue = pixel;\n                                            maxPosition = wDepth * effectiveFilterHeight *\n                                                effectiveFilterWidth +\n                                                wRow * effectiveFilterHeight + wCol;\n                                        }\n                                    }\n                                }\n                            }\n                            maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);\n                        }\n                    }\n                }\n            }\n        }\n        return maxPositions.toTensor();\n    };\n    MathBackendCPU.prototype.maxPool3dBackprop = function (dy, x, y, convInfo) {\n        cpu_util_1.assertNotComplex([x, y], 'maxPool3dBackprop');\n        var maxPositions = this.maxPool3dPositions(x, convInfo);\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var dx = ops.buffer(x.shape, 'float32');\n        var maxPosBuf = this.bufferSync(maxPositions);\n        var dyBuf = this.bufferSync(dy);\n        for (var batch = 0; batch < convInfo.batchSize; ++batch) {\n            for (var channel = 0; channel < convInfo.inChannels; ++channel) {\n                for (var dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n                    for (var dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n                        for (var dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n                            // Shader code begins\n                            var dyDepthCorner = dxDepth - padFront;\n                            var dyRowCorner = dxRow - padTop;\n                            var dyColCorner = dxCol - padLeft;\n                            var dotProd = 0;\n                            for (var wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {\n                                var dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                                    Math.floor(dyDepth) !== dyDepth) {\n                                    continue;\n                                }\n                                for (var wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {\n                                    var dyRow = (dyRowCorner + wRow) / strideHeight;\n                                    if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                                        Math.floor(dyRow) !== dyRow) {\n                                        continue;\n                                    }\n                                    for (var wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {\n                                        var dyCol = (dyColCorner + wCol) / strideWidth;\n                                        if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                                            Math.floor(dyCol) !== dyCol) {\n                                            continue;\n                                        }\n                                        var maxPos = effectiveFilterDepth *\n                                            effectiveFilterHeight * effectiveFilterWidth -\n                                            1 -\n                                            maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                                        var curPos = wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                                            wRow * effectiveFilterWidth + wCol;\n                                        var mask = maxPos === curPos ? 1 : 0;\n                                        if (mask === 0) {\n                                            continue;\n                                        }\n                                        var pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                                        dotProd += pixel * mask;\n                                    }\n                                }\n                            }\n                            dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);\n                        }\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.cast = function (x, dtype) {\n        return backend_util.castTensor(x, dtype, this);\n    };\n    MathBackendCPU.prototype.reshape = function (x, shape) {\n        return backend_util.reshapeTensor(x, shape);\n    };\n    MathBackendCPU.prototype.avgPool = function (x, convInfo) {\n        cpu_util_1.assertNotComplex(x, 'avgPool');\n        return this.pool(x, convInfo, 'avg').toFloat();\n    };\n    MathBackendCPU.prototype.resizeBilinear = function (x, newHeight, newWidth, alignCorners) {\n        cpu_util_1.assertNotComplex(x, 'resizeBilinear');\n        var _a = x.shape, batch = _a[0], oldHeight = _a[1], oldWidth = _a[2], numChannels = _a[3];\n        var xValues = this.readSync(x.dataId);\n        var result = new Float32Array(util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n        var effectiveInputSize = [\n            (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n            (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n        ];\n        var effectiveOutputSize = [\n            (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n            (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n        ];\n        var outputIdx = 0;\n        var effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n        var effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n        for (var b = 0; b < batch; b++) {\n            for (var r = 0; r < newHeight; r++) {\n                var sourceFracRow = effectiveRowSizeRatio * r;\n                var sourceRowFloor = Math.floor(sourceFracRow);\n                var rowFrac = sourceFracRow - sourceRowFloor;\n                var sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n                var topRowOffset = b * x.strides[0] + sourceRowFloor * x.strides[1];\n                var botRowOffset = b * x.strides[0] + sourceRowCeil * x.strides[1];\n                for (var c = 0; c < newWidth; c++) {\n                    var sourceFracCol = effectiveColSizeRatio * c;\n                    var sourceColFloor = Math.floor(sourceFracCol);\n                    var colFrac = sourceFracCol - sourceColFloor;\n                    var sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n                    var topLeftOffest = topRowOffset + sourceColFloor * x.strides[2];\n                    var botLeftOffset = botRowOffset + sourceColFloor * x.strides[2];\n                    var topRightOffset = topRowOffset + sourceColCeil * x.strides[2];\n                    var botRightOffest = botRowOffset + sourceColCeil * x.strides[2];\n                    for (var d = 0; d < numChannels; d++) {\n                        // Begin shader.\n                        // Compute the fractional index of the source.\n                        var topLeft = xValues[topLeftOffest + d];\n                        var bottomLeft = xValues[botLeftOffset + d];\n                        var topRight = xValues[topRightOffset + d];\n                        var bottomRight = xValues[botRightOffest + d];\n                        var top_1 = topLeft + (topRight - topLeft) * colFrac;\n                        var bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n                        var newValue = top_1 + (bottom - top_1) * rowFrac;\n                        result[outputIdx++] = newValue;\n                    }\n                }\n            }\n        }\n        return ops.tensor(result, [batch, newHeight, newWidth, numChannels]);\n    };\n    MathBackendCPU.prototype.resizeBilinearBackprop = function (dy, x, alignCorners) {\n        cpu_util_1.assertNotComplex([dy, x], 'resizeBilinearBackprop');\n        var _a = x.shape, batch = _a[0], xHeight = _a[1], xWidth = _a[2], depth = _a[3];\n        var _b = dy.shape, yHeight = _b[1], yWidth = _b[2];\n        var output = new Float32Array(batch * xHeight * xWidth * depth);\n        // In the backwards pass, we want to find the pixels that were generated\n        // for each pixel in the input image the forward pass and add the\n        // corresponding coefficient from dy to the gradient (with some\n        // interpolation).\n        var effectiveXSize = [\n            (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n            (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n        ];\n        var effectiveYSize = [\n            (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n            (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n        ];\n        var heightScale = effectiveXSize[0] / effectiveYSize[0];\n        var widthScale = effectiveXSize[1] / effectiveYSize[1];\n        // Reference implementation\n        // tslint:disable-next-line:max-line-length\n        // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n        var dyValues = this.readSync(dy.dataId);\n        var offset = 0;\n        for (var b = 0; b < batch; b++) {\n            var bOffset = b * x.strides[0];\n            for (var r = 0; r < yHeight; r++) {\n                var dxR = r * heightScale;\n                var topDxRIndex = Math.floor(dxR);\n                var bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n                var topDxROffset = bOffset + topDxRIndex * x.strides[1];\n                var bottomDxROffset = bOffset + bottomDxRIndex * x.strides[1];\n                var dxRLerp = dxR - topDxRIndex;\n                var inverseDxRLerp = 1.0 - dxRLerp;\n                for (var c = 0; c < yWidth; c++) {\n                    var dxC = c * widthScale;\n                    var leftDxCIndex = Math.floor(dxC);\n                    var rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n                    var dxCLerp = dxC - leftDxCIndex;\n                    var inverseDxCLerp = 1.0 - dxCLerp;\n                    var topLeftRCOffset = topDxROffset + leftDxCIndex * x.strides[2];\n                    var topRightRCOffset = topDxROffset + rightDxCIndex * x.strides[2];\n                    var bottomLeftRCOffset = bottomDxROffset + leftDxCIndex * x.strides[2];\n                    var bottomRightRCOffset = bottomDxROffset + rightDxCIndex * x.strides[2];\n                    var inverseDxRLerpTimesInverseDxCLerp = inverseDxRLerp * inverseDxCLerp;\n                    var inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n                    var dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n                    var dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n                    for (var d = 0; d < depth; d++) {\n                        var dyVal = dyValues[offset++];\n                        output[topLeftRCOffset + d] +=\n                            dyVal * inverseDxRLerpTimesInverseDxCLerp;\n                        output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n                        output[bottomLeftRCOffset + d] +=\n                            dyVal * dxRLerpTimesInverseDxCLerp;\n                        output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n                    }\n                }\n            }\n        }\n        return ops.tensor4d(output, [batch, xWidth, xHeight, depth], x.dtype);\n    };\n    MathBackendCPU.prototype.resizeNearestNeighbor = function (x, newHeight, newWidth, alignCorners) {\n        cpu_util_1.assertNotComplex(x, 'resizeNearestNeighbor');\n        var _a = x.shape, batch = _a[0], oldHeight = _a[1], oldWidth = _a[2], numChannels = _a[3];\n        var xValues = this.readSync(x.dataId);\n        var output = new Float32Array(batch * newHeight * newWidth * numChannels);\n        var effectiveInputSize = [\n            (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n            (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n        ];\n        var effectiveOutputSize = [\n            (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n            (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n        ];\n        var effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];\n        var effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];\n        var outputOffset = 0;\n        for (var b = 0; b < batch; b++) {\n            var batchOffset = b * x.strides[0];\n            for (var r = 0; r < newHeight; r++) {\n                var sourceFracRow = effectiveRowSizeRatio * r;\n                var sourceNearestRow = Math.min(oldHeight - 1, alignCorners ? Math.round(sourceFracRow) :\n                    Math.floor(sourceFracRow));\n                var rowOffset = batchOffset + sourceNearestRow * x.strides[1];\n                for (var c = 0; c < newWidth; c++) {\n                    var sourceFracCol = effectiveColSizeRatio * c;\n                    var sourceNearestCol = Math.min(oldWidth - 1, alignCorners ? Math.round(sourceFracCol) :\n                        Math.floor(sourceFracCol));\n                    var colOffset = rowOffset + sourceNearestCol * x.strides[2];\n                    for (var d = 0; d < numChannels; d++) {\n                        // Begin shader.\n                        // Compute the fractional index of the source.\n                        var newVal = xValues[colOffset + d];\n                        output[outputOffset++] = newVal;\n                    }\n                }\n            }\n        }\n        return ops.tensor(output, [batch, newHeight, newWidth, numChannels], x.dtype);\n    };\n    MathBackendCPU.prototype.resizeNearestNeighborBackprop = function (dy, x, alignCorners) {\n        cpu_util_1.assertNotComplex([dy, x], 'resizeNearestNeighborBackprop');\n        var _a = x.shape, batch = _a[0], xHeight = _a[1], xWidth = _a[2], depth = _a[3];\n        var _b = dy.shape, yHeight = _b[1], yWidth = _b[2];\n        var output = new Float32Array(batch * xHeight * xWidth * depth);\n        var dyValues = this.readSync(dy.dataId);\n        // In the backwards pass, we want to find the pixels that were generated\n        // for each pixel in the input image the forward pass\n        var effectiveXSize = [\n            (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n            (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n        ];\n        var effectiveYSize = [\n            (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n            (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n        ];\n        var heightScale = effectiveXSize[0] / effectiveYSize[0];\n        var widthScale = effectiveXSize[1] / effectiveYSize[1];\n        var invHeightScale = 1 / heightScale;\n        var invWidthScale = 1 / widthScale;\n        // This defines the size of the window of values around a particular\n        // index in dy that we want to search for contributions to dx.\n        var winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n        var winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n        // Loop over the output space.\n        for (var b = 0; b < batch; b++) {\n            var batchOffset = b * x.strides[0];\n            for (var r = 0; r < xHeight; r++) {\n                var rowOffset = batchOffset + r * x.strides[1];\n                // Compute bounds for where in dy we will look\n                var startRLerp = Math.floor(r * invHeightScale);\n                var startDyR = Math.floor(startRLerp - (winHeight / 2));\n                for (var c = 0; c < xWidth; c++) {\n                    var colOffset = rowOffset + c * x.strides[2];\n                    // Compute bounds for where in dy we will look\n                    var startCLerp = Math.floor(c * invWidthScale);\n                    var startDyC = Math.floor(startCLerp - (winWidth / 2));\n                    for (var d = 0; d < depth; d++) {\n                        var accum = 0;\n                        // loop over dy\n                        for (var dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n                            var dyR = dyRIndex + startDyR;\n                            // Guard against the window exceeding the bounds of dy\n                            if (dyR < 0 || dyR >= yHeight) {\n                                continue;\n                            }\n                            var dyROffset = batchOffset + dyR * dy.strides[1];\n                            var sourceFracRow = dyR * heightScale;\n                            var sourceNearestRow = Math.min(xHeight - 1, alignCorners ? Math.round(sourceFracRow) :\n                                Math.floor(sourceFracRow));\n                            if (r !== sourceNearestRow) {\n                                continue;\n                            }\n                            for (var dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n                                var dyC = dyCIndex + startDyC;\n                                // Guard against the window exceeding the bounds of dy\n                                if (dyC < 0 || dyC >= yWidth) {\n                                    continue;\n                                }\n                                var dyCOffset = dyROffset + dyC * dy.strides[2];\n                                var sourceFracCol = dyC * widthScale;\n                                var sourceNearestCol = Math.min(xWidth - 1, alignCorners ? Math.round(sourceFracCol) :\n                                    Math.floor(sourceFracCol));\n                                if (c === sourceNearestCol) {\n                                    accum += dyValues[dyCOffset + d];\n                                }\n                            }\n                        }\n                        output[colOffset + d] = accum;\n                    }\n                }\n            }\n        }\n        return ops.tensor4d(output, x.shape, x.dtype);\n    };\n    MathBackendCPU.prototype.batchNormalization = function (x, mean, variance, varianceEpsilon, scale, offset) {\n        cpu_util_1.assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n        var xVals = this.readSync(x.dataId);\n        var mVals = this.readSync(mean.dataId);\n        var varVals = this.readSync(variance.dataId);\n        var sVals = scale ? this.readSync(scale.dataId) :\n            new Float32Array([1]);\n        var offVals = offset ? this.readSync(offset.dataId) :\n            new Float32Array([0]);\n        var outVals = new Float32Array(xVals.length);\n        var offValsLength = offVals.length;\n        var sValsLength = sVals.length;\n        var varValsLength = varVals.length;\n        var mValsLength = mVals.length;\n        var offi = 0;\n        var mi = 0;\n        var si = 0;\n        var vi = 0;\n        for (var i = 0; i < xVals.length; ++i) {\n            outVals[i] = offVals[offi++] +\n                (xVals[i] - mVals[mi++]) * sVals[si++] /\n                    Math.sqrt(varVals[vi++] + varianceEpsilon);\n            if (offi >= offValsLength) {\n                offi = 0;\n            }\n            if (mi >= mValsLength) {\n                mi = 0;\n            }\n            if (si >= sValsLength) {\n                si = 0;\n            }\n            if (vi >= varValsLength) {\n                vi = 0;\n            }\n        }\n        return ops_1.tensor4d(outVals, x.shape);\n    };\n    MathBackendCPU.prototype.localResponseNormalization4D = function (x, depthRadius, bias, alpha, beta) {\n        cpu_util_1.assertNotComplex(x, 'localResponseNormalization4D');\n        var channels = x.shape[3];\n        var maxD = channels - 1;\n        var xValues = this.readSync(x.dataId);\n        var size = x.size;\n        var result = new Float32Array(size);\n        function sumAcrossChannels(offset) {\n            var currentChannel = offset % channels;\n            var beginSumOffset = offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n            var endSumOffset = offset - currentChannel +\n                Math.min(currentChannel + depthRadius, maxD);\n            var sum = 0.0;\n            for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n                var z = xValues[beginSumOffset];\n                sum += z * z;\n            }\n            return sum;\n        }\n        for (var offset = 0; offset < size; offset++) {\n            var sum = sumAcrossChannels(offset);\n            var val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n            result[offset] = val;\n        }\n        return ops.tensor4d(result, x.shape);\n    };\n    MathBackendCPU.prototype.LRNGrad = function (dy, inputImage, outputImage, depthRadius, bias, alpha, beta) {\n        cpu_util_1.assertNotComplex(dy, 'LRNGrad');\n        var channels = dy.shape[3];\n        var dyValues = this.readSync(dy.dataId);\n        var inputImageValues = this.readSync(inputImage.dataId);\n        var outputImageValues = this.readSync(outputImage.dataId);\n        var result = new Float32Array(dy.size);\n        var size = dy.size;\n        for (var offset = 0; offset < size; offset++) {\n            var currentChannel = offset % channels;\n            var depthBegin = (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n            var depthEnd = (offset - currentChannel) +\n                Math.min(channels, currentChannel + depthRadius + 1);\n            var norm = 0;\n            for (var k = depthBegin; k < depthEnd; k++) {\n                norm += Math.pow(inputImageValues[k], 2);\n            }\n            norm = alpha * norm + bias;\n            for (var k = depthBegin; k < depthEnd; k++) {\n                var dyi = -2 * alpha * beta * inputImageValues[k] *\n                    outputImageValues[offset] / norm;\n                if (offset === k) {\n                    dyi += Math.pow(norm, -beta);\n                }\n                dyi *= dyValues[offset];\n                result[k] += dyi;\n            }\n        }\n        return ops.tensor4d(result, dy.shape);\n    };\n    MathBackendCPU.prototype.multinomial = function (logits, normalized, numSamples, seed) {\n        cpu_util_1.assertNotComplex(logits, 'multinomial');\n        var probabilities = normalized ? logits : ops.softmax(logits);\n        var batchSize = probabilities.shape[0];\n        var numEvents = probabilities.shape[1];\n        var res = ops.zeros([batchSize, numSamples], 'int32');\n        var resVals = this.readSync(res.dataId);\n        var probVals = this.readSync(probabilities.dataId);\n        for (var b = 0; b < batchSize; ++b) {\n            var offset = b * numEvents;\n            // The cdf won't include the last event. It will be implicit if no other\n            // event happened.\n            var cdf = new Float32Array(numEvents - 1);\n            cdf[0] = probVals[offset];\n            for (var event_1 = 1; event_1 < cdf.length; ++event_1) {\n                cdf[event_1] = cdf[event_1 - 1] + probVals[offset + event_1];\n            }\n            var random = seedrandom.alea(seed.toString());\n            var outOffset = b * numSamples;\n            for (var sampleId = 0; sampleId < numSamples; ++sampleId) {\n                var r = random();\n                // Assume last event happened by default.\n                resVals[outOffset + sampleId] = cdf.length;\n                for (var event_2 = 0; event_2 < cdf.length; event_2++) {\n                    if (r < cdf[event_2]) {\n                        resVals[outOffset + sampleId] = event_2;\n                        break;\n                    }\n                }\n            }\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.oneHot = function (indices, depth, onValue, offValue) {\n        cpu_util_1.assertNotComplex(indices, 'oneHot');\n        var res = new Float32Array(indices.size * depth);\n        res.fill(offValue);\n        var indicesVal = this.readSync(indices.dataId);\n        for (var event_3 = 0; event_3 < indices.size; ++event_3) {\n            if (indicesVal[event_3] >= 0 && indicesVal[event_3] < depth) {\n                res[event_3 * depth + indicesVal[event_3]] = onValue;\n            }\n        }\n        return ops.tensor2d(res, [indices.size, depth], 'int32');\n    };\n    MathBackendCPU.prototype.nonMaxSuppression = function (boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n        cpu_util_1.assertNotComplex(boxes, 'nonMaxSuppression');\n        var boxesVals = this.readSync(boxes.dataId);\n        var scoresVals = this.readSync(scores.dataId);\n        return non_max_suppression_impl_1.nonMaxSuppressionV3(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n    };\n    MathBackendCPU.prototype.fft = function (x) {\n        return this.fftBatch(x, false);\n    };\n    MathBackendCPU.prototype.ifft = function (x) {\n        return this.fftBatch(x, true);\n    };\n    /**\n     * Calculate FFT of inner most elements of batch tensor.\n     */\n    MathBackendCPU.prototype.fftBatch = function (x, inverse) {\n        var batch = x.shape[0];\n        var innerDim = x.shape[1];\n        // Collects real and imaginary values separately.\n        var realResult = ops.buffer(x.shape, 'float32');\n        var imagResult = ops.buffer(x.shape, 'float32');\n        var real = ops.real(x).as2D(batch, innerDim);\n        var imag = ops.imag(x).as2D(batch, innerDim);\n        for (var b = 0; b < batch; b++) {\n            // TODO: Support slice ops for complex type.\n            var r = real.slice([b, 0], [1, innerDim]);\n            var i = imag.slice([b, 0], [1, innerDim]);\n            var input = ops.complex(r, i);\n            // Run FFT by batch element.\n            var res = this.readSync(this.fftImpl(input, inverse).dataId);\n            for (var d = 0; d < innerDim; d++) {\n                var c = complex_util.getComplexWithIndex(res, d);\n                realResult.values[b * innerDim + d] = c.real;\n                imagResult.values[b * innerDim + d] = c.imag;\n            }\n        }\n        var t = ops.complex(realResult.toTensor(), imagResult.toTensor());\n        return t.as2D(batch, innerDim);\n    };\n    MathBackendCPU.prototype.fftImpl = function (x, inverse) {\n        var x1D = x.as1D();\n        var n = x1D.size;\n        if (this.isExponentOf2(n)) {\n            var result = this.fftRadix2(x1D, n, inverse).as2D(x.shape[0], x.shape[1]);\n            if (inverse) {\n                result = ops.complex(ops.real(result).div(ops_1.scalar(n)), ops.imag(result).div(ops_1.scalar(n)));\n            }\n            return result;\n        }\n        else {\n            var data = this.readSync(x.dataId);\n            var rawOutput = this.fourierTransformByMatmul(data, n, inverse);\n            var output = complex_util.splitRealAndImagArrays(rawOutput);\n            return ops.complex(output.real, output.imag).as2D(x.shape[0], x.shape[1]);\n        }\n    };\n    MathBackendCPU.prototype.isExponentOf2 = function (size) {\n        return (size & size - 1) === 0;\n    };\n    // FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\n    MathBackendCPU.prototype.fftRadix2 = function (input, size, inverse) {\n        if (size === 1) {\n            return input;\n        }\n        var data = this.readSync(input.dataId);\n        var half = size / 2;\n        var evenComplex = complex_util.complexWithEvenIndex(data);\n        var evenTensor = ops.complex(evenComplex.real, evenComplex.imag).as1D();\n        var oddComplex = complex_util.complexWithOddIndex(data);\n        var oddTensor = ops.complex(oddComplex.real, oddComplex.imag).as1D();\n        // Recursive call for half part of original input.\n        evenTensor = this.fftRadix2(evenTensor, half, inverse);\n        oddTensor = this.fftRadix2(oddTensor, half, inverse);\n        var e = complex_util.exponents(size, inverse);\n        var exponent = ops.complex(e.real, e.imag).mul(oddTensor);\n        var addPart = evenTensor.add(exponent);\n        var subPart = evenTensor.sub(exponent);\n        var realTensor = ops.real(addPart).concat(ops.real(subPart));\n        var imagTensor = ops.imag(addPart).concat(ops.imag(subPart));\n        return ops.complex(realTensor, imagTensor).as1D();\n    };\n    // Calculate fourier transform by multplying sinusoid matrix.\n    MathBackendCPU.prototype.fourierTransformByMatmul = function (data, size, inverse) {\n        var ret = new Float32Array(size * 2);\n        // TODO: Use matmul instead once it supports complex64 type.\n        for (var r = 0; r < size; r++) {\n            var real_2 = 0.0;\n            var imag_2 = 0.0;\n            for (var c = 0; c < size; c++) {\n                var e = complex_util.exponent(r * c, size, inverse);\n                var term = complex_util.getComplexWithIndex(data, c);\n                real_2 += term.real * e.real - term.imag * e.imag;\n                imag_2 += term.real * e.imag + term.imag * e.real;\n            }\n            if (inverse) {\n                real_2 /= size;\n                imag_2 /= size;\n            }\n            complex_util.assignToTypedArray(ret, real_2, imag_2, r);\n        }\n        return ret;\n    };\n    MathBackendCPU.prototype.depthToSpace = function (x, blockSize, dataFormat) {\n        util.assert(dataFormat === 'NHWC', function () { return \"Only NHWC dataFormat supported on CPU for depthToSpace. Got \" + dataFormat; });\n        util.assert(blockSize > 1, function () {\n            return \"blockSize should be > 1 for depthToSpace, but was: \" + blockSize;\n        });\n        var batchSize = x.shape[0];\n        var inputHeight = x.shape[1];\n        var inputWidth = x.shape[2];\n        var inputDepth = x.shape[3];\n        var outputHeight = inputHeight * blockSize;\n        var outputWidth = inputWidth * blockSize;\n        var outputDepth = inputDepth / (blockSize * blockSize);\n        var xValues = this.readSync(x.dataId);\n        var result = new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n        var outputIdx = 0;\n        for (var b = 0; b < batchSize; ++b) {\n            for (var h = 0; h < outputHeight; ++h) {\n                var inH = Math.floor(h / blockSize);\n                var offsetH = (h % blockSize);\n                for (var w = 0; w < outputWidth; ++w) {\n                    var inW = Math.floor(w / blockSize);\n                    var offsetW = (w % blockSize);\n                    var offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n                    for (var d = 0; d < outputDepth; ++d) {\n                        var inD = d + offsetD;\n                        var inputIdx = inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n                        result[outputIdx++] = xValues[inputIdx];\n                    }\n                }\n            }\n        }\n        return ops.tensor4d(result, [batchSize, outputHeight, outputWidth, outputDepth]);\n    };\n    MathBackendCPU.prototype.broadcastedBinaryOp = function (a, b, dtype, op) {\n        var newShape = broadcast_util.assertAndGetBroadcastShape(a.shape, b.shape);\n        var result = ops.buffer(newShape, dtype);\n        var aVals = this.readSync(a.dataId);\n        var bVals = this.readSync(b.dataId);\n        var aBroadcastDims = broadcast_util.getBroadcastDims(a.shape, newShape);\n        var bBroadcastDims = broadcast_util.getBroadcastDims(b.shape, newShape);\n        var resVals = result.values;\n        if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n            for (var i = 0; i < resVals.length; ++i) {\n                resVals[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n            }\n        }\n        else {\n            var aBuf = this.bufferSync(a);\n            var bBuf = this.bufferSync(b);\n            var _loop_2 = function (i) {\n                var loc = result.indexToLoc(i);\n                var aLoc = loc.slice(-a.rank);\n                aBroadcastDims.forEach(function (d) { return aLoc[d] = 0; });\n                var aIndex = aBuf.locToIndex(aLoc);\n                var bLoc = loc.slice(-b.rank);\n                bBroadcastDims.forEach(function (d) { return bLoc[d] = 0; });\n                var bIndex = bBuf.locToIndex(bLoc);\n                resVals[i] = op(aVals[aIndex], bVals[bIndex]);\n            };\n            for (var i = 0; i < resVals.length; ++i) {\n                _loop_2(i);\n            }\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.broadcastedBinaryComplexOp = function (a, b, op) {\n        var newShape = broadcast_util.assertAndGetBroadcastShape(a.shape, b.shape);\n        var realResult = ops.buffer(newShape, 'float32');\n        var imagResult = ops.buffer(newShape, 'float32');\n        var aVals = this.readSync(a.dataId);\n        var bVals = this.readSync(b.dataId);\n        var aBroadcastDims = broadcast_util.getBroadcastDims(a.shape, newShape);\n        var bBroadcastDims = broadcast_util.getBroadcastDims(b.shape, newShape);\n        var realVals = realResult.values;\n        var imagVals = imagResult.values;\n        if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n            for (var i = 0; i < realVals.length; i++) {\n                var aIdx = i % aVals.length;\n                var bIdx = i % bVals.length;\n                var result = op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2], bVals[bIdx * 2 + 1]);\n                realVals[i] = result.real;\n                imagVals[i] = result.imag;\n            }\n        }\n        else {\n            var aRealBuf = this.bufferSync(this.data.get(a.dataId).complexTensors.real);\n            var bRealBuf = this.bufferSync(this.data.get(b.dataId).complexTensors.real);\n            var _loop_3 = function (i) {\n                var loc = realResult.indexToLoc(i);\n                var aLoc = loc.slice(-a.rank);\n                aBroadcastDims.forEach(function (d) { return aLoc[d] = 0; });\n                var aIndex = aRealBuf.locToIndex(aLoc);\n                var bLoc = loc.slice(-b.rank);\n                bBroadcastDims.forEach(function (d) { return bLoc[d] = 0; });\n                var bIndex = bRealBuf.locToIndex(bLoc);\n                var opResult = op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2], bVals[bIndex * 2 + 1]);\n                realVals[i] = opResult.real;\n                imagVals[i] = opResult.imag;\n            };\n            for (var i = 0; i < realVals.length; i++) {\n                _loop_3(i);\n            }\n        }\n        return this.complex(realResult.toTensor(), imagResult.toTensor());\n    };\n    MathBackendCPU.prototype.split = function (x, sizeSplits, axis) {\n        return split_shared_1.split(x, sizeSplits, axis);\n    };\n    MathBackendCPU.prototype.dispose = function () { };\n    MathBackendCPU.prototype.floatPrecision = function () {\n        return 32;\n    };\n    /** Returns the smallest representable number.  */\n    MathBackendCPU.prototype.epsilon = function () {\n        return backend_1.EPSILON_FLOAT32;\n    };\n    MathBackendCPU.prototype.cropAndResize = function (images, boxes, boxIndex, cropSize, method, extrapolationValue) {\n        var _a = images.shape, batch = _a[0], imageHeight = _a[1], imageWidth = _a[2], numChannels = _a[3];\n        var numBoxes = boxes.shape[0];\n        var cropHeight = cropSize[0], cropWidth = cropSize[1];\n        var output = ops.buffer([numBoxes, cropHeight, cropWidth, numChannels], 'float32');\n        var boxVals = this.readSync(boxes.dataId);\n        var boxIndVals = this.readSync(boxIndex.dataId);\n        var imageVals = this.readSync(images.dataId);\n        var inStride = images.strides; // to calculate flat indexes into image\n        var outStride = output.strides; // to calculate flat indexes into output\n        // Reference implementation\n        // tslint:disable-next-line:max-line-length\n        // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n        for (var b = 0; b < numBoxes; b++) {\n            var startInd = b * 4;\n            var y1 = boxVals[startInd];\n            var x1 = boxVals[startInd + 1];\n            var y2 = boxVals[startInd + 2];\n            var x2 = boxVals[startInd + 3];\n            var bInd = boxIndVals[b];\n            if (bInd >= batch) {\n                continue;\n            }\n            var heightScale = (cropHeight > 1) ?\n                (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) :\n                0;\n            var widthScale = (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n            for (var y = 0; y < cropHeight; y++) {\n                var yInd = (cropHeight > 1) ?\n                    y1 * (imageHeight - 1) + y * (heightScale) :\n                    0.5 * (y1 + y2) * (imageHeight - 1);\n                if (yInd < 0 || yInd > imageHeight - 1) {\n                    for (var x = 0; x < cropWidth; x++) {\n                        for (var c = 0; c < numChannels; c++) {\n                            var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                            output.values[ind] = extrapolationValue;\n                        }\n                    }\n                    continue;\n                }\n                if (method === 'bilinear') {\n                    var topInd = Math.floor(yInd);\n                    var bottomInd = Math.ceil(yInd);\n                    var yLerp = yInd - topInd;\n                    for (var x = 0; x < cropWidth; x++) {\n                        var xInd = (cropWidth > 1) ?\n                            x1 * (imageWidth - 1) + x * widthScale :\n                            0.5 * (x1 + x2) * (imageWidth - 1);\n                        if (xInd < 0 || xInd > imageWidth - 1) {\n                            for (var c = 0; c < numChannels; c++) {\n                                var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                                output.values[ind] = extrapolationValue;\n                            }\n                            continue;\n                        }\n                        var leftInd = Math.floor(xInd);\n                        var rightInd = Math.ceil(xInd);\n                        var xLerp = xInd - leftInd;\n                        for (var c = 0; c < numChannels; c++) {\n                            var ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                                bInd * inStride[0];\n                            var topLeft = imageVals[ind];\n                            ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                                bInd * inStride[0];\n                            var topRight = imageVals[ind];\n                            ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                                bInd * inStride[0];\n                            var bottomLeft = imageVals[ind];\n                            ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                                bInd * inStride[0];\n                            var bottomRight = imageVals[ind];\n                            var top_2 = topLeft + (topRight - topLeft) * xLerp;\n                            var bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n                            ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                            output.values[ind] = top_2 + ((bottom - top_2) * yLerp);\n                        }\n                    }\n                }\n                else { // method == \"nearest\"\n                    for (var x = 0; x < cropWidth; ++x) {\n                        var xInd = (cropWidth > 1) ?\n                            x1 * (imageWidth - 1) + x * widthScale :\n                            0.5 * (x1 + x2) * (imageWidth - 1);\n                        if (xInd < 0 || xInd > imageWidth - 1) {\n                            for (var c = 0; c < numChannels; c++) {\n                                var ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                                output.values[ind] = extrapolationValue;\n                            }\n                            continue;\n                        }\n                        var closestX = Math.round(xInd);\n                        var closestY = Math.round(yInd);\n                        for (var c = 0; c < numChannels; c++) {\n                            var inInd = c + closestX * inStride[2] +\n                                closestY * inStride[1] + bInd * inStride[0];\n                            var outInd = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                            output.values[outInd] = imageVals[inInd];\n                        }\n                    }\n                }\n            }\n        }\n        return output.toTensor();\n    };\n    MathBackendCPU.prototype.sparseToDense = function (sparseIndices, sparseValues, outputShape, defaultValue) {\n        var _a = scatter_nd_util.calculateShapes(sparseValues, sparseIndices, outputShape), sliceRank = _a.sliceRank, numUpdates = _a.numUpdates, sliceSize = _a.sliceSize, strides = _a.strides, outputSize = _a.outputSize;\n        var sumDupeIndices = false;\n        return this.scatter(sparseIndices, sparseValues, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices);\n    };\n    MathBackendCPU.prototype.gatherND = function (x, indices) {\n        var indicesShape = indices.shape;\n        var sliceRank = indicesShape[indicesShape.length - 1];\n        var _a = gather_nd_util.prepareAndValidate(x, indices), resultShape = _a[0], numSlices = _a[1], sliceSize = _a[2], strides = _a[3];\n        if (numSlices === 0) {\n            return ops_1.tensor([], resultShape, x.dtype);\n        }\n        var buffer = new tensor_1.TensorBuffer([numSlices, sliceSize], x.dtype);\n        var indicesData = this.readSync(indices.dataId);\n        var xData = this.readSync(x.dataId);\n        for (var i = 0; i < numSlices; i++) {\n            var index = [];\n            var flattenIndex = 0;\n            for (var j = 0; j < sliceRank; j++) {\n                var dim = indicesData[i * sliceRank + j];\n                flattenIndex += dim * strides[j];\n                index.push(dim);\n            }\n            if (flattenIndex < 0 || flattenIndex >= x.size / sliceSize) {\n                throw new Error(\"Invalid indices: \" + index + \" does not index into \" + x.shape);\n            }\n            for (var k = 0; k < sliceSize; k++) {\n                buffer.values[i * sliceSize + k] = xData[flattenIndex * sliceSize + k];\n            }\n        }\n        return buffer.toTensor().reshape(resultShape);\n    };\n    MathBackendCPU.prototype.scatterND = function (indices, updates, shape) {\n        var _a = scatter_nd_util.calculateShapes(updates, indices, shape), sliceRank = _a.sliceRank, numUpdates = _a.numUpdates, sliceSize = _a.sliceSize, strides = _a.strides, outputSize = _a.outputSize;\n        var defaultValue = ops_1.scalar(0);\n        var sumDupeIndices = true;\n        return this.scatter(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices);\n    };\n    MathBackendCPU.prototype.fill = function (shape, value, dtype) {\n        dtype = dtype || util_1.inferDtype(value);\n        var values = util_1.getArrayFromDType(dtype, util_1.sizeFromShape(shape));\n        values.fill(value);\n        return engine_1.ENGINE.makeTensor(values, shape, dtype, this);\n    };\n    MathBackendCPU.prototype.onesLike = function (x) {\n        if (x.dtype === 'string') {\n            throw new Error('onesLike is not supported for string tensors');\n        }\n        else {\n            return this.fill(x.shape, 1, x.dtype);\n        }\n    };\n    MathBackendCPU.prototype.zerosLike = function (x) {\n        var values = util_1.getArrayFromDType(x.dtype, util_1.sizeFromShape(x.shape));\n        return this.makeOutput(values, x.shape, x.dtype);\n    };\n    MathBackendCPU.prototype.linspace = function (start, stop, num) {\n        return backend_util.linspaceImpl(start, stop, num);\n    };\n    MathBackendCPU.prototype.scatter = function (indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {\n        var flattenShape = [outputSize / sliceSize, sliceSize];\n        var indicesData = this.readSync(indices.dataId);\n        var updatesData = this.readSync(updates.dataId);\n        if (outputSize === 0) {\n            return ops_1.tensor([], shape, updates.dtype);\n        }\n        var buffer = new tensor_1.TensorBuffer(flattenShape, updates.dtype);\n        buffer.values.fill(this.readSync(defaultValue.dataId)[0]);\n        for (var i = 0; i < numUpdates; i++) {\n            var index = [];\n            var flattenIndex = 0;\n            for (var j = 0; j < sliceRank; j++) {\n                var dim = indicesData[i * sliceRank + j];\n                index.push(dim);\n                flattenIndex += dim * strides[j];\n            }\n            if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n                throw new Error(\"Invalid indices: \" + index + \" does not index into \" + shape);\n            }\n            for (var k = 0; k < sliceSize; k++) {\n                if (sumDupeIndices) {\n                    buffer.values[flattenIndex * sliceSize + k] +=\n                        updatesData[i * sliceSize + k];\n                }\n                else {\n                    buffer.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n                        updatesData[0] :\n                        updatesData[i * sliceSize + k];\n                }\n            }\n        }\n        return buffer.toTensor().reshape(shape);\n    };\n    return MathBackendCPU;\n}(backend_1.KernelBackend));\nexports.MathBackendCPU = MathBackendCPU;\nengine_1.ENGINE.registerBackend('cpu', function () { return new MathBackendCPU(); }, 1 /* priority */);\n//# sourceMappingURL=backend_cpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/backend_cpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/cpu_util.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/cpu_util.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nfunction assertNotComplex(tensor, opName) {\n    if (!Array.isArray(tensor)) {\n        tensor = [tensor];\n    }\n    tensor.forEach(function (t) {\n        if (t != null) {\n            util_1.assert(t.dtype !== 'complex64', function () { return opName + \" does not support complex64 tensors.\"; });\n        }\n    });\n}\nexports.assertNotComplex = assertNotComplex;\n//# sourceMappingURL=cpu_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/cpu_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/NonMaxSuppressionV5.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/NonMaxSuppressionV5.js ***!
  \*********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar kernel_names_1 = __webpack_require__(/*! ../../../kernel_names */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js\");\nvar non_max_suppression_impl_1 = __webpack_require__(/*! ../../non_max_suppression_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js\");\nvar cpu_util_1 = __webpack_require__(/*! ../cpu_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/cpu_util.js\");\nexports.nonMaxSuppressionV5Config = {\n    kernelName: kernel_names_1.NonMaxSuppressionV5,\n    backendName: 'cpu',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, backend = _a.backend, attrs = _a.attrs;\n        var _b = inputs, boxes = _b.boxes, scores = _b.scores;\n        var _c = attrs, maxOutputSize = _c.maxOutputSize, iouThreshold = _c.iouThreshold, scoreThreshold = _c.scoreThreshold, softNmsSigma = _c.softNmsSigma;\n        var cpuBackend = backend;\n        cpu_util_1.assertNotComplex(boxes, 'NonMaxSuppressionWithScore');\n        var boxesVals = cpuBackend.data.get(boxes.dataId).values;\n        var scoresVals = cpuBackend.data.get(scores.dataId).values;\n        var maxOutputSizeVal = maxOutputSize;\n        var iouThresholdVal = iouThreshold;\n        var scoreThresholdVal = scoreThreshold;\n        var softNmsSigmaVal = softNmsSigma;\n        var _d = non_max_suppression_impl_1.nonMaxSuppressionV5(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal), selectedIndices = _d.selectedIndices, selectedScores = _d.selectedScores;\n        return [selectedIndices, selectedScores];\n    }\n};\n//# sourceMappingURL=NonMaxSuppressionV5.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/NonMaxSuppressionV5.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/Square.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/Square.js ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar kernel_names_1 = __webpack_require__(/*! ../../../kernel_names */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js\");\nvar cpu_util_1 = __webpack_require__(/*! ../cpu_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/cpu_util.js\");\nexports.squareConfig = {\n    kernelName: kernel_names_1.Square,\n    backendName: 'cpu',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, backend = _a.backend;\n        var x = inputs.x;\n        var cpuBackend = backend;\n        cpu_util_1.assertNotComplex(x, 'square');\n        var values = cpuBackend.data.get(x.dataId).values;\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = value * value;\n        }\n        var dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n        return { dataId: dataId, shape: x.shape, dtype: x.dtype };\n    }\n};\n//# sourceMappingURL=Square.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/Square.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/SquaredDifference.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/SquaredDifference.js ***!
  \*******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar kernel_names_1 = __webpack_require__(/*! ../../../kernel_names */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js\");\nvar cpu_util_1 = __webpack_require__(/*! ../cpu_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/cpu_util.js\");\nvar kernel_utils_1 = __webpack_require__(/*! ../utils/kernel_utils */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/utils/kernel_utils.js\");\nexports.squaredDifferenceConfig = {\n    kernelName: kernel_names_1.SquaredDifference,\n    backendName: 'cpu',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, backend = _a.backend;\n        var _b = inputs, a = _b.a, b = _b.b;\n        var cpuBackend = backend;\n        cpu_util_1.assertNotComplex([a, b], kernel_names_1.SquaredDifference);\n        var aVals = cpuBackend.data.get(a.dataId).values;\n        var bVals = cpuBackend.data.get(b.dataId).values;\n        var _c = kernel_utils_1.broadcastedBinaryOp(a.shape, b.shape, aVals, bVals, a.dtype, function (aVal, bVal) {\n            var diff = aVal - bVal;\n            return diff * diff;\n        }), resultData = _c[0], resultShape = _c[1];\n        var dataId = cpuBackend.write(resultData, resultShape, a.dtype);\n        return { dataId: dataId, shape: resultShape, dtype: a.dtype };\n    }\n};\n//# sourceMappingURL=SquaredDifference.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/SquaredDifference.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/register_all_kernels.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/register_all_kernels.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// We explicitly import the modular kernels so they get registered in the\n// global registry when we compile the library. A modular build would replace\n// the contents of this file and import only the kernels that are needed.\nvar kernel_registry_1 = __webpack_require__(/*! ../../kernel_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js\");\nvar NonMaxSuppressionV5_1 = __webpack_require__(/*! ./kernels/NonMaxSuppressionV5 */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/NonMaxSuppressionV5.js\");\nvar Square_1 = __webpack_require__(/*! ./kernels/Square */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/Square.js\");\nvar SquaredDifference_1 = __webpack_require__(/*! ./kernels/SquaredDifference */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/kernels/SquaredDifference.js\");\n// List all kernel configs here\nvar kernelConfigs = [\n    NonMaxSuppressionV5_1.nonMaxSuppressionV5Config,\n    Square_1.squareConfig,\n    SquaredDifference_1.squaredDifferenceConfig,\n];\nfor (var _i = 0, kernelConfigs_1 = kernelConfigs; _i < kernelConfigs_1.length; _i++) {\n    var kernelConfig = kernelConfigs_1[_i];\n    kernel_registry_1.registerKernel(kernelConfig);\n}\n//# sourceMappingURL=register_all_kernels.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/register_all_kernels.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/utils/kernel_utils.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/utils/kernel_utils.js ***!
  \************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar backend_util = __webpack_require__(/*! ../../../backends/backend_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js\");\nvar util = __webpack_require__(/*! ../../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nfunction broadcastedBinaryOp(aShape, bShape, aVals, bVals, dtype, op) {\n    var newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    var resultRank = newShape.length;\n    var resultStrides = util.computeStrides(newShape);\n    var resultSize = util.sizeFromShape(newShape);\n    var result = util.getTypedArrayFromDType(dtype, resultSize);\n    var aRank = aShape.length;\n    var bRank = bShape.length;\n    var aStrides = util.computeStrides(aShape);\n    var bStrides = util.computeStrides(bShape);\n    var aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    var bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n        for (var i = 0; i < result.length; ++i) {\n            result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n        }\n    }\n    else {\n        var _loop_1 = function (i) {\n            var loc = util.indexToLoc(i, resultRank, resultStrides);\n            var aLoc = loc.slice(-aRank);\n            aBroadcastDims.forEach(function (d) { return aLoc[d] = 0; });\n            var aIndex = util.locToIndex(aLoc, aRank, aStrides);\n            var bLoc = loc.slice(-bRank);\n            bBroadcastDims.forEach(function (d) { return bLoc[d] = 0; });\n            var bIndex = util.locToIndex(bLoc, bRank, bStrides);\n            result[i] = op(aVals[aIndex], bVals[bIndex]);\n        };\n        for (var i = 0; i < result.length; ++i) {\n            _loop_1(i);\n        }\n    }\n    return [result, newShape];\n}\nexports.broadcastedBinaryOp = broadcastedBinaryOp;\n//# sourceMappingURL=kernel_utils.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/utils/kernel_utils.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Implementation of the NonMaxSuppression kernel shared between webgl and cpu.\n */\nvar tensor_ops_1 = __webpack_require__(/*! ../ops/tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\nvar array_util_1 = __webpack_require__(/*! ./array_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/array_util.js\");\nfunction nonMaxSuppressionV3(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    var dummySoftNmsSigma = 0.0;\n    return nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, dummySoftNmsSigma)\n        .selectedIndices;\n}\nexports.nonMaxSuppressionV3 = nonMaxSuppressionV3;\nfunction nonMaxSuppressionV5(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    // For NonMaxSuppressionV5Op, we always return a second output holding\n    // corresponding scores.\n    var returnScoresTensor = true;\n    var result = nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor);\n    result.numValidOutputs.dispose();\n    return {\n        selectedIndices: result.selectedIndices,\n        selectedScores: result.selectedScores\n    };\n}\nexports.nonMaxSuppressionV5 = nonMaxSuppressionV5;\nfunction nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor, padToMaxOutputSize) {\n    if (returnScoresTensor === void 0) { returnScoresTensor = false; }\n    if (padToMaxOutputSize === void 0) { padToMaxOutputSize = false; }\n    // The list is sorted in ascending order, so that we can always pop the\n    // candidate with the largest score in O(1) time.\n    var candidates = Array.from(scores)\n        .map(function (score, boxIndex) { return ({ score: score, boxIndex: boxIndex, suppressBeginIndex: 0 }); })\n        .filter(function (c) { return c.score > scoreThreshold; })\n        .sort(ascendingComparator);\n    // If softNmsSigma is 0, the outcome of this algorithm is exactly same as\n    // before.\n    var scale = softNmsSigma > 0 ? (-0.5 / softNmsSigma) : 0.0;\n    var selectedIndices = [];\n    var selectedScores = [];\n    while (selectedIndices.length < maxOutputSize && candidates.length > 0) {\n        var candidate = candidates.pop();\n        var originalScore = candidate.score, boxIndex = candidate.boxIndex, suppressBeginIndex = candidate.suppressBeginIndex;\n        if (originalScore < scoreThreshold) {\n            break;\n        }\n        // Overlapping boxes are likely to have similar scores, therefore we\n        // iterate through the previously selected boxes backwards in order to\n        // see if candidate's score should be suppressed. We use\n        // suppressBeginIndex to track and ensure a candidate can be suppressed\n        // by a selected box no more than once. Also, if the overlap exceeds\n        // iouThreshold, we simply ignore the candidate.\n        var ignoreCandidate = false;\n        for (var j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {\n            var iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);\n            if (iou >= iouThreshold) {\n                ignoreCandidate = true;\n                break;\n            }\n            candidate.score =\n                candidate.score * suppressWeight(iouThreshold, scale, iou);\n            if (candidate.score <= scoreThreshold) {\n                break;\n            }\n        }\n        // At this point, if `candidate.score` has not dropped below\n        // `scoreThreshold`, then we know that we went through all of the\n        // previous selections and can safely update `suppressBeginIndex` to the\n        // end of the selected array. Then we can re-insert the candidate with\n        // the updated score and suppressBeginIndex back in the candidate list.\n        // If on the other hand, `candidate.score` has dropped below the score\n        // threshold, we will not add it back to the candidates list.\n        candidate.suppressBeginIndex = selectedIndices.length;\n        if (!ignoreCandidate) {\n            // Candidate has passed all the tests, and is not suppressed, so\n            // select the candidate.\n            if (candidate.score === originalScore) {\n                selectedIndices.push(boxIndex);\n                selectedScores.push(candidate.score);\n            }\n            else if (candidate.score > scoreThreshold) {\n                // Candidate's score is suppressed but is still high enough to be\n                // considered, so add back to the candidates list.\n                array_util_1.binaryInsert(candidates, candidate, ascendingComparator);\n            }\n        }\n    }\n    // NonMaxSuppressionV4 feature: padding output to maxOutputSize.\n    var numValidOutputs = selectedIndices.length;\n    if (padToMaxOutputSize) {\n        selectedIndices.fill(0, numValidOutputs);\n        selectedScores.fill(0.0, numValidOutputs);\n    }\n    return {\n        selectedIndices: tensor_ops_1.tensor1d(selectedIndices, 'int32'),\n        selectedScores: tensor_ops_1.tensor1d(selectedScores, 'float32'),\n        numValidOutputs: tensor_ops_1.scalar(numValidOutputs, 'int32')\n    };\n}\nfunction intersectionOverUnion(boxes, i, j) {\n    var iCoord = boxes.subarray(i * 4, i * 4 + 4);\n    var jCoord = boxes.subarray(j * 4, j * 4 + 4);\n    var yminI = Math.min(iCoord[0], iCoord[2]);\n    var xminI = Math.min(iCoord[1], iCoord[3]);\n    var ymaxI = Math.max(iCoord[0], iCoord[2]);\n    var xmaxI = Math.max(iCoord[1], iCoord[3]);\n    var yminJ = Math.min(jCoord[0], jCoord[2]);\n    var xminJ = Math.min(jCoord[1], jCoord[3]);\n    var ymaxJ = Math.max(jCoord[0], jCoord[2]);\n    var xmaxJ = Math.max(jCoord[1], jCoord[3]);\n    var areaI = (ymaxI - yminI) * (xmaxI - xminI);\n    var areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);\n    if (areaI <= 0 || areaJ <= 0) {\n        return 0.0;\n    }\n    var intersectionYmin = Math.max(yminI, yminJ);\n    var intersectionXmin = Math.max(xminI, xminJ);\n    var intersectionYmax = Math.min(ymaxI, ymaxJ);\n    var intersectionXmax = Math.min(xmaxI, xmaxJ);\n    var intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0.0) *\n        Math.max(intersectionXmax - intersectionXmin, 0.0);\n    return intersectionArea / (areaI + areaJ - intersectionArea);\n}\n// A Gaussian penalty function, this method always returns values in [0, 1].\n// The weight is a function of similarity, the more overlap two boxes are, the\n// smaller the weight is, meaning highly overlapping boxe will be significantly\n// penalized. On the other hand, a non-overlapping box will not be penalized.\nfunction suppressWeight(iouThreshold, scale, iou) {\n    var weight = Math.exp(scale * iou * iou);\n    return iou <= iouThreshold ? weight : 0.0;\n}\nfunction ascendingComparator(c1, c2) {\n    // For objects with same scores, we make the object with the larger index go\n    // first. In an array that pops from the end, this means that the object with\n    // the smaller index will be popped first. This ensures the same output as\n    // the TensorFlow python version.\n    return (c1.score - c2.score) ||\n        ((c1.score === c2.score) && (c2.boxIndex - c1.boxIndex));\n}\n//# sourceMappingURL=non_max_suppression_impl.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction getVecChannels(name, rank) {\n    return ['x', 'y', 'z', 'w', 'u', 'v'].slice(0, rank).map(function (d) { return name + \".\" + d; });\n}\nexports.getVecChannels = getVecChannels;\nfunction getChannels(name, rank) {\n    if (rank === 1) {\n        return [name];\n    }\n    return getVecChannels(name, rank);\n}\nexports.getChannels = getChannels;\nfunction getSourceCoords(rank, dims) {\n    if (rank === 1) {\n        return 'rc';\n    }\n    var coords = '';\n    for (var i = 0; i < rank; i++) {\n        coords += dims[i];\n        if (i < rank - 1) {\n            coords += ',';\n        }\n    }\n    return coords;\n}\nexports.getSourceCoords = getSourceCoords;\n//# sourceMappingURL=packing_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/split_shared.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/split_shared.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** Shared implementation of the split kernel across WebGL and CPU. */\nfunction split(x, sizeSplits, axis) {\n    var begin = new Array(x.rank).fill(0);\n    var size = x.shape.slice();\n    return sizeSplits.map(function (s) {\n        size[axis] = s;\n        var slice = x.slice(begin, size);\n        begin[axis] += s;\n        return slice;\n    });\n}\nexports.split = split;\n//# sourceMappingURL=split_shared.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/split_shared.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/tile_impl.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/tile_impl.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * An implementation of the tile kernel shared between webgl and cpu for string\n * tensors only.\n */\nvar array_ops_1 = __webpack_require__(/*! ../ops/array_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js\");\nfunction tile(xBuf, reps) {\n    var newShape = new Array(xBuf.rank);\n    for (var i = 0; i < newShape.length; i++) {\n        newShape[i] = xBuf.shape[i] * reps[i];\n    }\n    var result = array_ops_1.buffer(newShape, xBuf.dtype);\n    for (var i = 0; i < result.values.length; ++i) {\n        var newLoc = result.indexToLoc(i);\n        var originalLoc = new Array(xBuf.rank);\n        for (var j = 0; j < originalLoc.length; j++) {\n            originalLoc[j] = newLoc[j] % xBuf.shape[j];\n        }\n        var originalIndex = xBuf.locToIndex(originalLoc);\n        result.values[i] = xBuf.values[originalIndex];\n    }\n    return result.toTensor();\n}\nexports.tile = tile;\n//# sourceMappingURL=tile_impl.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/tile_impl.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/topk_impl.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/topk_impl.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** An implementation of the TopK kernel shared between webgl and cpu. */\nvar tensor_ops_1 = __webpack_require__(/*! ../ops/tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nfunction topkImpl(x, xShape, xDtype, k, sorted) {\n    // Reshape into a 2d tensor [batch, lastDim] and compute topk along lastDim.\n    var lastDim = xShape[xShape.length - 1];\n    var _a = [x.length / lastDim, lastDim], batch = _a[0], size = _a[1];\n    var allTopKVals = util_1.getTypedArrayFromDType(xDtype, batch * k);\n    var allTopKIndices = util_1.getTypedArrayFromDType('int32', batch * k);\n    for (var b = 0; b < batch; b++) {\n        var offset = b * size;\n        var vals = x.subarray(offset, offset + size);\n        var valAndInd = [];\n        for (var i = 0; i < vals.length; i++) {\n            valAndInd.push({ value: vals[i], index: i });\n        }\n        valAndInd.sort(function (a, b) { return b.value - a.value; });\n        var outOffset = b * k;\n        var topKVals = allTopKVals.subarray(outOffset, outOffset + k);\n        var topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);\n        for (var i = 0; i < k; i++) {\n            topKVals[i] = valAndInd[i].value;\n            topKIndices[i] = valAndInd[i].index;\n        }\n    }\n    // Reshape back to the original input shape, except that the last\n    // dimension is k.\n    var outputShape = xShape.slice();\n    outputShape[outputShape.length - 1] = k;\n    return [\n        tensor_ops_1.tensor(allTopKVals, outputShape, xDtype),\n        tensor_ops_1.tensor(allTopKIndices, outputShape, 'int32')\n    ];\n}\nexports.topkImpl = topkImpl;\n//# sourceMappingURL=topk_impl.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/topk_impl.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/addn_gpu.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/addn_gpu.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar AddNProgram = /** @class */ (function () {\n    function AddNProgram(outputShape, shapes) {\n        this.outputShape = [];\n        this.outputShape = outputShape;\n        this.variableNames = shapes.map(function (_, i) { return \"T\" + i; });\n        var snippets = [];\n        // Get target elements from every input tensor.\n        this.variableNames.forEach(function (variable) {\n            snippets.push(\"float v\" + variable + \" = get\" + variable + \"AtOutCoords();\");\n        });\n        // Calculate the sum of all elements.\n        var operation = this.variableNames\n            .map(function (variable) {\n            return \"v\" + variable;\n        })\n            .join(' + ');\n        this.userCode = \"\\n      void main() {\\n        \" + snippets.join('\\n        ') + \"\\n\\n        float result = \" + operation + \";\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return AddNProgram;\n}());\nexports.AddNProgram = AddNProgram;\n//# sourceMappingURL=addn_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/addn_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/addn_packed_gpu.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/addn_packed_gpu.js ***!
  \***********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar AddNPackedProgram = /** @class */ (function () {\n    function AddNPackedProgram(outputShape, shapes) {\n        this.outputShape = [];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = outputShape;\n        this.variableNames = shapes.map(function (_, i) { return \"T\" + i; });\n        var snippets = [];\n        // Get target elements from every input tensor.\n        this.variableNames.forEach(function (variable) {\n            snippets.push(\"vec4 v\" + variable + \" = get\" + variable + \"AtOutCoords();\");\n        });\n        // Calculate the sum of all elements.\n        var operation = this.variableNames\n            .map(function (variable) {\n            return \"v\" + variable;\n        })\n            .join(' + ');\n        this.userCode = \"\\n      void main() {\\n        \" + snippets.join('\\n        ') + \"\\n\\n        vec4 result = \" + operation + \";\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return AddNPackedProgram;\n}());\nexports.AddNPackedProgram = AddNPackedProgram;\n//# sourceMappingURL=addn_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/addn_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/argminmax_gpu.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/argminmax_gpu.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ArgMinMaxProgram = /** @class */ (function () {\n    function ArgMinMaxProgram(reduceInfo, op, firstPass) {\n        this.variableNames = ['A'];\n        var windowSize = reduceInfo.windowSize;\n        var batchSize = reduceInfo.batchSize;\n        var inSize = reduceInfo.inSize;\n        var outSize = Math.ceil(inSize / windowSize);\n        if (!firstPass) {\n            this.variableNames.push('bestIndicesA');\n        }\n        this.outputShape = [batchSize, outSize];\n        var compOp = (op === 'max') ? '>' : '<';\n        var indexSnippet = firstPass ?\n            'inOffset + i;' :\n            'round(getBestIndicesA(batch, inOffset + i));';\n        this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \" + windowSize + \";\\n\\n        int bestIndex = inOffset;\\n        float bestValue = getA(batch, bestIndex);\\n\\n        for (int i = 0; i < \" + windowSize + \"; i++) {\\n          int inIdx = \" + indexSnippet + \";\\n          float candidate = getA(batch, inIdx);\\n          if (candidate \" + compOp + \" bestValue) {\\n            bestValue = candidate;\\n            bestIndex = inIdx;\\n          }\\n        }\\n        setOutput(float(bestIndex));\\n      }\\n    \";\n    }\n    return ArgMinMaxProgram;\n}());\nexports.ArgMinMaxProgram = ArgMinMaxProgram;\n//# sourceMappingURL=argminmax_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/argminmax_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/argminmax_packed_gpu.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/argminmax_packed_gpu.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar packing_util_1 = __webpack_require__(/*! ../packing_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js\");\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar ArgMinMaxPackedProgram = /** @class */ (function () {\n    function ArgMinMaxPackedProgram(shape, windowSize, op, firstPass) {\n        this.variableNames = ['A'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        util_1.assert(shape.length > 2, function () { return \"Packed arg\" + (op.charAt(0).toUpperCase() +\n            op.slice(1)) + \" supports only inputs with rank above 2.\"; });\n        var inSize = shape[shape.length - 1];\n        var outSize = Math.ceil(inSize / windowSize);\n        this.outputShape = shape.slice(0, -1);\n        if (outSize > 1) {\n            this.outputShape.push(outSize);\n        }\n        if (!firstPass) {\n            this.variableNames.push('bestIndicesA');\n        }\n        var outShape = this.outputShape;\n        var rank = outShape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(rank);\n        var coords = packing_util_1.getChannels('coords', rank);\n        var sourceLocSetup;\n        var sourceRank;\n        if (outSize === 1) {\n            sourceRank = rank + 1;\n            var sourceLocDType = shader_compiler_1.getCoordsDataType(sourceRank);\n            sourceLocSetup = \"\\n        \" + sourceLocDType + \" sourceLocR = \" + sourceLocDType + \"(\" + coords.join() + \", 0);\\n        ++\" + coords[rank - 1] + \";\\n        \" + sourceLocDType + \" sourceLocG = \" + sourceLocDType + \"(\" + coords.join() + \", 0);\\n        ++\" + coords[rank - 2] + \";\\n        \" + sourceLocDType + \" sourceLocA = \" + sourceLocDType + \"(\" + coords.join() + \", 0);\\n        --\" + coords[rank - 1] + \";\\n        \" + sourceLocDType + \" sourceLocB = \" + sourceLocDType + \"(\" + coords.join() + \", 0);\\n        --\" + coords[rank - 2] + \";\";\n        }\n        else {\n            sourceRank = rank;\n            sourceLocSetup = \"\\n        \" + dtype + \" sourceLocR = coords;\\n        ++\" + coords[rank - 1] + \";\\n        \" + dtype + \" sourceLocG = coords;\\n        ++\" + coords[rank - 2] + \";\\n        \" + dtype + \" sourceLocA = coords;\\n        --\" + coords[rank - 1] + \";\\n        \" + dtype + \" sourceLocB = coords;\\n        --\" + coords[rank - 2] + \";\";\n        }\n        var channels = ['x', 'y', 'z', 'w', 'u', 'v'].slice(0, sourceRank);\n        var inChannel = '.' + channels[sourceRank - 1]; // e.g. \".b\" for rank 3.\n        var intChannels = channels.map(function (x) { return 'int ' + x; });\n        var srcRCoords = packing_util_1.getChannels('sourceLocR', sourceRank - 1).concat('inIdx.r');\n        var srcGCoords = packing_util_1.getChannels('sourceLocG', sourceRank - 1).concat('inIdx.g');\n        var srcBCoords = packing_util_1.getChannels('sourceLocB', sourceRank - 1).concat('inIdx.b');\n        var srcACoords = packing_util_1.getChannels('sourceLocA', sourceRank - 1).concat('inIdx.a');\n        var compOp = (op === 'max') ? 'greaterThan' : 'lessThan';\n        var fetchCandidateIdx = firstPass ? '' : \"\\n          inIdx = round(vec4(getBestIndicesAChannel(\" + srcRCoords.join() + \"),\\n                             getBestIndicesAChannel(\" + srcGCoords.join() + \"),\\n                             getBestIndicesAChannel(\" + srcBCoords.join() + \"),\\n                             getBestIndicesAChannel(\" + srcACoords.join() + \")));\";\n        var fetchValue = \"vec4(\\n            getAChannel(\" + srcRCoords.join() + \"),\\n            hasNextCol ? getAChannel(\" + srcGCoords.join() + \") : 0.,\\n            hasNextRow ? getAChannel(\" + srcBCoords.join() + \") : 0.,\\n            hasNextRow && hasNextCol ? getAChannel(\" + srcACoords.join() + \") : 0.)\";\n        var getBestIndicesAChannelSnippet = firstPass ? '' : \"\\n      float getBestIndicesAChannel(\" + intChannels.join() + \") {\\n        return getChannel(getBestIndicesA(\" + channels.join() + \"),\\n                                          vec2(\" + channels.slice(-2).join() + \"));\\n      }\";\n        this.userCode = \"\\n      float getAChannel(\" + intChannels.join() + \") {\\n        return getChannel(getA(\" + channels.join() + \"),\\n                               vec2(\" + channels.slice(-2).join() + \"));\\n      }\\n      \" + getBestIndicesAChannelSnippet + \"\\n      void main() {\\n        \" + dtype + \" coords = getOutputCoords();\\n        bool hasNextCol = \" + coords[rank - 1] + \" < \" + (outShape[rank - 1] - 1) + \";\\n        bool hasNextRow = \" + coords[rank - 2] + \" < \" + (outShape[rank - 2] - 1) + \";\\n        \" + sourceLocSetup + \"\\n        ivec4 srcIdx = ivec4(sourceLocR\" + inChannel + \", sourceLocG\" + inChannel + \",\\n          sourceLocB\" + inChannel + \", sourceLocA\" + inChannel + \") * \" + windowSize + \";\\n        ivec4 inIdx = srcIdx;\\n        vec4 bestIndex = vec4(inIdx);\\n        vec4 bestValue = \" + fetchValue + \";\\n\\n        for (int i = 0; i < \" + windowSize + \"; i++) {\\n          inIdx = srcIdx;\\n          \" + fetchCandidateIdx + \"\\n          vec4 candidate = \" + fetchValue + \";\\n          bvec4 nan = isnan(candidate);\\n          bvec4 replace = bvec4(\\n            vec4(\" + compOp + \"(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\\n\\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\\n                           replace.y  ? candidate.y : bestValue.y,\\n                           replace.z  ? candidate.z : bestValue.z,\\n                           replace.w  ? candidate.w : bestValue.w);\\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\\n          srcIdx++;\\n        }\\n        setOutput(bestIndex);\\n      }\\n    \";\n    }\n    return ArgMinMaxPackedProgram;\n}());\nexports.ArgMinMaxPackedProgram = ArgMinMaxPackedProgram;\n//# sourceMappingURL=argminmax_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/argminmax_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/avg_pool_backprop_gpu.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/avg_pool_backprop_gpu.js ***!
  \*****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar AvgPool2DBackpropProgram = /** @class */ (function () {\n    function AvgPool2DBackpropProgram(convInfo) {\n        this.variableNames = ['dy'];\n        this.outputShape = convInfo.inShape;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var avgMultiplier = 1 / (filterHeight * filterWidth);\n        this.userCode = \"\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n      const float avgMultiplier = float(\" + avgMultiplier + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 dyRCCorner = coords.yz - pads;\\n        int dyRCorner = dyRCCorner.x;\\n        int dyCCorner = dyRCCorner.y;\\n\\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n            wR += \" + dilationHeight + \") {\\n          float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n          if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          for (int wC = 0; wC < \" + effectiveFilterWidth + \";\\n            wC+= \" + dilationWidth + \") {\\n            float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n            if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            float dyValue = getDy(b, idyR, idyC, d);\\n\\n            dotProd += dyValue * avgMultiplier;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return AvgPool2DBackpropProgram;\n}());\nexports.AvgPool2DBackpropProgram = AvgPool2DBackpropProgram;\nvar AvgPool3DBackpropProgram = /** @class */ (function () {\n    function AvgPool3DBackpropProgram(convInfo) {\n        this.variableNames = ['dy'];\n        this.outputShape = convInfo.inShape;\n        var filterDepth = convInfo.filterDepth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n        this.userCode = \"\\n      const ivec3 pads = ivec3(\" + padFront + \", \" + padTop + \", \" + padLeft + \");\\n      const float avgMultiplier = float(\" + avgMultiplier + \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyDCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\\n        // dx(xD, xR, xC, ch).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int wD = 0; wD < \" + effectiveFilterDepth + \";\\n            wD += \" + dilationDepth + \") {\\n          float dyD = float(dyDCorner + wD) / \" + strideDepth + \".0;\\n\\n          if (dyD < 0.0 || dyD >= \" + convInfo.outDepth + \".0 || fract(dyD) > 0.0) {\\n            continue;\\n          }\\n          int idyD = int(dyD);\\n\\n          for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n              wR += \" + dilationHeight + \") {\\n            float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n            if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 ||\\n                fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            for (int wC = 0; wC < \" + effectiveFilterWidth + \";\\n                wC += \" + dilationWidth + \") {\\n              float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n              if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\\n\\n              dotProd += dyValue * avgMultiplier;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return AvgPool3DBackpropProgram;\n}());\nexports.AvgPool3DBackpropProgram = AvgPool3DBackpropProgram;\n//# sourceMappingURL=avg_pool_backprop_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/avg_pool_backprop_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/backend_webgl.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/backend_webgl.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Import webgl flags.\n__webpack_require__(/*! ./flags_webgl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/flags_webgl.js\");\nvar device_util = __webpack_require__(/*! ../../device_util */ \"./node_modules/@tensorflow/tfjs-core/dist/device_util.js\");\nvar engine_1 = __webpack_require__(/*! ../../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar environment_1 = __webpack_require__(/*! ../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar globals_1 = __webpack_require__(/*! ../../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar log_1 = __webpack_require__(/*! ../../log */ \"./node_modules/@tensorflow/tfjs-core/dist/log.js\");\nvar array_ops_1 = __webpack_require__(/*! ../../ops/array_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js\");\nvar array_ops_util = __webpack_require__(/*! ../../ops/array_ops_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js\");\nvar axis_util = __webpack_require__(/*! ../../ops/axis_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js\");\nvar complex_ops_1 = __webpack_require__(/*! ../../ops/complex_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/complex_ops.js\");\nvar concat_util_1 = __webpack_require__(/*! ../../ops/concat_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js\");\nvar gather_nd_util = __webpack_require__(/*! ../../ops/gather_nd_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js\");\nvar reduce_util = __webpack_require__(/*! ../../ops/reduce_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js\");\nvar scatter_nd_util = __webpack_require__(/*! ../../ops/scatter_nd_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js\");\nvar segment_util = __webpack_require__(/*! ../../ops/segment_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js\");\nvar slice_util = __webpack_require__(/*! ../../ops/slice_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js\");\nvar softmax_1 = __webpack_require__(/*! ../../ops/softmax */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ../../ops/tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\nvar types_1 = __webpack_require__(/*! ../../types */ \"./node_modules/@tensorflow/tfjs-core/dist/types.js\");\nvar util = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar util_1 = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar backend_1 = __webpack_require__(/*! ../backend */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/backend.js\");\nvar backend_util = __webpack_require__(/*! ../backend_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js\");\nvar complex_util_1 = __webpack_require__(/*! ../complex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js\");\nvar non_max_suppression_impl_1 = __webpack_require__(/*! ../non_max_suppression_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js\");\nvar split_shared_1 = __webpack_require__(/*! ../split_shared */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/split_shared.js\");\nvar tile_impl_1 = __webpack_require__(/*! ../tile_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/tile_impl.js\");\nvar topk_impl_1 = __webpack_require__(/*! ../topk_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/topk_impl.js\");\nvar where_impl_1 = __webpack_require__(/*! ../where_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js\");\nvar addn_gpu_1 = __webpack_require__(/*! ./addn_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/addn_gpu.js\");\nvar addn_packed_gpu_1 = __webpack_require__(/*! ./addn_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/addn_packed_gpu.js\");\nvar argminmax_gpu_1 = __webpack_require__(/*! ./argminmax_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/argminmax_gpu.js\");\nvar argminmax_packed_gpu_1 = __webpack_require__(/*! ./argminmax_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/argminmax_packed_gpu.js\");\nvar avg_pool_backprop_gpu_1 = __webpack_require__(/*! ./avg_pool_backprop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/avg_pool_backprop_gpu.js\");\nvar batchnorm_gpu_1 = __webpack_require__(/*! ./batchnorm_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/batchnorm_gpu.js\");\nvar batchnorm_packed_gpu_1 = __webpack_require__(/*! ./batchnorm_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/batchnorm_packed_gpu.js\");\nvar binaryop_complex_gpu = __webpack_require__(/*! ./binaryop_complex_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_complex_gpu.js\");\nvar binaryop_complex_gpu_1 = __webpack_require__(/*! ./binaryop_complex_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_complex_gpu.js\");\nvar binaryop_gpu = __webpack_require__(/*! ./binaryop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_gpu.js\");\nvar binaryop_gpu_1 = __webpack_require__(/*! ./binaryop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_gpu.js\");\nvar binaryop_packed_gpu = __webpack_require__(/*! ./binaryop_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_packed_gpu.js\");\nvar binaryop_packed_gpu_1 = __webpack_require__(/*! ./binaryop_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_packed_gpu.js\");\nvar canvas_util_1 = __webpack_require__(/*! ./canvas_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/canvas_util.js\");\nvar clip_gpu_1 = __webpack_require__(/*! ./clip_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/clip_gpu.js\");\nvar clip_packed_gpu_1 = __webpack_require__(/*! ./clip_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/clip_packed_gpu.js\");\nvar complex_abs_gpu_1 = __webpack_require__(/*! ./complex_abs_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/complex_abs_gpu.js\");\nvar concat_gpu_1 = __webpack_require__(/*! ./concat_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/concat_gpu.js\");\nvar concat_packed_gpu_1 = __webpack_require__(/*! ./concat_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/concat_packed_gpu.js\");\nvar conv_backprop_gpu_1 = __webpack_require__(/*! ./conv_backprop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_backprop_gpu.js\");\nvar conv_backprop_gpu_depthwise_1 = __webpack_require__(/*! ./conv_backprop_gpu_depthwise */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_backprop_gpu_depthwise.js\");\nvar conv_gpu_1 = __webpack_require__(/*! ./conv_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_gpu.js\");\nvar conv_gpu_depthwise_1 = __webpack_require__(/*! ./conv_gpu_depthwise */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_gpu_depthwise.js\");\nvar conv_packed_gpu_depthwise_1 = __webpack_require__(/*! ./conv_packed_gpu_depthwise */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_packed_gpu_depthwise.js\");\nvar crop_and_resize_gpu_1 = __webpack_require__(/*! ./crop_and_resize_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/crop_and_resize_gpu.js\");\nvar cumsum_gpu_1 = __webpack_require__(/*! ./cumsum_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/cumsum_gpu.js\");\nvar decode_matrix_gpu_1 = __webpack_require__(/*! ./decode_matrix_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/decode_matrix_gpu.js\");\nvar decode_matrix_packed_gpu_1 = __webpack_require__(/*! ./decode_matrix_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/decode_matrix_packed_gpu.js\");\nvar depth_to_space_gpu_1 = __webpack_require__(/*! ./depth_to_space_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/depth_to_space_gpu.js\");\nvar diag_gpu_1 = __webpack_require__(/*! ./diag_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/diag_gpu.js\");\nvar encode_float_gpu_1 = __webpack_require__(/*! ./encode_float_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_float_gpu.js\");\nvar encode_float_packed_gpu_1 = __webpack_require__(/*! ./encode_float_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_float_packed_gpu.js\");\nvar encode_matrix_gpu_1 = __webpack_require__(/*! ./encode_matrix_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_matrix_gpu.js\");\nvar encode_matrix_packed_gpu_1 = __webpack_require__(/*! ./encode_matrix_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_matrix_packed_gpu.js\");\nvar fft_gpu = __webpack_require__(/*! ./fft_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/fft_gpu.js\");\nvar fft_gpu_1 = __webpack_require__(/*! ./fft_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/fft_gpu.js\");\nvar fill_gpu_1 = __webpack_require__(/*! ./fill_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/fill_gpu.js\");\nvar gather_gpu_1 = __webpack_require__(/*! ./gather_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gather_gpu.js\");\nvar gather_nd_gpu_1 = __webpack_require__(/*! ./gather_nd_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gather_nd_gpu.js\");\nvar gpgpu_context_1 = __webpack_require__(/*! ./gpgpu_context */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_context.js\");\nvar gpgpu_math = __webpack_require__(/*! ./gpgpu_math */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_math.js\");\nvar im2col_packed_gpu_1 = __webpack_require__(/*! ./im2col_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/im2col_packed_gpu.js\");\nvar lrn_gpu_1 = __webpack_require__(/*! ./lrn_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_gpu.js\");\nvar lrn_grad_gpu_1 = __webpack_require__(/*! ./lrn_grad_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_grad_gpu.js\");\nvar lrn_packed_gpu_1 = __webpack_require__(/*! ./lrn_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_packed_gpu.js\");\nvar max_pool_backprop_gpu_1 = __webpack_require__(/*! ./max_pool_backprop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/max_pool_backprop_gpu.js\");\nvar mulmat_packed_gpu_1 = __webpack_require__(/*! ./mulmat_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/mulmat_packed_gpu.js\");\nvar multinomial_gpu_1 = __webpack_require__(/*! ./multinomial_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/multinomial_gpu.js\");\nvar onehot_gpu_1 = __webpack_require__(/*! ./onehot_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/onehot_gpu.js\");\nvar pack_gpu_1 = __webpack_require__(/*! ./pack_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pack_gpu.js\");\nvar pad_gpu_1 = __webpack_require__(/*! ./pad_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pad_gpu.js\");\nvar pad_packed_gpu_1 = __webpack_require__(/*! ./pad_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pad_packed_gpu.js\");\nvar pool_gpu_1 = __webpack_require__(/*! ./pool_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pool_gpu.js\");\nvar reduce_gpu_1 = __webpack_require__(/*! ./reduce_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reduce_gpu.js\");\nvar reshape_packed_gpu_1 = __webpack_require__(/*! ./reshape_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reshape_packed_gpu.js\");\nvar resize_bilinear_backprop_gpu_1 = __webpack_require__(/*! ./resize_bilinear_backprop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_backprop_gpu.js\");\nvar resize_bilinear_gpu_1 = __webpack_require__(/*! ./resize_bilinear_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_gpu.js\");\nvar resize_bilinear_packed_gpu_1 = __webpack_require__(/*! ./resize_bilinear_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_packed_gpu.js\");\nvar resize_nearest_neighbor_backprop_gpu_1 = __webpack_require__(/*! ./resize_nearest_neighbor_backprop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_nearest_neighbor_backprop_gpu.js\");\nvar resize_nearest_neighbor_gpu_1 = __webpack_require__(/*! ./resize_nearest_neighbor_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_nearest_neighbor_gpu.js\");\nvar reverse_gpu_1 = __webpack_require__(/*! ./reverse_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reverse_gpu.js\");\nvar reverse_packed_gpu_1 = __webpack_require__(/*! ./reverse_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reverse_packed_gpu.js\");\nvar scatter_gpu_1 = __webpack_require__(/*! ./scatter_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/scatter_gpu.js\");\nvar segment_gpu_1 = __webpack_require__(/*! ./segment_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/segment_gpu.js\");\nvar select_gpu_1 = __webpack_require__(/*! ./select_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/select_gpu.js\");\nvar slice_gpu_1 = __webpack_require__(/*! ./slice_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/slice_gpu.js\");\nvar slice_packed_gpu_1 = __webpack_require__(/*! ./slice_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/slice_packed_gpu.js\");\nvar strided_slice_gpu_1 = __webpack_require__(/*! ./strided_slice_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/strided_slice_gpu.js\");\nvar tex_util = __webpack_require__(/*! ./tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nvar tex_util_1 = __webpack_require__(/*! ./tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nvar texture_manager_1 = __webpack_require__(/*! ./texture_manager */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/texture_manager.js\");\nvar tile_gpu_1 = __webpack_require__(/*! ./tile_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tile_gpu.js\");\nvar transpose_gpu_1 = __webpack_require__(/*! ./transpose_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/transpose_gpu.js\");\nvar transpose_packed_gpu_1 = __webpack_require__(/*! ./transpose_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/transpose_packed_gpu.js\");\nvar unary_op = __webpack_require__(/*! ./unaryop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_gpu.js\");\nvar unaryop_gpu_1 = __webpack_require__(/*! ./unaryop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_gpu.js\");\nvar unary_packed_op = __webpack_require__(/*! ./unaryop_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_packed_gpu.js\");\nvar unaryop_packed_gpu_1 = __webpack_require__(/*! ./unaryop_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_packed_gpu.js\");\nvar unpack_gpu_1 = __webpack_require__(/*! ./unpack_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unpack_gpu.js\");\nvar webgl_util = __webpack_require__(/*! ./webgl_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/webgl_util.js\");\nvar binaryCaches = {};\nfunction getBinaryCache(webGLVersion) {\n    if (webGLVersion in binaryCaches) {\n        return binaryCaches[webGLVersion];\n    }\n    binaryCaches[webGLVersion] = {};\n    return binaryCaches[webGLVersion];\n}\nexports.getBinaryCache = getBinaryCache;\nfunction mapActivationToShaderProgram(activation, packed) {\n    if (packed === void 0) { packed = false; }\n    if (activation === 'linear') {\n        if (packed) {\n            return unary_packed_op.LINEAR;\n        }\n        return unary_op.LINEAR;\n    }\n    else if (activation === 'relu') {\n        if (packed) {\n            return unary_packed_op.RELU;\n        }\n        return unary_op.RELU;\n    }\n    else if (activation === 'elu') {\n        if (packed) {\n            return unary_packed_op.ELU;\n        }\n        return unary_op.ELU;\n    }\n    else if (activation === 'relu6') {\n        if (packed) {\n            return unary_packed_op.RELU6;\n        }\n        return unary_op.RELU6;\n    }\n    else if (activation === 'prelu') {\n        if (packed) {\n            return binaryop_packed_gpu.PRELU;\n        }\n        return binaryop_gpu.PRELU;\n    }\n    throw new Error(\"Activation \" + activation + \" has not been implemented for the WebGL backend.\");\n}\n// Empirically determined constant used to determine size threshold for handing\n// off execution to the CPU.\nvar CPU_HANDOFF_SIZE_THRESHOLD = 128;\n// Empirically determined constant used to decide the number of MB on GPU\n// before we warn about high memory use. The MB are this constant * screen area\n// * dpi / 1024 / 1024.\nvar BEFORE_PAGING_CONSTANT = 600;\nfunction numMBBeforeWarning() {\n    if (environment_1.env().global.screen == null) {\n        return 1024; // 1 GB.\n    }\n    return (environment_1.env().global.screen.height * environment_1.env().global.screen.width *\n        window.devicePixelRatio) *\n        BEFORE_PAGING_CONSTANT / 1024 / 1024;\n}\n// Empirically determined minimal shared dimension in matmul before we forward\n// to a.mul(b).sum() in order to take advantage of GPU parallelism. See\n// https://github.com/tensorflow/tfjs-core/pull/1379 for benchmarks.\nexports.MATMUL_SHARED_DIM_THRESHOLD = 1000;\nvar MathBackendWebGL = /** @class */ (function (_super) {\n    __extends(MathBackendWebGL, _super);\n    function MathBackendWebGL(gpgpu) {\n        var _this = _super.call(this) || this;\n        // Maps data ids that have a pending read operation, to list of subscribers.\n        _this.pendingRead = new WeakMap();\n        // List of data ids that are scheduled for disposal, but are waiting on a\n        // pending read operation.\n        _this.pendingDisposal = new WeakSet();\n        // Used to count the number of 'shallow' sliced tensors that point to the\n        // same data id.\n        _this.dataRefCount = new WeakMap();\n        _this.numBytesInGPU = 0;\n        // Accumulated time spent (including blocking) in uploading data to webgl.\n        _this.uploadWaitMs = 0;\n        // Accumulated time spent (including blocking in downloading data from webgl.\n        _this.downloadWaitMs = 0;\n        _this.warnedAboutMemory = false;\n        _this.pendingDeletes = 0;\n        _this.disposed = false;\n        if (!environment_1.env().getBool('HAS_WEBGL')) {\n            throw new Error('WebGL is not supported on this device');\n        }\n        if (gpgpu == null) {\n            var gl = canvas_util_1.getWebGLContext(environment_1.env().getNumber('WEBGL_VERSION'));\n            _this.binaryCache = getBinaryCache(environment_1.env().getNumber('WEBGL_VERSION'));\n            _this.gpgpu = new gpgpu_context_1.GPGPUContext(gl);\n            _this.canvas = gl.canvas;\n            _this.gpgpuCreatedLocally = true;\n        }\n        else {\n            _this.gpgpu = gpgpu;\n            _this.binaryCache = {};\n            _this.gpgpuCreatedLocally = false;\n            _this.canvas = gpgpu.gl.canvas;\n        }\n        _this.textureManager = new texture_manager_1.TextureManager(_this.gpgpu);\n        _this.numMBBeforeWarning = numMBBeforeWarning();\n        _this.texData = new backend_1.DataStorage(_this, engine_1.ENGINE);\n        return _this;\n    }\n    MathBackendWebGL.prototype.numDataIds = function () {\n        return this.texData.numDataIds() +\n            (this.cpuBackend ? this.cpuBackend.numDataIds() : 0) -\n            this.pendingDeletes;\n    };\n    MathBackendWebGL.prototype.write = function (values, shape, dtype) {\n        if (environment_1.env().getBool('DEBUG')) {\n            this.checkNumericalProblems(values);\n        }\n        if (dtype === 'complex64' && values != null) {\n            throw new Error(\"Cannot write to a complex64 dtype. \" +\n                \"Please use tf.complex(real, imag).\");\n        }\n        var dataId = {};\n        this.texData.set(dataId, { shape: shape, dtype: dtype, values: values, usage: tex_util_1.TextureUsage.UPLOAD });\n        return dataId;\n    };\n    MathBackendWebGL.prototype.move = function (dataId, values, shape, dtype) {\n        if (environment_1.env().getBool('DEBUG')) {\n            this.checkNumericalProblems(values);\n        }\n        if (dtype === 'complex64') {\n            throw new Error(\"Cannot write to a complex64 dtype. \" +\n                \"Please use tf.complex(real, imag).\");\n        }\n        this.texData.set(dataId, { shape: shape, dtype: dtype, values: values, usage: tex_util_1.TextureUsage.UPLOAD });\n    };\n    MathBackendWebGL.prototype.readSync = function (dataId) {\n        var texData = this.texData.get(dataId);\n        var values = texData.values, dtype = texData.dtype, complexTensors = texData.complexTensors, slice = texData.slice, shape = texData.shape, isPacked = texData.isPacked;\n        if (slice != null) {\n            var program = void 0;\n            if (isPacked) {\n                program = new unaryop_packed_gpu_1.UnaryOpPackedProgram(shape, unary_op.CLONE);\n            }\n            else {\n                program = new unaryop_gpu_1.UnaryOpProgram(shape, unary_op.CLONE);\n            }\n            var res = this.runWebGLProgram(program, [{ dataId: dataId, shape: shape, dtype: dtype }], dtype);\n            var data = this.readSync(res.dataId);\n            this.disposeData(res.dataId);\n            return data;\n        }\n        if (values != null) {\n            return this.convertAndCacheOnCPU(dataId);\n        }\n        if (dtype === 'string') {\n            return values;\n        }\n        var shouldTimeProgram = this.activeTimers != null;\n        var start;\n        if (shouldTimeProgram) {\n            start = util.now();\n        }\n        var result;\n        if (dtype === 'complex64') {\n            var realValues = complexTensors.real.dataSync();\n            var imagValues = complexTensors.imag.dataSync();\n            result = complex_util_1.mergeRealAndImagArrays(realValues, imagValues);\n        }\n        else {\n            result = this.getValuesFromTexture(dataId);\n        }\n        if (shouldTimeProgram) {\n            this.downloadWaitMs += util.now() - start;\n        }\n        return this.convertAndCacheOnCPU(dataId, result);\n    };\n    MathBackendWebGL.prototype.read = function (dataId) {\n        return __awaiter(this, void 0, void 0, function () {\n            var subscribers_1, texData, values, shape, slice, dtype, complexTensors, isPacked, program, res, data, buffer, tmpDownloadTarget, tmpData, vals, ps, realValues, imagValues, size, dTypeVals, subscribers;\n            var _a;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        if (this.pendingRead.has(dataId)) {\n                            subscribers_1 = this.pendingRead.get(dataId);\n                            return [2 /*return*/, new Promise(function (resolve) { return subscribers_1.push(resolve); })];\n                        }\n                        texData = this.texData.get(dataId);\n                        values = texData.values, shape = texData.shape, slice = texData.slice, dtype = texData.dtype, complexTensors = texData.complexTensors, isPacked = texData.isPacked;\n                        if (slice != null) {\n                            program = void 0;\n                            if (isPacked) {\n                                program = new unaryop_packed_gpu_1.UnaryOpPackedProgram(shape, unary_op.CLONE);\n                            }\n                            else {\n                                program = new unaryop_gpu_1.UnaryOpProgram(shape, unary_op.CLONE);\n                            }\n                            res = this.runWebGLProgram(program, [{ dataId: dataId, shape: shape, dtype: dtype }], dtype);\n                            data = this.read(res.dataId);\n                            this.disposeData(res.dataId);\n                            return [2 /*return*/, data];\n                        }\n                        if (values != null) {\n                            return [2 /*return*/, this.convertAndCacheOnCPU(dataId)];\n                        }\n                        if (!environment_1.env().getBool('WEBGL_DOWNLOAD_FLOAT_ENABLED') &&\n                            environment_1.env().getNumber('WEBGL_VERSION') === 2) {\n                            throw new Error(\"tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and \" +\n                                \"WEBGL_VERSION=2 not yet supported.\");\n                        }\n                        buffer = null;\n                        if (dtype !== 'complex64' && environment_1.env().get('WEBGL_BUFFER_SUPPORTED')) {\n                            // Possibly copy the texture into a buffer before inserting a fence.\n                            tmpDownloadTarget = this.decode(dataId);\n                            tmpData = this.texData.get(tmpDownloadTarget.dataId);\n                            buffer = (_a = this.gpgpu).createBufferFromTexture.apply(_a, [tmpData.texture].concat(tex_util.getDenseTexShape(shape)));\n                        }\n                        this.pendingRead.set(dataId, []);\n                        if (!(dtype !== 'complex64')) return [3 /*break*/, 2];\n                        // Create a fence and wait for it to resolve.\n                        return [4 /*yield*/, this.gpgpu.createAndWaitForFence()];\n                    case 1:\n                        // Create a fence and wait for it to resolve.\n                        _b.sent();\n                        _b.label = 2;\n                    case 2:\n                        if (!(dtype === 'complex64')) return [3 /*break*/, 4];\n                        return [4 /*yield*/, Promise.all([complexTensors.real.data(), complexTensors.imag.data()])];\n                    case 3:\n                        ps = _b.sent();\n                        realValues = ps[0];\n                        imagValues = ps[1];\n                        vals = complex_util_1.mergeRealAndImagArrays(realValues, imagValues);\n                        return [3 /*break*/, 5];\n                    case 4:\n                        if (buffer == null) {\n                            vals = this.getValuesFromTexture(dataId);\n                        }\n                        else {\n                            size = util.sizeFromShape(shape);\n                            vals = this.gpgpu.downloadFloat32MatrixFromBuffer(buffer, size);\n                        }\n                        _b.label = 5;\n                    case 5:\n                        if (tmpDownloadTarget != null) {\n                            this.disposeData(tmpDownloadTarget.dataId);\n                        }\n                        dTypeVals = this.convertAndCacheOnCPU(dataId, vals);\n                        subscribers = this.pendingRead.get(dataId);\n                        this.pendingRead.delete(dataId);\n                        // Notify all pending reads.\n                        subscribers.forEach(function (resolve) { return resolve(dTypeVals); });\n                        if (this.pendingDisposal.has(dataId)) {\n                            this.pendingDisposal.delete(dataId);\n                            this.disposeData(dataId);\n                            this.pendingDeletes--;\n                        }\n                        return [2 /*return*/, dTypeVals];\n                }\n            });\n        });\n    };\n    MathBackendWebGL.prototype.checkNumericalProblems = function (values) {\n        if (values == null) {\n            return;\n        }\n        for (var i = 0; i < values.length; i++) {\n            var num = values[i];\n            if (!webgl_util.canBeRepresented(num)) {\n                if (environment_1.env().getBool('WEBGL_RENDER_FLOAT32_CAPABLE')) {\n                    throw Error(\"The value \" + num + \" cannot be represented with your \" +\n                        \"current settings. Consider enabling float32 rendering: \" +\n                        \"'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'\");\n                }\n                throw Error(\"The value \" + num + \" cannot be represented on this device.\");\n            }\n        }\n    };\n    MathBackendWebGL.prototype.getValuesFromTexture = function (dataId) {\n        var _a;\n        var _b = this.texData.get(dataId), shape = _b.shape, dtype = _b.dtype, isPacked = _b.isPacked;\n        var size = util.sizeFromShape(shape);\n        if (environment_1.env().getBool('WEBGL_DOWNLOAD_FLOAT_ENABLED')) {\n            var tmpTarget = this.decode(dataId);\n            var tmpData_1 = this.texData.get(tmpTarget.dataId);\n            var vals_1 = (_a = this.gpgpu).downloadMatrixFromPackedTexture.apply(_a, [tmpData_1.texture].concat(tex_util.getDenseTexShape(shape))).subarray(0, size);\n            this.disposeData(tmpTarget.dataId);\n            return vals_1;\n        }\n        var shouldUsePackedProgram = environment_1.env().getBool('WEBGL_PACK') && isPacked === true;\n        var outputShape = shouldUsePackedProgram ? webgl_util.getShapeAs3D(shape) : shape;\n        var program = shouldUsePackedProgram ?\n            new encode_float_packed_gpu_1.EncodeFloatPackedProgram(outputShape) :\n            new encode_float_gpu_1.EncodeFloatProgram(outputShape);\n        var output = this.runWebGLProgram(program, [{ shape: outputShape, dtype: dtype, dataId: dataId }], 'float32');\n        var tmpData = this.texData.get(output.dataId);\n        var vals = this.gpgpu\n            .downloadByteEncodedFloatMatrixFromOutputTexture(tmpData.texture, tmpData.texShape[0], tmpData.texShape[1])\n            .subarray(0, size);\n        this.disposeData(output.dataId);\n        return vals;\n    };\n    MathBackendWebGL.prototype.time = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            var oldActiveTimers, newActiveTimers, outerMostTime, flattenedActiveTimerQueries, flattenedActiveTimerNames, res, kernelMs_1;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        oldActiveTimers = this.activeTimers;\n                        newActiveTimers = [];\n                        outerMostTime = false;\n                        if (this.programTimersStack == null) {\n                            this.programTimersStack = newActiveTimers;\n                            outerMostTime = true;\n                        }\n                        else {\n                            this.activeTimers.push(newActiveTimers);\n                        }\n                        this.activeTimers = newActiveTimers;\n                        f();\n                        flattenedActiveTimerQueries = util.flatten(this.activeTimers.map(function (d) { return d.query; }))\n                            .filter(function (d) { return d != null; });\n                        flattenedActiveTimerNames = util.flatten(this.activeTimers.map(function (d) { return d.name; }))\n                            .filter(function (d) { return d != null; });\n                        this.activeTimers = oldActiveTimers;\n                        if (outerMostTime) {\n                            this.programTimersStack = null;\n                        }\n                        res = {\n                            uploadWaitMs: this.uploadWaitMs,\n                            downloadWaitMs: this.downloadWaitMs,\n                            kernelMs: null,\n                            wallMs: null // will be filled by the engine\n                        };\n                        if (!(environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0)) return [3 /*break*/, 2];\n                        return [4 /*yield*/, Promise.all(flattenedActiveTimerQueries)];\n                    case 1:\n                        kernelMs_1 = _a.sent();\n                        res['kernelMs'] = util.sum(kernelMs_1);\n                        res['getExtraProfileInfo'] = function () {\n                            return kernelMs_1.map(function (d, i) { return ({ name: flattenedActiveTimerNames[i], ms: d }); })\n                                .map(function (d) { return d.name + \": \" + d.ms; })\n                                .join(', ');\n                        };\n                        return [3 /*break*/, 3];\n                    case 2:\n                        res['kernelMs'] = {\n                            error: 'WebGL query timers are not supported in this environment.'\n                        };\n                        _a.label = 3;\n                    case 3:\n                        this.uploadWaitMs = 0;\n                        this.downloadWaitMs = 0;\n                        return [2 /*return*/, res];\n                }\n            });\n        });\n    };\n    MathBackendWebGL.prototype.memory = function () {\n        return { unreliable: false, numBytesInGPU: this.numBytesInGPU };\n    };\n    MathBackendWebGL.prototype.startTimer = function () {\n        if (environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0) {\n            return this.gpgpu.beginQuery();\n        }\n        return { startMs: util.now(), endMs: null };\n    };\n    MathBackendWebGL.prototype.endTimer = function (query) {\n        if (environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0) {\n            this.gpgpu.endQuery();\n            return query;\n        }\n        query.endMs = util.now();\n        return query;\n    };\n    MathBackendWebGL.prototype.getQueryTime = function (query) {\n        return __awaiter(this, void 0, void 0, function () {\n            var timerQuery;\n            return __generator(this, function (_a) {\n                if (environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0) {\n                    return [2 /*return*/, this.gpgpu.waitForQueryAndGetTime(query)];\n                }\n                timerQuery = query;\n                return [2 /*return*/, timerQuery.endMs - timerQuery.startMs];\n            });\n        });\n    };\n    MathBackendWebGL.prototype.disposeData = function (dataId) {\n        if (this.pendingDisposal.has(dataId)) {\n            return;\n        }\n        if (this.pendingRead.has(dataId)) {\n            this.pendingDisposal.add(dataId);\n            this.pendingDeletes++;\n            return;\n        }\n        // No-op if already disposed.\n        if (!this.texData.has(dataId)) {\n            return;\n        }\n        this.releaseGPUData(dataId);\n        var complexTensors = this.texData.get(dataId).complexTensors;\n        if (complexTensors != null) {\n            complexTensors.real.dispose();\n            complexTensors.imag.dispose();\n        }\n        this.texData.delete(dataId);\n    };\n    MathBackendWebGL.prototype.releaseGPUData = function (dataId) {\n        var _a = this.texData.get(dataId), texture = _a.texture, dtype = _a.dtype, texShape = _a.texShape, usage = _a.usage, isPacked = _a.isPacked, slice = _a.slice;\n        var key = slice && slice.origDataId || dataId;\n        var refCount = this.dataRefCount.get(key);\n        if (refCount > 1) {\n            this.dataRefCount.set(key, refCount - 1);\n        }\n        else {\n            this.dataRefCount.delete(key);\n            if (texture != null) {\n                this.numBytesInGPU -= this.computeBytes(texShape, dtype);\n                this.textureManager.releaseTexture(texture, texShape, usage, isPacked);\n            }\n        }\n        var texData = this.texData.get(dataId);\n        texData.texture = null;\n        texData.texShape = null;\n        texData.isPacked = false;\n        texData.slice = null;\n    };\n    MathBackendWebGL.prototype.getTexture = function (dataId) {\n        this.uploadToGPU(dataId);\n        return this.texData.get(dataId).texture;\n    };\n    /**\n     * Returns internal information for the specific data bucket. Used in unit\n     * tests.\n     */\n    MathBackendWebGL.prototype.getDataInfo = function (dataId) {\n        return this.texData.get(dataId);\n    };\n    MathBackendWebGL.prototype.getCPUBackend = function () {\n        if (!environment_1.env().getBool('WEBGL_CPU_FORWARD')) {\n            return null;\n        }\n        if (this.cpuBackend == null) {\n            this.cpuBackend = engine_1.ENGINE.findBackend('cpu');\n        }\n        return this.cpuBackend;\n    };\n    /*\n    Tests whether all the inputs to an op are small and on the CPU. This heuristic\n    determines when it would be faster to execute a kernel on the CPU. WebGL\n    kernels opt into running this check and forwarding when appropriate.\n    TODO(https://github.com/tensorflow/tfjs/issues/872): Develop a more\n    sustainable strategy for optimizing backend execution of ops.\n     */\n    MathBackendWebGL.prototype.shouldExecuteOnCPU = function (inputs, sizeThreshold) {\n        var _this = this;\n        if (sizeThreshold === void 0) { sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD; }\n        return this.getCPUBackend() != null &&\n            inputs.every(function (input) { return _this.texData.get(input.dataId).texture == null &&\n                input.size < sizeThreshold; });\n    };\n    MathBackendWebGL.prototype.getGPGPUContext = function () {\n        return this.gpgpu;\n    };\n    MathBackendWebGL.prototype.complex = function (real, imag) {\n        var result = this.makeOutput(real.shape, 'complex64');\n        var resultData = this.texData.get(result.dataId);\n        // The backend owns the reference to the underlying real and imaginary\n        // clones. These will explicitly get disposed when the complex tensor is\n        // disposed.\n        resultData.complexTensors = {\n            real: engine_1.ENGINE.keep(real.clone()),\n            imag: engine_1.ENGINE.keep(imag.clone())\n        };\n        return result;\n    };\n    MathBackendWebGL.prototype.real = function (input) {\n        var resultData = this.texData.get(input.dataId);\n        return resultData.complexTensors.real.clone();\n    };\n    MathBackendWebGL.prototype.imag = function (input) {\n        var resultData = this.texData.get(input.dataId);\n        return resultData.complexTensors.imag.clone();\n    };\n    MathBackendWebGL.prototype.slice = function (x, begin, size) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.slice(x, begin, size);\n        }\n        // Short-circuit computation if the slice is zero-sized.\n        if (util.sizeFromShape(size) === 0) {\n            return tensor_ops_1.tensor([], size, x.dtype);\n        }\n        var isPacked = this.texData.get(x.dataId).isPacked;\n        var isContinous = slice_util.isSliceContinous(x.shape, begin, size);\n        if (isPacked || !isContinous) {\n            var program = environment_1.env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n                new slice_packed_gpu_1.SlicePackedProgram(size) :\n                new slice_gpu_1.SliceProgram(size);\n            var customSetup = program.getCustomSetupFunc(begin);\n            return this.compileAndRun(program, [x], null, customSetup);\n        }\n        this.uploadToGPU(x.dataId);\n        return this.shallowSlice(x, begin, size);\n    };\n    MathBackendWebGL.prototype.shallowSlice = function (x, begin, size) {\n        var xTexData = this.texData.get(x.dataId);\n        var t = this.makeOutput(size, x.dtype);\n        var newTexData = this.texData.get(t.dataId);\n        // Copy texture data from the original tensor.\n        Object.assign(newTexData, xTexData);\n        newTexData.shape = size;\n        newTexData.dtype = x.dtype;\n        var flatOffset = slice_util.computeFlatOffset(begin, x.strides);\n        if (xTexData.slice) {\n            // We are slicing an already sliced tensor, so we have to accumulate\n            // the offset.\n            flatOffset += xTexData.slice.flatOffset;\n        }\n        newTexData.slice = {\n            flatOffset: flatOffset,\n            // Point to the original dataId, which is used to do ref counting.\n            origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n        };\n        // Increase the ref count for that data bucket.\n        var refCount = this.dataRefCount.get(newTexData.slice.origDataId) || 1;\n        this.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n        return t;\n    };\n    MathBackendWebGL.prototype.stridedSlice = function (x, begin, end, strides) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.stridedSlice(x, begin, end, strides);\n        }\n        var outShape = slice_util.computeOutShape(begin, end, strides);\n        if (outShape.some(function (axis) { return axis === 0; })) {\n            return tensor_ops_1.tensor([], outShape);\n        }\n        var program = new strided_slice_gpu_1.StridedSliceProgram(begin, strides, outShape);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.reverse = function (x, axis) {\n        var program = environment_1.env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n            new reverse_packed_gpu_1.ReversePackedProgram(x.shape, axis) :\n            new reverse_gpu_1.ReverseProgram(x.shape, axis);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.concat = function (tensors, axis) {\n        if (tensors[0].dtype === 'complex64') {\n            var reals = tensors.map(function (t) { return complex_ops_1.real(t); });\n            var imags = tensors.map(function (t) { return complex_ops_1.imag(t); });\n            return complex_ops_1.complex(this.concat(reals, axis), this.concat(imags, axis));\n        }\n        if (this.shouldExecuteOnCPU(tensors)) {\n            return this.cpuBackend.concat(tensors, axis);\n        }\n        if (tensors.length === 1) {\n            return tensors[0];\n        }\n        if (tensors.length > environment_1.env().getNumber('WEBGL_MAX_TEXTURES_IN_SHADER')) {\n            var midIndex = Math.floor(tensors.length / 2);\n            var leftSide = this.concat(tensors.slice(0, midIndex), axis);\n            var rightSide = this.concat(tensors.slice(midIndex), axis);\n            return this.concat([leftSide, rightSide], axis);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') && tensors[0].rank > 1) {\n            var program_1 = new concat_packed_gpu_1.ConcatPackedProgram(tensors.map(function (t) { return t.shape; }), axis);\n            return this.compileAndRun(program_1, tensors);\n        }\n        // Any concat of n-dimensional tensors across any axis can be reduced to\n        // a concatenation of two-dimensional tensors across the axis 1 by first\n        // partitioning the axes of the original tensors into those less than the\n        // axis to be concatenated and the rest. Then reshape the tensors\n        // into a two-dimensional tensor by collapsing these two sets of axes and\n        // concatenate the resulting matrices across the axis 1, finally reshaping\n        // the result to have the proper shape.\n        var outShape = concat_util_1.computeOutShape(tensors.map(function (t) { return t.shape; }), axis);\n        var tensors2D = tensors.map(function (t) { return t.as2D(-1, util_1.sizeFromShape(t.shape.slice(axis))); });\n        var program = new concat_gpu_1.ConcatProgram(tensors2D.map(function (t) { return t.shape; }));\n        var res = this.compileAndRun(program, tensors2D);\n        return res.reshape(outShape);\n    };\n    MathBackendWebGL.prototype.neg = function (x) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.neg(x);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n            return this.packedUnaryOp(x, unary_op.NEG, x.dtype);\n        }\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.NEG);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.batchMatMul = function (a, b, transposeA, transposeB) {\n        var outerShapeA = transposeA ? a.shape[2] : a.shape[1];\n        var outerShapeB = transposeB ? b.shape[1] : b.shape[2];\n        var sharedDim = transposeA ? a.shape[1] : a.shape[2];\n        var _a = a.shape, batch = _a[0];\n        // Since the matrices are vectors, it is faster to call mul().sum()\n        // because sum() is O(sqrt(N)) due to divide-and-conquer.\n        if ((outerShapeA === 1 || outerShapeB === 1) &&\n            sharedDim > exports.MATMUL_SHARED_DIM_THRESHOLD) {\n            if (transposeA) {\n                a = a.transpose([0, 2, 1]);\n            }\n            if (transposeB) {\n                b = b.transpose([0, 2, 1]);\n            }\n            var a3D = outerShapeB === 1 ? a : a.as3D(batch, sharedDim, 1);\n            var axis = outerShapeB === 1 ? 2 : 1;\n            var b3D = outerShapeB === 1 ? b.as3D(batch, 1, sharedDim) : b;\n            return this.multiply(a3D, b3D).sum(axis, true /* keepDims */);\n        }\n        var dtype = types_1.upcastType(a.dtype, b.dtype);\n        var program = new mulmat_packed_gpu_1.MatMulPackedProgram(a.shape, [batch, outerShapeA, outerShapeB], transposeA, transposeB);\n        return this.compileAndRun(program, [a, b], dtype);\n    };\n    MathBackendWebGL.prototype.fusedBatchMatMul = function (_a) {\n        var a = _a.a, b = _a.b, transposeA = _a.transposeA, transposeB = _a.transposeB, bias = _a.bias, activation = _a.activation, preluActivationWeights = _a.preluActivationWeights;\n        var outerShapeA = transposeA ? a.shape[2] : a.shape[1];\n        var outerShapeB = transposeB ? b.shape[1] : b.shape[2];\n        var _b = a.shape, batch = _b[0];\n        var dtype = types_1.upcastType(a.dtype, b.dtype);\n        var hasBias = bias != null;\n        var hasPreluActivationWeights = preluActivationWeights != null;\n        var fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n        var program = new mulmat_packed_gpu_1.MatMulPackedProgram(a.shape, [batch, outerShapeA, outerShapeB], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights);\n        var inputs = [a, b];\n        if (bias) {\n            inputs.push(bias);\n        }\n        if (preluActivationWeights) {\n            inputs.push(preluActivationWeights);\n        }\n        return this.compileAndRun(program, inputs, dtype);\n    };\n    MathBackendWebGL.prototype.multiply = function (a, b) {\n        if (a.dtype === 'complex64') {\n            var aData = this.texData.get(a.dataId);\n            var bData = this.texData.get(b.dataId);\n            var realProgram = new binaryop_complex_gpu_1.BinaryOpComplexProgram(binaryop_complex_gpu.COMPLEX_MULTIPLY.REAL, a.shape, b.shape);\n            var imagProgram = new binaryop_complex_gpu_1.BinaryOpComplexProgram(binaryop_complex_gpu.COMPLEX_MULTIPLY.IMAG, a.shape, b.shape);\n            var inputs = [\n                this.makeComplexComponentTensorInfo(a, aData.complexTensors.real),\n                this.makeComplexComponentTensorInfo(a, aData.complexTensors.imag),\n                this.makeComplexComponentTensorInfo(b, bData.complexTensors.real),\n                this.makeComplexComponentTensorInfo(b, bData.complexTensors.imag)\n            ];\n            var real_1 = this.compileAndRun(realProgram, inputs);\n            var imag_1 = this.compileAndRun(imagProgram, inputs);\n            var complex_1 = this.complex(real_1, imag_1);\n            real_1.dispose();\n            imag_1.dispose();\n            return complex_1;\n        }\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.multiply(a, b);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_gpu.MUL, a.dtype);\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.MUL, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], a.dtype);\n    };\n    MathBackendWebGL.prototype.batchNormalization = function (x, mean, variance, varianceEpsilon, scale, offset) {\n        var inputs = [x, mean, variance];\n        var offsetShape = null;\n        if (offset != null) {\n            offsetShape = offset.shape;\n            inputs.push(offset);\n        }\n        var scaleShape = null;\n        if (scale != null) {\n            scaleShape = scale.shape;\n            inputs.push(scale);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_NORMALIZATION')) {\n            var batchNormPackedProgram = new batchnorm_packed_gpu_1.BatchNormPackedProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon);\n            return this.compileAndRun(batchNormPackedProgram, inputs);\n        }\n        var batchNormProgram = new batchnorm_gpu_1.BatchNormProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon);\n        return this.compileAndRun(batchNormProgram, inputs);\n    };\n    MathBackendWebGL.prototype.localResponseNormalization4D = function (x, radius, bias, alpha, beta) {\n        var program = environment_1.env().getBool('WEBGL_PACK_NORMALIZATION') ?\n            new lrn_packed_gpu_1.LRNPackedProgram(x.shape, radius, bias, alpha, beta) :\n            new lrn_gpu_1.LRNProgram(x.shape, radius, bias, alpha, beta);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.LRNGrad = function (dy, inputImage, outputImage, depthRadius, bias, alpha, beta) {\n        var program = new lrn_grad_gpu_1.LRNGradProgram(inputImage.shape, depthRadius, bias, alpha, beta);\n        return this.compileAndRun(program, [inputImage, outputImage, dy]);\n    };\n    MathBackendWebGL.prototype.tile = function (x, reps) {\n        if (x.dtype === 'string') {\n            var data = this.readSync(x.dataId);\n            var decodedData = data.map(function (d) { return util.decodeString(d); });\n            var buf = array_ops_1.buffer(x.shape, x.dtype, decodedData);\n            return tile_impl_1.tile(buf, reps);\n        }\n        var program = new tile_gpu_1.TileProgram(x.shape, reps);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.pad = function (x, paddings, constantValue) {\n        var program = environment_1.env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n            new pad_packed_gpu_1.PadPackedProgram(x.shape, paddings, constantValue) :\n            new pad_gpu_1.PadProgram(x.shape, paddings, constantValue);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.transpose = function (x, perm) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.transpose(x, perm);\n        }\n        var program = environment_1.env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n            new transpose_packed_gpu_1.TransposePackedProgram(x.shape, perm) :\n            new transpose_gpu_1.TransposeProgram(x.shape, perm);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.gather = function (x, indices, axis) {\n        if (this.shouldExecuteOnCPU([x, indices])) {\n            return this.cpuBackend.gather(x, indices, axis);\n        }\n        var program = new gather_gpu_1.GatherProgram(x.shape, indices.size, axis);\n        return this.compileAndRun(program, [x, indices]);\n    };\n    MathBackendWebGL.prototype.batchToSpaceND = function (x, blockShape, crops) {\n        util.assert(x.rank <= 4, function () { return 'batchToSpaceND for rank > 4 with a WebGL backend not ' +\n            'implemented yet'; });\n        var prod = blockShape.reduce(function (a, b) { return a * b; });\n        var reshaped = array_ops_util.getReshaped(x.shape, blockShape, prod);\n        var permuted = array_ops_util.getPermuted(reshaped.length, blockShape.length);\n        var reshapedPermuted = array_ops_util.getReshapedPermuted(x.shape, blockShape, prod);\n        var sliceBeginCoords = array_ops_util.getSliceBeginCoords(crops, blockShape.length);\n        var sliceSize = array_ops_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n        return x.reshape(reshaped)\n            .transpose(permuted)\n            .reshape(reshapedPermuted)\n            .slice(sliceBeginCoords, sliceSize);\n    };\n    MathBackendWebGL.prototype.spaceToBatchND = function (x, blockShape, paddings) {\n        util.assert(x.rank <= 4, function () { return 'spaceToBatchND for rank > 4 with a WebGL backend not ' +\n            'implemented yet'; });\n        var prod = blockShape.reduce(function (a, b) { return a * b; });\n        var completePaddings = [[0, 0]];\n        completePaddings.push.apply(completePaddings, paddings);\n        for (var i = 1 + blockShape.length; i < x.shape.length; ++i) {\n            completePaddings.push([0, 0]);\n        }\n        var paddedX = x.pad(completePaddings);\n        var reshapedPaddedShape = array_ops_util.getReshaped(paddedX.shape, blockShape, prod, false);\n        var permutedReshapedPaddedPermutation = array_ops_util.getPermuted(reshapedPaddedShape.length, blockShape.length, false);\n        var flattenShape = array_ops_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n        return paddedX.reshape(reshapedPaddedShape)\n            .transpose(permutedReshapedPaddedPermutation)\n            .reshape(flattenShape);\n    };\n    MathBackendWebGL.prototype.reduce = function (x, reduceType, dtype) {\n        var batchSize = x.shape[0];\n        var inSize = x.shape[1];\n        var windowSize = reduce_util.computeOptimalWindowSize(inSize);\n        var reduceInfo = { windowSize: windowSize, inSize: inSize, batchSize: batchSize };\n        var program = new reduce_gpu_1.ReduceProgram(reduceInfo, reduceType);\n        var output = this.compileAndRun(program, [x], dtype);\n        // No need to run another GPGPU program.\n        if (output.shape[1] === 1) {\n            return output;\n        }\n        return this.reduce(output, reduceType, dtype);\n    };\n    MathBackendWebGL.prototype.argReduce = function (x, reduceType, bestIndicesA) {\n        if (bestIndicesA === void 0) { bestIndicesA = null; }\n        var batchSize = x.shape[0];\n        var inSize = x.shape[1];\n        if (bestIndicesA != null) {\n            batchSize = bestIndicesA.shape[0];\n            inSize = bestIndicesA.shape[1];\n        }\n        var windowSize = reduce_util.computeOptimalWindowSize(inSize);\n        var reduceInfo = { windowSize: windowSize, inSize: inSize, batchSize: batchSize };\n        var program = new argminmax_gpu_1.ArgMinMaxProgram(reduceInfo, reduceType, bestIndicesA == null);\n        var inputs = [x];\n        if (bestIndicesA != null) {\n            inputs.push(bestIndicesA);\n        }\n        var output = this.compileAndRun(program, inputs, 'int32');\n        // No need to run another GPGPU program.\n        if (output.shape[1] === 1) {\n            return output;\n        }\n        return this.argReduce(x, reduceType, output);\n    };\n    MathBackendWebGL.prototype.argReducePacked = function (x, reduceType, bestIndicesA) {\n        if (bestIndicesA === void 0) { bestIndicesA = null; }\n        var inShape = bestIndicesA != null ? bestIndicesA.shape : x.shape;\n        var inSize = inShape[inShape.length - 1];\n        var windowSize = reduce_util.computeOptimalWindowSize(inSize);\n        var program = new argminmax_packed_gpu_1.ArgMinMaxPackedProgram(inShape, windowSize, reduceType, bestIndicesA == null);\n        var inputs = bestIndicesA == null ? [x] : [x, bestIndicesA];\n        var output = this.compileAndRun(program, inputs, 'int32');\n        if (output.rank === x.rank) {\n            return this.argReducePacked(x, reduceType, output);\n        }\n        return output;\n    };\n    MathBackendWebGL.prototype.sum = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        var outputDType = types_1.sumOutType(x.dtype);\n        return this.reduce(a2D, 'sum', outputDType).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.prod = function (x, axes) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.prod(x, axes);\n        }\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        var outputDType = types_1.sumOutType(x.dtype);\n        return this.reduce(a2D, 'prod', outputDType).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.unsortedSegmentSum = function (x, segmentIds, numSegments) {\n        var axis = 0;\n        var permutation = axis_util.getAxesPermutation([axis], x.rank);\n        var permutedX = x;\n        if (permutation != null) {\n            permutedX = x.transpose(permutation);\n            axis = axis_util.getInnerMostAxes(1, x.rank)[0];\n        }\n        var outShape = segment_util.computeOutShape(permutedX.shape, axis, numSegments);\n        var inSize = util.sizeFromShape([permutedX.shape[axis]]);\n        var a2D = permutedX.as2D(-1, inSize);\n        var outputDType = types_1.sumOutType(x.dtype);\n        var result = this.segOpCompute(a2D, 'unsortedSegmentSum', segmentIds, outputDType, numSegments)\n            .reshape(outShape);\n        if (permutation != null) {\n            result = result.transpose(axis_util.getUndoAxesPermutation(permutation));\n        }\n        return result;\n    };\n    MathBackendWebGL.prototype.segOpCompute = function (x, segOpType, segmentIds, dtype, numSegments) {\n        var batchSize = x.shape[0];\n        var inSize = x.shape[1];\n        var windowSize = segment_util.segOpComputeOptimalWindowSize(inSize, numSegments);\n        var segOpInfo = { windowSize: windowSize, inSize: inSize, batchSize: batchSize, numSegments: numSegments };\n        var program = new segment_gpu_1.SegmentOpProgram(segOpInfo, segOpType);\n        var output = this.compileAndRun(program, [x, segmentIds], dtype);\n        // No need to run another GPGPU program.\n        if (output.shape[1] === numSegments) {\n            return output;\n        }\n        segmentIds = tensor_ops_1.range(0, numSegments).tile([inSize / windowSize]);\n        return this.segOpCompute(output, segOpType, segmentIds, dtype, numSegments);\n    };\n    MathBackendWebGL.prototype.argMinMaxReduce = function (x, axis, reduceType) {\n        var axes = [axis];\n        axis_util.assertAxesAreInnerMostDims('arg' + reduceType.charAt(0).toUpperCase() + reduceType.slice(1), axes, x.rank);\n        if (!environment_1.env().getBool('WEBGL_PACK_REDUCE') || x.rank <= 2) {\n            var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n            var inSize = util.sizeFromShape(reduceShape);\n            var a2D = x.as2D(-1, inSize);\n            return this.argReduce(a2D, reduceType).reshape(outShape);\n        }\n        return this.argReducePacked(x, reduceType);\n    };\n    MathBackendWebGL.prototype.argMin = function (x, axis) {\n        return this.argMinMaxReduce(x, axis, 'min');\n    };\n    MathBackendWebGL.prototype.argMax = function (x, axis) {\n        return this.argMinMaxReduce(x, axis, 'max');\n    };\n    MathBackendWebGL.prototype.cumsum = function (x, axis, exclusive, reverse) {\n        if (axis !== x.rank - 1) {\n            throw new Error(\"WebGL cumsum shader expects an inner-most axis=\" + (x.rank - 1) + \" \" +\n                (\"but got axis=\" + axis));\n        }\n        var program = new cumsum_gpu_1.CumSumProgram(x.shape, exclusive, reverse);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.equal = function (a, b) {\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.EQUAL, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.EQUAL, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], 'bool');\n    };\n    MathBackendWebGL.prototype.notEqual = function (a, b) {\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.NOT_EQUAL, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.NOT_EQUAL, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], 'bool');\n    };\n    MathBackendWebGL.prototype.less = function (a, b) {\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.less(a, b);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.LESS, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.LESS, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], 'bool');\n    };\n    MathBackendWebGL.prototype.lessEqual = function (a, b) {\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.LESS_EQUAL, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.LESS_EQUAL, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], 'bool');\n    };\n    MathBackendWebGL.prototype.greater = function (a, b) {\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.greater(a, b);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.GREATER, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.GREATER, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], 'bool');\n    };\n    MathBackendWebGL.prototype.greaterEqual = function (a, b) {\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.GREATER_EQUAL, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.GREATER_EQUAL, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], 'bool');\n    };\n    MathBackendWebGL.prototype.logicalNot = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.LOGICAL_NOT);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.logicalAnd = function (a, b) {\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.LOGICAL_AND, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.LOGICAL_AND, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], 'bool');\n    };\n    MathBackendWebGL.prototype.logicalOr = function (a, b) {\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.LOGICAL_OR, 'bool');\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.LOGICAL_OR, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], 'bool');\n    };\n    MathBackendWebGL.prototype.select = function (condition, a, b) {\n        var program = new select_gpu_1.SelectProgram(condition.rank, a.shape, a.rank);\n        return this.compileAndRun(program, [condition, a, b], types_1.upcastType(a.dtype, b.dtype));\n    };\n    MathBackendWebGL.prototype.where = function (condition) {\n        log_1.warn('tf.where() in webgl locks the UI thread. ' +\n            'Call tf.whereAsync() instead');\n        var condVals = condition.dataSync();\n        return where_impl_1.whereImpl(condition.shape, condVals);\n    };\n    MathBackendWebGL.prototype.topk = function (x, k, sorted) {\n        var xVals = x.dataSync();\n        return topk_impl_1.topkImpl(xVals, x.shape, x.dtype, k, sorted);\n    };\n    MathBackendWebGL.prototype.min = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        return this.reduce(a2D, 'min', a2D.dtype).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.minimum = function (a, b) {\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.minimum(a, b);\n        }\n        var program = environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.MIN, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.MIN, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b]);\n    };\n    MathBackendWebGL.prototype.mod = function (a, b) {\n        var program = environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.MOD, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.MOD, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b]);\n    };\n    MathBackendWebGL.prototype.max = function (x, axes) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.max(x, axes);\n        }\n        axis_util.assertAxesAreInnerMostDims('max', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        return this.reduce(a2D, 'max', a2D.dtype).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.maximum = function (a, b) {\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.maximum(a, b);\n        }\n        var program = environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.MAX, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.MAX, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b]);\n    };\n    MathBackendWebGL.prototype.all = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('all', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        return this.reduce(a2D, 'all', a2D.dtype).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.any = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('any', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        return this.reduce(a2D, 'any', a2D.dtype).reshape(outShape);\n    };\n    MathBackendWebGL.prototype.realDivide = function (a, b) {\n        var op = binaryop_gpu.DIV;\n        var outputDtype = 'float32';\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            var checkOutOfBounds = true;\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.DIV, outputDtype, checkOutOfBounds);\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(op, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], outputDtype);\n    };\n    MathBackendWebGL.prototype.floorDiv = function (a, b) {\n        var op = binaryop_gpu.INT_DIV;\n        var outputDtype = 'int32';\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_packed_gpu.INT_DIV, outputDtype);\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(op, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], outputDtype);\n    };\n    MathBackendWebGL.prototype.add = function (a, b) {\n        if (a.dtype === 'complex64' && b.dtype === 'complex64') {\n            return this.complexSeparableBinaryOp(a, b, binaryop_gpu.ADD);\n        }\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.add(a, b);\n        }\n        var dtype = types_1.upcastType(a.dtype, b.dtype);\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_gpu.ADD, dtype);\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.ADD, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], dtype);\n    };\n    MathBackendWebGL.prototype.packedUnaryOp = function (x, op, dtype) {\n        var program = new unaryop_packed_gpu_1.UnaryOpPackedProgram(x.shape, op);\n        return this.compileAndRun(program, [x], dtype);\n    };\n    MathBackendWebGL.prototype.packedBinaryOp = function (a, b, op, dtype, checkOutOfBounds) {\n        if (checkOutOfBounds === void 0) { checkOutOfBounds = false; }\n        var program = new binaryop_packed_gpu_1.BinaryOpPackedProgram(op, a.shape, b.shape, checkOutOfBounds);\n        return this.compileAndRun(program, [a, b], dtype);\n    };\n    /**\n     * Computes a complex binary operation that can be decomposed into a simple\n     * binary operation on both the real and imagary parts.\n     */\n    MathBackendWebGL.prototype.complexSeparableBinaryOp = function (a, b, op) {\n        var _this = this;\n        var aData = this.texData.get(a.dataId);\n        var bData = this.texData.get(b.dataId);\n        var _a = [\n            [aData.complexTensors.real, bData.complexTensors.real],\n            [aData.complexTensors.imag, bData.complexTensors.imag]\n        ].map(function (complexParts) {\n            var aPart = complexParts[0], bPart = complexParts[1];\n            var aHandle = _this.makeComplexComponentTensorInfo(a, aPart);\n            var bHandle = _this.makeComplexComponentTensorInfo(b, bPart);\n            var program = new binaryop_gpu_1.BinaryOpProgram(op, a.shape, b.shape);\n            return _this.compileAndRun(program, [aHandle, bHandle], types_1.upcastType(aPart.dtype, bPart.dtype));\n        }), real = _a[0], imag = _a[1];\n        var complex = this.complex(real, imag);\n        real.dispose();\n        imag.dispose();\n        return complex;\n    };\n    // Returns a TensorInfo with the complex shape and the dataId of the\n    // underlying part. We need to do this because a reshaped complex tensor is\n    // not reflected in its parts.\n    MathBackendWebGL.prototype.makeComplexComponentTensorInfo = function (complexTensor, complexPart) {\n        return {\n            dataId: complexPart.dataId,\n            dtype: complexPart.dtype,\n            shape: complexTensor.shape\n        };\n    };\n    MathBackendWebGL.prototype.addN = function (tensors) {\n        if (tensors.length === 1) {\n            return tensors[0];\n        }\n        // Limit the number of uploaded textures for optimization.\n        if (tensors.length > environment_1.env().get('WEBGL_MAX_TEXTURES_IN_SHADER')) {\n            var midIndex = Math.floor(tensors.length / 2);\n            var leftSide = this.addN(tensors.slice(0, midIndex));\n            var rightSide = this.addN(tensors.slice(midIndex));\n            return this.addN([leftSide, rightSide]);\n        }\n        var dtype = tensors.map(function (t) { return t.dtype; }).reduce(function (d1, d2) { return types_1.upcastType(d1, d2); });\n        var shapes = tensors.map(function (t) { return t.shape; });\n        // We can make sure shapes are identical in op level.\n        var usePackedOp = environment_1.env().getBool('WEBGL_PACK');\n        var program = usePackedOp ?\n            new addn_packed_gpu_1.AddNPackedProgram(tensors[0].shape, shapes) :\n            new addn_gpu_1.AddNProgram(tensors[0].shape, shapes);\n        return this.compileAndRun(program, tensors, dtype);\n    };\n    MathBackendWebGL.prototype.subtract = function (a, b) {\n        if (a.dtype === 'complex64' && b.dtype === 'complex64') {\n            return this.complexSeparableBinaryOp(a, b, binaryop_gpu.SUB);\n        }\n        if (this.shouldExecuteOnCPU([a, b])) {\n            return this.cpuBackend.subtract(a, b);\n        }\n        var dtype = types_1.upcastType(a.dtype, b.dtype);\n        if (environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n            return this.packedBinaryOp(a, b, binaryop_gpu.SUB, a.dtype);\n        }\n        var program = new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.SUB, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b], dtype);\n    };\n    MathBackendWebGL.prototype.pow = function (a, b) {\n        var usePackedOp = environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS');\n        var program = usePackedOp ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.POW, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.POW, a.shape, b.shape);\n        var dtype = types_1.upcastType(a.dtype, b.dtype);\n        return this.compileAndRun(program, [a, b], dtype);\n    };\n    MathBackendWebGL.prototype.ceil = function (x) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.ceil(x);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n            return this.packedUnaryOp(x, unary_op.CEIL, x.dtype);\n        }\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.CEIL);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.floor = function (x) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.floor(x);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n            return this.packedUnaryOp(x, unary_op.FLOOR, x.dtype);\n        }\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.FLOOR);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.sign = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SIGN);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.isNaN = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.IS_NAN);\n        return this.compileAndRun(program, [x], 'bool');\n    };\n    MathBackendWebGL.prototype.isInf = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.IS_INF);\n        return this.compileAndRun(program, [x], 'bool');\n    };\n    MathBackendWebGL.prototype.isFinite = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.IS_FINITE);\n        return this.compileAndRun(program, [x], 'bool');\n    };\n    MathBackendWebGL.prototype.round = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ROUND);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.exp = function (x) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.exp(x);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n            return this.packedUnaryOp(x, unary_op.EXP, x.dtype);\n        }\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.EXP);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.expm1 = function (x) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.expm1(x);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n            return this.packedUnaryOp(x, unary_op.EXPM1, x.dtype);\n        }\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.EXPM1);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.softmax = function (logits, dim) {\n        var axes = util.parseAxisParam([dim], logits.shape);\n        var maxLogit = this.max(logits, axes);\n        var expandedShape = axis_util.expandShapeToKeepDim(maxLogit.shape, axes);\n        var a = this.subtract(logits, maxLogit.reshape(expandedShape));\n        var b = this.exp(a);\n        var sumExp = this.sum(b, axes).reshape(expandedShape);\n        return this.realDivide(b, sumExp);\n    };\n    MathBackendWebGL.prototype.log = function (x) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.log(x);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n            return this.packedUnaryOp(x, unary_packed_op.LOG, x.dtype);\n        }\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.LOG);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.log1p = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.LOG1P);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.sqrt = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SQRT);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.rsqrt = function (x) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.rsqrt(x);\n        }\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.RSQRT);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.reciprocal = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.RECIPROCAL);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.relu = function (x) {\n        var program;\n        if (environment_1.env().getBool('WEBGL_PACK')) {\n            program = new unaryop_packed_gpu_1.UnaryOpPackedProgram(x.shape, unary_packed_op.RELU);\n        }\n        else {\n            program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.RELU);\n        }\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.relu6 = function (x) {\n        var program;\n        if (environment_1.env().getBool('WEBGL_PACK')) {\n            program = new unaryop_packed_gpu_1.UnaryOpPackedProgram(x.shape, unary_packed_op.RELU6);\n        }\n        else {\n            program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.RELU6);\n        }\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.prelu = function (x, alpha) {\n        var program = environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.PRELU, x.shape, alpha.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.PRELU, x.shape, alpha.shape);\n        return this.compileAndRun(program, [x, alpha]);\n    };\n    MathBackendWebGL.prototype.elu = function (x) {\n        if (environment_1.env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n            return this.packedUnaryOp(x, unary_packed_op.ELU, x.dtype);\n        }\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ELU);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.eluDer = function (dy, y) {\n        var program = environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.ELU_DER, dy.shape, y.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.ELU_DER, dy.shape, y.shape);\n        return this.compileAndRun(program, [dy, y]);\n    };\n    MathBackendWebGL.prototype.selu = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SELU);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.int = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.TO_INT);\n        return this.compileAndRun(program, [x], 'int32');\n    };\n    MathBackendWebGL.prototype.clip = function (x, min, max) {\n        var program;\n        if (environment_1.env().getBool('WEBGL_PACK_CLIP')) {\n            program = new clip_packed_gpu_1.ClipPackedProgram(x.shape);\n        }\n        else {\n            program = new clip_gpu_1.ClipProgram(x.shape);\n        }\n        var customSetup = program.getCustomSetupFunc(min, max);\n        return this.compileAndRun(program, [x], null, customSetup);\n    };\n    MathBackendWebGL.prototype.abs = function (x) {\n        if (this.shouldExecuteOnCPU([x])) {\n            return this.cpuBackend.abs(x);\n        }\n        if (environment_1.env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n            return this.packedUnaryOp(x, unary_op.ABS, x.dtype);\n        }\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ABS);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.complexAbs = function (x) {\n        var xData = this.texData.get(x.dataId);\n        var program = new complex_abs_gpu_1.ComplexAbsProgram(x.shape);\n        var inputs = [\n            this.makeComplexComponentTensorInfo(x, xData.complexTensors.real),\n            this.makeComplexComponentTensorInfo(x, xData.complexTensors.imag),\n        ];\n        return this.compileAndRun(program, inputs);\n    };\n    MathBackendWebGL.prototype.sigmoid = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SIGMOID);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.softplus = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SOFTPLUS);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.sin = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SIN);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.cos = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.COS);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.tan = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.TAN);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.asin = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ASIN);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.acos = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ACOS);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.atan = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ATAN);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.atan2 = function (a, b) {\n        var program = environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(binaryop_packed_gpu.ATAN2, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(binaryop_gpu.ATAN2, a.shape, b.shape);\n        return this.compileAndRun(program, [a, b]);\n    };\n    MathBackendWebGL.prototype.sinh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.SINH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.cosh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.COSH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.tanh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.TANH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.asinh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ASINH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.acosh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ACOSH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.atanh = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ATANH);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.erf = function (x) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.ERF);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.step = function (x, alpha) {\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unary_op.STEP(alpha));\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.conv2dByMatMul = function (x, filter, convInfo, bias, activation, preluActivationWeights) {\n        // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n        // result from 2D to 4D.\n        var xShape = x.shape;\n        var xTexData = this.texData.get(x.dataId);\n        var sharedMatMulDim = convInfo.inChannels;\n        var outerShapeX = xShape[0] * xShape[1] * xShape[2];\n        var outerShapeFilter = convInfo.outChannels;\n        var isChannelsLast = convInfo.dataFormat === 'channelsLast';\n        var transposeA = false;\n        var transposeB = false;\n        // TODO: Once reduction ops are packed, batchMatMul will always be packed\n        // and we can remove this condition.\n        var batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) &&\n            sharedMatMulDim > exports.MATMUL_SHARED_DIM_THRESHOLD;\n        var reshapeWillBeExpensive = xShape[2] % 2 !== 0 && !!xTexData.isPacked;\n        if (batchMatMulWillBeUnpacked || !environment_1.env().getBool('WEBGL_LAZILY_UNPACK') ||\n            !environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ||\n            !reshapeWillBeExpensive) {\n            var targetShape_1 = isChannelsLast ? xShape[0] * xShape[1] * xShape[2] :\n                xShape[0] * xShape[2] * xShape[3];\n            var xReshaped_1 = this.reshape(x, [1, targetShape_1, convInfo.inChannels]);\n            var filterReshaped_1 = this.reshape(filter, [1, convInfo.inChannels, convInfo.outChannels]);\n            return this.reshape(this.fusedBatchMatMul({\n                a: xReshaped_1,\n                b: filterReshaped_1,\n                transposeA: transposeA,\n                transposeB: transposeB,\n                bias: bias,\n                activation: activation,\n                preluActivationWeights: preluActivationWeights\n            }), convInfo.outShape);\n        }\n        // Following optimization is specific to packed |x| with odd row count\n        // (For example, in channelLast mode, 'row count' refers to x.shape[2]):\n        // we avoid expensive packed 2x2 reshape by padding row count to next,\n        // even number. When x.shape[2] is odd, the result of packed batchMatMul is\n        // the same (has the same texture layout and and values in the texture) as\n        // it is for even x.shape[2] + 1. We make the odd-rows tensor to look like\n        // even-rows tensor before the operation and, after the batchMatMul,\n        // fix the even-rows result to have odd number of rows.\n        var targetShape = isChannelsLast ?\n            xShape[0] * xShape[1] * (xShape[2] + 1) :\n            xShape[0] * xShape[2] * (xShape[3] + 1);\n        var xReshaped = {\n            dataId: x.dataId,\n            shape: [1, targetShape, convInfo.inChannels],\n            dtype: x.dtype\n        };\n        // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n        // Decrementing row count, after batchMatMul->...->compileProgram leads to\n        // invalid row count within the reference in GPGPUBinary.inShapeInfos.\n        // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n        // in compileProgram method, but that would affect compilation of all\n        // programs - instead, provide a copy here, with even row count, before\n        // calling batchMatMul->...->compileProgram and after that, the original\n        // xTexData.shape is restored.\n        var originalXTexDataShape = xTexData.shape;\n        xTexData.shape = xTexData.shape.slice();\n        xTexData.shape[xTexData.shape.length - 2]++;\n        util.assert(webgl_util.isReshapeFree(xTexData.shape, xReshaped.shape), function () { return \"packed reshape \" + xTexData.shape + \" to \" + xReshaped.shape + \" isn't free\"; });\n        var filterReshaped = this.reshape(filter, [1, convInfo.inChannels, convInfo.outChannels]);\n        var pointwiseConv = this.fusedBatchMatMul({\n            a: xReshaped,\n            b: filterReshaped,\n            transposeA: transposeA,\n            transposeB: transposeB,\n            bias: bias,\n            activation: activation,\n            preluActivationWeights: preluActivationWeights\n        });\n        var pointwiseConvTexData = this.texData.get(pointwiseConv.dataId);\n        util.assert(pointwiseConvTexData.isPacked, function () { return 'batchMatMul result is expected to be packed'; });\n        // Restore the input shape to original.\n        xTexData.shape = originalXTexDataShape;\n        // Set the output shape - there is no need for expensive reshape as data\n        // layout is already correct.\n        pointwiseConvTexData.shape = convInfo.outShape;\n        return engine_1.ENGINE.makeTensorFromDataId(pointwiseConv.dataId, convInfo.outShape, pointwiseConv.dtype);\n    };\n    MathBackendWebGL.prototype.conv2dWithIm2Row = function (x, filter, convInfo, bias, activation, preluActivationWeights) {\n        // Rearranges conv2d input so each block to be convolved over forms the\n        // column of a new matrix with shape [filterWidth * filterHeight *\n        // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n        // output channel forms a row of a new matrix with shape [outChannels,\n        // filterWidth * filterHeight * inChannels]. The convolution is then\n        // computed by multiplying these matrices and reshaping the result.\n        var filterWidth = convInfo.filterWidth, filterHeight = convInfo.filterHeight, inChannels = convInfo.inChannels, outWidth = convInfo.outWidth, outHeight = convInfo.outHeight, dataFormat = convInfo.dataFormat;\n        var isChannelsLast = dataFormat === 'channelsLast';\n        var sharedDim = filterWidth * filterHeight * inChannels;\n        var numCols = outHeight * outWidth;\n        var x2ColShape = [sharedDim, numCols];\n        var transposeA = true;\n        var transposeB = false;\n        var xSqueezed = x.squeeze([0]);\n        var w2Row = filter.reshape([1, sharedDim, -1]);\n        var im2ColProgram = new im2col_packed_gpu_1.Im2ColPackedProgram(x2ColShape, xSqueezed.shape, convInfo);\n        var im2Col = this.compileAndRun(im2ColProgram, [xSqueezed]).reshape([\n            1, x2ColShape[0], x2ColShape[1]\n        ]);\n        var hasBias = bias != null;\n        var hasPreluActivationWeights = preluActivationWeights != null;\n        var fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n        var matmulProgram = new mulmat_packed_gpu_1.MatMulPackedProgram(im2Col.shape, [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights);\n        var inputs = [im2Col, w2Row];\n        if (bias) {\n            inputs.push(bias);\n        }\n        if (hasPreluActivationWeights) {\n            inputs.push(preluActivationWeights);\n        }\n        var product = this.compileAndRun(matmulProgram, inputs);\n        if (isChannelsLast) {\n            return product.reshape([1, outHeight, outWidth, convInfo.outChannels]);\n        }\n        else {\n            return product.reshape([1, convInfo.outChannels, outHeight, outWidth]);\n        }\n    };\n    MathBackendWebGL.prototype.fusedConv2d = function (_a) {\n        var input = _a.input, filter = _a.filter, convInfo = _a.convInfo, bias = _a.bias, activation = _a.activation, preluActivationWeights = _a.preluActivationWeights;\n        if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&\n            convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n            convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n            (convInfo.padInfo.type === 'SAME' ||\n                convInfo.padInfo.type === 'VALID')) {\n            return this.conv2dByMatMul(input, filter, convInfo, bias, activation, preluActivationWeights);\n        }\n        if (environment_1.env().getBool('WEBGL_CONV_IM2COL') && input.shape[0] === 1) {\n            return this.conv2dWithIm2Row(input, filter, convInfo, bias, activation, preluActivationWeights);\n        }\n        var hasBias = bias != null;\n        var hasPreluActivationWeights = preluActivationWeights != null;\n        var fusedActivation = activation ? mapActivationToShaderProgram(activation, false) : null;\n        var program = new conv_gpu_1.Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights);\n        var inputs = [input, filter];\n        if (bias) {\n            inputs.push(bias);\n        }\n        if (preluActivationWeights) {\n            inputs.push(preluActivationWeights);\n        }\n        return this.compileAndRun(program, inputs);\n    };\n    MathBackendWebGL.prototype.conv2d = function (x, filter, convInfo) {\n        if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&\n            convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n            convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n            (convInfo.padInfo.type === 'SAME' ||\n                convInfo.padInfo.type === 'VALID')) {\n            return this.conv2dByMatMul(x, filter, convInfo);\n        }\n        if (environment_1.env().getBool('WEBGL_CONV_IM2COL') && x.shape[0] === 1) {\n            return this.conv2dWithIm2Row(x, filter, convInfo);\n        }\n        var program = new conv_gpu_1.Conv2DProgram(convInfo);\n        return this.compileAndRun(program, [x, filter]);\n    };\n    MathBackendWebGL.prototype.conv2dDerInput = function (dy, filter, convInfo) {\n        var program = new conv_backprop_gpu_1.Conv2DDerInputProgram(convInfo);\n        return this.compileAndRun(program, [dy, filter]);\n    };\n    MathBackendWebGL.prototype.conv2dDerFilter = function (x, dy, convInfo) {\n        var program = new conv_backprop_gpu_1.Conv2DDerFilterProgram(convInfo);\n        return this.compileAndRun(program, [x, dy]);\n    };\n    MathBackendWebGL.prototype.fusedDepthwiseConv2D = function (_a) {\n        var input = _a.input, filter = _a.filter, convInfo = _a.convInfo, bias = _a.bias, activation = _a.activation, preluActivationWeights = _a.preluActivationWeights;\n        var shouldPackDepthwiseConv = environment_1.env().getBool('WEBGL_PACK_DEPTHWISECONV') &&\n            convInfo.strideWidth <= 2 &&\n            convInfo.outChannels / convInfo.inChannels === 1;\n        var fusedActivation = activation ?\n            mapActivationToShaderProgram(activation, shouldPackDepthwiseConv) :\n            null;\n        var inputs = [input, filter];\n        var hasBias = bias != null;\n        var hasPreluActivationWeights = preluActivationWeights != null;\n        if (hasBias) {\n            inputs.push(bias);\n        }\n        if (hasPreluActivationWeights) {\n            inputs.push(preluActivationWeights);\n        }\n        var program;\n        if (shouldPackDepthwiseConv) {\n            program = new conv_packed_gpu_depthwise_1.DepthwiseConvPacked2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights);\n            return this.compileAndRun(program, inputs);\n        }\n        program = new conv_gpu_depthwise_1.DepthwiseConv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights);\n        return this.compileAndRun(program, inputs);\n    };\n    MathBackendWebGL.prototype.depthwiseConv2D = function (x, filter, convInfo) {\n        var program;\n        if (environment_1.env().getBool('WEBGL_PACK_DEPTHWISECONV') &&\n            convInfo.strideWidth <= 2 &&\n            convInfo.outChannels / convInfo.inChannels === 1) {\n            program = new conv_packed_gpu_depthwise_1.DepthwiseConvPacked2DProgram(convInfo);\n            return this.compileAndRun(program, [x, filter]);\n        }\n        program = new conv_gpu_depthwise_1.DepthwiseConv2DProgram(convInfo);\n        return this.compileAndRun(program, [x, filter]);\n    };\n    MathBackendWebGL.prototype.depthwiseConv2DDerInput = function (dy, filter, convInfo) {\n        var program = new conv_backprop_gpu_depthwise_1.DepthwiseConv2DDerInputProgram(convInfo);\n        return this.compileAndRun(program, [dy, filter]);\n    };\n    MathBackendWebGL.prototype.depthwiseConv2DDerFilter = function (x, dy, convInfo) {\n        var program = new conv_backprop_gpu_depthwise_1.DepthwiseConv2DDerFilterProgram(convInfo);\n        return this.compileAndRun(program, [x, dy]);\n    };\n    MathBackendWebGL.prototype.conv3d = function (x, filter, convInfo) {\n        var program = new conv_gpu_1.Conv3DProgram(convInfo);\n        return this.compileAndRun(program, [x, filter]);\n    };\n    MathBackendWebGL.prototype.conv3dDerInput = function (dy, filter, convInfo) {\n        var program = new conv_backprop_gpu_1.Conv3DDerInputProgram(convInfo);\n        return this.compileAndRun(program, [dy, filter]);\n    };\n    MathBackendWebGL.prototype.conv3dDerFilter = function (x, dy, convInfo) {\n        var program = new conv_backprop_gpu_1.Conv3DDerFilterProgram(convInfo);\n        return this.compileAndRun(program, [x, dy]);\n    };\n    MathBackendWebGL.prototype.maxPool = function (x, convInfo) {\n        var program = new pool_gpu_1.Pool2DProgram(convInfo, 'max', false);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.avgPool = function (x, convInfo) {\n        var program = new pool_gpu_1.Pool2DProgram(convInfo, 'avg', false);\n        return this.compileAndRun(program, [x], 'float32');\n    };\n    MathBackendWebGL.prototype.maxPoolBackprop = function (dy, x, y, convInfo) {\n        var getPositions = true;\n        var maxPoolPositionsProgram = new pool_gpu_1.Pool2DProgram(convInfo, 'max', getPositions);\n        var maxPoolPositions = this.compileAndRun(maxPoolPositionsProgram, [x]);\n        var maxPoolBackPropProgram = new max_pool_backprop_gpu_1.MaxPool2DBackpropProgram(convInfo);\n        var result = this.compileAndRun(maxPoolBackPropProgram, [dy, maxPoolPositions], x.dtype);\n        maxPoolPositions.dispose();\n        return result;\n    };\n    MathBackendWebGL.prototype.avgPoolBackprop = function (dy, x, convInfo) {\n        var avgPoolBackpropProgram = new avg_pool_backprop_gpu_1.AvgPool2DBackpropProgram(convInfo);\n        return this.compileAndRun(avgPoolBackpropProgram, [dy], x.dtype);\n    };\n    MathBackendWebGL.prototype.cast = function (x, dtype) {\n        return backend_util.castTensor(x, dtype, this);\n    };\n    MathBackendWebGL.prototype.unstack = function (x, axis) {\n        var num = x.shape[axis];\n        var outShape = new Array(x.rank - 1);\n        var outIndex = 0;\n        for (var i = 0; i < x.rank; i++) {\n            if (i !== axis) {\n                outShape[outIndex++] = x.shape[i];\n            }\n        }\n        var begin = new Array(x.rank).fill(0);\n        var size = x.shape.slice();\n        size[axis] = 1;\n        var res = new Array(num);\n        for (var i = 0; i < res.length; i++) {\n            begin[axis] = i;\n            res[i] = this.slice(x, begin, size).reshape(outShape);\n        }\n        return res;\n    };\n    MathBackendWebGL.prototype.avgPool3d = function (x, convInfo) {\n        var program = new pool_gpu_1.Pool3DProgram(convInfo, 'avg', false);\n        return this.compileAndRun(program, [x], 'float32');\n    };\n    MathBackendWebGL.prototype.avgPool3dBackprop = function (dy, x, convInfo) {\n        var avgPool3dBackpropProgram = new avg_pool_backprop_gpu_1.AvgPool3DBackpropProgram(convInfo);\n        return this.compileAndRun(avgPool3dBackpropProgram, [dy], x.dtype);\n    };\n    MathBackendWebGL.prototype.maxPool3d = function (x, convInfo) {\n        var program = new pool_gpu_1.Pool3DProgram(convInfo, 'max', false);\n        return this.compileAndRun(program, [x], 'float32');\n    };\n    MathBackendWebGL.prototype.maxPool3dBackprop = function (dy, x, y, convInfo) {\n        var getPositions = true;\n        var maxPool3dPositionsProgram = new pool_gpu_1.Pool3DProgram(convInfo, 'max', getPositions);\n        var maxPool3dPositions = this.compileAndRun(maxPool3dPositionsProgram, [x]);\n        var maxPool3dBackPropProgram = new max_pool_backprop_gpu_1.MaxPool3DBackpropProgram(convInfo);\n        var result = this.compileAndRun(maxPool3dBackPropProgram, [dy, maxPool3dPositions], x.dtype);\n        maxPool3dPositions.dispose();\n        return result;\n    };\n    MathBackendWebGL.prototype.reshape = function (x, shape) {\n        var texData = this.texData.get(x.dataId);\n        if (texData.isPacked && !webgl_util.isReshapeFree(x.shape, shape) &&\n            !(texData.texture !== null &&\n                webgl_util.isReshapeFree(texData.shape, shape))) {\n            var info = this.packedReshape(x, shape);\n            return engine_1.ENGINE.makeTensorFromDataId(info.dataId, info.shape, info.dtype);\n        }\n        return backend_util.reshapeTensor(x, shape);\n    };\n    MathBackendWebGL.prototype.resizeBilinear = function (x, newHeight, newWidth, alignCorners) {\n        var program = environment_1.env().getBool('WEBGL_PACK_IMAGE_OPERATIONS') ?\n            new resize_bilinear_packed_gpu_1.ResizeBilinearPackedProgram(x.shape, newHeight, newWidth, alignCorners) :\n            new resize_bilinear_gpu_1.ResizeBilinearProgram(x.shape, newHeight, newWidth, alignCorners);\n        return this.compileAndRun(program, [x], 'float32');\n    };\n    MathBackendWebGL.prototype.resizeBilinearBackprop = function (dy, x, alignCorners) {\n        var program = new resize_bilinear_backprop_gpu_1.ResizeBilinearBackpropProgram(dy, x, alignCorners);\n        return this.compileAndRun(program, [dy]);\n    };\n    MathBackendWebGL.prototype.resizeNearestNeighbor = function (x, newHeight, newWidth, alignCorners) {\n        var program = new resize_nearest_neighbor_gpu_1.ResizeNearestNeighborProgram(x.shape, newHeight, newWidth, alignCorners);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.resizeNearestNeighborBackprop = function (dy, x, alignCorners) {\n        var program = new resize_nearest_neighbor_backprop_gpu_1.ResizeNearestNeigborBackpropProgram(dy, x, alignCorners);\n        return this.compileAndRun(program, [dy]);\n    };\n    MathBackendWebGL.prototype.multinomial = function (logits, normalized, numSamples, seed) {\n        var probs = normalized ? logits : softmax_1.softmax(logits);\n        var batchSize = probs.shape[0];\n        var numOutcomes = probs.shape[1];\n        var program = new multinomial_gpu_1.MultinomialProgram(batchSize, numOutcomes, numSamples);\n        var customSetup = program.getCustomSetupFunc(seed);\n        return this.compileAndRun(program, [probs], 'int32', customSetup);\n    };\n    MathBackendWebGL.prototype.oneHot = function (indices, depth, onValue, offValue) {\n        var program = new onehot_gpu_1.OneHotProgram(indices.size, depth, onValue, offValue);\n        return this.compileAndRun(program, [indices]);\n    };\n    MathBackendWebGL.prototype.diag = function (x) {\n        var program = new diag_gpu_1.DiagProgram(x.size);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.nonMaxSuppression = function (boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n        log_1.warn('tf.nonMaxSuppression() in webgl locks the UI thread. ' +\n            'Call tf.nonMaxSuppressionAsync() instead');\n        var boxesVals = boxes.dataSync();\n        var scoresVals = scores.dataSync();\n        return non_max_suppression_impl_1.nonMaxSuppressionV3(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n    };\n    MathBackendWebGL.prototype.cropAndResize = function (image, boxes, boxIndex, cropSize, method, extrapolationValue) {\n        var program = new crop_and_resize_gpu_1.CropAndResizeProgram(image.shape, boxes.shape, cropSize, method, extrapolationValue);\n        return this.compileAndRun(program, [image, boxes, boxIndex], 'float32');\n    };\n    MathBackendWebGL.prototype.depthToSpace = function (x, blockSize, dataFormat) {\n        util.assert(blockSize > 1, function () {\n            return \"blockSize should be > 1 for depthToSpace, but was: \" + blockSize;\n        });\n        var batchSize = x.shape[0];\n        var inputHeight = (dataFormat === 'NHWC') ? x.shape[1] : x.shape[2];\n        var inputWidth = (dataFormat === 'NHWC') ? x.shape[2] : x.shape[3];\n        var inputDepth = (dataFormat === 'NHWC') ? x.shape[3] : x.shape[1];\n        var outputHeight = inputHeight * blockSize;\n        var outputWidth = inputWidth * blockSize;\n        var outputDepth = inputDepth / (blockSize * blockSize);\n        var outputShape = (dataFormat === 'NHWC') ?\n            [batchSize, outputHeight, outputWidth, outputDepth] :\n            [batchSize, outputDepth, outputHeight, outputWidth];\n        var program = new depth_to_space_gpu_1.DepthToSpaceProgram(outputShape, blockSize, dataFormat);\n        return this.compileAndRun(program, [x]);\n    };\n    MathBackendWebGL.prototype.split = function (x, sizeSplits, axis) {\n        return split_shared_1.split(x, sizeSplits, axis);\n    };\n    MathBackendWebGL.prototype.scatterND = function (indices, updates, shape) {\n        var _a = scatter_nd_util.calculateShapes(updates, indices, shape), sliceRank = _a.sliceRank, numUpdates = _a.numUpdates, sliceSize = _a.sliceSize, strides = _a.strides, outputSize = _a.outputSize;\n        var flattenShape = [outputSize / sliceSize, sliceSize];\n        var flattenIndices = indices.reshape([numUpdates, sliceRank]);\n        var flattenX = updates.reshape([numUpdates, sliceSize]);\n        if (outputSize === 0) {\n            return backend_util.reshapeTensor(tensor_ops_1.tensor([]), shape);\n        }\n        var defaultValue = tensor_ops_1.scalar(0);\n        var program = new scatter_gpu_1.ScatterProgram(numUpdates, sliceRank, flattenIndices.rank, flattenX.rank, strides, flattenShape);\n        var res = this.compileAndRun(program, [flattenX, flattenIndices, defaultValue]);\n        return res.reshape(shape);\n    };\n    MathBackendWebGL.prototype.sparseToDense = function (sparseIndices, sparseValues, outputShape, defaultValue) {\n        var _a = scatter_nd_util.calculateShapes(sparseValues, sparseIndices, outputShape), sliceRank = _a.sliceRank, numUpdates = _a.numUpdates, strides = _a.strides, outputSize = _a.outputSize;\n        var sumDupeIndices = false;\n        var program = new scatter_gpu_1.ScatterProgram(numUpdates, sliceRank, sparseIndices.rank, sparseValues.rank, strides, [outputSize, 1], sumDupeIndices);\n        var res = this.compileAndRun(program, [sparseValues, sparseIndices, defaultValue]);\n        return res.reshape(outputShape);\n    };\n    MathBackendWebGL.prototype.fft = function (x) {\n        var inverse = false;\n        return this.fftImpl(x, inverse);\n    };\n    MathBackendWebGL.prototype.ifft = function (x) {\n        var inverse = true;\n        return this.fftImpl(x, inverse);\n    };\n    MathBackendWebGL.prototype.fftImpl = function (x, inverse) {\n        var xData = this.texData.get(x.dataId);\n        var realProgram = new fft_gpu_1.FFTProgram(fft_gpu.COMPLEX_FFT.REAL, x.shape, inverse);\n        var imagProgram = new fft_gpu_1.FFTProgram(fft_gpu.COMPLEX_FFT.IMAG, x.shape, inverse);\n        var inputs = [\n            this.makeComplexComponentTensorInfo(x, xData.complexTensors.real),\n            this.makeComplexComponentTensorInfo(x, xData.complexTensors.imag),\n        ];\n        var real = this.compileAndRun(realProgram, inputs);\n        var imag = this.compileAndRun(imagProgram, inputs);\n        var complex = this.complex(real, imag).as2D(x.shape[0], x.shape[1]);\n        real.dispose();\n        imag.dispose();\n        return complex;\n    };\n    MathBackendWebGL.prototype.gatherND = function (x, indices) {\n        var indicesShape = indices.shape;\n        var sliceRank = indicesShape[indicesShape.length - 1];\n        var _a = gather_nd_util.prepareAndValidate(x, indices), resultShape = _a[0], numSlices = _a[1], sliceSize = _a[2], strides = _a[3];\n        var flattenIndices = indices.reshape([numSlices, sliceRank]);\n        var flattenX = x.reshape([x.size / sliceSize, sliceSize]);\n        var program = new gather_nd_gpu_1.GatherNDProgram(sliceRank, strides, [numSlices, sliceSize]);\n        var res = this.compileAndRun(program, [flattenX, flattenIndices]);\n        return res.reshape(resultShape);\n    };\n    MathBackendWebGL.prototype.fill = function (shape, value, dtype) {\n        dtype = dtype || util_1.inferDtype(value);\n        if (dtype === 'string') {\n            // String type should be handled in CPU memory.\n            var values = util_1.getArrayFromDType(dtype, util_1.sizeFromShape(shape));\n            values.fill(value);\n            return engine_1.ENGINE.makeTensor(values, shape, dtype, this);\n        }\n        else {\n            var program = new fill_gpu_1.FillProgram(shape, value);\n            var customSetup = program.getCustomSetupFunc(value);\n            return this.compileAndRun(program, [], dtype, customSetup);\n        }\n    };\n    MathBackendWebGL.prototype.onesLike = function (x) {\n        if (x.dtype === 'string') {\n            throw new Error('onesLike is not supported under string dtype');\n        }\n        else {\n            // TODO(cais, smilkov): Add WebGL shader for onesLike:\n            //   https://github.com/tensorflow/tfjs/issues/1293\n            return this.fill(x.shape, 1, x.dtype);\n        }\n    };\n    MathBackendWebGL.prototype.zerosLike = function (x) {\n        return this.fill(x.shape, x.dtype === 'string' ? '' : 0, x.dtype);\n    };\n    MathBackendWebGL.prototype.linspace = function (start, stop, num) {\n        // TODO: Use CPU implementation due to the precision problem in Safari.\n        return backend_util.linspaceImpl(start, stop, num);\n    };\n    MathBackendWebGL.prototype.makeTensorInfo = function (shape, dtype) {\n        var dataId = this.write(null /* values */, shape, dtype);\n        this.texData.get(dataId).usage = null;\n        return { dataId: dataId, shape: shape, dtype: dtype };\n    };\n    MathBackendWebGL.prototype.makeOutput = function (shape, dtype) {\n        var dataId = this.makeTensorInfo(shape, dtype).dataId;\n        return engine_1.ENGINE.makeTensorFromDataId(dataId, shape, dtype, this);\n    };\n    MathBackendWebGL.prototype.unpackTensor = function (input) {\n        var program = new unpack_gpu_1.UnpackProgram(input.shape);\n        return this.runWebGLProgram(program, [input], input.dtype);\n    };\n    MathBackendWebGL.prototype.packTensor = function (input) {\n        var program = new pack_gpu_1.PackProgram(input.shape);\n        var preventEagerUnpackingOutput = true;\n        return this.runWebGLProgram(program, [input], input.dtype, null /* customSetup */, preventEagerUnpackingOutput);\n    };\n    MathBackendWebGL.prototype.packedReshape = function (input, afterShape) {\n        var input3DShape = [\n            webgl_util.getBatchDim(input.shape)\n        ].concat(webgl_util.getRowsCols(input.shape));\n        var input3D = {\n            dtype: input.dtype,\n            shape: input3DShape,\n            dataId: input.dataId\n        };\n        var afterShapeAs3D = [\n            webgl_util.getBatchDim(afterShape)\n        ].concat(webgl_util.getRowsCols(afterShape));\n        var program = new reshape_packed_gpu_1.ReshapePackedProgram(afterShapeAs3D, input3DShape);\n        var preventEagerUnpackingOfOutput = true;\n        var output = this.runWebGLProgram(program, [input3D], input.dtype, null /* customSetup */, preventEagerUnpackingOfOutput);\n        return { dataId: output.dataId, shape: afterShape, dtype: output.dtype };\n    };\n    MathBackendWebGL.prototype.decode = function (dataId) {\n        var texData = this.texData.get(dataId);\n        var isPacked = texData.isPacked, shape = texData.shape, dtype = texData.dtype;\n        var shapeAs3D = webgl_util.getShapeAs3D(shape);\n        var program;\n        if (isPacked) {\n            program = new decode_matrix_packed_gpu_1.DecodeMatrixPackedProgram(shapeAs3D);\n        }\n        else {\n            program = new decode_matrix_gpu_1.DecodeMatrixProgram(shapeAs3D);\n        }\n        var preventEagerUnpackingOfOutput = true;\n        var out = this.runWebGLProgram(program, [{ shape: shapeAs3D, dtype: dtype, dataId: dataId }], dtype, null /* customSetup */, preventEagerUnpackingOfOutput);\n        return { dtype: dtype, shape: shape, dataId: out.dataId };\n    };\n    MathBackendWebGL.prototype.runWebGLProgram = function (program, inputs, outputDtype, customSetup, preventEagerUnpackingOfOutput) {\n        var _this = this;\n        if (preventEagerUnpackingOfOutput === void 0) { preventEagerUnpackingOfOutput = false; }\n        var output = this.makeTensorInfo(program.outputShape, outputDtype);\n        var outData = this.texData.get(output.dataId);\n        if (program.packedOutput) {\n            outData.isPacked = true;\n        }\n        if (program.outPackingScheme === tex_util.PackingScheme.DENSE) {\n            var texelShape = tex_util.getDenseTexShape(program.outputShape);\n            // For a densely packed output, we explicitly set texShape\n            // so it doesn't get assigned later according to our typical packing\n            // scheme wherein a single texel can only contain values from adjacent\n            // rows/cols.\n            outData.texShape = texelShape.map(function (d) { return d * 2; });\n        }\n        if (program.outTexUsage != null) {\n            outData.usage = program.outTexUsage;\n        }\n        if (util_1.sizeFromShape(output.shape) === 0) {\n            // Short-circuit the computation since the result is empty (has 0 in its\n            // shape).\n            outData.values = util_1.getTypedArrayFromDType(output.dtype, 0);\n            return output;\n        }\n        var dataToDispose = [];\n        var inputsData = inputs.map(function (input) {\n            if (input.dtype === 'complex64') {\n                throw new Error(\"GPGPUProgram does not support complex64 input. For complex64 \" +\n                    \"dtypes, please separate the program into real and imaginary \" +\n                    \"parts.\");\n            }\n            var texData = _this.texData.get(input.dataId);\n            if (texData.texture == null) {\n                if (!program.packedInputs &&\n                    util.sizeFromShape(input.shape) <=\n                        environment_1.env().getNumber('WEBGL_SIZE_UPLOAD_UNIFORM')) {\n                    // Upload small tensors that live on the CPU as uniforms, not as\n                    // textures. Do this only when the environment supports 32bit floats\n                    // due to problems when comparing 16bit floats with 32bit floats.\n                    // TODO(https://github.com/tensorflow/tfjs/issues/821): Make it\n                    // possible for packed shaders to sample from uniforms.\n                    return {\n                        shape: input.shape,\n                        texData: null,\n                        isUniform: true,\n                        uniformValues: texData.values\n                    };\n                }\n                // This ensures that if a packed program's inputs have not yet been\n                // uploaded to the GPU, they get uploaded as packed right off the bat.\n                if (program.packedInputs) {\n                    texData.isPacked = true;\n                    texData.shape = input.shape;\n                }\n            }\n            else if (!!texData.isPacked !== !!program.packedInputs) {\n                input = texData.isPacked ? _this.unpackTensor(input) :\n                    _this.packTensor(input);\n                dataToDispose.push(input);\n                texData = _this.texData.get(input.dataId);\n            }\n            else if (texData.isPacked &&\n                !webgl_util.isReshapeFree(texData.shape, input.shape)) {\n                // This is a special case where a texture exists for a tensor\n                // but the shapes are incompatible (due to packing constraints) because\n                // the tensor did not have a chance to go through the packed reshape\n                // shader. This only happens when we reshape the *same* tensor to form\n                // *distinct* inputs to an op, e.g. dotting a vector with itself. This\n                // case will disappear once packed uploading is the default.\n                var savedInput = input;\n                var targetShape = input.shape;\n                input.shape = texData.shape;\n                input = _this.packedReshape(input, targetShape);\n                dataToDispose.push(input);\n                texData = _this.texData.get(input.dataId);\n                savedInput.shape = targetShape;\n            }\n            _this.uploadToGPU(input.dataId);\n            return { shape: input.shape, texData: texData, isUniform: false };\n        });\n        this.uploadToGPU(output.dataId);\n        var outputData = { shape: output.shape, texData: outData, isUniform: false };\n        var key = gpgpu_math.makeShaderKey(program, inputsData, outputData);\n        var binary = this.getAndSaveBinary(key, function () {\n            return gpgpu_math.compileProgram(_this.gpgpu, program, inputsData, outputData);\n        });\n        var shouldTimeProgram = this.activeTimers != null;\n        var query;\n        if (shouldTimeProgram) {\n            query = this.startTimer();\n        }\n        gpgpu_math.runProgram(this.gpgpu, binary, inputsData, outputData, customSetup);\n        dataToDispose.forEach(function (info) { return _this.disposeData(info.dataId); });\n        if (shouldTimeProgram) {\n            query = this.endTimer(query);\n            this.activeTimers.push({ name: program.constructor.name, query: this.getQueryTime(query) });\n        }\n        if (!environment_1.env().getBool('WEBGL_LAZILY_UNPACK') && outData.isPacked &&\n            preventEagerUnpackingOfOutput === false) {\n            var unpacked = this.unpackTensor(output);\n            this.disposeData(output.dataId);\n            return unpacked;\n        }\n        return output;\n    };\n    MathBackendWebGL.prototype.compileAndRun = function (program, inputs, outputDtype, customSetup, preventEagerUnpackingOfOutput) {\n        if (preventEagerUnpackingOfOutput === void 0) { preventEagerUnpackingOfOutput = false; }\n        outputDtype = outputDtype || inputs[0].dtype;\n        var outInfo = this.runWebGLProgram(program, inputs, outputDtype, customSetup, preventEagerUnpackingOfOutput);\n        return engine_1.ENGINE.makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);\n    };\n    MathBackendWebGL.prototype.getAndSaveBinary = function (key, getBinary) {\n        if (!(key in this.binaryCache)) {\n            this.binaryCache[key] = getBinary();\n        }\n        return this.binaryCache[key];\n    };\n    MathBackendWebGL.prototype.getTextureManager = function () {\n        return this.textureManager;\n    };\n    MathBackendWebGL.prototype.dispose = function () {\n        var _this = this;\n        if (this.disposed) {\n            return;\n        }\n        // Avoid disposing the compiled webgl programs during unit testing because\n        // it slows down test execution.\n        if (!environment_1.env().getBool('IS_TEST')) {\n            var allKeys = Object.keys(this.binaryCache);\n            allKeys.forEach(function (key) {\n                _this.gpgpu.deleteProgram(_this.binaryCache[key].webGLProgram);\n                delete _this.binaryCache[key];\n            });\n        }\n        this.textureManager.dispose();\n        if (this.canvas != null &&\n            (typeof (HTMLCanvasElement) !== 'undefined' &&\n                this.canvas instanceof HTMLCanvasElement)) {\n            this.canvas.remove();\n        }\n        else {\n            this.canvas = null;\n        }\n        if (this.gpgpuCreatedLocally) {\n            this.gpgpu.program = null;\n            this.gpgpu.dispose();\n        }\n        this.disposed = true;\n    };\n    MathBackendWebGL.prototype.floatPrecision = function () {\n        var _this = this;\n        if (this.floatPrecisionValue == null) {\n            this.floatPrecisionValue = globals_1.tidy(function () {\n                if (!environment_1.env().get('WEBGL_RENDER_FLOAT32_ENABLED')) {\n                    // Momentarily switching DEBUG flag to false so we don't throw an\n                    // error trying to upload a small value.\n                    var debugFlag = environment_1.env().getBool('DEBUG');\n                    environment_1.env().set('DEBUG', false);\n                    var underflowCheckValue = _this.abs(tensor_ops_1.scalar(1e-8)).dataSync()[0];\n                    environment_1.env().set('DEBUG', debugFlag);\n                    if (underflowCheckValue > 0) {\n                        return 32;\n                    }\n                }\n                return 16;\n            });\n        }\n        return this.floatPrecisionValue;\n    };\n    /** Returns the smallest representable number.  */\n    MathBackendWebGL.prototype.epsilon = function () {\n        return this.floatPrecision() === 32 ? backend_1.EPSILON_FLOAT32 : backend_1.EPSILON_FLOAT16;\n    };\n    MathBackendWebGL.prototype.uploadToGPU = function (dataId) {\n        var _a;\n        var texData = this.texData.get(dataId);\n        var shape = texData.shape, dtype = texData.dtype, values = texData.values, texture = texData.texture, usage = texData.usage, isPacked = texData.isPacked;\n        if (texture != null) {\n            // Array is already on GPU. No-op.\n            return;\n        }\n        var shouldTimeProgram = this.activeTimers != null;\n        var start;\n        if (shouldTimeProgram) {\n            start = util.now();\n        }\n        var texShape = texData.texShape;\n        if (texShape == null) {\n            texShape = webgl_util.getTextureShapeFromLogicalShape(shape, isPacked);\n            texData.texShape = texShape;\n        }\n        if (values != null) {\n            var shapeAs3D = webgl_util.getShapeAs3D(shape);\n            var program = void 0;\n            var width = texShape[1], height = texShape[0];\n            var isByteArray = values instanceof Uint8Array;\n            if (isPacked) {\n                _a = tex_util.getPackedMatrixTextureShapeWidthHeight(texShape[0], texShape[1]), width = _a[0], height = _a[1];\n                program = new encode_matrix_packed_gpu_1.EncodeMatrixPackedProgram(shapeAs3D, [height, width], isByteArray);\n            }\n            else {\n                program =\n                    new encode_matrix_gpu_1.EncodeMatrixProgram(shapeAs3D, [height, width], isByteArray);\n            }\n            var tempDenseInputHandle = this.makeTensorInfo([height, width], dtype);\n            if (isByteArray) {\n                this.texData.get(tempDenseInputHandle.dataId).usage =\n                    tex_util_1.TextureUsage.PIXELS;\n            }\n            else {\n                this.texData.get(tempDenseInputHandle.dataId).usage =\n                    tex_util_1.TextureUsage.UPLOAD;\n            }\n            this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(tempDenseInputHandle.dataId), width, height, values);\n            // We want the output to remain packed regardless of the value of\n            // WEBGL_PACK.\n            var preventEagerUnpacking = true;\n            var encodedOutputTarget = this.runWebGLProgram(program, [tempDenseInputHandle], dtype, null, preventEagerUnpacking);\n            // Have the original texture assume the identity of the encoded output.\n            var outputTexData = this.texData.get(encodedOutputTarget.dataId);\n            texData.texture = outputTexData.texture;\n            texData.texShape = outputTexData.texShape;\n            texData.isPacked = outputTexData.isPacked;\n            texData.usage = outputTexData.usage;\n            this.disposeData(tempDenseInputHandle.dataId);\n            this.texData.delete(encodedOutputTarget.dataId);\n            // Once uploaded, don't store the values on cpu.\n            texData.values = null;\n            if (shouldTimeProgram) {\n                this.uploadWaitMs += util.now() - start;\n            }\n        }\n        else {\n            var newTexture = this.acquireTexture(texShape, usage, dtype, isPacked);\n            texData.texture = newTexture;\n        }\n    };\n    MathBackendWebGL.prototype.convertAndCacheOnCPU = function (dataId, float32Values) {\n        var texData = this.texData.get(dataId);\n        var dtype = texData.dtype;\n        this.releaseGPUData(dataId);\n        if (float32Values != null) {\n            texData.values = float32ToTypedArray(float32Values, dtype);\n        }\n        return texData.values;\n    };\n    MathBackendWebGL.prototype.acquireTexture = function (texShape, texType, dtype, isPacked) {\n        this.numBytesInGPU += this.computeBytes(texShape, dtype);\n        if (!this.warnedAboutMemory &&\n            this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {\n            var mb = (this.numBytesInGPU / 1024 / 1024).toFixed(2);\n            this.warnedAboutMemory = true;\n            console.warn(\"High memory usage in GPU: \" + mb + \" MB, \" +\n                \"most likely due to a memory leak\");\n        }\n        return this.textureManager.acquireTexture(texShape, texType, isPacked);\n    };\n    MathBackendWebGL.prototype.computeBytes = function (shape, dtype) {\n        return shape[0] * shape[1] * util.bytesPerElement(dtype);\n    };\n    return MathBackendWebGL;\n}(backend_1.KernelBackend));\nexports.MathBackendWebGL = MathBackendWebGL;\nif (device_util.isBrowser()) {\n    engine_1.ENGINE.registerBackend('webgl', function () { return new MathBackendWebGL(); }, 2 /* priority */);\n}\nfunction float32ToTypedArray(a, dtype) {\n    if (dtype === 'float32' || dtype === 'complex64') {\n        return a;\n    }\n    else if (dtype === 'int32' || dtype === 'bool') {\n        var result = (dtype === 'int32') ? new Int32Array(a.length) :\n            new Uint8Array(a.length);\n        for (var i = 0; i < result.length; ++i) {\n            result[i] = Math.round(a[i]);\n        }\n        return result;\n    }\n    else {\n        throw new Error(\"Unknown dtype \" + dtype);\n    }\n}\n//# sourceMappingURL=backend_webgl.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/backend_webgl.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/batchnorm_gpu.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/batchnorm_gpu.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = __webpack_require__(/*! ../../ops/broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar BatchNormProgram = /** @class */ (function () {\n    function BatchNormProgram(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {\n        this.outputShape = [];\n        this.variableNames = ['x', 'mean', 'variance'];\n        broadcast_util.assertAndGetBroadcastShape(xShape, meanShape);\n        broadcast_util.assertAndGetBroadcastShape(xShape, varianceShape);\n        var offsetSnippet = '0.0';\n        if (offsetShape != null) {\n            broadcast_util.assertAndGetBroadcastShape(xShape, offsetShape);\n            this.variableNames.push('offset');\n            offsetSnippet = 'getOffsetAtOutCoords()';\n        }\n        var scaleSnippet = '1.0';\n        if (scaleShape != null) {\n            broadcast_util.assertAndGetBroadcastShape(xShape, scaleShape);\n            this.variableNames.push('scale');\n            scaleSnippet = 'getScaleAtOutCoords()';\n        }\n        this.outputShape = xShape;\n        this.userCode = \"\\n      void main() {\\n        float x = getXAtOutCoords();\\n        float mean = getMeanAtOutCoords();\\n        float variance = getVarianceAtOutCoords();\\n        float offset = \" + offsetSnippet + \";\\n        float scale = \" + scaleSnippet + \";\\n        float inv = scale * inversesqrt(variance + float(\" + varianceEpsilon + \"));\\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\\n      }\\n    \";\n    }\n    return BatchNormProgram;\n}());\nexports.BatchNormProgram = BatchNormProgram;\n//# sourceMappingURL=batchnorm_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/batchnorm_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/batchnorm_packed_gpu.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/batchnorm_packed_gpu.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = __webpack_require__(/*! ../../ops/broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar BatchNormPackedProgram = /** @class */ (function () {\n    function BatchNormPackedProgram(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.variableNames = ['x', 'mean', 'variance'];\n        broadcast_util.assertAndGetBroadcastShape(xShape, meanShape);\n        broadcast_util.assertAndGetBroadcastShape(xShape, varianceShape);\n        var offsetSnippet = 'vec4(0.0)';\n        if (offsetShape != null) {\n            broadcast_util.assertAndGetBroadcastShape(xShape, offsetShape);\n            this.variableNames.push('offset');\n            offsetSnippet = 'getOffsetAtOutCoords()';\n        }\n        var scaleSnippet = 'vec4(1.0)';\n        if (scaleShape != null) {\n            broadcast_util.assertAndGetBroadcastShape(xShape, scaleShape);\n            this.variableNames.push('scale');\n            scaleSnippet = 'getScaleAtOutCoords()';\n        }\n        this.outputShape = xShape;\n        this.userCode = \"\\n      void main() {\\n        vec4 offset = \" + offsetSnippet + \";\\n        vec4 scale = \" + scaleSnippet + \";\\n\\n        vec4 x = getXAtOutCoords();\\n        vec4 mean = getMeanAtOutCoords();\\n        vec4 variance = getVarianceAtOutCoords();\\n\\n        vec4 inv = scale * inversesqrt(variance + vec4(\" + varianceEpsilon + \"));\\n\\n        setOutput((x - mean) * inv + offset);\\n      }\\n    \";\n    }\n    return BatchNormPackedProgram;\n}());\nexports.BatchNormPackedProgram = BatchNormPackedProgram;\n//# sourceMappingURL=batchnorm_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/batchnorm_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_complex_gpu.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_complex_gpu.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = __webpack_require__(/*! ../../ops/broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\n// (Ar + Ai)(Br + Bi) =\n// ArBr + ArBi + AiBr + AiBi = ArBr - AB + ArBi + AiBr\n// Yr = ArBr - AB\n// Yi = ArBi + AiBr\nexports.COMPLEX_MULTIPLY = {\n    REAL: 'return areal * breal - aimag * bimag;',\n    IMAG: 'return areal * bimag + aimag * breal;'\n};\nvar BinaryOpComplexProgram = /** @class */ (function () {\n    function BinaryOpComplexProgram(op, aShape, bShape) {\n        this.variableNames = ['AReal', 'AImag', 'BReal', 'BImag'];\n        this.outputShape =\n            broadcast_util.assertAndGetBroadcastShape(aShape, bShape);\n        this.userCode = \"\\n      float binaryOpComplex(\\n          float areal, float aimag, float breal, float bimag) {\\n        \" + op + \"\\n      }\\n\\n      void main() {\\n        float areal = getARealAtOutCoords();\\n        float aimag = getAImagAtOutCoords();\\n        float breal = getBRealAtOutCoords();\\n        float bimag = getBImagAtOutCoords();\\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\\n      }\\n    \";\n    }\n    return BinaryOpComplexProgram;\n}());\nexports.BinaryOpComplexProgram = BinaryOpComplexProgram;\n//# sourceMappingURL=binaryop_complex_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_complex_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_gpu.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_gpu.js ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = __webpack_require__(/*! ../../ops/broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar CHECK_NAN_SNIPPET = \"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\";\nexports.ADD = 'return a + b;';\nexports.SUB = 'return a - b;';\nexports.MUL = 'return a * b;';\n// Without the equality check div produces 0.9999 for a = b, which when\n// floored can cause errors.\nexports.DIV = \"\\nif (a == b) {\\n  return 1.0;\\n};\\nreturn a / b;\";\n// We use native integer division to deal with floating point imprecision. Since\n// we implement floor division and glsl implements truncated division, we\n// correct for this by subtracting 1 from result when the result is negative and\n// there is a remainder.\nexports.INT_DIV = \"\\n  float s = sign(a) * sign(b);\\n  int ia = round(a);\\n  int ib = round(b);\\n  if (ib != 0) {\\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n    return float(idiv(ia, ib, s));\\n  } else {\\n    return NAN;\\n  }\\n\";\nexports.POW = \"\\nif(a < 0.0 && floor(b) < b){\\n  return NAN;\\n}\\nif (b == 0.0) {\\n  return 1.0;\\n}\\nreturn (round(mod(b, 2.0)) != 1) ?\\n    pow(abs(a), b) : sign(a) * pow(abs(a), b);\\n\";\nexports.SQUARED_DIFFERENCE = 'return (a - b) * (a - b);';\nexports.EQUAL = \"return float(a == b);\";\nexports.NOT_EQUAL = \"return float(a != b);\";\nexports.LESS = \"return float(a < b);\";\nexports.LESS_EQUAL = \"return float(a <= b);\";\nexports.GREATER = \"return float(a > b);\";\nexports.GREATER_EQUAL = \"return float(a >= b);\";\nexports.LOGICAL_AND = \"return float(a >= 1.0 && b >= 1.0);\";\nexports.LOGICAL_OR = \"return float(a >= 1.0 || b >= 1.0);\";\nexports.MAX = CHECK_NAN_SNIPPET + \"\\n  return max(a, b);\\n\";\nexports.MIN = CHECK_NAN_SNIPPET + \"\\n  return min(a, b);\\n\";\nexports.MOD = \"if (b == 0.0) return NAN;\\n  return mod(a, b);\";\nexports.ATAN2 = CHECK_NAN_SNIPPET + \"\\n  return atan(a, b);\\n\";\nexports.ELU_DER = \"return (b >= 1.0) ? a : a * (b + 1.0);\";\nexports.PRELU = \"return (a < 0.) ? b * a : a;\";\nvar BinaryOpProgram = /** @class */ (function () {\n    function BinaryOpProgram(op, aShape, bShape) {\n        this.variableNames = ['A', 'B'];\n        this.outputShape =\n            broadcast_util.assertAndGetBroadcastShape(aShape, bShape);\n        this.userCode = \"\\n      float binaryOperation(float a, float b) {\\n        \" + op + \"\\n      }\\n\\n      void main() {\\n        float a = getAAtOutCoords();\\n        float b = getBAtOutCoords();\\n        setOutput(binaryOperation(a, b));\\n      }\\n    \";\n    }\n    return BinaryOpProgram;\n}());\nexports.BinaryOpProgram = BinaryOpProgram;\n//# sourceMappingURL=binaryop_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_packed_gpu.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_packed_gpu.js ***!
  \***************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util = __webpack_require__(/*! ../../ops/broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar util_1 = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar packing_util_1 = __webpack_require__(/*! ../packing_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js\");\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar CHECK_NAN_SNIPPET = \"\\n  result.r = isNaN.r > 0. ? NAN : result.r;\\n  result.g = isNaN.g > 0. ? NAN : result.g;\\n  result.b = isNaN.b > 0. ? NAN : result.b;\\n  result.a = isNaN.a > 0. ? NAN : result.a;\\n\";\n// We do the same as in ./binaryop_gpu, with vec4 and ivec4.\n// On Linux, the vectorized implementation produces NaNs when a and b are 0.\nexports.DIV = \"\\n  // vec4 one = vec4(equal(a, b));\\n  // return one + (vec4(1.0) - one) * a / b;\\n  vec4 result = a / b;\\n  if(a.x == b.x) {\\n    result.x = 1.;\\n  }\\n  if(a.y == b.y) {\\n    result.y = 1.;\\n  }\\n  if(a.z == b.z) {\\n    result.z = 1.;\\n  }\\n  if(a.w == b.w) {\\n    result.w = 1.;\\n  }\\n\\n  return result;\\n\";\nexports.INT_DIV = \"\\n  ivec4 ia = round(a);\\n  ivec4 ib = round(b);\\n  bvec4 cond = notEqual(ib, ivec4(0));\\n  ivec4 result = ivec4(0);\\n  vec4 s = sign(a) * sign(b);\\n\\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n  if (cond[0]) {\\n    result[0] = idiv(ia[0], ib[0], s[0]);\\n  }\\n  if (cond[1]) {\\n    result[1] = idiv(ia[1], ib[1], s[1]);\\n  }\\n  if (cond[2]) {\\n    result[2] = idiv(ia[2], ib[2], s[2]);\\n  }\\n  if (cond[3]) {\\n    result[3] = idiv(ia[3], ib[3], s[3]);\\n  }\\n  return vec4(result);\\n\";\nexports.POW = \"\\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\\n  vec4 result = multiplier * pow(abs(a), b);\\n\\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\\n  bvec4 isExpZero = equal(b, vec4(0.0));\\n  result.r = isExpZero.r ? 1.0 : result.r;\\n  result.g = isExpZero.g ? 1.0 : result.g;\\n  result.b = isExpZero.b ? 1.0 : result.b;\\n  result.a = isExpZero.a ? 1.0 : result.a;\\n\\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\\n  \" +\n    CHECK_NAN_SNIPPET + \"\\n  return result;\\n\";\nexports.PRELU = \"\\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\\n\";\nexports.ELU_DER = \"\\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\\n\";\nexports.ATAN2 = \"\\n  vec4 result = atan(a, b);\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \" +\n    CHECK_NAN_SNIPPET + \"\\n  return result;\\n\";\nexports.EQUAL = \"\\n  return vec4(equal(a, b));\\n\";\nexports.NOT_EQUAL = \"\\n  return vec4(notEqual(a, b));\\n\";\nexports.LESS = \"\\n  return vec4(lessThan(a, b));\\n\";\nexports.LESS_EQUAL = \"\\n  return vec4(lessThanEqual(a, b));\\n\";\nexports.GREATER = \"\\n  return vec4(greaterThan(a, b));\\n\";\nexports.GREATER_EQUAL = \"\\n  return vec4(greaterThanEqual(a, b));\\n\";\nexports.LOGICAL_AND = \"\\n  return vec4(\\n    vec4(greaterThanEqual(a, vec4(1.0))) *\\n    vec4(greaterThanEqual(b, vec4(1.0))));\\n\";\nexports.LOGICAL_OR = \"\\n  return min(\\n    vec4(greaterThanEqual(a, vec4(1.0))) +\\n    vec4(greaterThanEqual(b, vec4(1.0))),\\n    vec4(1.0));\\n\";\nexports.MAX = \"\\n  vec4 result = vec4(max(a, b));\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \" +\n    CHECK_NAN_SNIPPET + \"\\n  return result;\\n\";\nexports.MIN = \"\\n  vec4 result = vec4(min(a, b));\\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\\n  \" +\n    CHECK_NAN_SNIPPET + \"\\n  return result;\\n\";\nexports.MOD = \"\\n  vec4 result = mod(a, b);\\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\\n  \" +\n    CHECK_NAN_SNIPPET + \"\\n  return result;\\n\";\nvar BinaryOpPackedProgram = /** @class */ (function () {\n    function BinaryOpPackedProgram(op, aShape, bShape, checkOutOfBounds) {\n        if (checkOutOfBounds === void 0) { checkOutOfBounds = false; }\n        this.variableNames = ['A', 'B'];\n        this.supportsBroadcasting = true;\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape =\n            broadcast_util.assertAndGetBroadcastShape(aShape, bShape);\n        var rank = this.outputShape.length;\n        var checkOutOfBoundsString = '';\n        if (checkOutOfBounds) {\n            if (rank === 0 || util_1.sizeFromShape(this.outputShape) === 1) {\n                checkOutOfBoundsString = \"\\n          result.y = 0.;\\n          result.z = 0.;\\n          result.w = 0.;\\n        \";\n            }\n            else {\n                var dtype = shader_compiler_1.getCoordsDataType(rank);\n                checkOutOfBoundsString = \"\\n          \" + dtype + \" coords = getOutputCoords();\\n        \";\n                if (rank === 1) {\n                    checkOutOfBoundsString += \"\\n            result.y = (coords + 1) >= \" + this.outputShape[0] + \" ? 0. : result.y;\\n            result.z = 0.;\\n            result.w = 0.;\\n          \";\n                }\n                else {\n                    var channels = packing_util_1.getChannels('coords', rank);\n                    checkOutOfBoundsString += \"\\n            bool nextRowOutOfBounds =\\n              (\" + channels[rank - 2] + \" + 1) >= \" + this.outputShape[rank - 2] + \";\\n            bool nextColOutOfBounds =\\n              (\" + channels[rank - 1] + \" + 1) >= \" + this.outputShape[rank - 1] + \";\\n            result.y = nextColOutOfBounds ? 0. : result.y;\\n            result.z = nextRowOutOfBounds ? 0. : result.z;\\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\\n          \";\n                }\n            }\n        }\n        this.userCode = \"\\n      vec4 binaryOperation(vec4 a, vec4 b) {\\n        \" + op + \"\\n      }\\n\\n      void main() {\\n        vec4 a = getAAtOutCoords();\\n        vec4 b = getBAtOutCoords();\\n\\n        vec4 result = binaryOperation(a, b);\\n        \" + checkOutOfBoundsString + \"\\n\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return BinaryOpPackedProgram;\n}());\nexports.BinaryOpPackedProgram = BinaryOpPackedProgram;\n//# sourceMappingURL=binaryop_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/canvas_util.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/canvas_util.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar contexts = {};\nvar WEBGL_ATTRIBUTES = {\n    alpha: false,\n    antialias: false,\n    premultipliedAlpha: false,\n    preserveDrawingBuffer: false,\n    depth: false,\n    stencil: false,\n    failIfMajorPerformanceCaveat: true\n};\nfunction setWebGLContext(webGLVersion, gl) {\n    contexts[webGLVersion] = gl;\n}\nexports.setWebGLContext = setWebGLContext;\nfunction getWebGLContext(webGLVersion) {\n    if (!(webGLVersion in contexts)) {\n        contexts[webGLVersion] = getWebGLRenderingContext(webGLVersion);\n    }\n    var gl = contexts[webGLVersion];\n    if (gl.isContextLost()) {\n        delete contexts[webGLVersion];\n        return getWebGLContext(webGLVersion);\n    }\n    gl.disable(gl.DEPTH_TEST);\n    gl.disable(gl.STENCIL_TEST);\n    gl.disable(gl.BLEND);\n    gl.disable(gl.DITHER);\n    gl.disable(gl.POLYGON_OFFSET_FILL);\n    gl.disable(gl.SAMPLE_COVERAGE);\n    gl.enable(gl.SCISSOR_TEST);\n    gl.enable(gl.CULL_FACE);\n    gl.cullFace(gl.BACK);\n    return contexts[webGLVersion];\n}\nexports.getWebGLContext = getWebGLContext;\nfunction createCanvas(webGLVersion) {\n    if (typeof OffscreenCanvas !== 'undefined' && webGLVersion === 2) {\n        return new OffscreenCanvas(300, 150);\n    }\n    else if (typeof document !== 'undefined') {\n        return document.createElement('canvas');\n    }\n    else {\n        throw new Error('Cannot create a canvas in this context');\n    }\n}\nfunction getWebGLRenderingContext(webGLVersion) {\n    if (webGLVersion !== 1 && webGLVersion !== 2) {\n        throw new Error('Cannot get WebGL rendering context, WebGL is disabled.');\n    }\n    var canvas = createCanvas(webGLVersion);\n    canvas.addEventListener('webglcontextlost', function (ev) {\n        ev.preventDefault();\n        delete contexts[webGLVersion];\n    }, false);\n    if (webGLVersion === 1) {\n        return (canvas.getContext('webgl', WEBGL_ATTRIBUTES) ||\n            canvas.getContext('experimental-webgl', WEBGL_ATTRIBUTES));\n    }\n    return canvas.getContext('webgl2', WEBGL_ATTRIBUTES);\n}\n//# sourceMappingURL=canvas_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/canvas_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/clip_gpu.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/clip_gpu.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ClipProgram = /** @class */ (function () {\n    function ClipProgram(aShape) {\n        this.variableNames = ['A'];\n        this.outputShape = aShape;\n        this.userCode = \"\\n      uniform float minVal;\\n      uniform float maxVal;\\n\\n      void main() {\\n        float value = getAAtOutCoords();\\n        if (isnan(value)) {\\n          setOutput(value);\\n          return;\\n        }\\n\\n        setOutput(clamp(value, minVal, maxVal));\\n      }\\n    \";\n    }\n    ClipProgram.prototype.getCustomSetupFunc = function (min, max) {\n        var _this = this;\n        return function (gpgpu, webGLProgram) {\n            if (_this.minLoc == null) {\n                _this.minLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'minVal');\n                _this.maxLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'maxVal');\n            }\n            gpgpu.gl.uniform1f(_this.minLoc, min);\n            gpgpu.gl.uniform1f(_this.maxLoc, max);\n        };\n    };\n    return ClipProgram;\n}());\nexports.ClipProgram = ClipProgram;\n//# sourceMappingURL=clip_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/clip_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/clip_packed_gpu.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/clip_packed_gpu.js ***!
  \***********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ClipPackedProgram = /** @class */ (function () {\n    function ClipPackedProgram(aShape) {\n        this.variableNames = ['A'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = aShape;\n        this.userCode = \"\\n      uniform float minVal;\\n      uniform float maxVal;\\n\\n      void main() {\\n        vec4 value = getAAtOutCoords();\\n\\n        if (any(isnan(value))) {\\n          setOutput(value);\\n          return;\\n        }\\n\\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\\n      }\\n    \";\n    }\n    ClipPackedProgram.prototype.getCustomSetupFunc = function (min, max) {\n        var _this = this;\n        return function (gpgpu, webGLProgram) {\n            if (_this.minLoc == null) {\n                _this.minLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'minVal');\n                _this.maxLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'maxVal');\n            }\n            gpgpu.gl.uniform1f(_this.minLoc, min);\n            gpgpu.gl.uniform1f(_this.maxLoc, max);\n        };\n    };\n    return ClipPackedProgram;\n}());\nexports.ClipPackedProgram = ClipPackedProgram;\n//# sourceMappingURL=clip_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/clip_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/complex_abs_gpu.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/complex_abs_gpu.js ***!
  \***********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ComplexAbsProgram = /** @class */ (function () {\n    function ComplexAbsProgram(shape) {\n        this.variableNames = ['real', 'imag'];\n        this.outputShape = shape;\n        this.userCode = \"\\n      void main() {\\n        float re = abs(getRealAtOutCoords());\\n        float im = abs(getImagAtOutCoords());\\n        float mx = max(re, im);\\n\\n        // sadly the length function in glsl is not underflow-safe\\n        // (at least not on Intel GPUs). So the safe solution is\\n        // to ensure underflow-safety in all cases.\\n        setOutput(\\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\\n        );\\n      }\\n    \";\n    }\n    return ComplexAbsProgram;\n}());\nexports.ComplexAbsProgram = ComplexAbsProgram;\n//# sourceMappingURL=complex_abs_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/complex_abs_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/concat_gpu.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/concat_gpu.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar concat_util = __webpack_require__(/*! ../../ops/concat_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js\");\nvar ConcatProgram = /** @class */ (function () {\n    // Concats 2d tensors along axis=1. See comments in MathBackendWebGL.concat().\n    function ConcatProgram(shapes) {\n        this.outputShape = [];\n        this.outputShape = concat_util.computeOutShape(shapes, 1 /* axis */);\n        this.variableNames = shapes.map(function (_, i) { return \"T\" + i; });\n        var offsets = new Array(shapes.length - 1);\n        offsets[0] = shapes[0][1];\n        for (var i = 1; i < offsets.length; i++) {\n            offsets[i] = offsets[i - 1] + shapes[i][1];\n        }\n        var snippets = [\"if (yC < \" + offsets[0] + \") setOutput(getT0(yR, yC));\"];\n        for (var i = 1; i < offsets.length; i++) {\n            var shift = offsets[i - 1];\n            snippets.push(\"else if (yC < \" + offsets[i] + \") \" +\n                (\"setOutput(getT\" + i + \"(yR, yC-\" + shift + \"));\"));\n        }\n        var lastIndex = offsets.length;\n        var lastShift = offsets[offsets.length - 1];\n        snippets.push(\"else setOutput(getT\" + lastIndex + \"(yR, yC-\" + lastShift + \"));\");\n        this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int yR = coords.x;\\n        int yC = coords.y;\\n\\n        \" + snippets.join('\\n        ') + \"\\n      }\\n    \";\n    }\n    return ConcatProgram;\n}());\nexports.ConcatProgram = ConcatProgram;\n//# sourceMappingURL=concat_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/concat_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/concat_packed_gpu.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/concat_packed_gpu.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar concat_util = __webpack_require__(/*! ../../ops/concat_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js\");\nvar packing_util_1 = __webpack_require__(/*! ../packing_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js\");\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar ConcatPackedProgram = /** @class */ (function () {\n    function ConcatPackedProgram(shapes, axis) {\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = [];\n        this.outputShape = concat_util.computeOutShape(shapes, axis);\n        var shape = this.outputShape;\n        var rank = shape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(rank);\n        var coords = packing_util_1.getChannels('coords', rank);\n        var channels = ['x', 'y', 'z', 'w', 'u', 'v'].slice(0, rank);\n        this.variableNames = shapes.map(function (_, i) { return \"T\" + i; });\n        var offsets = new Array(shapes.length - 1);\n        offsets[0] = shapes[0][axis];\n        for (var i = 1; i < offsets.length; i++) {\n            offsets[i] = offsets[i - 1] + shapes[i][axis];\n        }\n        var channel = channels[axis];\n        var lastChannels = channels.slice(-2);\n        var allChannels = channels.join();\n        var getValueSnippet = \"if (\" + channel + \" < \" + offsets[0] + \") {\\n        return getChannel(\\n            getT0(\" + allChannels + \"), vec2(\" + lastChannels.join() + \"));\\n        }\";\n        for (var i = 1; i < offsets.length; i++) {\n            var shift_1 = offsets[i - 1];\n            // Note: the >= comparison below may seem unnecessary given the check\n            // above but is needed to workaround branch execution issues on some\n            // devices. It makes all the conditions exclusive without relying on\n            // execution order.\n            getValueSnippet += \"\\n        if (\" + channel + \" < \" + offsets[i] + \"  && \" + channel + \" >= \" + offsets[i - 1] + \") {\\n          return getChannel(\\n            getT\" + i + \"(\" + shiftedChannels(channels, channel, shift_1) + \"),\\n            vec2(\" + shiftedChannels(lastChannels, channel, shift_1) + \"));\\n        }\";\n        }\n        var lastIndex = offsets.length;\n        var shift = offsets[offsets.length - 1];\n        getValueSnippet += \"\\n        return getChannel(\\n          getT\" + lastIndex + \"(\" + shiftedChannels(channels, channel, shift) + \"),\\n          vec2(\" + shiftedChannels(lastChannels, channel, shift) + \"));\";\n        this.userCode = \"\\n      float getValue(\" + channels.map(function (x) { return 'int ' + x; }) + \") {\\n        \" + getValueSnippet + \"\\n      }\\n\\n      void main() {\\n        \" + dtype + \" coords = getOutputCoords();\\n        vec4 result = vec4(getValue(\" + coords + \"), 0., 0., 0.);\\n\\n        \" + coords[rank - 1] + \" = \" + coords[rank - 1] + \" + 1;\\n        if (\" + coords[rank - 1] + \" < \" + shape[rank - 1] + \") {\\n          result.g = getValue(\" + coords + \");\\n        }\\n\\n        \" + coords[rank - 2] + \" = \" + coords[rank - 2] + \" + 1;\\n        if (\" + coords[rank - 2] + \" < \" + shape[rank - 2] + \") {\\n          result.a = getValue(\" + coords + \");\\n        }\\n\\n        \" + coords[rank - 1] + \" = \" + coords[rank - 1] + \" - 1;\\n        if (\" + coords[rank - 2] + \" < \" + shape[rank - 2] + \" &&\\n            \" + coords[rank - 1] + \" < \" + shape[rank - 1] + \") {\\n          result.b = getValue(\" + coords + \");\\n        }\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return ConcatPackedProgram;\n}());\nexports.ConcatPackedProgram = ConcatPackedProgram;\n/**\n * Return an expression for coordinates into a vector where a given channel\n * will be offset by [shift].\n *\n * @param channels the channels to consider\n * @param channel the channel we want shifted\n * @param shift  the amount to subtract from the channel.\n *\n * @returns a string of the form 'x, y-[shift], z' where any one channel can\n * have the shift applied.\n */\nfunction shiftedChannels(channels, channel, shift) {\n    var channelIdx = channels.indexOf(channel);\n    var res = channels.map(function (c, idx) {\n        if (idx === channelIdx) {\n            return c + \" - \" + shift;\n        }\n        else {\n            return c;\n        }\n    });\n    return res.join();\n}\n//# sourceMappingURL=concat_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/concat_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_backprop_gpu.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_backprop_gpu.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar Conv2DDerFilterProgram = /** @class */ (function () {\n    function Conv2DDerFilterProgram(convInfo) {\n        this.variableNames = ['x', 'dy'];\n        this.outputShape = convInfo.filterShape;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var isChannelsLast = convInfo.dataFormat === 'channelsLast';\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int wR = coords.x;\\n        int wC = coords.y;\\n        int d1 = coords.z;\\n        int d2 = coords.w;\\n\\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int b = 0; b < \" + convInfo.batchSize + \"; b++) {\\n          for (int yR = 0; yR < \" + convInfo.outHeight + \"; yR++) {\\n            int xR = wR + yR * \" + strideHeight + \" - \" + padTop + \";\\n\\n            if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n              continue;\\n            }\\n\\n            for (int yC = 0; yC < \" + convInfo.outWidth + \"; yC++) {\\n              int xC = wC + yC * \" + strideWidth + \" - \" + padLeft + \";\\n\\n              if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                continue;\\n              }\\n\\n              if (\" + isChannelsLast + \") {\\n                float dyValue = getDy(b, yR, yC, d2);\\n                float xValue = getX(b, xR, xC, d1);\\n                dotProd += (xValue * dyValue);\\n              } else {\\n                float dyValue = getDy(b, d2, yR, yC);\\n                float xValue = getX(b, d1, xR, xC);\\n                dotProd += (xValue * dyValue);\\n              }\\n\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv2DDerFilterProgram;\n}());\nexports.Conv2DDerFilterProgram = Conv2DDerFilterProgram;\nvar Conv2DDerInputProgram = /** @class */ (function () {\n    function Conv2DDerInputProgram(convInfo) {\n        this.variableNames = ['dy', 'W'];\n        this.outputShape = convInfo.inShape;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var isChannelsLast = convInfo.dataFormat === 'channelsLast';\n        var padTop = filterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n        var rowDim = isChannelsLast ? 1 : 2;\n        var colDim = isChannelsLast ? 2 : 3;\n        var channelDim = isChannelsLast ? 3 : 1;\n        this.userCode = \"\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d1 = coords[\" + channelDim + \"];\\n\\n        ivec2 dyCorner = ivec2(coords[\" + rowDim + \"], coords[\" + colDim + \"]) - pads;\\n        int dyRCorner = dyCorner.x;\\n        int dyCCorner = dyCorner.y;\\n\\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n          float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n          if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          int wRPerm = \" + filterHeight + \" - 1 - wR;\\n\\n          for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n            if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            int wCPerm = \" + filterWidth + \" - 1 - wC;\\n\\n            for (int d2 = 0; d2 < \" + convInfo.outChannels + \"; d2++) {\\n\\n              if (\" + isChannelsLast + \") {\\n                float xValue = getDy(batch, idyR, idyC, d2);\\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              } else {\\n                float xValue = getDy(batch, d2, idyR, idyC);\\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              }\\n\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv2DDerInputProgram;\n}());\nexports.Conv2DDerInputProgram = Conv2DDerInputProgram;\nvar Conv3DDerFilterProgram = /** @class */ (function () {\n    function Conv3DDerFilterProgram(convInfo) {\n        this.variableNames = ['x', 'dy'];\n        this.outputShape = convInfo.filterShape;\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padFront = convInfo.padInfo.front;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        this.userCode = \"\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int wF = coords.x;\\n        int wR = coords.y;\\n        int wC = coords.z;\\n        int d1 = coords.w;\\n        int d2 = coords.u;\\n\\n        float dotProd = 0.0;\\n\\n        for (int b = 0; b < \" + convInfo.batchSize + \"; b++) {\\n          for (int yF = 0; yF < \" + convInfo.outDepth + \"; yF++) {\\n            int xF = wF + yF * \" + strideDepth + \" - \" + padFront + \";\\n\\n            if (xF < 0 || xF >= \" + convInfo.inDepth + \") {\\n              continue;\\n            }\\n\\n            for (int yR = 0; yR < \" + convInfo.outHeight + \"; yR++) {\\n              int xR = wR + yR * \" + strideHeight + \" - \" + padTop + \";\\n\\n              if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n                continue;\\n              }\\n\\n              for (int yC = 0; yC < \" + convInfo.outWidth + \"; yC++) {\\n                int xC = wC + yC * \" + strideWidth + \" - \" + padLeft + \";\\n\\n                if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                  continue;\\n                }\\n\\n                float dyValue = getDy(b, yF, yR, yC, d2);\\n                float xValue = getX(b, xF, xR, xC, d1);\\n                dotProd += (xValue * dyValue);\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv3DDerFilterProgram;\n}());\nexports.Conv3DDerFilterProgram = Conv3DDerFilterProgram;\nvar Conv3DDerInputProgram = /** @class */ (function () {\n    function Conv3DDerInputProgram(convInfo) {\n        this.variableNames = ['dy', 'W'];\n        this.outputShape = convInfo.inShape;\n        var filterDepth = convInfo.filterDepth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padFront = filterDepth - 1 - convInfo.padInfo.front;\n        var padTop = filterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n        this.userCode = \"\\n      const ivec3 pads = ivec3(\" + padFront + \", \" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d1 = coords.u;\\n\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyFCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        float dotProd = 0.0;\\n        for (int wF = 0; wF < \" + filterDepth + \"; wF++) {\\n          float dyF = float(dyFCorner + wF) / \" + strideDepth + \".0;\\n\\n          if (dyF < 0.0 || dyF >= \" + convInfo.outDepth + \".0 || fract(dyF) > 0.0) {\\n            continue;\\n          }\\n          int idyF = int(dyF);\\n\\n          int wFPerm = \" + filterDepth + \" - 1 - wF;\\n\\n          for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n            float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n            if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 ||\\n              fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            int wRPerm = \" + filterHeight + \" - 1 - wR;\\n\\n            for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n              float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n              if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              int wCPerm = \" + filterWidth + \" - 1 - wC;\\n\\n              for (int d2 = 0; d2 < \" + convInfo.outChannels + \"; d2++) {\\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\\n                dotProd += xValue * wValue;\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv3DDerInputProgram;\n}());\nexports.Conv3DDerInputProgram = Conv3DDerInputProgram;\n//# sourceMappingURL=conv_backprop_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_backprop_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_backprop_gpu_depthwise.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_backprop_gpu_depthwise.js ***!
  \***********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar DepthwiseConv2DDerFilterProgram = /** @class */ (function () {\n    function DepthwiseConv2DDerFilterProgram(convInfo) {\n        this.variableNames = ['x', 'dy'];\n        this.outputShape = convInfo.filterShape;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var channelMul = convInfo.outChannels / convInfo.inChannels;\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int wR = coords.x;\\n        int wC = coords.y;\\n        int d1 = coords.z;\\n        int dm = coords.w;\\n        int d2 = d1 * \" + channelMul + \" + dm;\\n\\n        float dotProd = 0.0;\\n\\n        // TO DO: Vec4 over the batch size\\n        for (int b = 0; b < \" + convInfo.batchSize + \"; b++) {\\n          for (int yR = 0; yR < \" + convInfo.outHeight + \"; yR++) {\\n            int xR = wR + yR * \" + strideHeight + \" - \" + padTop + \";\\n\\n            if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n              continue;\\n            }\\n\\n            for (int yC = 0; yC < \" + convInfo.outWidth + \"; yC++) {\\n              int xC = wC + yC * \" + strideWidth + \" - \" + padLeft + \";\\n\\n              if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                continue;\\n              }\\n\\n              float dyValue = getDy(b, yR, yC, d2);\\n              float xValue = getX(b, xR, xC, d1);\\n              dotProd += (xValue * dyValue);\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return DepthwiseConv2DDerFilterProgram;\n}());\nexports.DepthwiseConv2DDerFilterProgram = DepthwiseConv2DDerFilterProgram;\nvar DepthwiseConv2DDerInputProgram = /** @class */ (function () {\n    function DepthwiseConv2DDerInputProgram(convInfo) {\n        this.variableNames = ['dy', 'W'];\n        this.outputShape = convInfo.inShape;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var padTop = filterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n        var channelMul = convInfo.outChannels / convInfo.inChannels;\n        this.userCode = \"\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d1 = coords[3];\\n        ivec2 dyCorner = coords.yz - pads;\\n        int dyRCorner = dyCorner.x;\\n        int dyCCorner = dyCorner.y;\\n\\n        float dotProd = 0.0;\\n\\n        for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n          float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n          if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          int wRPerm = \" + filterHeight + \" - 1 - wR;\\n\\n          for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n            if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            int wCPerm = \" + filterWidth + \" - 1 - wC;\\n\\n            // TO DO: Vec4 over the channelMul\\n            for (int dm = 0; dm < \" + channelMul + \"; dm++) {\\n              int d2 = d1 * \" + channelMul + \" + dm;\\n              float xValue = getDy(batch, idyR, idyC, d2);\\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\\n              dotProd += xValue * wValue;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return DepthwiseConv2DDerInputProgram;\n}());\nexports.DepthwiseConv2DDerInputProgram = DepthwiseConv2DDerInputProgram;\n//# sourceMappingURL=conv_backprop_gpu_depthwise.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_backprop_gpu_depthwise.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_gpu.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_gpu.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar Conv2DProgram = /** @class */ (function () {\n    function Conv2DProgram(convInfo, addBias, activation, hasPreluActivationWeights) {\n        if (addBias === void 0) { addBias = false; }\n        if (activation === void 0) { activation = null; }\n        if (hasPreluActivationWeights === void 0) { hasPreluActivationWeights = false; }\n        this.variableNames = ['x', 'W'];\n        this.outputShape = convInfo.outShape;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;\n        var inputDepthVec4Remainder = convInfo.inChannels % 4;\n        var isChannelsLast = convInfo.dataFormat === 'channelsLast';\n        var rowDim = isChannelsLast ? 1 : 2;\n        var colDim = isChannelsLast ? 2 : 3;\n        var channelDim = isChannelsLast ? 3 : 1;\n        var activationSnippet = '', applyActivationSnippet = '';\n        if (activation) {\n            if (hasPreluActivationWeights) {\n                activationSnippet = \"float activation(float a) {\\n          float b = getPreluActivationWeightsAtOutCoords();\\n          \" + activation + \"\\n        }\";\n            }\n            else {\n                activationSnippet = \"\\n          float activation(float x) {\\n            \" + activation + \"\\n          }\\n        \";\n            }\n            applyActivationSnippet = \"result = activation(result);\";\n        }\n        var addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n        if (addBias) {\n            this.variableNames.push('bias');\n        }\n        if (hasPreluActivationWeights) {\n            this.variableNames.push('preluActivationWeights');\n        }\n        this.userCode = \"\\n      \" + activationSnippet + \"\\n\\n      const ivec2 strides = ivec2(\" + strideHeight + \", \" + strideWidth + \");\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d2 = coords[\" + channelDim + \"];\\n\\n        ivec2 xRCCorner =\\n            ivec2(coords[\" + rowDim + \"], coords[\" + colDim + \"]) * strides - pads;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n          int xR = xRCorner + wR * \" + dilationHeight + \";\\n\\n          if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n            int xC = xCCorner + wC * \" + dilationWidth + \";\\n\\n            if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n              continue;\\n            }\\n\\n            for (int d1 = 0; d1 < \" + inputDepthNearestVec4 + \"; d1 += 4) {\\n              vec4 wValues = vec4(\\n                getW(wR, wC, d1, d2),\\n                getW(wR, wC, d1 + 1, d2),\\n                getW(wR, wC, d1 + 2, d2),\\n                getW(wR, wC, d1 + 3, d2)\\n              );\\n\\n              if (\" + isChannelsLast + \") {\\n                vec4 xValues = vec4(\\n                  getX(batch, xR, xC, d1),\\n                  getX(batch, xR, xC, d1 + 1),\\n                  getX(batch, xR, xC, d1 + 2),\\n                  getX(batch, xR, xC, d1 + 3)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec4 xValues = vec4(\\n                  getX(batch, d1, xR, xC),\\n                  getX(batch, d1 + 1, xR, xC),\\n                  getX(batch, d1 + 2, xR, xC),\\n                  getX(batch, d1 + 3, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n            }\\n\\n            if (\" + (inputDepthVec4Remainder === 1) + \") {\\n\\n              if (\" + isChannelsLast + \") {\\n                dotProd +=\\n                    getX(batch, xR, xC, \" + inputDepthNearestVec4 + \") *\\n                    getW(wR, wC, \" + inputDepthNearestVec4 + \", d2);\\n              } else {\\n                dotProd +=\\n                    getX(batch, \" + inputDepthNearestVec4 + \", xR, xC) *\\n                    getW(wR, wC, \" + inputDepthNearestVec4 + \", d2);\\n              }\\n\\n            } else if (\" + (inputDepthVec4Remainder === 2) + \") {\\n              vec2 wValues = vec2(\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \", d2),\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \" + 1, d2)\\n              );\\n\\n              if (\" + isChannelsLast + \") {\\n                vec2 xValues = vec2(\\n                  getX(batch, xR, xC, \" + inputDepthNearestVec4 + \"),\\n                  getX(batch, xR, xC, \" + inputDepthNearestVec4 + \" + 1)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec2 xValues = vec2(\\n                  getX(batch, \" + inputDepthNearestVec4 + \", xR, xC),\\n                  getX(batch, \" + inputDepthNearestVec4 + \" + 1, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n            } else if (\" + (inputDepthVec4Remainder === 3) + \") {\\n              vec3 wValues = vec3(\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \", d2),\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \" + 1, d2),\\n                getW(wR, wC, \" + inputDepthNearestVec4 + \" + 2, d2)\\n              );\\n\\n              if (\" + isChannelsLast + \") {\\n                vec3 xValues = vec3(\\n                  getX(batch, xR, xC, \" + inputDepthNearestVec4 + \"),\\n                  getX(batch, xR, xC, \" + inputDepthNearestVec4 + \" + 1),\\n                  getX(batch, xR, xC, \" + inputDepthNearestVec4 + \" + 2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else {\\n                vec3 xValues = vec3(\\n                  getX(batch, \" + inputDepthNearestVec4 + \", xR, xC),\\n                  getX(batch, \" + inputDepthNearestVec4 + \" + 1, xR, xC),\\n                  getX(batch, \" + inputDepthNearestVec4 + \" + 2, xR, xC)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n            }\\n          }\\n        }\\n\\n        float result = dotProd;\\n        \" + addBiasSnippet + \"\\n        \" + applyActivationSnippet + \"\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return Conv2DProgram;\n}());\nexports.Conv2DProgram = Conv2DProgram;\nvar Conv3DProgram = /** @class */ (function () {\n    function Conv3DProgram(convInfo) {\n        this.variableNames = ['x', 'W'];\n        this.outputShape = convInfo.outShape;\n        var padFront = convInfo.padInfo.front;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var filterDepth = convInfo.filterDepth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;\n        var inputDepthVec4Remainder = convInfo.inChannels % 4;\n        this.userCode = \"\\n      const ivec3 strides = ivec3(\" + strideDepth + \", \" + strideHeight + \", \" + strideWidth + \");\\n      const ivec3 pads = ivec3(\" + padFront + \", \" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int d2 = coords.u;\\n\\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n        int xFCorner = xFRCCorner.x;\\n        int xRCorner = xFRCCorner.y;\\n        int xCCorner = xFRCCorner.z;\\n\\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\\n        // values in that axis.\\n        float dotProd = 0.0;\\n        for (int wF = 0; wF < \" + filterDepth + \"; wF++) {\\n          int xF = xFCorner + wF * \" + dilationDepth + \";\\n\\n          if (xF < 0 || xF >= \" + convInfo.inDepth + \") {\\n            continue;\\n          }\\n\\n          for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n            int xR = xRCorner + wR * \" + dilationHeight + \";\\n\\n            if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n              int xC = xCCorner + wC * \" + dilationWidth + \";\\n\\n              if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                continue;\\n              }\\n\\n              for (int d1 = 0; d1 < \" + inputDepthNearestVec4 + \"; d1 += 4) {\\n                vec4 xValues = vec4(\\n                  getX(batch, xF, xR, xC, d1),\\n                  getX(batch, xF, xR, xC, d1 + 1),\\n                  getX(batch, xF, xR, xC, d1 + 2),\\n                  getX(batch, xF, xR, xC, d1 + 3)\\n                );\\n                vec4 wValues = vec4(\\n                  getW(wF, wR, wC, d1, d2),\\n                  getW(wF, wR, wC, d1 + 1, d2),\\n                  getW(wF, wR, wC, d1 + 2, d2),\\n                  getW(wF, wR, wC, d1 + 3, d2)\\n                );\\n\\n                dotProd += dot(xValues, wValues);\\n              }\\n\\n              if (\" + (inputDepthVec4Remainder === 1) + \") {\\n                dotProd +=\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \") *\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \", d2);\\n              } else if (\" + (inputDepthVec4Remainder === 2) + \") {\\n                vec2 xValues = vec2(\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \"),\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \" + 1)\\n                );\\n                vec2 wValues = vec2(\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \", d2),\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \" + 1, d2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              } else if (\" + (inputDepthVec4Remainder === 3) + \") {\\n                vec3 xValues = vec3(\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \"),\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \" + 1),\\n                  getX(batch, xF, xR, xC, \" + inputDepthNearestVec4 + \" + 2)\\n                );\\n                vec3 wValues = vec3(\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \", d2),\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \" + 1, d2),\\n                  getW(wF, wR, wC, \" + inputDepthNearestVec4 + \" + 2, d2)\\n                );\\n                dotProd += dot(xValues, wValues);\\n              }\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return Conv3DProgram;\n}());\nexports.Conv3DProgram = Conv3DProgram;\n//# sourceMappingURL=conv_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_gpu_depthwise.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_gpu_depthwise.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar DepthwiseConv2DProgram = /** @class */ (function () {\n    function DepthwiseConv2DProgram(convInfo, addBias, activation, hasPreluActivation) {\n        if (addBias === void 0) { addBias = false; }\n        if (activation === void 0) { activation = null; }\n        if (hasPreluActivation === void 0) { hasPreluActivation = false; }\n        this.variableNames = ['x', 'W'];\n        this.outputShape = convInfo.outShape;\n        var xNumRows = convInfo.inHeight;\n        var xNumCols = convInfo.inWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var channelMul = convInfo.outChannels / convInfo.inChannels;\n        var activationSnippet = '', applyActivationSnippet = '';\n        if (activation) {\n            if (hasPreluActivation) {\n                activationSnippet = \"float activation(float a) {\\n          float b = getPreluActivationWeightsAtOutCoords();\\n          \" + activation + \"\\n        }\";\n            }\n            else {\n                activationSnippet = \"\\n          float activation(float x) {\\n            \" + activation + \"\\n          }\\n        \";\n            }\n            applyActivationSnippet = \"result = activation(result);\";\n        }\n        var addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n        if (addBias) {\n            this.variableNames.push('bias');\n        }\n        if (hasPreluActivation) {\n            this.variableNames.push('preluActivationWeights');\n        }\n        this.userCode = \"\\n      \" + activationSnippet + \"\\n\\n      const ivec2 strides = ivec2(\" + strideHeight + \", \" + strideWidth + \");\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2 / \" + channelMul + \";\\n        int q = d2 - d1 * \" + channelMul + \";\\n\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\\n        for (int wR = 0; wR < \" + filterHeight + \"; wR++) {\\n          int xR = xRCorner + wR * \" + dilationHeight + \";\\n\\n          if (xR < 0 || xR >= \" + xNumRows + \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \" + filterWidth + \"; wC++) {\\n            int xC = xCCorner + wC * \" + dilationWidth + \";\\n\\n            if (xC < 0 || xC >= \" + xNumCols + \") {\\n              continue;\\n            }\\n\\n            float xVal = getX(batch, xR, xC, d1);\\n            float wVal = getW(wR, wC, d1, q);\\n            dotProd += xVal * wVal;\\n          }\\n        }\\n\\n        float result = dotProd;\\n        \" + addBiasSnippet + \"\\n        \" + applyActivationSnippet + \"\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return DepthwiseConv2DProgram;\n}());\nexports.DepthwiseConv2DProgram = DepthwiseConv2DProgram;\n//# sourceMappingURL=conv_gpu_depthwise.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_gpu_depthwise.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_packed_gpu_depthwise.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_packed_gpu_depthwise.js ***!
  \*********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar DepthwiseConvPacked2DProgram = /** @class */ (function () {\n    function DepthwiseConvPacked2DProgram(convInfo, addBias, activation, hasPreluActivation) {\n        if (addBias === void 0) { addBias = false; }\n        if (activation === void 0) { activation = null; }\n        if (hasPreluActivation === void 0) { hasPreluActivation = false; }\n        this.variableNames = ['x', 'W'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = convInfo.outShape;\n        var xNumRows = convInfo.inHeight;\n        var xNumCols = convInfo.inWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var texelsAcross = filterWidth;\n        var mainLoop = \"int xR; int xC; int xCOffset;\";\n        for (var r = 0; r < filterHeight; r++) {\n            for (var c = 0; c < filterWidth; c++) {\n                mainLoop += \"\\n          vec4 xTexelR\" + r + \"C\" + c * 2 + \" = vec4(0.);\\n          vec4 wR\" + r + \"C\" + c + \" = vec4(0.);\\n          vec4 xR\" + r + \"C\" + c + \" = vec4(0.);\";\n            }\n        }\n        /**\n         * This vectorized implementation works by gathering the values needed for\n         * each output channel's dot product into vec4's and then multiplying them\n         * all together (this happens in the final double for-loop below). Most of\n         * the main loop consists of constructing these vec4's with the minimum\n         * number of texture2D calls, which means making use of all four returned\n         * values from a texture2D call at once.\n         */\n        for (var r = 0; r < filterHeight; r++) {\n            for (var texelC = 0; texelC < texelsAcross; texelC++) {\n                var c = texelC * 2;\n                mainLoop += \"\\n          xR = xRCorner + \" + r * dilationHeight + \";\\n          xC = xCCorner + \" + c * dilationWidth + \";\\n        \";\n                if (strideWidth === 1) {\n                    if (c < filterWidth) {\n                        // If padding is odd, the outer texels have to be composed.\n                        if (padLeft % 2 === 1) {\n                            // TODO: Ensure vec4 previous does not result in redundant sample,\n                            // and avoid setting xTexelRC's that exceed the boundary in the\n                            // first place rather than resetting them to vec4(0)).\n                            // To compute xCOffset:\n                            // - If padding is odd, we must add 1 to ensure we ask for an\n                            // even-numbered row.\n                            // - We subtract 2 to access the previous texel.\n                            mainLoop += \"\\n                xCOffset = xC + 1;\\n                if(xR >= 0 && xR < \" + xNumRows + \" && xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + c + \" = getX(batch, xR, xCOffset, d1);\\n\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if(xCOffset + 1 >= \" + xNumCols + \") {\\n                    xTexelR\" + r + \"C\" + c + \".zw = vec2(0.);\\n                  }\\n                } else {\\n                  xTexelR\" + r + \"C\" + c + \" = vec4(0.);\\n                }\\n\\n                xCOffset = xC + 1 - 2;\\n                if(xR >= 0 && xR < \" + xNumRows + \" && xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                  vec4 previous = getX(batch, xR, xCOffset, d1);\\n\\n                  // Need to manually clear unused channels in case\\n                  // we're reading from recycled texture.\\n                  if(xCOffset + 1 >= \" + xNumCols + \") {\\n                    previous.zw = vec2(0.);\\n                  }\\n\\n                  xR\" + r + \"C\" + c + \" = vec4(previous.zw, xTexelR\" + r + \"C\" + c + \".xy);\\n                } else {\\n                  xR\" + r + \"C\" + c + \" = vec4(0, 0, xTexelR\" + r + \"C\" + c + \".xy);\\n                }\\n              \";\n                        }\n                        else {\n                            // Padding is even, so xRC corresponds to a single texel.\n                            mainLoop += \"\\n                if(xR >= 0 && xR < \" + xNumRows + \" && xC >= 0 && xC < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + c + \" = getX(batch, xR, xC, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + c + \" = vec4(0.);\\n                }\\n\\n                xR\" + r + \"C\" + c + \" = xTexelR\" + r + \"C\" + c + \";\\n              \";\n                        }\n                        if (c + 1 < filterWidth) {\n                            // If dilation is even, the second entry should match the first\n                            // (either both are composed or both are single samples). But if\n                            // dilation is odd, then the second entry should be the opposite\n                            // of the first (if the first is composed, the second is a single\n                            // sample, and vice versa.)\n                            var nextTexelOffset = padLeft % 2 === 0 ?\n                                util.nearestLargerEven(dilationWidth) :\n                                dilationWidth;\n                            if ((dilationWidth % 2 === 0 && padLeft % 2 === 1) ||\n                                (dilationWidth % 2 !== 0 && padLeft % 2 !== 1)) {\n                                mainLoop += \"\\n                  xCOffset = xC + \" + padLeft % 2 + \" + \" + nextTexelOffset + \";\\n\\n                  if(xR >= 0 && xR < \" + xNumRows + \" &&\\n                    xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                    xTexelR\" + r + \"C\" + (c + 2) + \" = getX(batch, xR, xCOffset, d1);\\n                  }\\n                \";\n                                // If dilation > 1 then the xRC's will not be able to share any\n                                // values, so each xRC will require two unique calls to getX.\n                                if (dilationWidth > 1) {\n                                    mainLoop += \"\\n                    xCOffset -= 2;\\n                    if(xR >= 0 && xR < \" + xNumRows + \" &&\\n                      xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                      xTexelR\" + r + \"C\" + c + \" = getX(batch, xR, xCOffset, d1);\\n                    } else {\\n                      xTexelR\" + r + \"C\" + c + \" = vec4(0.);\\n                    }\\n                  \";\n                                }\n                                mainLoop += \"\\n                  xR\" + r + \"C\" + (c + 1) + \" = vec4(\\n                    xTexelR\" + r + \"C\" + c + \".zw, xTexelR\" + r + \"C\" + (c + 2) + \".xy);\\n                \";\n                            }\n                            else {\n                                mainLoop += \"\\n                  xCOffset = xC + \" + nextTexelOffset + \";\\n\\n                  if(xR >= 0 && xR < \" + xNumRows + \" &&\\n                    xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                    xTexelR\" + r + \"C\" + (c + 2) + \" = getX(batch, xR, xCOffset, d1);\\n                  }\\n\\n                  xR\" + r + \"C\" + (c + 1) + \" = xTexelR\" + r + \"C\" + (c + 2) + \";\\n                \";\n                            }\n                        }\n                    }\n                }\n                else { // stride > 1\n                    if (c < filterWidth) {\n                        mainLoop += \"\\n              if(xR >= 0 && xR < \" + xNumRows + \") {\\n            \";\n                        // Depending on whether padLeft is even or odd, we want either the\n                        // xy or zw channels from X texels for xR${r}C${c}. If padLeft is\n                        // even, xR${r}C${c + 1} is simply the zw channels of texels we've\n                        // already sampled. But if padLeft is odd, xR${r}C{$c + 1}.zw will\n                        // need to come from the xy channels of a new texel, hence the `vec4\n                        // final` initialized below.\n                        if (padLeft % 2 === 1) {\n                            mainLoop += \"\\n                xCOffset = xC + 1 - \" + strideWidth + \";\\n                if(xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + c + \" = getX(batch, xR, xCOffset, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + c + \" = vec4(0.);\\n                }\\n\\n                if(xC + 1 >= 0 && xC + 1 < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + (c + 2) + \" = getX(batch, xR, xC + 1, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + (c + 2) + \" = vec4(0.);\\n                }\\n\\n                xR\" + r + \"C\" + c + \" = vec4(\\n                  xTexelR\" + r + \"C\" + c + \".zw, xTexelR\" + r + \"C\" + (c + 2) + \".zw);\\n              \";\n                            if (c + 1 < filterWidth) {\n                                mainLoop += \"\\n                  vec4 final = vec4(0.);\\n                  xCOffset = xC + 1 + \" + strideWidth + \";\\n                  if(xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                    final = getX(batch, xR, xCOffset, d1);\\n                  }\\n                  xR\" + r + \"C\" + (c + 1) + \" = vec4(xTexelR\" + r + \"C\" + (c + 2) + \".xy, final.xy);\\n                \";\n                            }\n                        }\n                        else {\n                            mainLoop += \"\\n                if(xC >= 0 && xC < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + c + \" = getX(batch, xR, xC, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + c + \" = vec4(0.);\\n                }\\n\\n                xCOffset = xC + \" + strideWidth + \";\\n                if(xCOffset >= 0 && xCOffset < \" + xNumCols + \") {\\n                  xTexelR\" + r + \"C\" + (c + 2) + \" = getX(batch, xR, xCOffset, d1);\\n                } else {\\n                  xTexelR\" + r + \"C\" + (c + 2) + \" = vec4(0.);\\n                }\\n\\n                xR\" + r + \"C\" + c + \" = vec4(\\n                  xTexelR\" + r + \"C\" + c + \".xy, xTexelR\" + r + \"C\" + (c + 2) + \".xy);\\n              \";\n                            if (c + 1 < filterWidth) {\n                                mainLoop += \"\\n                  xR\" + r + \"C\" + (c + 1) + \" = vec4(\\n                    xTexelR\" + r + \"C\" + c + \".zw, xTexelR\" + r + \"C\" + (c + 2) + \".zw);\\n                \";\n                            }\n                        }\n                        mainLoop += \"}\";\n                    }\n                }\n                if (c < filterWidth) {\n                    mainLoop += \"\\n            vec4 wTexelR\" + r + \"C\" + c + \" = getW(\" + r + \", \" + c + \", d1, q);\\n            wR\" + r + \"C\" + c + \" = vec4(wTexelR\" + r + \"C\" + c + \".xz, wTexelR\" + r + \"C\" + c + \".xz);\\n          \";\n                    if (c + 1 < filterWidth) {\n                        mainLoop += \"\\n              vec4 wTexelR\" + r + \"C\" + (c + 1) + \" = getW(\" + r + \", \" + (c + 1) + \", d1, q);\\n              wR\" + r + \"C\" + (c + 1) + \" =\\n                vec4(wTexelR\" + r + \"C\" + (c + 1) + \".xz, wTexelR\" + r + \"C\" + (c + 1) + \".xz);\";\n                    }\n                }\n            }\n        }\n        for (var r = 0; r < filterHeight; r++) {\n            for (var c = 0; c < filterWidth; c++) {\n                mainLoop += \"dotProd += xR\" + r + \"C\" + c + \" * wR\" + r + \"C\" + c + \";\";\n            }\n        }\n        var activationSnippet = '', applyActivationSnippet = '';\n        if (activation) {\n            if (hasPreluActivation) {\n                activationSnippet = \"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \" + activation + \"\\n        }\";\n            }\n            else {\n                activationSnippet = \"vec4 activation(vec4 x) {\\n          \" + activation + \"\\n        }\";\n            }\n            applyActivationSnippet = \"result = activation(result);\";\n        }\n        var addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n        if (addBias) {\n            this.variableNames.push('bias');\n        }\n        if (hasPreluActivation) {\n            this.variableNames.push('preluActivationWeights');\n        }\n        this.userCode = \"\\n      \" + activationSnippet + \"\\n\\n      const ivec2 strides = ivec2(\" + strideHeight + \", \" + strideWidth + \");\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords.x;\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int d2 = coords.w;\\n        int d1 = d2;\\n        int q = 0;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        vec4 dotProd = vec4(0.);\\n\\n        \" + mainLoop + \"\\n\\n        vec4 result = dotProd;\\n        \" + addBiasSnippet + \"\\n        \" + applyActivationSnippet + \"\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return DepthwiseConvPacked2DProgram;\n}());\nexports.DepthwiseConvPacked2DProgram = DepthwiseConvPacked2DProgram;\n//# sourceMappingURL=conv_packed_gpu_depthwise.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/conv_packed_gpu_depthwise.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/crop_and_resize_gpu.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/crop_and_resize_gpu.js ***!
  \***************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar CropAndResizeProgram = /** @class */ (function () {\n    function CropAndResizeProgram(imageShape, boxShape, cropSize, method, extrapolationValue) {\n        this.variableNames = ['Image', 'Boxes', 'BoxInd'];\n        this.outputShape = [];\n        var batch = imageShape[0], imageHeight = imageShape[1], imageWidth = imageShape[2], depth = imageShape[3];\n        var numBoxes = boxShape[0];\n        var cropHeight = cropSize[0], cropWidth = cropSize[1];\n        this.outputShape = [numBoxes, cropHeight, cropWidth, depth];\n        var methodId = method === 'bilinear' ? 1 : 0;\n        var _a = [imageHeight - 1 + \".0\", imageWidth - 1 + \".0\"], inputHeightFloat = _a[0], inputWidthFloat = _a[1];\n        var _b = cropHeight > 1 ?\n            [\n                \"\" + (imageHeight - 1) / (cropHeight - 1),\n                '(y2-y1) * height_ratio',\n                \"y1*\" + inputHeightFloat + \" + float(y)*(height_scale)\",\n            ] :\n            [\n                '0.0',\n                '0.0',\n                \"0.5 * (y1+y2) * \" + inputHeightFloat,\n            ], heightRatio = _b[0], heightScale = _b[1], inY = _b[2];\n        var _c = cropWidth > 1 ?\n            [\n                \"\" + (imageWidth - 1) / (cropWidth - 1),\n                '(x2-x1) * width_ratio',\n                \"x1*\" + inputWidthFloat + \" + float(x)*(width_scale)\",\n            ] :\n            [\n                '0.0',\n                '0.0',\n                \"0.5 * (x1+x2) * \" + inputWidthFloat,\n            ], widthRatio = _c[0], widthScale = _c[1], inX = _c[2];\n        // Reference implementation\n        // tslint:disable-next-line:max-line-length\n        // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op_gpu.cu.cc\n        this.userCode = \"\\n      const float height_ratio = float(\" + heightRatio + \");\\n      const float width_ratio = float(\" + widthRatio + \");\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int y = coords[1];\\n        int x = coords[2];\\n        int d = coords[3];\\n\\n        // get box vals\\n        float y1 = getBoxes(b,0);\\n        float x1 = getBoxes(b,1);\\n        float y2 = getBoxes(b,2);\\n        float x2 = getBoxes(b,3);\\n\\n        // get image in batch index\\n        int bInd = round(getBoxInd(b));\\n        if(bInd < 0 || bInd >= \" + batch + \") {\\n          return;\\n        }\\n\\n        float height_scale = \" + heightScale + \";\\n        float width_scale = \" + widthScale + \";\\n\\n        float in_y = \" + inY + \";\\n        if( in_y < 0.0 || in_y > \" + inputHeightFloat + \" ) {\\n          setOutput(float(\" + extrapolationValue + \"));\\n          return;\\n        }\\n        float in_x = \" + inX + \";\\n        if( in_x < 0.0 || in_x > \" + inputWidthFloat + \" ) {\\n          setOutput(float(\" + extrapolationValue + \"));\\n          return;\\n        }\\n\\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\\n        if(\" + methodId + \" == 1) {\\n          // Compute the four integer indices.\\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\\n\\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\\n\\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\\n\\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\\n          float newValue = top + (bottom - top) * fracCR.y;\\n          setOutput(newValue);\\n        } else {\\n          // Compute the coordinators of nearest neighbor point.\\n          ivec2 sourceNearestCR = ivec2(floor(\\n            sourceFracIndexCR + vec2(0.5,0.5)));\\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\\n          setOutput(newValue);\\n        }\\n      }\\n    \";\n    }\n    return CropAndResizeProgram;\n}());\nexports.CropAndResizeProgram = CropAndResizeProgram;\n//# sourceMappingURL=crop_and_resize_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/crop_and_resize_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/cumsum_gpu.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/cumsum_gpu.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar CumSumProgram = /** @class */ (function () {\n    function CumSumProgram(shape, exclusive, reverse) {\n        this.variableNames = ['x'];\n        this.outputShape = shape;\n        var rank = shape.length;\n        var finalDim = shape[shape.length - 1];\n        var comparator = reverse ? '<' : '>';\n        this.userCode = \"\\n      int getIndex(int i) {\\n        \" + (reverse ? \"return \" + finalDim + \" -i - 1;\" : 'return i;') + \"\\n      }\\n\\n      void main() {\\n        \" + shader_compiler_1.getCoordsDataType(rank) + \" coords = getOutputCoords();\\n        int end = \" + getFinalCoord(rank, 'coords') + \";\\n        float val = 0.0;\\n        for (int i = \" + finalDim + \" - 1; i >= 0; i -= 1) {\\n          int idx = getIndex(i);\\n          if (idx \" + comparator + \" end) {\\n            continue;\\n          }\\n          if (idx == end && \" + exclusive + \") {\\n            continue;\\n          }\\n          \" + getFinalCoord(rank, 'coords') + \" = idx;\\n          val += getX(\" + getCoords(rank, 'coords') + \");\\n        }\\n        setOutput(val);\\n      }\\n    \";\n    }\n    return CumSumProgram;\n}());\nexports.CumSumProgram = CumSumProgram;\nfunction getCoords(rank, name) {\n    if (rank === 1) {\n        return \"\" + name;\n    }\n    else if (rank === 2) {\n        return name + \".x, \" + name + \".y\";\n    }\n    else if (rank === 3) {\n        return name + \".x, \" + name + \".y, \" + name + \".z\";\n    }\n    else if (rank === 4) {\n        return name + \".x, \" + name + \".y, \" + name + \".z, \" + name + \".w\";\n    }\n    else {\n        throw Error(\"Cumulative sum for rank \" + rank + \" is not yet supported\");\n    }\n}\nfunction getFinalCoord(rank, name) {\n    if (rank === 1) {\n        return \"\" + name;\n    }\n    else if (rank === 2) {\n        return name + \".y\";\n    }\n    else if (rank === 3) {\n        return name + \".z\";\n    }\n    else if (rank === 4) {\n        return name + \".w\";\n    }\n    else {\n        throw Error(\"Cumulative sum for rank \" + rank + \" is not yet supported\");\n    }\n}\n//# sourceMappingURL=cumsum_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/cumsum_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/decode_matrix_gpu.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/decode_matrix_gpu.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = __webpack_require__(/*! ./glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar shader_util = __webpack_require__(/*! ./shader_compiler_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js\");\nvar tex_util_1 = __webpack_require__(/*! ./tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nvar DecodeMatrixProgram = /** @class */ (function () {\n    function DecodeMatrixProgram(outputShape) {\n        this.variableNames = ['A'];\n        this.packedInputs = false;\n        this.packedOutput = true;\n        this.outPackingScheme = tex_util_1.PackingScheme.DENSE;\n        var texShape = tex_util_1.getDenseTexShape(outputShape);\n        var glsl = glsl_version_1.getGlslDifferences();\n        this.outputShape = outputShape;\n        this.userCode = \"\\n      ivec3 outCoordsFromFlatIndex(int index) {\\n        \" + shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd'], outputShape) + \"\\n        return ivec3(r, c, d);\\n      }\\n\\n      void main() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n          vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n        int index = 4 * (resTexRC.x * \" + texShape[1] + \" + resTexRC.y);\\n\\n        vec4 result = vec4(0.);\\n\\n        for (int i=0; i<4; i++) {\\n          int flatIndex = index + i;\\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\\n          result[i] = getA(rc.x, rc.y, rc.z);\\n        }\\n\\n        \" + glsl.output + \" = result;\\n      }\\n    \";\n    }\n    return DecodeMatrixProgram;\n}());\nexports.DecodeMatrixProgram = DecodeMatrixProgram;\n//# sourceMappingURL=decode_matrix_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/decode_matrix_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/decode_matrix_packed_gpu.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/decode_matrix_packed_gpu.js ***!
  \********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = __webpack_require__(/*! ./glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar shader_util = __webpack_require__(/*! ./shader_compiler_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js\");\nvar tex_util_1 = __webpack_require__(/*! ./tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nvar DecodeMatrixPackedProgram = /** @class */ (function () {\n    function DecodeMatrixPackedProgram(outputShape) {\n        this.variableNames = ['A'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outPackingScheme = tex_util_1.PackingScheme.DENSE;\n        var texShape = tex_util_1.getDenseTexShape(outputShape);\n        var glsl = glsl_version_1.getGlslDifferences();\n        this.outputShape = outputShape;\n        this.userCode = \"\\n      ivec3 outCoordsFromFlatIndex(int index) {\\n        \" + shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd'], outputShape) + \"\\n        return ivec3(r, c, d);\\n      }\\n\\n      void main() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n          vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n        int index = 4 * (resTexRC.x * \" + texShape[1] + \" + resTexRC.y);\\n\\n        vec4 result = vec4(0.);\\n\\n        for (int i=0; i<4; i++) {\\n          int flatIndex = index + i;\\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\\n        }\\n\\n        \" + glsl.output + \" = result;\\n      }\\n    \";\n    }\n    return DecodeMatrixPackedProgram;\n}());\nexports.DecodeMatrixPackedProgram = DecodeMatrixPackedProgram;\n//# sourceMappingURL=decode_matrix_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/decode_matrix_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/depth_to_space_gpu.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/depth_to_space_gpu.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar DepthToSpaceProgram = /** @class */ (function () {\n    function DepthToSpaceProgram(outputShape, blockSize, dataFormat) {\n        this.variableNames = ['x'];\n        this.outputShape = [];\n        this.outputShape = outputShape;\n        this.blockSize = blockSize;\n        this.dataFormat = dataFormat;\n        this.userCode = \"\\n    void main() {\\n      ivec4 coords = getOutputCoords();\\n      int b = coords[0];\\n      int h = \" + this.getHeightCoordString() + \";\\n      int w = \" + this.getWidthCoordString() + \";\\n      int d = \" + this.getDepthCoordString() + \";\\n\\n      int in_h = h / \" + blockSize + \";\\n      int offset_h = imod(h, \" + blockSize + \");\\n      int in_w = w / \" + blockSize + \";\\n      int offset_w = imod(w, \" + blockSize + \");\\n      int offset_d = (offset_h * \" + blockSize + \" + offset_w) *\\n        \" + this.getOutputDepthSize() + \";\\n      int in_d = d + offset_d;\\n\\n      float result = \" + this.getInputSamplingString() + \";\\n      setOutput(result);\\n    }\\n  \";\n    }\n    DepthToSpaceProgram.prototype.getHeightCoordString = function () {\n        if (this.dataFormat === 'NHWC') {\n            return \"coords[1]\";\n        }\n        else {\n            return \"coords[2]\";\n        }\n    };\n    DepthToSpaceProgram.prototype.getWidthCoordString = function () {\n        if (this.dataFormat === 'NHWC') {\n            return \"coords[2]\";\n        }\n        else {\n            return \"coords[3]\";\n        }\n    };\n    DepthToSpaceProgram.prototype.getDepthCoordString = function () {\n        if (this.dataFormat === 'NHWC') {\n            return \"coords[3]\";\n        }\n        else {\n            return \"coords[1]\";\n        }\n    };\n    DepthToSpaceProgram.prototype.getOutputDepthSize = function () {\n        if (this.dataFormat === 'NHWC') {\n            return this.outputShape[3];\n        }\n        else {\n            return this.outputShape[1];\n        }\n    };\n    DepthToSpaceProgram.prototype.getInputSamplingString = function () {\n        if (this.dataFormat === 'NHWC') {\n            return \"getX(b, in_h, in_w, in_d)\";\n        }\n        else {\n            return \"getX(b, in_d, in_h, in_w)\";\n        }\n    };\n    return DepthToSpaceProgram;\n}());\nexports.DepthToSpaceProgram = DepthToSpaceProgram;\n//# sourceMappingURL=depth_to_space_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/depth_to_space_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/diag_gpu.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/diag_gpu.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar DiagProgram = /** @class */ (function () {\n    function DiagProgram(size) {\n        this.variableNames = ['X'];\n        this.outputShape = [size, size];\n        this.userCode = \"\\n      void main() {\\n          ivec2 coords = getOutputCoords();\\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\\n          setOutput(val);\\n      }\\n    \";\n    }\n    return DiagProgram;\n}());\nexports.DiagProgram = DiagProgram;\n//# sourceMappingURL=diag_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/diag_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_float_gpu.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_float_gpu.js ***!
  \************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = __webpack_require__(/*! ./glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar shader_compiler_util_1 = __webpack_require__(/*! ./shader_compiler_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js\");\nvar tex_util_1 = __webpack_require__(/*! ./tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nvar EncodeFloatProgram = /** @class */ (function () {\n    function EncodeFloatProgram(outputShape) {\n        this.variableNames = ['A'];\n        this.outTexUsage = tex_util_1.TextureUsage.DOWNLOAD;\n        var glsl = glsl_version_1.getGlslDifferences();\n        this.outputShape = outputShape;\n        this.userCode = \"\\n      \" + shader_compiler_util_1.ENCODE_FLOAT_SNIPPET + \"\\n\\n      void main() {\\n        float x = getAAtOutCoords();\\n        \" + glsl.output + \" = encode_float(x);\\n      }\\n    \";\n    }\n    return EncodeFloatProgram;\n}());\nexports.EncodeFloatProgram = EncodeFloatProgram;\n//# sourceMappingURL=encode_float_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_float_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_float_packed_gpu.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_float_packed_gpu.js ***!
  \*******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = __webpack_require__(/*! ./glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar shader_compiler_util_1 = __webpack_require__(/*! ./shader_compiler_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js\");\nvar tex_util_1 = __webpack_require__(/*! ./tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nvar EncodeFloatPackedProgram = /** @class */ (function () {\n    function EncodeFloatPackedProgram(outputShape) {\n        this.variableNames = ['A'];\n        this.packedInputs = true;\n        this.packedOutput = false;\n        this.outTexUsage = tex_util_1.TextureUsage.DOWNLOAD;\n        var glsl = glsl_version_1.getGlslDifferences();\n        this.outputShape = outputShape;\n        this.userCode = \"\\n      \" + shader_compiler_util_1.ENCODE_FLOAT_SNIPPET + \"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\\n        \" + glsl.output + \" = encode_float(x);\\n      }\\n    \";\n    }\n    return EncodeFloatPackedProgram;\n}());\nexports.EncodeFloatPackedProgram = EncodeFloatPackedProgram;\n//# sourceMappingURL=encode_float_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_float_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_matrix_gpu.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_matrix_gpu.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = __webpack_require__(/*! ./glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar shader_util = __webpack_require__(/*! ./shader_compiler_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js\");\nvar EncodeMatrixProgram = /** @class */ (function () {\n    function EncodeMatrixProgram(outputShape, texShape, inputIsUnsignedByte) {\n        if (inputIsUnsignedByte === void 0) { inputIsUnsignedByte = false; }\n        this.variableNames = ['A'];\n        var glsl = glsl_version_1.getGlslDifferences();\n        var height = texShape[0], width = texShape[1];\n        this.outputShape = outputShape;\n        var output = \"result\";\n        if (inputIsUnsignedByte) {\n            output = \"floor(result * 255. + 0.5)\";\n        }\n        this.userCode = \"\\n      \" + shader_util.getFlatIndexFrom3D(outputShape) + \"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n\\n        int flatIndex = getFlatIndex(coords);\\n        int offset = imod(flatIndex, 4);\\n\\n        flatIndex = idiv(flatIndex, 4, 1.);\\n        \\n        int r = flatIndex / \" + width + \";\\n        int c = imod(flatIndex, \" + width + \");\\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(\" + width + \".0, \" + height + \".0);\\n        vec4 values = \" + glsl.texture2D + \"(A, uv);\\n\\n        float result;\\n\\n        if(offset == 0) {\\n          result = values[0];\\n        } else if(offset == 1) {\\n          result = values[1];\\n        } else if(offset == 2) {\\n          result = values[2];\\n        } else {\\n          result = values[3];\\n        }\\n\\n        \" + glsl.output + \" = vec4(\" + output + \", 0., 0., 0.);\\n      }\\n    \";\n    }\n    return EncodeMatrixProgram;\n}());\nexports.EncodeMatrixProgram = EncodeMatrixProgram;\n//# sourceMappingURL=encode_matrix_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_matrix_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_matrix_packed_gpu.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_matrix_packed_gpu.js ***!
  \********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = __webpack_require__(/*! ./glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar shader_util = __webpack_require__(/*! ./shader_compiler_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js\");\n/*\nThis is how the shader encodes a tensor with shape = [2, 3, 5]\n(indices are [batch, row, col]).\n\n000|001   002|003   004|xxx   020|021   022|023   024|xxx\n-------   -------   -------   -------   -------   -------\n010|011   012|013   014|xxx   xxx|xxx   xxx|xxx   xxx|xxx\n\n100|101   102|103   104|xxx   120|121   122|123   124|xxx\n-------   -------   -------   -------   -------   -------\n110|111   112|113   114|xxx   xxx|xxx   xxx|xxx   xxx|xxx\n\nSingle texels contain only values from the same batch, and from adjacent rows\nand columns.\n */\nvar EncodeMatrixPackedProgram = /** @class */ (function () {\n    function EncodeMatrixPackedProgram(outputShape, texShape, inputIsUnsignedByte) {\n        if (inputIsUnsignedByte === void 0) { inputIsUnsignedByte = false; }\n        this.variableNames = ['A'];\n        this.packedInputs = false;\n        this.packedOutput = true;\n        var glsl = glsl_version_1.getGlslDifferences();\n        var height = texShape[0], width = texShape[1];\n        this.outputShape = outputShape;\n        var mainLoop = '';\n        var output = 'result';\n        if (inputIsUnsignedByte) {\n            output = 'floor(result * 255. + 0.5)';\n        }\n        for (var row = 0; row <= 1; row++) {\n            for (var col = 0; col <= 1; col++) {\n                var channel = row * 2 + col;\n                mainLoop += \"\\n          localCoords = coords;\\n          if(localCoords[2] + \" + col + \" < \" + outputShape[2] + \") {\\n            localCoords[2] += \" + col + \";\\n            if(localCoords[1] + \" + row + \" < \" + outputShape[1] + \") {\\n              localCoords[1] += \" + row + \";\\n\\n              flatIndex = getFlatIndex(localCoords);\\n              offset = imod(flatIndex, 4);\\n\\n              flatIndex = idiv(flatIndex, 4, 1.);\\n\\n              r = flatIndex / \" + width + \";\\n              c = imod(flatIndex, \" + width + \");\\n              uv = (vec2(c, r) + halfCR) / vec2(\" + width + \".0, \" + height + \".0);\\n              values = \" + glsl.texture2D + \"(A, uv);\\n\\n              if(offset == 0) {\\n                result[\" + channel + \"] = values[0];\\n              } else if(offset == 1) {\\n                result[\" + channel + \"] = values[1];\\n              } else if(offset == 2) {\\n                result[\" + channel + \"] = values[2];\\n              } else {\\n                result[\" + channel + \"] = values[3];\\n              }\\n            }\\n          }\\n        \";\n            }\n        }\n        this.userCode = \"\\n      \" + shader_util.getFlatIndexFrom3D(outputShape) + \"\\n\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n\\n        vec4 result = vec4(0.);\\n        int flatIndex, r, c, offset;\\n        ivec3 localCoords;\\n        vec2 uv;\\n        vec4 values;\\n\\n        \" + mainLoop + \"\\n\\n        \" + glsl.output + \" = \" + output + \";\\n      }\\n    \";\n    }\n    return EncodeMatrixPackedProgram;\n}());\nexports.EncodeMatrixPackedProgram = EncodeMatrixPackedProgram;\n//# sourceMappingURL=encode_matrix_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/encode_matrix_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/fft_gpu.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/fft_gpu.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.COMPLEX_FFT = {\n    REAL: 'return real * expR - imag * expI;',\n    IMAG: 'return real * expI + imag * expR;'\n};\nvar FFTProgram = /** @class */ (function () {\n    function FFTProgram(op, inputShape, inverse) {\n        this.variableNames = ['real', 'imag'];\n        var innerDim = inputShape[1];\n        this.outputShape = inputShape;\n        var exponentMultiplierSnippet = inverse ? \"2.0 * \" + Math.PI : \"-2.0 * \" + Math.PI;\n        var resultDenominator = inverse ? innerDim + \".0\" : '1.0';\n        this.userCode = \"\\n      const float exponentMultiplier = \" + exponentMultiplierSnippet + \";\\n\\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\\n        \" + op + \"\\n      }\\n\\n      float mulMatDFT(int batch, int index) {\\n        float indexRatio = float(index) / float(\" + innerDim + \");\\n        float exponentMultiplierTimesIndexRatio =\\n            exponentMultiplier * indexRatio;\\n\\n        float result = 0.0;\\n\\n        for (int i = 0; i < \" + innerDim + \"; i++) {\\n          // x = (-2|2 * PI / N) * index * i;\\n          float x = exponentMultiplierTimesIndexRatio * float(i);\\n          float expR = cos(x);\\n          float expI = sin(x);\\n          float real = getReal(batch, i);\\n          float imag = getImag(batch, i);\\n\\n          result +=\\n              unaryOpComplex(real, expR, imag, expI) / \" + resultDenominator + \";\\n        }\\n\\n        return result;\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        setOutput(mulMatDFT(coords[0], coords[1]));\\n      }\\n    \";\n    }\n    return FFTProgram;\n}());\nexports.FFTProgram = FFTProgram;\n//# sourceMappingURL=fft_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/fft_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/fill_gpu.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/fill_gpu.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar FillProgram = /** @class */ (function () {\n    function FillProgram(shape, value) {\n        this.outputShape = [];\n        this.variableNames = ['x'];\n        this.outputShape = shape;\n        this.userCode = \"\\n      uniform float value;\\n      void main() {\\n        // Input can be obtained from uniform value.\\n        setOutput(value);\\n      }\\n    \";\n    }\n    FillProgram.prototype.getCustomSetupFunc = function (value) {\n        var _this = this;\n        return function (gpgpu, webGLProgram) {\n            if (_this.valueLoc == null) {\n                _this.valueLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'value');\n            }\n            gpgpu.gl.uniform1f(_this.valueLoc, value);\n        };\n    };\n    return FillProgram;\n}());\nexports.FillProgram = FillProgram;\n//# sourceMappingURL=fill_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/fill_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/flags_webgl.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/flags_webgl.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar device_util = __webpack_require__(/*! ../../device_util */ \"./node_modules/@tensorflow/tfjs-core/dist/device_util.js\");\nvar environment_1 = __webpack_require__(/*! ../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar webgl_util = __webpack_require__(/*! ./webgl_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/webgl_util.js\");\nvar ENV = environment_1.env();\n/**\n * This file contains WebGL-specific flag registrations.\n */\n/**\n * True if WebGL is supported.\n */\nENV.registerFlag('HAS_WEBGL', function () { return ENV.getNumber('WEBGL_VERSION') > 0; });\n/** 0: No WebGL, 1: WebGL 1.0, 2: WebGL 2.0. */\nENV.registerFlag('WEBGL_VERSION', function () {\n    if (webgl_util.isWebGLVersionEnabled(2)) {\n        return 2;\n    }\n    else if (webgl_util.isWebGLVersionEnabled(1)) {\n        return 1;\n    }\n    return 0;\n});\nENV.registerFlag('WEBGL_BUFFER_SUPPORTED', function () { return ENV.get('WEBGL_VERSION') === 2; });\n/** Whether the WebGL backend will sometimes forward ops to the CPU. */\nENV.registerFlag('WEBGL_CPU_FORWARD', function () { return true; });\n/** Whether the WebGL backend will always use f16 textures for rendering. */\nENV.registerFlag('WEBGL_FORCE_F16_TEXTURES', function () { return false; });\n/** Whether to turn all packing related flags on. */\nENV.registerFlag('WEBGL_PACK', function () { return ENV.getBool('HAS_WEBGL'); });\n/** Whether we will pack the batchnormalization op. */\nENV.registerFlag('WEBGL_PACK_NORMALIZATION', function () { return ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack the clip op. */\nENV.registerFlag('WEBGL_PACK_CLIP', function () { return ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack the depthwise conv op. */\n// TODO: https://github.com/tensorflow/tfjs/issues/1679\nENV.registerFlag('WEBGL_PACK_DEPTHWISECONV', function () { return false; });\n/** Whether we will pack binary ops. */\nENV.registerFlag('WEBGL_PACK_BINARY_OPERATIONS', function () { return ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack unary ops. */\nENV.registerFlag('WEBGL_PACK_UNARY_OPERATIONS', function () { return ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack array ops. */\nENV.registerFlag('WEBGL_PACK_ARRAY_OPERATIONS', function () { return ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack image ops. */\nENV.registerFlag('WEBGL_PACK_IMAGE_OPERATIONS', function () { return ENV.getBool('WEBGL_PACK'); });\n/** Whether we will pack reduce ops. */\nENV.registerFlag('WEBGL_PACK_REDUCE', function () { return ENV.getBool('WEBGL_PACK'); });\n/** Whether packed WebGL kernels lazily unpack their outputs. */\nENV.registerFlag('WEBGL_LAZILY_UNPACK', function () { return ENV.getBool('WEBGL_PACK'); });\n/** Whether we will use the im2col algorithm to speed up convolutions. */\nENV.registerFlag('WEBGL_CONV_IM2COL', function () { return ENV.getBool('WEBGL_PACK'); });\n/** The maximum texture dimension. */\nENV.registerFlag('WEBGL_MAX_TEXTURE_SIZE', function () { return webgl_util.getWebGLMaxTextureSize(ENV.getNumber('WEBGL_VERSION')); });\n/** The maximum texture dimension. */\nENV.registerFlag('WEBGL_MAX_TEXTURES_IN_SHADER', function () { return webgl_util.getMaxTexturesInShader(ENV.getNumber('WEBGL_VERSION')); });\n/**\n * The disjoint_query_timer extension version.\n * 0: disabled, 1: EXT_disjoint_timer_query, 2:\n * EXT_disjoint_timer_query_webgl2.\n * In Firefox with WebGL 2.0,\n * EXT_disjoint_timer_query_webgl2 is not available, so we must use the\n * WebGL 1.0 extension.\n */\nENV.registerFlag('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION', function () {\n    var webGLVersion = ENV.getNumber('WEBGL_VERSION');\n    if (webGLVersion === 0) {\n        return 0;\n    }\n    return webgl_util.getWebGLDisjointQueryTimerVersion(webGLVersion);\n});\n/**\n * Whether the timer object from the disjoint_query_timer extension gives\n * timing information that is reliable.\n */\nENV.registerFlag('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE', function () { return ENV.getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') > 0 &&\n    !device_util.isMobile(); });\n/**\n * Whether the device is physically capable of rendering to float32 textures.\n */\nENV.registerFlag('WEBGL_RENDER_FLOAT32_CAPABLE', function () { return webgl_util.isCapableOfRenderingToFloatTexture(ENV.getNumber('WEBGL_VERSION')); });\n/**\n * Whether rendering to float32 textures is enabled. If disabled, renders to\n * float16 textures.\n */\nENV.registerFlag('WEBGL_RENDER_FLOAT32_ENABLED', function () {\n    return ENV.getBool('WEBGL_FORCE_F16_TEXTURES') ?\n        false :\n        ENV.getBool('WEBGL_RENDER_FLOAT32_CAPABLE');\n});\n/**\n * Whether downloading float textures is enabled (16 or 32 bit). If disabled,\n * uses IEEE 754 encoding of the float32 values to 4 uint8 when downloading.\n */\nENV.registerFlag('WEBGL_DOWNLOAD_FLOAT_ENABLED', function () { return webgl_util.isDownloadFloatTextureEnabled(ENV.getNumber('WEBGL_VERSION')); });\n/** Whether the fence API is available. */\nENV.registerFlag('WEBGL_FENCE_API_ENABLED', function () { return webgl_util.isWebGLFenceEnabled(ENV.getNumber('WEBGL_VERSION')); });\n/**\n * Tensors with size <= than this will be uploaded as uniforms, not textures.\n */\nENV.registerFlag('WEBGL_SIZE_UPLOAD_UNIFORM', function () {\n    // Use uniform uploads only when 32bit floats are supported. In\n    // 16bit\n    // environments there are problems with comparing a 16bit texture value\n    // with a 32bit uniform value.\n    var useUniforms = ENV.getBool('WEBGL_RENDER_FLOAT32_ENABLED');\n    return useUniforms ? 4 : 0;\n});\n//# sourceMappingURL=flags_webgl.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/flags_webgl.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gather_gpu.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gather_gpu.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar GatherProgram = /** @class */ (function () {\n    function GatherProgram(aShape, indicesLength, axis) {\n        this.variableNames = ['A', 'indices'];\n        var outputShape = aShape.slice();\n        outputShape[axis] = indicesLength;\n        this.outputShape = outputShape;\n        this.rank = outputShape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var sourceCoords = getSourceCoords(aShape, axis);\n        this.userCode = \"\\n      void main() {\\n        \" + dtype + \" resRC = getOutputCoords();\\n        setOutput(getA(\" + sourceCoords + \"));\\n      }\\n    \";\n    }\n    return GatherProgram;\n}());\nexports.GatherProgram = GatherProgram;\nfunction getSourceCoords(aShape, axis) {\n    var rank = aShape.length;\n    if (rank > 4) {\n        throw Error(\"Gather for rank \" + rank + \" is not yet supported\");\n    }\n    if (rank === 1) {\n        return \"int(getIndices(resRC))\";\n    }\n    var currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n    var sourceCoords = [];\n    for (var i = 0; i < aShape.length; i++) {\n        if (i === axis) {\n            sourceCoords.push(\"int(getIndices(\" + currentCoords[i] + \"))\");\n        }\n        else {\n            sourceCoords.push(\"\" + currentCoords[i]);\n        }\n    }\n    return sourceCoords.join();\n}\n//# sourceMappingURL=gather_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gather_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gather_nd_gpu.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gather_nd_gpu.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar GatherNDProgram = /** @class */ (function () {\n    function GatherNDProgram(sliceDim, strides, shape) {\n        this.sliceDim = sliceDim;\n        this.strides = strides;\n        this.variableNames = ['x', 'indices'];\n        this.outputShape = shape;\n        var stridesType = shader_compiler_1.getCoordsDataType(strides.length);\n        var dtype = shader_compiler_1.getCoordsDataType(shape.length);\n        var strideString = this.sliceDim > 1 ? 'strides[j]' : 'strides';\n        this.userCode = \"\\n        \" + stridesType + \" strides = \" + stridesType + \"(\" + this.strides + \");\\n         void main() {\\n          \" + dtype + \" coords = getOutputCoords();\\n          int flattenIndex = 0;\\n          for (int j = 0; j < \" + this.sliceDim + \"; j++) {\\n            int index = round(getIndices(coords[0], j));\\n            flattenIndex += index * \" + strideString + \";\\n          }\\n          setOutput(getX(flattenIndex, coords[1]));\\n        }\\n      \";\n    }\n    return GatherNDProgram;\n}());\nexports.GatherNDProgram = GatherNDProgram;\n//# sourceMappingURL=gather_nd_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gather_nd_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar environment_1 = __webpack_require__(/*! ../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nfunction getGlslDifferences() {\n    var version;\n    var attribute;\n    var varyingVs;\n    var varyingFs;\n    var texture2D;\n    var output;\n    var defineOutput;\n    var defineSpecialNaN;\n    var defineSpecialInf;\n    var defineRound;\n    if (environment_1.env().getNumber('WEBGL_VERSION') === 2) {\n        version = '#version 300 es';\n        attribute = 'in';\n        varyingVs = 'out';\n        varyingFs = 'in';\n        texture2D = 'texture';\n        output = 'outputColor';\n        defineOutput = 'out vec4 outputColor;';\n        // Use custom isnan definition to work across differences between\n        // implementations on various platforms. While this should happen in ANGLE\n        // we still see differences between android and windows (on chrome) when\n        // using isnan directly.\n        defineSpecialNaN = \"\\n      bool isnan_custom(float val) {\\n        return (val > 0.0 || val < 0.0) ? false : val != 0.0;\\n      }\\n\\n      bvec4 isnan_custom(vec4 val) {\\n        return bvec4(isnan_custom(val.x),\\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\\n      }\\n\\n      #define isnan(value) isnan_custom(value)\\n    \";\n        // In webgl 2 we do not need to specify a custom isinf so there is no\n        // need for a special INFINITY constant.\n        defineSpecialInf = \"\";\n        defineRound = \"\\n      #define round(value) newRound(value)\\n      int newRound(float value) {\\n        return int(floor(value + 0.5));\\n      }\\n\\n      ivec4 newRound(vec4 value) {\\n        return ivec4(floor(value + vec4(0.5)));\\n      }\\n    \";\n    }\n    else {\n        version = '';\n        attribute = 'attribute';\n        varyingVs = 'varying';\n        varyingFs = 'varying';\n        texture2D = 'texture2D';\n        output = 'gl_FragColor';\n        defineOutput = '';\n        // WebGL1 has no built in isnan so we define one here.\n        defineSpecialNaN = \"\\n      #define isnan(value) isnan_custom(value)\\n      bool isnan_custom(float val) {\\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\\n      }\\n      bvec4 isnan_custom(vec4 val) {\\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\\n      }\\n    \";\n        defineSpecialInf = \"\\n      uniform float INFINITY;\\n\\n      bool isinf(float val) {\\n        return abs(val) == INFINITY;\\n      }\\n      bvec4 isinf(vec4 val) {\\n        return equal(abs(val), vec4(INFINITY));\\n      }\\n    \";\n        defineRound = \"\\n      int round(float value) {\\n        return int(floor(value + 0.5));\\n      }\\n\\n      ivec4 round(vec4 value) {\\n        return ivec4(floor(value + vec4(0.5)));\\n      }\\n    \";\n    }\n    return {\n        version: version,\n        attribute: attribute,\n        varyingVs: varyingVs,\n        varyingFs: varyingFs,\n        texture2D: texture2D,\n        output: output,\n        defineOutput: defineOutput,\n        defineSpecialNaN: defineSpecialNaN,\n        defineSpecialInf: defineSpecialInf,\n        defineRound: defineRound\n    };\n}\nexports.getGlslDifferences = getGlslDifferences;\n//# sourceMappingURL=glsl_version.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_context.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_context.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar util = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar canvas_util_1 = __webpack_require__(/*! ./canvas_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/canvas_util.js\");\nvar gpgpu_util = __webpack_require__(/*! ./gpgpu_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_util.js\");\nvar tex_util = __webpack_require__(/*! ./tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nvar webgl_util = __webpack_require__(/*! ./webgl_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/webgl_util.js\");\nvar GPGPUContext = /** @class */ (function () {\n    function GPGPUContext(gl) {\n        this.outputTexture = null;\n        this.program = null;\n        this.disposed = false;\n        this.vertexAttrsAreBound = false;\n        this.itemsToPoll = [];\n        var glVersion = environment_1.env().getNumber('WEBGL_VERSION');\n        if (gl != null) {\n            this.gl = gl;\n            canvas_util_1.setWebGLContext(glVersion, gl);\n        }\n        else {\n            this.gl = canvas_util_1.getWebGLContext(glVersion);\n        }\n        // WebGL 2.0 enables texture floats without an extension.\n        var COLOR_BUFFER_FLOAT = 'WEBGL_color_buffer_float';\n        var COLOR_BUFFER_HALF_FLOAT = 'EXT_color_buffer_half_float';\n        if (environment_1.env().getNumber('WEBGL_VERSION') === 1) {\n            var TEXTURE_FLOAT = 'OES_texture_float';\n            var TEXTURE_HALF_FLOAT = 'OES_texture_half_float';\n            this.textureFloatExtension =\n                webgl_util.getExtensionOrThrow(this.gl, this.debug, TEXTURE_FLOAT);\n            if (webgl_util.hasExtension(this.gl, TEXTURE_HALF_FLOAT)) {\n                this.textureHalfFloatExtension = webgl_util.getExtensionOrThrow(this.gl, this.debug, TEXTURE_HALF_FLOAT);\n            }\n            else if (environment_1.env().get('WEBGL_FORCE_F16_TEXTURES')) {\n                throw new Error('GL context does not support half float textures, yet the ' +\n                    'environment flag WEBGL_FORCE_F16_TEXTURES is set to true.');\n            }\n            this.colorBufferFloatExtension = this.gl.getExtension(COLOR_BUFFER_FLOAT);\n            if (webgl_util.hasExtension(this.gl, COLOR_BUFFER_HALF_FLOAT)) {\n                this.colorBufferHalfFloatExtension = webgl_util.getExtensionOrThrow(this.gl, this.debug, COLOR_BUFFER_HALF_FLOAT);\n            }\n            else if (environment_1.env().get('WEBGL_FORCE_F16_TEXTURES')) {\n                throw new Error('GL context does not support color renderable half floats, yet ' +\n                    'the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.');\n            }\n        }\n        else {\n            COLOR_BUFFER_FLOAT = 'EXT_color_buffer_float';\n            if (webgl_util.hasExtension(this.gl, COLOR_BUFFER_FLOAT)) {\n                this.colorBufferFloatExtension =\n                    this.gl.getExtension(COLOR_BUFFER_FLOAT);\n            }\n            else if (webgl_util.hasExtension(this.gl, COLOR_BUFFER_HALF_FLOAT)) {\n                this.colorBufferHalfFloatExtension =\n                    this.gl.getExtension(COLOR_BUFFER_HALF_FLOAT);\n            }\n            else {\n                throw new Error('GL context does not support color renderable floats');\n            }\n        }\n        this.vertexBuffer = gpgpu_util.createVertexBuffer(this.gl, this.debug);\n        this.indexBuffer = gpgpu_util.createIndexBuffer(this.gl, this.debug);\n        this.framebuffer = webgl_util.createFramebuffer(this.gl, this.debug);\n        this.textureConfig =\n            tex_util.getTextureConfig(this.gl, this.textureHalfFloatExtension);\n    }\n    Object.defineProperty(GPGPUContext.prototype, \"debug\", {\n        get: function () {\n            return environment_1.env().getBool('DEBUG');\n        },\n        enumerable: true,\n        configurable: true\n    });\n    GPGPUContext.prototype.dispose = function () {\n        var _this = this;\n        if (this.disposed) {\n            return;\n        }\n        if (this.program != null) {\n            console.warn('Disposing a GPGPUContext that still has a bound WebGLProgram.' +\n                ' This is probably a resource leak, delete the program with ' +\n                'GPGPUContext.deleteProgram before disposing.');\n        }\n        if (this.outputTexture != null) {\n            console.warn('Disposing a GPGPUContext that still has a bound output matrix ' +\n                'texture.  This is probably a resource leak, delete the output ' +\n                'matrix texture with GPGPUContext.deleteMatrixTexture before ' +\n                'disposing.');\n        }\n        var gl = this.gl;\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.finish(); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.bindFramebuffer(gl.FRAMEBUFFER, null); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.deleteFramebuffer(_this.framebuffer); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.bindBuffer(gl.ARRAY_BUFFER, null); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.deleteBuffer(_this.indexBuffer); });\n        this.disposed = true;\n    };\n    GPGPUContext.prototype.createFloat32MatrixTexture = function (rows, columns) {\n        this.throwIfDisposed();\n        return gpgpu_util.createFloat32MatrixTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.createFloat16MatrixTexture = function (rows, columns) {\n        this.throwIfDisposed();\n        return gpgpu_util.createFloat16MatrixTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.createUnsignedBytesMatrixTexture = function (rows, columns) {\n        this.throwIfDisposed();\n        return gpgpu_util.createUnsignedBytesMatrixTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.uploadPixelDataToTexture = function (texture, pixels) {\n        this.throwIfDisposed();\n        gpgpu_util.uploadPixelDataToTexture(this.gl, this.debug, texture, pixels);\n    };\n    GPGPUContext.prototype.uploadDenseMatrixToTexture = function (texture, width, height, data) {\n        this.throwIfDisposed();\n        gpgpu_util.uploadDenseMatrixToTexture(this.gl, this.debug, texture, width, height, data, this.textureConfig);\n    };\n    GPGPUContext.prototype.createFloat16PackedMatrixTexture = function (rows, columns) {\n        this.throwIfDisposed();\n        return gpgpu_util.createFloat16PackedMatrixTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.createPackedMatrixTexture = function (rows, columns) {\n        this.throwIfDisposed();\n        return gpgpu_util.createPackedMatrixTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n    };\n    GPGPUContext.prototype.deleteMatrixTexture = function (texture) {\n        var _this = this;\n        this.throwIfDisposed();\n        if (this.outputTexture === texture) {\n            webgl_util.unbindColorTextureFromFramebuffer(this.gl, this.debug, this.framebuffer);\n            this.outputTexture = null;\n        }\n        webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.deleteTexture(texture); });\n    };\n    GPGPUContext.prototype.downloadByteEncodedFloatMatrixFromOutputTexture = function (texture, rows, columns) {\n        var _this = this;\n        return this.downloadMatrixDriver(texture, function () { return gpgpu_util.downloadByteEncodedFloatMatrixFromOutputTexture(_this.gl, _this.debug, rows, columns, _this.textureConfig); });\n    };\n    GPGPUContext.prototype.downloadPackedMatrixFromBuffer = function (buffer, batch, rows, columns, physicalRows, physicalCols) {\n        return gpgpu_util.downloadPackedMatrixFromBuffer(this.gl, buffer, batch, rows, columns, physicalRows, physicalCols, this.textureConfig);\n    };\n    GPGPUContext.prototype.downloadFloat32MatrixFromBuffer = function (buffer, size) {\n        return gpgpu_util.downloadFloat32MatrixFromBuffer(this.gl, buffer, size);\n    };\n    GPGPUContext.prototype.createBufferFromTexture = function (texture, rows, columns) {\n        this.bindTextureToFrameBuffer(texture);\n        var result = gpgpu_util.createBufferFromOutputTexture(this.gl, this.debug, rows, columns, this.textureConfig);\n        this.unbindTextureToFrameBuffer();\n        return result;\n    };\n    GPGPUContext.prototype.createAndWaitForFence = function () {\n        var fenceContext = this.createFence(this.gl);\n        return this.pollFence(fenceContext);\n    };\n    GPGPUContext.prototype.createFence = function (gl) {\n        var _this = this;\n        var query;\n        var isFencePassed;\n        if (environment_1.env().getBool('WEBGL_FENCE_API_ENABLED')) {\n            var gl2_1 = gl;\n            var sync_1 = gl2_1.fenceSync(gl2_1.SYNC_GPU_COMMANDS_COMPLETE, 0);\n            gl.flush();\n            isFencePassed = function () {\n                var status = gl2_1.clientWaitSync(sync_1, 0, 0);\n                return status === gl2_1.ALREADY_SIGNALED ||\n                    status === gl2_1.CONDITION_SATISFIED;\n            };\n            query = sync_1;\n        }\n        else if (environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') > 0) {\n            query = this.beginQuery();\n            this.endQuery();\n            isFencePassed = function () { return _this.isQueryAvailable(query, environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION')); };\n        }\n        else {\n            // If we have no way to fence, return true immediately. This will fire in\n            // WebGL 1.0 when there is no disjoint query timer. In this case, because\n            // the fence passes immediately, we'll immediately ask for a download of\n            // the texture, which will cause the UI thread to hang.\n            isFencePassed = function () { return true; };\n        }\n        return { query: query, isFencePassed: isFencePassed };\n    };\n    GPGPUContext.prototype.downloadMatrixFromPackedTexture = function (texture, physicalRows, physicalCols) {\n        var _this = this;\n        return this.downloadMatrixDriver(texture, function () { return gpgpu_util.downloadMatrixFromPackedOutputTexture(_this.gl, _this.debug, physicalRows, physicalCols); });\n    };\n    GPGPUContext.prototype.createProgram = function (fragmentShaderSource) {\n        this.throwIfDisposed();\n        var gl = this.gl;\n        var fragmentShader = webgl_util.createFragmentShader(gl, this.debug, fragmentShaderSource);\n        var vertexShader = gpgpu_util.createVertexShader(gl, this.debug);\n        var program = webgl_util.createProgram(gl, this.debug);\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.attachShader(program, vertexShader); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.attachShader(program, fragmentShader); });\n        webgl_util.linkProgram(gl, this.debug, program);\n        if (this.debug) {\n            webgl_util.validateProgram(gl, this.debug, program);\n        }\n        if (!this.vertexAttrsAreBound) {\n            this.setProgram(program);\n            this.vertexAttrsAreBound = gpgpu_util.bindVertexProgramAttributeStreams(gl, this.debug, this.program, this.vertexBuffer);\n        }\n        return program;\n    };\n    GPGPUContext.prototype.deleteProgram = function (program) {\n        var _this = this;\n        this.throwIfDisposed();\n        if (program === this.program) {\n            this.program = null;\n        }\n        if (program != null) {\n            webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.deleteProgram(program); });\n        }\n    };\n    GPGPUContext.prototype.setProgram = function (program) {\n        var _this = this;\n        this.throwIfDisposed();\n        this.program = program;\n        if ((this.program != null) && this.debug) {\n            webgl_util.validateProgram(this.gl, this.debug, this.program);\n        }\n        webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.useProgram(program); });\n    };\n    GPGPUContext.prototype.getUniformLocation = function (program, uniformName, shouldThrow) {\n        if (shouldThrow === void 0) { shouldThrow = true; }\n        this.throwIfDisposed();\n        if (shouldThrow) {\n            return webgl_util.getProgramUniformLocationOrThrow(this.gl, this.debug, program, uniformName);\n        }\n        else {\n            return webgl_util.getProgramUniformLocation(this.gl, program, uniformName);\n        }\n    };\n    GPGPUContext.prototype.getAttributeLocation = function (program, attribute) {\n        var _this = this;\n        this.throwIfDisposed();\n        return webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.getAttribLocation(program, attribute); });\n    };\n    GPGPUContext.prototype.getUniformLocationNoThrow = function (program, uniformName) {\n        this.throwIfDisposed();\n        return this.gl.getUniformLocation(program, uniformName);\n    };\n    GPGPUContext.prototype.setInputMatrixTexture = function (inputMatrixTexture, uniformLocation, textureUnit) {\n        this.throwIfDisposed();\n        this.throwIfNoProgram();\n        webgl_util.bindTextureToProgramUniformSampler(this.gl, this.debug, this.program, inputMatrixTexture, uniformLocation, textureUnit);\n    };\n    GPGPUContext.prototype.setOutputMatrixTexture = function (outputMatrixTexture, rows, columns) {\n        this.setOutputMatrixTextureDriver(outputMatrixTexture, columns, rows);\n    };\n    GPGPUContext.prototype.setOutputPackedMatrixTexture = function (outputPackedMatrixTexture, rows, columns) {\n        this.throwIfDisposed();\n        var _a = tex_util.getPackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n        this.setOutputMatrixTextureDriver(outputPackedMatrixTexture, width, height);\n    };\n    GPGPUContext.prototype.setOutputMatrixWriteRegion = function (startRow, numRows, startColumn, numColumns) {\n        this.setOutputMatrixWriteRegionDriver(startColumn, startRow, numColumns, numRows);\n    };\n    GPGPUContext.prototype.setOutputPackedMatrixWriteRegion = function (startRow, numRows, startColumn, numColumns) {\n        throw new Error('setOutputPackedMatrixWriteRegion not implemented.');\n    };\n    GPGPUContext.prototype.debugValidate = function () {\n        if (this.program != null) {\n            webgl_util.validateProgram(this.gl, this.debug, this.program);\n        }\n        webgl_util.validateFramebuffer(this.gl);\n    };\n    GPGPUContext.prototype.executeProgram = function () {\n        this.throwIfDisposed();\n        this.throwIfNoProgram();\n        var gl = this.gl;\n        if (this.debug) {\n            this.debugValidate();\n        }\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.drawElements(gl.TRIANGLES, 6, gl.UNSIGNED_SHORT, 0); });\n    };\n    GPGPUContext.prototype.blockUntilAllProgramsCompleted = function () {\n        var _this = this;\n        this.throwIfDisposed();\n        webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.finish(); });\n    };\n    GPGPUContext.prototype.getQueryTimerExtension = function () {\n        if (this.disjointQueryTimerExtension == null) {\n            this.disjointQueryTimerExtension =\n                webgl_util.getExtensionOrThrow(this.gl, this.debug, environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') === 2 ?\n                    'EXT_disjoint_timer_query_webgl2' :\n                    'EXT_disjoint_timer_query');\n        }\n        return this.disjointQueryTimerExtension;\n    };\n    GPGPUContext.prototype.getQueryTimerExtensionWebGL2 = function () {\n        return this.getQueryTimerExtension();\n    };\n    GPGPUContext.prototype.getQueryTimerExtensionWebGL1 = function () {\n        return this.getQueryTimerExtension();\n    };\n    GPGPUContext.prototype.beginQuery = function () {\n        if (environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') === 2) {\n            var gl2 = this.gl;\n            var ext_1 = this.getQueryTimerExtensionWebGL2();\n            var query_1 = gl2.createQuery();\n            gl2.beginQuery(ext_1.TIME_ELAPSED_EXT, query_1);\n            return query_1;\n        }\n        var ext = this.getQueryTimerExtensionWebGL1();\n        var query = ext.createQueryEXT();\n        ext.beginQueryEXT(ext.TIME_ELAPSED_EXT, query);\n        return query;\n    };\n    GPGPUContext.prototype.endQuery = function () {\n        if (environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION') === 2) {\n            var gl2 = this.gl;\n            var ext_2 = this.getQueryTimerExtensionWebGL2();\n            gl2.endQuery(ext_2.TIME_ELAPSED_EXT);\n            return;\n        }\n        var ext = this.getQueryTimerExtensionWebGL1();\n        ext.endQueryEXT(ext.TIME_ELAPSED_EXT);\n    };\n    GPGPUContext.prototype.waitForQueryAndGetTime = function (query) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, util.repeatedTry(function () { return _this.disposed || // while testing contexts are created / disposed\n                            // in rapid succession, so without this check we\n                            // may poll for the query timer indefinitely\n                            _this.isQueryAvailable(query, environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION')); })];\n                    case 1:\n                        _a.sent();\n                        return [2 /*return*/, this.getQueryTime(query, environment_1.env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION'))];\n                }\n            });\n        });\n    };\n    GPGPUContext.prototype.getQueryTime = function (query, queryTimerVersion) {\n        if (queryTimerVersion === 0) {\n            return null;\n        }\n        if (queryTimerVersion === 2) {\n            var gl2 = this.gl;\n            var timeElapsedNanos = gl2.getQueryParameter(query, gl2.QUERY_RESULT);\n            // Return milliseconds.\n            return timeElapsedNanos / 1000000;\n        }\n        else {\n            var ext = this.getQueryTimerExtensionWebGL1();\n            var timeElapsedNanos = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_EXT);\n            // Return milliseconds.\n            return timeElapsedNanos / 1000000;\n        }\n    };\n    GPGPUContext.prototype.isQueryAvailable = function (query, queryTimerVersion) {\n        if (queryTimerVersion === 0) {\n            return true;\n        }\n        if (queryTimerVersion === 2) {\n            var gl2 = this.gl;\n            var ext = this.getQueryTimerExtensionWebGL2();\n            var available = gl2.getQueryParameter(query, gl2.QUERY_RESULT_AVAILABLE);\n            if (this.disjoint == null) {\n                this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);\n            }\n            return available && !this.disjoint;\n        }\n        else {\n            var ext = this.getQueryTimerExtensionWebGL1();\n            var available = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_AVAILABLE_EXT);\n            if (this.disjoint == null) {\n                this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);\n            }\n            return available && !this.disjoint;\n        }\n    };\n    GPGPUContext.prototype.pollFence = function (fenceContext) {\n        var _this = this;\n        return new Promise(function (resolve) {\n            _this.addItemToPoll(function () { return fenceContext.isFencePassed(); }, function () { return resolve(); });\n        });\n    };\n    GPGPUContext.prototype.pollItems = function () {\n        // Find the last query that has finished.\n        var index = linearSearchLastTrue(this.itemsToPoll.map(function (x) { return x.isDoneFn; }));\n        for (var i = 0; i <= index; ++i) {\n            var resolveFn = this.itemsToPoll[i].resolveFn;\n            resolveFn();\n        }\n        this.itemsToPoll = this.itemsToPoll.slice(index + 1);\n    };\n    GPGPUContext.prototype.addItemToPoll = function (isDoneFn, resolveFn) {\n        var _this = this;\n        this.itemsToPoll.push({ isDoneFn: isDoneFn, resolveFn: resolveFn });\n        if (this.itemsToPoll.length > 1) {\n            // We already have a running loop that polls.\n            return;\n        }\n        // Start a new loop that polls.\n        util.repeatedTry(function () {\n            _this.pollItems();\n            // End the loop if no more items to poll.\n            return _this.itemsToPoll.length === 0;\n        });\n    };\n    GPGPUContext.prototype.bindTextureToFrameBuffer = function (texture) {\n        this.throwIfDisposed();\n        webgl_util.bindColorTextureToFramebuffer(this.gl, this.debug, texture, this.framebuffer);\n        if (this.debug) {\n            webgl_util.validateFramebuffer(this.gl);\n        }\n    };\n    GPGPUContext.prototype.unbindTextureToFrameBuffer = function () {\n        if (this.outputTexture != null) {\n            webgl_util.bindColorTextureToFramebuffer(this.gl, this.debug, this.outputTexture, this.framebuffer);\n            if (this.debug) {\n                webgl_util.validateFramebuffer(this.gl);\n            }\n        }\n        else {\n            webgl_util.unbindColorTextureFromFramebuffer(this.gl, this.debug, this.framebuffer);\n        }\n    };\n    GPGPUContext.prototype.downloadMatrixDriver = function (texture, downloadAndDecode) {\n        this.bindTextureToFrameBuffer(texture);\n        var result = downloadAndDecode();\n        this.unbindTextureToFrameBuffer();\n        return result;\n    };\n    GPGPUContext.prototype.setOutputMatrixTextureDriver = function (outputMatrixTextureMaybePacked, width, height) {\n        this.throwIfDisposed();\n        var gl = this.gl;\n        webgl_util.bindColorTextureToFramebuffer(gl, this.debug, outputMatrixTextureMaybePacked, this.framebuffer);\n        if (this.debug) {\n            webgl_util.validateFramebuffer(gl);\n        }\n        this.outputTexture = outputMatrixTextureMaybePacked;\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.viewport(0, 0, width, height); });\n        webgl_util.callAndCheck(gl, this.debug, function () { return gl.scissor(0, 0, width, height); });\n    };\n    GPGPUContext.prototype.setOutputMatrixWriteRegionDriver = function (x, y, width, height) {\n        var _this = this;\n        this.throwIfDisposed();\n        webgl_util.callAndCheck(this.gl, this.debug, function () { return _this.gl.scissor(x, y, width, height); });\n    };\n    GPGPUContext.prototype.throwIfDisposed = function () {\n        if (this.disposed) {\n            throw new Error('Attempted to use disposed GPGPUContext.');\n        }\n    };\n    GPGPUContext.prototype.throwIfNoProgram = function () {\n        if (this.program == null) {\n            throw new Error('No GPU program is currently set.');\n        }\n    };\n    return GPGPUContext;\n}());\nexports.GPGPUContext = GPGPUContext;\n/**\n * Finds the index of the last true element using linear search.\n * Note: We can't do binary search because Chrome expects us to explicitly\n * test all fences before download:\n * https://github.com/tensorflow/tfjs/issues/1145\n */\nfunction linearSearchLastTrue(arr) {\n    var i = 0;\n    for (; i < arr.length; ++i) {\n        var isDone = arr[i]();\n        if (!isDone) {\n            break;\n        }\n    }\n    return i - 1;\n}\nexports.linearSearchLastTrue = linearSearchLastTrue;\n//# sourceMappingURL=gpgpu_context.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_context.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_math.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_math.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar util = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar shader_compiler = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nfunction compileProgram(gpgpu, program, inputs, output) {\n    var userCode = program.userCode;\n    var inputInfos = inputs.map(function (input, i) {\n        var shapeInfo = {\n            logicalShape: input.shape,\n            texShape: input.isUniform ? null : input.texData.texShape,\n            isUniform: input.isUniform,\n            isPacked: input.isUniform ? false : input.texData.isPacked,\n            flatOffset: null\n        };\n        if (input.texData != null && input.texData.slice != null &&\n            input.texData.slice.flatOffset > 0) {\n            shapeInfo.flatOffset = input.texData.slice.flatOffset;\n        }\n        return { name: program.variableNames[i], shapeInfo: shapeInfo };\n    });\n    var inShapeInfos = inputInfos.map(function (x) { return x.shapeInfo; });\n    var outShapeInfo = {\n        logicalShape: output.shape,\n        texShape: output.texData.texShape,\n        isUniform: false,\n        isPacked: output.texData.isPacked,\n        flatOffset: null\n    };\n    var source = shader_compiler.makeShader(inputInfos, outShapeInfo, userCode, program.packedInputs);\n    var webGLProgram = gpgpu.createProgram(source);\n    // Add special uniforms (NAN, INFINITY)\n    var infLoc = null;\n    var nanLoc = gpgpu.getUniformLocation(webGLProgram, 'NAN', false);\n    if (environment_1.env().getNumber('WEBGL_VERSION') === 1) {\n        infLoc = gpgpu.getUniformLocation(webGLProgram, 'INFINITY', false);\n    }\n    // Add user-defined uniforms\n    var uniformLocations = {};\n    for (var i = 0; i < program.variableNames.length; i++) {\n        var varName = program.variableNames[i];\n        var shouldThrow = false;\n        uniformLocations[varName] =\n            gpgpu.getUniformLocation(webGLProgram, varName, shouldThrow);\n        uniformLocations[\"offset\" + varName] =\n            gpgpu.getUniformLocation(webGLProgram, \"offset\" + varName, shouldThrow);\n    }\n    return {\n        program: program,\n        source: source,\n        webGLProgram: webGLProgram,\n        uniformLocations: uniformLocations,\n        inShapeInfos: inShapeInfos,\n        outShapeInfo: outShapeInfo,\n        infLoc: infLoc,\n        nanLoc: nanLoc,\n    };\n}\nexports.compileProgram = compileProgram;\nfunction validateBinaryAndProgram(shapeInfos, inputs) {\n    if (shapeInfos.length !== inputs.length) {\n        throw Error(\"Binary was compiled with \" + shapeInfos.length + \" inputs, but \" +\n            (\"was executed with \" + inputs.length + \" inputs\"));\n    }\n    shapeInfos.forEach(function (s, i) {\n        var shapeA = s.logicalShape;\n        var input = inputs[i];\n        var shapeB = input.shape;\n        if (!util.arraysEqual(shapeA, shapeB)) {\n            throw Error(\"Binary was compiled with different shapes than \" +\n                (\"the current args. Shapes \" + shapeA + \" and \" + shapeB + \" must match\"));\n        }\n        // The input is uploaded as uniform.\n        if (s.isUniform && input.isUniform) {\n            return;\n        }\n        var texShapeA = s.texShape;\n        var texShapeB = input.isUniform ? null : input.texData.texShape;\n        if (!util.arraysEqual(texShapeA, texShapeB)) {\n            throw Error(\"Binary was compiled with different texture shapes than the\" +\n                (\" current args. Shape \" + texShapeA + \" and \" + texShapeB + \" must match\"));\n        }\n    });\n}\nfunction runProgram(gpgpu, binary, inputs, output, customSetup) {\n    validateBinaryAndProgram(binary.inShapeInfos, inputs);\n    validateBinaryAndProgram([binary.outShapeInfo], [output]);\n    var outTex = output.texData.texture;\n    var outTexShape = output.texData.texShape;\n    if (output.texData.isPacked) {\n        gpgpu.setOutputPackedMatrixTexture(outTex, outTexShape[0], outTexShape[1]);\n    }\n    else {\n        gpgpu.setOutputMatrixTexture(outTex, outTexShape[0], outTexShape[1]);\n    }\n    gpgpu.setProgram(binary.webGLProgram);\n    // Set special uniforms (NAN, INFINITY)\n    if (environment_1.env().getNumber('WEBGL_VERSION') === 1) {\n        if (binary.infLoc !== null) {\n            gpgpu.gl.uniform1f(binary.infLoc, Infinity);\n        }\n    }\n    if (binary.nanLoc !== null) {\n        gpgpu.gl.uniform1f(binary.nanLoc, NaN);\n    }\n    // Set user-defined inputs\n    inputs.forEach(function (input, i) {\n        var varName = binary.program.variableNames[i];\n        var varLoc = binary.uniformLocations[varName];\n        var varOffsetLoc = binary.uniformLocations[\"offset\" + varName];\n        if (varLoc == null) {\n            // The compiler inferred that this variable is not used in this shader.\n            return;\n        }\n        if (input.isUniform) {\n            // Upload the values of the tensor as uniform.\n            if (util.sizeFromShape(input.shape) < 2) {\n                gpgpu.gl.uniform1f(varLoc, input.uniformValues[0]);\n            }\n            else {\n                var vals = input.uniformValues;\n                if (!(vals instanceof Float32Array)) {\n                    vals = new Float32Array(vals);\n                }\n                gpgpu.gl.uniform1fv(varLoc, vals);\n            }\n            return;\n        }\n        // If the input was sliced, upload the flat offset index.\n        if (input.texData.slice != null && varOffsetLoc != null) {\n            gpgpu.gl.uniform1i(varOffsetLoc, input.texData.slice.flatOffset);\n        }\n        gpgpu.setInputMatrixTexture(input.texData.texture, varLoc, i);\n    });\n    if (customSetup != null) {\n        customSetup(gpgpu, binary.webGLProgram);\n    }\n    gpgpu.executeProgram();\n}\nexports.runProgram = runProgram;\nfunction makeShaderKey(program, inputs, output) {\n    var keyInputs = '';\n    inputs.concat(output).forEach(function (x) {\n        var hasOffset = x.texData != null && x.texData.slice != null &&\n            x.texData.slice.flatOffset > 0;\n        var texShape = x.isUniform ? 'uniform' : x.texData.texShape;\n        keyInputs += x.shape + \"_\" + texShape + \"_\" + hasOffset;\n    });\n    var keyUserCode = program.userCode;\n    var key = program.constructor.name;\n    // Fast string concat. See https://jsperf.com/string-concatenation/14.\n    key += '_' + keyInputs + '_' + keyUserCode;\n    return key;\n}\nexports.makeShaderKey = makeShaderKey;\n//# sourceMappingURL=gpgpu_math.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_math.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_util.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_util.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = __webpack_require__(/*! ./glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar tex_util = __webpack_require__(/*! ./tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nvar webgl_util = __webpack_require__(/*! ./webgl_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/webgl_util.js\");\nfunction createVertexShader(gl, debug) {\n    var glsl = glsl_version_1.getGlslDifferences();\n    var vertexShaderSource = glsl.version + \"\\n    precision highp float;\\n    \" + glsl.attribute + \" vec3 clipSpacePos;\\n    \" + glsl.attribute + \" vec2 uv;\\n    \" + glsl.varyingVs + \" vec2 resultUV;\\n\\n    void main() {\\n      gl_Position = vec4(clipSpacePos, 1);\\n      resultUV = uv;\\n    }\";\n    return webgl_util.createVertexShader(gl, debug, vertexShaderSource);\n}\nexports.createVertexShader = createVertexShader;\nfunction createVertexBuffer(gl, debug) {\n    // [x y z u v] * [upper-left, lower-left, upper-right, lower-right]\n    var vertexArray = new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]);\n    return webgl_util.createStaticVertexBuffer(gl, debug, vertexArray);\n}\nexports.createVertexBuffer = createVertexBuffer;\nfunction createIndexBuffer(gl, debug) {\n    // OpenGL (and WebGL) have \"CCW == front\" winding\n    var triangleVertexIndices = new Uint16Array([0, 1, 2, 2, 1, 3]);\n    return webgl_util.createStaticIndexBuffer(gl, debug, triangleVertexIndices);\n}\nexports.createIndexBuffer = createIndexBuffer;\nfunction createAndConfigureTexture(gl, debug, width, height, internalFormat, textureFormat, textureType) {\n    webgl_util.validateTextureSize(width, height);\n    var texture = webgl_util.createTexture(gl, debug);\n    var tex2d = gl.TEXTURE_2D;\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(tex2d, texture); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texImage2D(tex2d, 0, internalFormat, width, height, 0, textureFormat, textureType, null); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, null); });\n    return texture;\n}\nfunction createFloat32MatrixTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getUnpackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n    return createAndConfigureTexture(gl, debug, width, height, textureConfig.internalFormatFloat, textureConfig.textureFormatFloat, gl.FLOAT);\n}\nexports.createFloat32MatrixTexture = createFloat32MatrixTexture;\nfunction createFloat16MatrixTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getUnpackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n    return createAndConfigureTexture(gl, debug, width, height, textureConfig.internalFormatHalfFloat, textureConfig.textureFormatFloat, textureConfig.textureTypeHalfFloat);\n}\nexports.createFloat16MatrixTexture = createFloat16MatrixTexture;\nfunction createUnsignedBytesMatrixTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getUnpackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n    return createAndConfigureTexture(gl, debug, width, height, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE);\n}\nexports.createUnsignedBytesMatrixTexture = createUnsignedBytesMatrixTexture;\nfunction createPackedMatrixTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getPackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n    return createAndConfigureTexture(gl, debug, width, height, textureConfig.internalFormatPackedFloat, gl.RGBA, gl.FLOAT);\n}\nexports.createPackedMatrixTexture = createPackedMatrixTexture;\nfunction createFloat16PackedMatrixTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getPackedMatrixTextureShapeWidthHeight(rows, columns), width = _a[0], height = _a[1];\n    return createAndConfigureTexture(gl, debug, width, height, textureConfig.internalFormatPackedHalfFloat, gl.RGBA, textureConfig.textureTypeHalfFloat);\n}\nexports.createFloat16PackedMatrixTexture = createFloat16PackedMatrixTexture;\nfunction bindVertexProgramAttributeStreams(gl, debug, program, vertexBuffer) {\n    var posOffset = 0; // x is the first buffer element\n    var uvOffset = 3 * 4; // uv comes after [x y z]\n    var stride = (3 * 4) + (2 * 4); // xyz + uv, each entry is 4-byte float.\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer); });\n    var success = webgl_util.bindVertexBufferToProgramAttribute(gl, debug, program, 'clipSpacePos', vertexBuffer, 3, stride, posOffset);\n    return success &&\n        webgl_util.bindVertexBufferToProgramAttribute(gl, debug, program, 'uv', vertexBuffer, 2, stride, uvOffset);\n}\nexports.bindVertexProgramAttributeStreams = bindVertexProgramAttributeStreams;\nfunction uploadDenseMatrixToTexture(gl, debug, texture, width, height, data, textureConfig) {\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, texture); });\n    var dataForUpload, texelDataType, internalFormat;\n    if (data instanceof Uint8Array) {\n        dataForUpload = new Uint8Array(width * height * 4);\n        texelDataType = gl.UNSIGNED_BYTE;\n        internalFormat = gl.RGBA;\n    }\n    else {\n        dataForUpload = new Float32Array(width * height * 4);\n        texelDataType = gl.FLOAT;\n        internalFormat = textureConfig.internalFormatPackedFloat;\n    }\n    dataForUpload.set(data);\n    webgl_util.callAndCheck(gl, debug, function () { return gl.texImage2D(gl.TEXTURE_2D, 0, internalFormat, width, height, 0, gl.RGBA, texelDataType, dataForUpload); });\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, null); });\n}\nexports.uploadDenseMatrixToTexture = uploadDenseMatrixToTexture;\nfunction uploadPixelDataToTexture(gl, debug, texture, pixels) {\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, texture); });\n    if (pixels.data instanceof Uint8Array) {\n        webgl_util.callAndCheck(gl, debug, function () { return gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, pixels.width, pixels.height, 0, gl.RGBA, gl.UNSIGNED_BYTE, pixels.data); });\n    }\n    else {\n        webgl_util.callAndCheck(gl, debug, function () { return gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, pixels); });\n    }\n    webgl_util.callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, null); });\n}\nexports.uploadPixelDataToTexture = uploadPixelDataToTexture;\nfunction createBufferFromOutputTexture(gl2, debug, rows, columns, textureConfig) {\n    // Create and bind the buffer.\n    var buffer = gl2.createBuffer();\n    webgl_util.callAndCheck(gl2, debug, function () { return gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer); });\n    // Initialize the buffer to the size of the texture in bytes.\n    var bytesPerFloat = 4;\n    var valuesPerTexel = 4;\n    var bufferSizeBytes = bytesPerFloat * valuesPerTexel * rows * columns;\n    webgl_util.callAndCheck(gl2, debug, function () { return gl2.bufferData(gl2.PIXEL_PACK_BUFFER, bufferSizeBytes, gl2.STREAM_READ); });\n    // Enqueue a command on the GPU command queue to copy of texture into the\n    // buffer.\n    webgl_util.callAndCheck(gl2, debug, function () { return gl2.readPixels(0, 0, columns, rows, gl2.RGBA, gl2.FLOAT, 0); });\n    webgl_util.callAndCheck(gl2, debug, function () { return gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null); });\n    return buffer;\n}\nexports.createBufferFromOutputTexture = createBufferFromOutputTexture;\nfunction downloadFloat32MatrixFromBuffer(gl, buffer, size) {\n    var gl2 = gl;\n    var downloadTarget = new Float32Array(size);\n    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer);\n    gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);\n    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);\n    return downloadTarget;\n}\nexports.downloadFloat32MatrixFromBuffer = downloadFloat32MatrixFromBuffer;\nfunction downloadByteEncodedFloatMatrixFromOutputTexture(gl, debug, rows, columns, textureConfig) {\n    var _a = tex_util.getUnpackedMatrixTextureShapeWidthHeight(rows, columns), w = _a[0], h = _a[1];\n    var numChannels = 4;\n    var downloadTarget = new Uint8Array(tex_util.getUnpackedArraySizeFromMatrixSize(rows * columns, numChannels));\n    webgl_util.callAndCheck(gl, debug, function () { return gl.readPixels(0, 0, w, h, textureConfig.downloadTextureFormat, gl.UNSIGNED_BYTE, downloadTarget); });\n    // By wrapping the buffer in a Float32Array, we use native browser IEEE 754\n    // decoding of the 4 bytes that back each 32 bit float.\n    return new Float32Array(downloadTarget.buffer);\n}\nexports.downloadByteEncodedFloatMatrixFromOutputTexture = downloadByteEncodedFloatMatrixFromOutputTexture;\nfunction downloadPackedMatrixFromBuffer(gl, buffer, batch, rows, cols, physicalRows, physicalCols, textureConfig) {\n    var gl2 = gl;\n    var downloadTarget = new Float32Array(tex_util.getPackedRGBAArraySizeFromMatrixShape(physicalRows, physicalCols));\n    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer);\n    gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);\n    gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);\n    return downloadTarget;\n}\nexports.downloadPackedMatrixFromBuffer = downloadPackedMatrixFromBuffer;\nfunction downloadMatrixFromPackedOutputTexture(gl, debug, physicalRows, physicalCols) {\n    var packedRGBA = new Float32Array(physicalRows * physicalCols * 4);\n    webgl_util.callAndCheck(gl, debug, function () { return gl.readPixels(0, 0, physicalCols, physicalRows, gl.RGBA, gl.FLOAT, packedRGBA); });\n    return packedRGBA;\n}\nexports.downloadMatrixFromPackedOutputTexture = downloadMatrixFromPackedOutputTexture;\n//# sourceMappingURL=gpgpu_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/im2col_packed_gpu.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/im2col_packed_gpu.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = __webpack_require__(/*! ./glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar Im2ColPackedProgram = /** @class */ (function () {\n    function Im2ColPackedProgram(outputShape, inputShape, convInfo) {\n        this.variableNames = ['A'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = outputShape;\n        var filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, strideWidth = convInfo.strideWidth, strideHeight = convInfo.strideHeight, padInfo = convInfo.padInfo, outWidth = convInfo.outWidth, dilationWidth = convInfo.dilationWidth, dilationHeight = convInfo.dilationHeight, dataFormat = convInfo.dataFormat;\n        var left = padInfo.left, top = padInfo.top;\n        var itemsPerBlockRow = inChannels * filterWidth;\n        var glsl = glsl_version_1.getGlslDifferences();\n        var isChannelsLast = dataFormat === 'channelsLast';\n        var rowDim = isChannelsLast ? 0 : 1;\n        var colDim = isChannelsLast ? 1 : 2;\n        var unrolled = \"\";\n        for (var row = 0; row <= 1; row++) {\n            for (var col = 0; col <= 1; col++) {\n                unrolled += \"\\n          blockIndex = rc.y + \" + col + \";\\n          pos = rc.x + \" + row + \";\\n\\n          if(blockIndex < \" + outputShape[1] + \" && pos < \" + outputShape[0] + \") {\\n            offsetY = int(blockIndex / (\" + outWidth + \")) * \" + strideHeight + \" - \" + top + \";\\n            d0 = offsetY + \" + dilationHeight + \" * (pos / \" + itemsPerBlockRow + \");\\n\\n            if(d0 < \" + inputShape[rowDim] + \" && d0 >= 0) {\\n\\n              offsetX = int(mod(float(blockIndex), \" + outWidth + \".) * \" + strideWidth + \". - \" + left + \".);\\n              d1 = offsetX + \" + dilationWidth + \" * (int(mod(float(pos), \" + itemsPerBlockRow + \".) / \" + inChannels + \".));\\n\\n              if(d1 < \" + inputShape[colDim] + \" && d1 >= 0) {\\n\\n                ch = int(mod(float(pos), \" + inChannels + \".));\\n\\n                if (\" + isChannelsLast + \") {\\n                  innerDims = vec2(d1, ch);\\n                  result[\" + (row * 2 + col) + \"] = getChannel(\\n                    getA(d0, int(innerDims.x),\\n                    int(innerDims.y)), innerDims);\\n                } else {\\n                  innerDims = vec2(d0, d1);\\n                  result[\" + (row * 2 + col) + \"] = getChannel(\\n                    getA(ch, int(innerDims.x),\\n                    int(innerDims.y)), innerDims);\\n                }\\n              }\\n            }\\n          }\\n        \";\n            }\n        }\n        this.userCode = \"\\n      void main() {\\n        ivec2 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0);\\n\\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\\n        vec2 innerDims;\\n\\n        \" + unrolled + \"\\n\\n        \" + glsl.output + \" = result;\\n      }\\n    \";\n    }\n    return Im2ColPackedProgram;\n}());\nexports.Im2ColPackedProgram = Im2ColPackedProgram;\n//# sourceMappingURL=im2col_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/im2col_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar kernel_names_1 = __webpack_require__(/*! ../../../kernel_names */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js\");\nvar tex_util_1 = __webpack_require__(/*! ../tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nvar from_pixels_gpu_1 = __webpack_require__(/*! ./FromPixels_utils/from_pixels_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels_utils/from_pixels_gpu.js\");\nvar from_pixels_packed_gpu_1 = __webpack_require__(/*! ./FromPixels_utils/from_pixels_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels_utils/from_pixels_packed_gpu.js\");\nexports.fromPixelsConfig = {\n    kernelName: kernel_names_1.FromPixels,\n    backendName: 'webgl',\n    kernelFunc: fromPixels,\n};\nvar fromPixels2DContext;\nfunction fromPixels(args) {\n    var inputs = args.inputs, backend = args.backend, attrs = args.attrs;\n    var pixels = inputs.pixels;\n    var numChannels = attrs.numChannels;\n    var isVideo = typeof (HTMLVideoElement) !== 'undefined' &&\n        pixels instanceof HTMLVideoElement;\n    var isImage = typeof (HTMLImageElement) !== 'undefined' &&\n        pixels instanceof HTMLImageElement;\n    var _a = isVideo ?\n        [\n            pixels.videoWidth,\n            pixels.videoHeight\n        ] :\n        [pixels.width, pixels.height], width = _a[0], height = _a[1];\n    var texShape = [height, width];\n    var outShape = [height, width, numChannels];\n    if (isImage || isVideo) {\n        if (fromPixels2DContext == null) {\n            fromPixels2DContext = document.createElement('canvas').getContext('2d');\n        }\n        fromPixels2DContext.canvas.width = width;\n        fromPixels2DContext.canvas.height = height;\n        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);\n        pixels = fromPixels2DContext.canvas;\n    }\n    var tempPixelHandle = backend.makeTensorInfo(texShape, 'int32');\n    // This is a byte texture with pixels.\n    backend.texData.get(tempPixelHandle.dataId).usage = tex_util_1.TextureUsage.PIXELS;\n    backend.gpgpu.uploadPixelDataToTexture(backend.getTexture(tempPixelHandle.dataId), pixels);\n    var program = environment_1.env().getBool('WEBGL_PACK') ?\n        new from_pixels_packed_gpu_1.FromPixelsPackedProgram(outShape) :\n        new from_pixels_gpu_1.FromPixelsProgram(outShape);\n    var res = backend.runWebGLProgram(program, [tempPixelHandle], 'int32');\n    backend.disposeData(tempPixelHandle.dataId);\n    return res;\n}\n//# sourceMappingURL=FromPixels.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels_utils/from_pixels_gpu.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels_utils/from_pixels_gpu.js ***!
  \************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = __webpack_require__(/*! ../../glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar FromPixelsProgram = /** @class */ (function () {\n    function FromPixelsProgram(outputShape) {\n        this.variableNames = ['A'];\n        var glsl = glsl_version_1.getGlslDifferences();\n        var height = outputShape[0], width = outputShape[1];\n        this.outputShape = outputShape;\n        this.userCode = \"\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        int texR = coords[0];\\n        int texC = coords[1];\\n        int depth = coords[2];\\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\" + width + \".0, \" + height + \".0);\\n\\n        vec4 values = \" + glsl.texture2D + \"(A, uv);\\n        float value;\\n        if (depth == 0) {\\n          value = values.r;\\n        } else if (depth == 1) {\\n          value = values.g;\\n        } else if (depth == 2) {\\n          value = values.b;\\n        } else if (depth == 3) {\\n          value = values.a;\\n        }\\n\\n        setOutput(floor(value * 255.0 + 0.5));\\n      }\\n    \";\n    }\n    return FromPixelsProgram;\n}());\nexports.FromPixelsProgram = FromPixelsProgram;\n//# sourceMappingURL=from_pixels_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels_utils/from_pixels_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels_utils/from_pixels_packed_gpu.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels_utils/from_pixels_packed_gpu.js ***!
  \*******************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar glsl_version_1 = __webpack_require__(/*! ../../glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar FromPixelsPackedProgram = /** @class */ (function () {\n    function FromPixelsPackedProgram(outputShape) {\n        this.variableNames = ['A'];\n        this.packedInputs = false;\n        this.packedOutput = true;\n        var glsl = glsl_version_1.getGlslDifferences();\n        var height = outputShape[0], width = outputShape[1];\n        this.outputShape = outputShape;\n        this.userCode = \"\\n      void main() {\\n        ivec3 coords = getOutputCoords();\\n        int texR = coords[0];\\n        int texC = coords[1];\\n        int depth = coords[2];\\n\\n        vec4 result = vec4(0.);\\n\\n        for(int row=0; row<=1; row++) {\\n          for(int col=0; col<=1; col++) {\\n            texC = coords[1] + row;\\n            depth = coords[2] + col;\\n\\n            vec2 uv = (vec2(texC, texR) + halfCR) /\\n                       vec2(\" + width + \".0, \" + height + \".0);\\n            vec4 values = \" + glsl.texture2D + \"(A, uv);\\n            float value;\\n            if (depth == 0) {\\n              value = values.r;\\n            } else if (depth == 1) {\\n              value = values.g;\\n            } else if (depth == 2) {\\n              value = values.b;\\n            } else if (depth == 3) {\\n              value = values.a;\\n            }\\n\\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\\n          }\\n        }\\n\\n        \" + glsl.output + \" = result;\\n      }\\n    \";\n    }\n    return FromPixelsPackedProgram;\n}());\nexports.FromPixelsPackedProgram = FromPixelsPackedProgram;\n//# sourceMappingURL=from_pixels_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels_utils/from_pixels_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/NonMaxSuppressionV5.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/NonMaxSuppressionV5.js ***!
  \***********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar kernel_names_1 = __webpack_require__(/*! ../../../kernel_names */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js\");\nvar log_1 = __webpack_require__(/*! ../../../log */ \"./node_modules/@tensorflow/tfjs-core/dist/log.js\");\nvar non_max_suppression_impl_1 = __webpack_require__(/*! ../../non_max_suppression_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js\");\nexports.nonMaxSuppressionV5Config = {\n    kernelName: kernel_names_1.NonMaxSuppressionV5,\n    backendName: 'webgl',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, backend = _a.backend, attrs = _a.attrs;\n        log_1.warn('tf.nonMaxSuppression() in webgl locks the UI thread. ' +\n            'Call tf.nonMaxSuppressionAsync() instead');\n        var _b = inputs, boxes = _b.boxes, scores = _b.scores;\n        var _c = attrs, maxOutputSize = _c.maxOutputSize, iouThreshold = _c.iouThreshold, scoreThreshold = _c.scoreThreshold, softNmsSigma = _c.softNmsSigma;\n        var gpuBackend = backend;\n        var boxesVals = gpuBackend.readSync(boxes.dataId);\n        var scoresVals = gpuBackend.readSync(scores.dataId);\n        var maxOutputSizeVal = maxOutputSize;\n        var iouThresholdVal = iouThreshold;\n        var scoreThresholdVal = scoreThreshold;\n        var softNmsSigmaVal = softNmsSigma;\n        var _d = non_max_suppression_impl_1.nonMaxSuppressionV5(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal), selectedIndices = _d.selectedIndices, selectedScores = _d.selectedScores;\n        return [selectedIndices, selectedScores];\n    }\n};\n//# sourceMappingURL=NonMaxSuppressionV5.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/NonMaxSuppressionV5.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/Square.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/Square.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar kernel_names_1 = __webpack_require__(/*! ../../../kernel_names */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js\");\nvar unaryop_gpu_1 = __webpack_require__(/*! ../unaryop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_gpu.js\");\nexports.squareConfig = {\n    kernelName: kernel_names_1.Square,\n    backendName: 'webgl',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, backend = _a.backend;\n        var x = inputs.x;\n        var webglBackend = backend;\n        var program = new unaryop_gpu_1.UnaryOpProgram(x.shape, unaryop_gpu_1.SQUARE);\n        return webglBackend.runWebGLProgram(program, [x], x.dtype);\n    }\n};\n//# sourceMappingURL=Square.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/Square.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/SquaredDifference.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/SquaredDifference.js ***!
  \*********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar kernel_names_1 = __webpack_require__(/*! ../../../kernel_names */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js\");\nvar binaryop_gpu_1 = __webpack_require__(/*! ../binaryop_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_gpu.js\");\nvar binaryop_packed_gpu_1 = __webpack_require__(/*! ../binaryop_packed_gpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/binaryop_packed_gpu.js\");\nexports.squaredDifferenceConfig = {\n    kernelName: kernel_names_1.SquaredDifference,\n    backendName: 'webgl',\n    kernelFunc: function (_a) {\n        var inputs = _a.inputs, backend = _a.backend;\n        var _b = inputs, a = _b.a, b = _b.b;\n        var SQUARED_DIFFERENCE = 'return (a - b) * (a - b);';\n        var webGLBackend = backend;\n        var program = environment_1.env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n            new binaryop_packed_gpu_1.BinaryOpPackedProgram(SQUARED_DIFFERENCE, a.shape, b.shape) :\n            new binaryop_gpu_1.BinaryOpProgram(SQUARED_DIFFERENCE, a.shape, b.shape);\n        return webGLBackend.compileAndRun(program, [a, b]);\n    }\n};\n//# sourceMappingURL=SquaredDifference.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/SquaredDifference.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_gpu.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_gpu.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar LRNProgram = /** @class */ (function () {\n    function LRNProgram(xShape, radius, bias, alpha, beta) {\n        this.variableNames = ['x'];\n        this.outputShape = [];\n        var rad = radius;\n        var maxD = xShape[3] - 1;\n        this.outputShape = xShape;\n        // optimize pow(bias + alpha * sum, -beta)\n        // src: https://github.com/tensorflow/tensorflow/..\n        // blob/26033a1644a9c4a5fbe3170ab2e864b6a4ccd4ca/..\n        // tensorflow/core/kernels/mkl_lrn_op.cc#L320\n        var powOperator;\n        var basis = \"float(\" + bias + \") + float(\" + alpha + \") * sum\";\n        if (beta === 0.5) {\n            powOperator = \"inversesqrt(\" + basis + \")\";\n        }\n        else if (beta === 1.0) {\n            powOperator = \"1.0/(\" + basis + \")\";\n        }\n        else {\n            powOperator = \"exp(log(\" + basis + \") * float(-\" + beta + \"));\";\n        }\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int r = coords[1];\\n        int c = coords[2];\\n        int d = coords[3];\\n        float x = getX(b, r, c, d);\\n        float sum = 0.0;\\n        for (int j = -\" + rad + \"; j <= \" + rad + \"; j++) {\\n          int idx = d + j;\\n          if (idx >= 0 && idx <=  \" + maxD + \") {\\n            float z = getX(b, r, c, idx);\\n            sum += z * z;\\n          }\\n        }\\n        float val = x * \" + powOperator + \";\\n        setOutput(val);\\n      }\\n    \";\n    }\n    return LRNProgram;\n}());\nexports.LRNProgram = LRNProgram;\n//# sourceMappingURL=lrn_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_grad_gpu.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_grad_gpu.js ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar LRNGradProgram = /** @class */ (function () {\n    function LRNGradProgram(inputShape, depthRadius, bias, alpha, beta) {\n        this.variableNames = ['inputImage', 'outputImage', 'dy'];\n        this.outputShape = [];\n        this.outputShape = inputShape;\n        this.depth = inputShape[3];\n        this.depthRadius = depthRadius;\n        this.bias = bias;\n        this.alpha = alpha;\n        this.beta = beta;\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float result = 0.0;\\n        for (int d = 0; d < \" + this.depth + \"; ++d) {\\n          int depthBegin = int(max(0.0, float(d - \" + depthRadius + \")));\\n          int depthEnd = int(min(float(\" + this.depth + \"),\\n              float(d + \" + depthRadius + \" + 1)));\\n\\n          const int MIN_DEPTH_BEGIN = 0;\\n          const int MAX_DEPTH_END = \" + this.depth + \";\\n\\n          float norm = 0.0;\\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\\n            if (k < depthBegin){\\n              continue;\\n            }\\n            else if (k >= depthBegin && k < depthEnd) {\\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\\n            }\\n            else {\\n              break;\\n            }\\n          }\\n\\n          norm = float(\" + alpha + \") * norm + float(\" + bias + \");\\n\\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\\n            if (k < depthBegin){\\n              continue;\\n            }\\n            else if (k >= depthBegin && k < depthEnd){\\n              float dyi = -2.0 * float(\" + alpha + \")\\n                * float(\" + beta + \")\\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\\n                / norm;\\n              if (k == d) {\\n                dyi += pow(norm, -1.0 * \" + beta + \");\\n              }\\n              if (k == coords[3]) {\\n                dyi *= getDy(b, r, c, d);\\n                result += dyi;\\n              }\\n            }\\n            else {\\n              break;\\n            }\\n          }\\n      }\\n      setOutput(result);\\n      }\\n    \";\n    }\n    return LRNGradProgram;\n}());\nexports.LRNGradProgram = LRNGradProgram;\n//# sourceMappingURL=lrn_grad_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_grad_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_packed_gpu.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_packed_gpu.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar LRNPackedProgram = /** @class */ (function () {\n    function LRNPackedProgram(xShape, radius, bias, alpha, beta) {\n        this.variableNames = ['x'];\n        this.outputShape = [];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        var rad = radius;\n        var maxD = xShape[3] - 1;\n        this.outputShape = xShape;\n        // optimize pow(bias + alpha * sum, -beta)\n        // src: https://github.com/tensorflow/tensorflow/..\n        // blob/26033a1644a9c4a5fbe3170ab2e864b6a4ccd4ca/..\n        // tensorflow/core/kernels/mkl_lrn_op.cc#L320\n        var powOperator;\n        var basis = \"float(\" + bias + \") + float(\" + alpha + \") * sum\";\n        if (beta === 0.5) {\n            powOperator = \"inversesqrt(\" + basis + \")\";\n        }\n        else if (beta === 1.0) {\n            powOperator = \"1.0/(\" + basis + \")\";\n        }\n        else {\n            powOperator = \"exp(log(\" + basis + \") * float(-\" + beta + \"));\";\n        }\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords.x;\\n        int r = coords.y;\\n        int c = coords.z;\\n        int d = coords.w;\\n\\n        bool hasNextCol = d < \" + this.outputShape[3] + \";\\n        bool hasNextRow = c < \" + this.outputShape[2] + \";\\n\\n        vec4 sum = vec4(0.);\\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\\n\\n        vec4 xAtOutputCoords = vec4(\\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\\n          hasNextCol ?\\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\\n          hasNextRow ?\\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\\n        );\\n\\n        int firstChannel = d - \" + rad + \";\\n        vec2 cache = vec2(0.);\\n        if(firstChannel >= 0){\\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\\n            if(hasNextRow){\\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\\n            }\\n        }\\n\\n        ivec2 depth = ivec2(d, d + 1);\\n        for (int j = - \" + rad + \"; j <= \" + rad + \"; j++) {\\n          ivec2 idx = depth + j;\\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(\" + maxD + \"));\\n\\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\\n\\n          if(depthInRange || depthPlusOneInRange){\\n            vec4 z = vec4(0.);\\n            vec4 xFragAtCurrentDepth;\\n            z.xz = cache.xy;\\n            if(depthPlusOneInRange && hasNextCol){\\n              xFragAtCurrentDepth = idx.y != d ?\\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\\n              if(hasNextRow){\\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\\n              }\\n            }\\n            cache.xy = z.yw;\\n            sum += z * z;\\n          }\\n        }\\n        vec4 result = xAtOutputCoords * \" + powOperator + \";\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return LRNPackedProgram;\n}());\nexports.LRNPackedProgram = LRNPackedProgram;\n//# sourceMappingURL=lrn_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/lrn_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/max_pool_backprop_gpu.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/max_pool_backprop_gpu.js ***!
  \*****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar MaxPool2DBackpropProgram = /** @class */ (function () {\n    function MaxPool2DBackpropProgram(convInfo) {\n        this.variableNames = ['dy', 'maxPos'];\n        this.outputShape = convInfo.inShape;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var lastIndex = effectiveFilterHeight * effectiveFilterWidth - 1;\n        this.userCode = \"\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 dyRCCorner = coords.yz - pads;\\n        int dyRCorner = dyRCCorner.x;\\n        int dyCCorner = dyRCCorner.y;\\n\\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n        for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n          wR += \" + dilationHeight + \") {\\n          float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n          if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 || fract(dyR) > 0.0) {\\n            continue;\\n          }\\n          int idyR = int(dyR);\\n\\n          for (int wC = 0; wC < \" + effectiveFilterWidth + \"; wC++) {\\n            float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n            if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                fract(dyC) > 0.0) {\\n              continue;\\n            }\\n            int idyC = int(dyC);\\n\\n            float dyValue = getDy(b, idyR, idyC, d);\\n            int maxPosValue = \" + lastIndex + \" - int(getMaxPos(b, idyR, idyC, d));\\n\\n            // Get the current value, check it against the value from the\\n            // position matrix.\\n            int curPosValue = wR * \" + effectiveFilterWidth + \" + wC;\\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\\n\\n            dotProd += dyValue * mask;\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return MaxPool2DBackpropProgram;\n}());\nexports.MaxPool2DBackpropProgram = MaxPool2DBackpropProgram;\nvar MaxPool3DBackpropProgram = /** @class */ (function () {\n    function MaxPool3DBackpropProgram(convInfo) {\n        this.variableNames = ['dy', 'maxPos'];\n        this.outputShape = convInfo.inShape;\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n        var padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n        var padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n        var lastIndex = effectiveFilterDepth * effectiveFilterHeight * effectiveFilterWidth - 1;\n        this.userCode = \"\\n      const ivec3 pads = ivec3(\" + padFront + \", \" + padTop + \", \" + padLeft + \");\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\\n        int dyDCorner = dyCorner.x;\\n        int dyRCorner = dyCorner.y;\\n        int dyCCorner = dyCorner.z;\\n\\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\\n        // dx(xD, xR, xC, ch).\\n        // ? = to be determined. : = across all values in that axis.\\n        float dotProd = 0.0;\\n\\n        for (int wD = 0; wD < \" + effectiveFilterDepth + \";\\n           wD += \" + dilationDepth + \") {\\n          float dyD = float(dyDCorner + wD) / \" + strideDepth + \".0;\\n\\n          if (dyD < 0.0 || dyD >= \" + convInfo.outDepth + \".0 || fract(dyD) > 0.0) {\\n            continue;\\n          }\\n          int idyD = int(dyD);\\n\\n          for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n              wR += \" + dilationHeight + \") {\\n            float dyR = float(dyRCorner + wR) / \" + strideHeight + \".0;\\n\\n            if (dyR < 0.0 || dyR >= \" + convInfo.outHeight + \".0 ||\\n                fract(dyR) > 0.0) {\\n              continue;\\n            }\\n            int idyR = int(dyR);\\n\\n            for (int wC = 0; wC < \" + effectiveFilterWidth + \";\\n                wC += \" + dilationWidth + \") {\\n              float dyC = float(dyCCorner + wC) / \" + strideWidth + \".0;\\n\\n              if (dyC < 0.0 || dyC >= \" + convInfo.outWidth + \".0 ||\\n                  fract(dyC) > 0.0) {\\n                continue;\\n              }\\n              int idyC = int(dyC);\\n\\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\\n              int maxPosValue = \" + lastIndex + \" -\\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\\n\\n              // Get the current value, check it against the value from the\\n              // position matrix.\\n              int curPosValue =\\n                  wD * \" + effectiveFilterHeight + \" * \" + effectiveFilterWidth + \" +\\n                  wR * \" + effectiveFilterWidth + \" + wC;\\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\\n\\n              dotProd += dyValue * mask;\\n            }\\n          }\\n        }\\n        setOutput(dotProd);\\n      }\\n    \";\n    }\n    return MaxPool3DBackpropProgram;\n}());\nexports.MaxPool3DBackpropProgram = MaxPool3DBackpropProgram;\n//# sourceMappingURL=max_pool_backprop_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/max_pool_backprop_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/mulmat_packed_gpu.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/mulmat_packed_gpu.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar MatMulPackedProgram = /** @class */ (function () {\n    function MatMulPackedProgram(aShape, outputShape, transposeA, transposeB, addBias, activation, hasPreluActivation) {\n        if (transposeA === void 0) { transposeA = false; }\n        if (transposeB === void 0) { transposeB = false; }\n        if (addBias === void 0) { addBias = false; }\n        if (activation === void 0) { activation = null; }\n        if (hasPreluActivation === void 0) { hasPreluActivation = false; }\n        this.variableNames = ['matrixA', 'matrixB'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = outputShape;\n        var sharedDim = transposeA ? aShape[1] : aShape[2];\n        var sharedDimensionPacked = Math.ceil(sharedDim / 2);\n        var aSample = transposeA ? 'i * 2, rc.y' : 'rc.y, i * 2';\n        var bSample = transposeB ? 'rc.z, i * 2' : 'i * 2, rc.z';\n        var aSwizzle = transposeA ? ['a.xxyy', 'a.zzww'] : ['a.xxzz', 'a.yyww'];\n        var bSwizzle = transposeB ? ['b.xzxz', 'b.ywyw'] : ['b.xyxy', 'b.zwzw'];\n        var activationSnippet = '', applyActivationSnippet = '';\n        if (activation) {\n            if (hasPreluActivation) {\n                activationSnippet = \"vec4 activation(vec4 a) {\\n          vec4 b = getPreluActivationWeightsAtOutCoords();\\n          \" + activation + \"\\n        }\";\n            }\n            else {\n                activationSnippet = \"vec4 activation(vec4 x) {\\n          \" + activation + \"\\n        }\";\n            }\n            applyActivationSnippet = \"result = activation(result);\";\n        }\n        var addBiasSnippet = addBias ? 'result += getBiasAtOutCoords();' : '';\n        if (addBias) {\n            this.variableNames.push('bias');\n        }\n        if (hasPreluActivation) {\n            this.variableNames.push('preluActivationWeights');\n        }\n        this.userCode = \"\\n      \" + activationSnippet + \"\\n\\n      const float sharedDimension = \" + sharedDimensionPacked + \".0;\\n\\n      vec4 dot2x2ARowBCol(ivec3 rc) {\\n        vec4 result = vec4(0);\\n        for (int i = 0; i < \" + sharedDimensionPacked + \"; i++) {\\n          vec4 a = getMatrixA(rc.x, \" + aSample + \");\\n          vec4 b = getMatrixB(rc.x, \" + bSample + \");\\n\\n          // These swizzled products need to be separately added.\\n          // See: https://github.com/tensorflow/tfjs/issues/1735\\n          result += (\" + aSwizzle[0] + \" * \" + bSwizzle[0] + \");\\n          result += (\" + aSwizzle[1] + \" * \" + bSwizzle[1] + \");\\n        }\\n        return result;\\n      }\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n        vec4 result = dot2x2ARowBCol(rc);\\n\\n        \" + addBiasSnippet + \"\\n\\n        \" + applyActivationSnippet + \"\\n\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return MatMulPackedProgram;\n}());\nexports.MatMulPackedProgram = MatMulPackedProgram;\n//# sourceMappingURL=mulmat_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/mulmat_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/multinomial_gpu.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/multinomial_gpu.js ***!
  \***********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar MultinomialProgram = /** @class */ (function () {\n    function MultinomialProgram(batchSize, numOutcomes, numSamples) {\n        this.variableNames = ['probs'];\n        this.outputShape = [batchSize, numSamples];\n        this.userCode = \"\\n      uniform float seed;\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n\\n        float r = random(seed);\\n        float cdf = 0.0;\\n\\n        for (int i = 0; i < \" + (numOutcomes - 1) + \"; i++) {\\n          cdf += getProbs(batch, i);\\n\\n          if (r < cdf) {\\n            setOutput(float(i));\\n            return;\\n          }\\n        }\\n\\n        // If no other event happened, last event happened.\\n        setOutput(float(\" + (numOutcomes - 1) + \"));\\n      }\\n    \";\n    }\n    MultinomialProgram.prototype.getCustomSetupFunc = function (seed) {\n        var _this = this;\n        return function (gpgpu, webGLProgram) {\n            if (_this.seedLoc == null) {\n                _this.seedLoc = gpgpu.getUniformLocation(webGLProgram, 'seed');\n            }\n            gpgpu.gl.uniform1f(_this.seedLoc, seed);\n        };\n    };\n    return MultinomialProgram;\n}());\nexports.MultinomialProgram = MultinomialProgram;\n//# sourceMappingURL=multinomial_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/multinomial_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/onehot_gpu.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/onehot_gpu.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar OneHotProgram = /** @class */ (function () {\n    function OneHotProgram(numIndices, depth, onValue, offValue) {\n        this.variableNames = ['indices'];\n        this.outputShape = [numIndices, depth];\n        this.userCode = \"\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int index = round(getIndices(coords.x));\\n        setOutput(mix(float(\" + offValue + \"), float(\" + onValue + \"),\\n                      float(index == coords.y)));\\n      }\\n    \";\n    }\n    return OneHotProgram;\n}());\nexports.OneHotProgram = OneHotProgram;\n//# sourceMappingURL=onehot_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/onehot_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pack_gpu.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pack_gpu.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar packing_util_1 = __webpack_require__(/*! ../packing_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js\");\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar PackProgram = /** @class */ (function () {\n    function PackProgram(outputShape) {\n        this.variableNames = ['A'];\n        this.packedInputs = false;\n        this.packedOutput = true;\n        // Only input / output 3D tensors.\n        this.outputShape = outputShape;\n        var rank = outputShape.length;\n        if (rank === 0) {\n            this.userCode = \"\\n        void main() {\\n          setOutput(vec4(getA(), 0., 0., 0.));\\n        }\\n      \";\n        }\n        else {\n            var channels = packing_util_1.getChannels('rc', rank);\n            var dtype = shader_compiler_1.getCoordsDataType(rank);\n            var outOfBoundsCondition = getOutOfBoundsCondition(rank, outputShape, channels);\n            var setup = getSetup(rank, outputShape[outputShape.length - 1], outputShape[outputShape.length - 2], channels);\n            var output = getOutput(outputShape, channels);\n            this.userCode = \"\\n        void main() {\\n          \" + dtype + \" rc = getOutputCoords();\\n\\n          if(\" + outOfBoundsCondition + \") {\\n            setOutput(vec4(0));\\n          } else {\\n            \" + setup + \"\\n\\n            setOutput(vec4(\" + output + \"));\\n          }\\n        }\\n      \";\n        }\n    }\n    return PackProgram;\n}());\nexports.PackProgram = PackProgram;\nfunction getSourceCoordsArr(rank, dims) {\n    var coords = [];\n    for (var row = 0; row <= 1; row++) {\n        for (var col = 0; col <= 1; col++) {\n            var coord = (row === 0 ? 'r' : 'rp1') + \", \" + (col === 0 ? 'c' : 'cp1');\n            for (var d = 2; d < rank; d++) {\n                coord = dims[dims.length - 1 - d] + \",\" + coord;\n            }\n            coords.push(coord);\n        }\n    }\n    return coords;\n}\nfunction getOutOfBoundsCondition(rank, shape, dims) {\n    if (rank === 1) {\n        return \"rc > \" + shape[0];\n    }\n    var cond = '';\n    for (var i = rank - 2; i < rank; i++) {\n        cond += dims[i] + \" >= \" + shape[i];\n        if (i < rank - 1) {\n            cond += '||';\n        }\n    }\n    return cond;\n}\nfunction getSetup(rank, cols, rows, dims) {\n    if (rank === 1) {\n        return '';\n    }\n    var innerDims = dims.slice(-2);\n    return \"\\n    int r = \" + innerDims[0] + \";\\n    int c = \" + innerDims[1] + \";\\n    int rp1 = r + 1;\\n    int cp1 = c + 1;\\n\\n    bool cEdge = cp1 >= \" + cols + \";\\n    bool rEdge = rp1 >= \" + rows + \";\\n  \";\n}\nfunction getOutput(shape, dims) {\n    var rank = shape.length;\n    var sourceCoords = getSourceCoordsArr(rank, dims);\n    if (rank === 1) {\n        return \"getA(rc),\\n            rc + 1 >= \" + shape[0] + \" ? 0. : getA(rc + 1),\\n            0, 0\";\n    }\n    return \"getA(\" + sourceCoords[0] + \"),\\n          cEdge ? 0. : getA(\" + sourceCoords[1] + \"),\\n          rEdge ? 0. : getA(\" + sourceCoords[2] + \"),\\n          rEdge || cEdge ? 0. : getA(\" + sourceCoords[3] + \")\";\n}\n//# sourceMappingURL=pack_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pack_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pad_gpu.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pad_gpu.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar PadProgram = /** @class */ (function () {\n    function PadProgram(xShape, paddings, constantValue) {\n        this.variableNames = ['x'];\n        this.outputShape = paddings.map(function (p, i) { return p[0] /* beforePad */ + xShape[i] + p[1]; } /* afterPad */);\n        var rank = xShape.length;\n        var type = shader_compiler_1.getCoordsDataType(rank);\n        var start = paddings.map(function (p) { return p[0]; }).join(',');\n        var end = paddings.map(function (p, i) { return p[0] + xShape[i]; }).join(',');\n        var unpackedCoords = ['coords[0]', 'coords[1]', 'coords[2]', 'coords[3]'].slice(0, rank);\n        if (rank === 1) {\n            this.userCode = \"\\n        int start = \" + start + \";\\n        int end = \" + end + \";\\n\\n        void main() {\\n          int outC = getOutputCoords();\\n          if (outC < start || outC >= end) {\\n            setOutput(float(\" + constantValue + \"));\\n          } else {\\n            setOutput(getX(outC - start));\\n          }\\n        }\\n      \";\n            return;\n        }\n        this.userCode = \"\\n      \" + type + \" start = \" + type + \"(\" + start + \");\\n      \" + type + \" end = \" + type + \"(\" + end + \");\\n\\n      void main() {\\n        \" + type + \" outC = getOutputCoords();\\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\\n          setOutput(float(\" + constantValue + \"));\\n        } else {\\n          \" + type + \" coords = outC - start;\\n          setOutput(getX(\" + unpackedCoords + \"));\\n        }\\n      }\\n    \";\n    }\n    return PadProgram;\n}());\nexports.PadProgram = PadProgram;\n//# sourceMappingURL=pad_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pad_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pad_packed_gpu.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pad_packed_gpu.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar packing_util_1 = __webpack_require__(/*! ../packing_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js\");\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar PadPackedProgram = /** @class */ (function () {\n    function PadPackedProgram(xShape, paddings, constantValue) {\n        this.variableNames = ['x'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = paddings.map(function (p, i) { return p[0] /* beforePad */ + xShape[i] + p[1]; } /* afterPad */);\n        var rank = xShape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(rank);\n        var start = paddings.map(function (p) { return p[0]; }).join(',');\n        var end = paddings.map(function (p, i) { return p[0] + xShape[i]; }).join(',');\n        var coords = packing_util_1.getChannels('rc', rank);\n        var source = packing_util_1.getChannels('source', rank);\n        var cLimit = coords[rank - 1] + \" < \" + this.outputShape[rank - 1];\n        var innerDims = rank === 1 ? 'source' : \"vec2(\" + source.slice(-2).join() + \")\";\n        var componentSetup = [\n            dtype + \" rc = outputLoc;\", coords[rank - 1] + \" += 1;\\n       if(\" + cLimit + \") {\\n      \",\n            rank === 1 ? '' : \"}\\n       rc = outputLoc;\\n       \" + coords[rank - 2] + \" += 1;\\n       if(\" + coords[rank - 2] + \" < \" + this.outputShape[rank - 2] + \") {\",\n            rank === 1 ? '' : \"  \" + coords[rank - 1] + \" += 1;\\n         if(\" + cLimit + \") {\"\n        ];\n        var paddingArea = rank === 1 ?\n            'rc < start || rc >= end' :\n            'any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))';\n        var mainLoop = '';\n        for (var i = 0, j = rank === 1 ? 2 : 4; i < j; i++) {\n            mainLoop += \"\\n        \" + componentSetup[i] + \"\\n        if (\" + paddingArea + \") {\\n          result[\" + i + \"] = float(\" + constantValue + \");\\n        } else {\\n          \" + dtype + \" source = rc - start;\\n          result[\" + i + \"] = getChannel(getX(\" + source.join() + \"), \" + innerDims + \");\\n        }\\n      \";\n        }\n        mainLoop += (rank === 1 ? \"} \" : \"}}\");\n        this.userCode = \"\\n      const \" + dtype + \" start = \" + dtype + \"(\" + start + \");\\n      const \" + dtype + \" end = \" + dtype + \"(\" + end + \");\\n\\n      void main() {\\n        \" + dtype + \" outputLoc = getOutputCoords();\\n        vec4 result = vec4(0.);\\n        \" + mainLoop + \"\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return PadPackedProgram;\n}());\nexports.PadPackedProgram = PadPackedProgram;\n//# sourceMappingURL=pad_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pad_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pool_gpu.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pool_gpu.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar Pool2DProgram = /** @class */ (function () {\n    function Pool2DProgram(convInfo, poolType, computePositions) {\n        this.variableNames = ['x'];\n        if (poolType === 'avg' && computePositions) {\n            throw new Error('Cannot compute positions for average pool.');\n        }\n        var filterWidth = convInfo.filterWidth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        this.outputShape = convInfo.outShape;\n        var isAvgPool = poolType === 'avg';\n        var initializationValue = '0.0';\n        if (!isAvgPool) {\n            // WebGL on Firefox Linux can't compile 1/0 so we do 1/eps.\n            initializationValue = '-1.0 / 1e-20';\n        }\n        if (computePositions) {\n            var compareOp_1 = '>=';\n            this.userCode = \"\\n        const ivec2 strides = ivec2(\" + strideHeight + \", \" + strideWidth + \");\\n        const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n\\n        void main() {\\n          ivec4 coords = getOutputCoords();\\n          int batch = coords[0];\\n          int d = coords[3];\\n\\n          ivec2 xRCCorner = coords.yz * strides - pads;\\n          int xRCorner = xRCCorner.x;\\n          int xCCorner = xRCCorner.y;\\n\\n          // max/min x(?, ?, d) to get y(yR, yC, d).\\n          // ? = to be determined\\n          float minMaxValue = 0.0;\\n          float minMaxValueFound = 0.0;\\n          int minMaxPosition = 0;\\n          float avgValue = 0.0;\\n\\n          for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n              wR += \" + dilationHeight + \") {\\n            int xR = xRCorner + wR;\\n\\n            if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \" + effectiveFilterWidth + \";\\n                wC += \" + dilationWidth + \") {\\n              int xC = xCCorner + wC;\\n\\n              if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                continue;\\n              }\\n\\n              float value = getX(batch, xR, xC, d);\\n\\n              // If a min / max value has already been found, use it. If not,\\n              // use the current value.\\n              float currMinMaxValue = mix(\\n                  value, minMaxValue, minMaxValueFound);\\n              if (value \" + compareOp_1 + \" currMinMaxValue) {\\n                minMaxValue = value;\\n                minMaxValueFound = 1.0;\\n                minMaxPosition = wR * \" + effectiveFilterWidth + \" + wC;\\n              }\\n            }\\n          }\\n          setOutput(float(minMaxPosition));\\n        }\\n      \";\n            return;\n        }\n        var compareOp = 'max';\n        var returnValue = poolType + \"(\" + poolType + \"(\" + poolType + \"(\" +\n            'minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])';\n        if (poolType === 'avg') {\n            returnValue = \"avgValue / count\";\n        }\n        var filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;\n        var filterWidthVec4Remainder = filterWidth % 4;\n        var updateSnippet = \"\\n      if (\" + isAvgPool + \") {\\n        avgValue += dot(values, ones);\\n      } else {\\n        minMaxValue = \" + compareOp + \"(values, minMaxValue);\\n      }\\n    \";\n        this.userCode = \"\\n      const ivec2 strides = ivec2(\" + strideHeight + \", \" + strideWidth + \");\\n      const ivec2 pads = ivec2(\" + padTop + \", \" + padLeft + \");\\n      const float initializationValue = \" + initializationValue + \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float count = 0.0;\\n\\n      float getValue(int batch, int xR, int xC, int d) {\\n        if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n          return initializationValue;\\n        }\\n        count += 1.0;\\n        return getX(batch, xR, xC, d);\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int d = coords[3];\\n\\n        ivec2 xRCCorner = coords.yz * strides - pads;\\n        int xRCorner = xRCCorner.x;\\n        int xCCorner = xRCCorner.y;\\n\\n        // max/min x(?, ?, d) to get y(yR, yC, d).\\n        // ? = to be determined\\n        vec4 minMaxValue = vec4(\" + initializationValue + \");\\n        float avgValue = 0.0;\\n        count = 0.0;\\n\\n        for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n            wR += \" + dilationHeight + \") {\\n          int xR = xRCorner + wR;\\n\\n          if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n            continue;\\n          }\\n\\n          for (int wC = 0; wC < \" + filterWidthNearestVec4 + \"; wC += 4) {\\n            int xC = xCCorner + wC * \" + dilationWidth + \";\\n\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \" + dilationWidth + \", d),\\n              getValue(batch, xR, xC + 2 * \" + dilationWidth + \", d),\\n              getValue(batch, xR, xC + 3 * \" + dilationWidth + \", d)\\n            );\\n\\n            \" + updateSnippet + \"\\n          }\\n\\n          int xC = xCCorner + \" + filterWidthNearestVec4 + \";\\n          if (\" + (filterWidthVec4Remainder === 1) + \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              initializationValue,\\n              initializationValue,\\n              initializationValue\\n            );\\n\\n            \" + updateSnippet + \"\\n          } else if (\" + (filterWidthVec4Remainder === 2) + \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \" + dilationWidth + \", d),\\n              initializationValue,\\n              initializationValue\\n            );\\n\\n            \" + updateSnippet + \"\\n          } else if (\" + (filterWidthVec4Remainder === 3) + \") {\\n            vec4 values = vec4(\\n              getValue(batch, xR, xC, d),\\n              getValue(batch, xR, xC + \" + dilationWidth + \", d),\\n              getValue(batch, xR, xC + 2 * \" + dilationWidth + \", d),\\n              initializationValue\\n            );\\n\\n            \" + updateSnippet + \"\\n          }\\n        }\\n        setOutput(\" + returnValue + \");\\n      }\\n    \";\n    }\n    return Pool2DProgram;\n}());\nexports.Pool2DProgram = Pool2DProgram;\nvar Pool3DProgram = /** @class */ (function () {\n    function Pool3DProgram(convInfo, poolType, computePositions) {\n        this.variableNames = ['x'];\n        if (poolType === 'avg' && computePositions) {\n            throw new Error('Cannot compute positions for average pool.');\n        }\n        var filterWidth = convInfo.filterWidth;\n        var strideDepth = convInfo.strideDepth;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dilationDepth = convInfo.dilationDepth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var effectiveFilterDepth = convInfo.effectiveFilterDepth;\n        var effectiveFilterHeight = convInfo.effectiveFilterHeight;\n        var effectiveFilterWidth = convInfo.effectiveFilterWidth;\n        var padFront = convInfo.padInfo.front;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        this.outputShape = convInfo.outShape;\n        var isAvgPool = poolType === 'avg';\n        var initializationValue = '0.0';\n        if (!isAvgPool) {\n            // WebGL on Firefox Linux can't compile 1/0 so we do 1/eps.\n            initializationValue = '-1.0 / 1e-20';\n        }\n        if (computePositions) {\n            var compareOp_2 = '>=';\n            this.userCode = \"\\n        const ivec3 strides =\\n            ivec3(\" + strideDepth + \", \" + strideHeight + \", \" + strideWidth + \");\\n        const ivec3 pads = ivec3(\" + padFront + \", \" + padTop + \", \" + padLeft + \");\\n\\n        void main() {\\n          ivec5 coords = getOutputCoords();\\n          int batch = coords.x;\\n          int ch = coords.u;\\n\\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n          int xDCorner = xCorner.x;\\n          int xRCorner = xCorner.y;\\n          int xCCorner = xCorner.z;\\n\\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\\n          // ? = to be determined\\n          float minMaxValue = 0.0;\\n          float minMaxValueFound = 0.0;\\n          int minMaxPosition = 0;\\n\\n          for (int wD = 0; wD < \" + effectiveFilterDepth + \";\\n              wD += \" + dilationDepth + \") {\\n            int xD = xDCorner + wD;\\n\\n            if (xD < 0 || xD >= \" + convInfo.inDepth + \") {\\n              continue;\\n            }\\n\\n            for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n                wR += \" + dilationHeight + \") {\\n              int xR = xRCorner + wR;\\n\\n              if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n                continue;\\n              }\\n\\n              for (int wC = 0; wC < \" + effectiveFilterWidth + \";\\n                  wC += \" + dilationWidth + \") {\\n                int xC = xCCorner + wC;\\n\\n                if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n                  continue;\\n                }\\n\\n                float value = getX(batch, xD, xR, xC, ch);\\n\\n                // If a min / max value has already been found, use it. If not,\\n                // use the current value.\\n                float currMinMaxValue = mix(\\n                    value, minMaxValue, minMaxValueFound);\\n                if (value \" + compareOp_2 + \" currMinMaxValue) {\\n                  minMaxValue = value;\\n                  minMaxValueFound = 1.0;\\n                  minMaxPosition =\\n                      wD * \" + effectiveFilterHeight + \" * \" + effectiveFilterWidth + \" +\\n                      wR * \" + effectiveFilterWidth + \" + wC;;\\n                }\\n              }\\n            }\\n          }\\n          setOutput(float(minMaxPosition));\\n        }\\n      \";\n            return;\n        }\n        var compareOp = 'max';\n        var returnValue = poolType + \"(\" + poolType + \"(\" + poolType + \"(\" +\n            'minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])';\n        if (poolType === 'avg') {\n            returnValue = \"avgValue / count\";\n        }\n        var filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;\n        var filterWidthVec4Remainder = filterWidth % 4;\n        var updateSnippet = \"\\n      if (\" + isAvgPool + \") {\\n        avgValue += dot(values, ones);\\n      } else {\\n        minMaxValue = \" + compareOp + \"(values, minMaxValue);\\n      }\\n    \";\n        this.userCode = \"\\n      const ivec3 strides =\\n        ivec3(\" + strideDepth + \", \" + strideHeight + \", \" + strideWidth + \");\\n      const ivec3 pads = ivec3(\" + padFront + \", \" + padTop + \", \" + padLeft + \");\\n      const float initializationValue = \" + initializationValue + \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float count = 0.0;\\n\\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\\n        if (xC < 0 || xC >= \" + convInfo.inWidth + \") {\\n          return initializationValue;\\n        }\\n        count += 1.0;\\n        return getX(batch, xD, xR, xC, ch);\\n      }\\n\\n      void main() {\\n        ivec5 coords = getOutputCoords();\\n        int batch = coords.x;\\n        int ch = coords.u;\\n\\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\\n        int xDCorner = xCorner.x;\\n        int xRCorner = xCorner.y;\\n        int xCCorner = xCorner.z;\\n\\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\\n        // ? = to be determined\\n        vec4 minMaxValue = vec4(\" + initializationValue + \");\\n        float avgValue = 0.0;\\n        count = 0.0;\\n\\n        for (int wD = 0; wD < \" + effectiveFilterDepth + \";\\n            wD += \" + dilationDepth + \") {\\n          int xD = xDCorner + wD;\\n\\n          if (xD < 0 || xD >= \" + convInfo.inDepth + \") {\\n            continue;\\n          }\\n\\n          for (int wR = 0; wR < \" + effectiveFilterHeight + \";\\n            wR += \" + dilationHeight + \") {\\n            int xR = xRCorner + wR;\\n\\n            if (xR < 0 || xR >= \" + convInfo.inHeight + \") {\\n              continue;\\n            }\\n\\n            for (int wC = 0; wC < \" + filterWidthNearestVec4 + \"; wC += 4) {\\n              int xC = xCCorner + wC * \" + dilationWidth + \";\\n\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \" + dilationWidth + \", ch),\\n                getValue(batch, xD, xR, xC + 2 * \" + dilationWidth + \", ch),\\n                getValue(batch, xD, xR, xC + 3 * \" + dilationWidth + \", ch)\\n              );\\n\\n              \" + updateSnippet + \"\\n            }\\n\\n            int xC = xCCorner + \" + filterWidthNearestVec4 + \";\\n            if (\" + (filterWidthVec4Remainder === 1) + \") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                initializationValue,\\n                initializationValue,\\n                initializationValue\\n              );\\n\\n              \" + updateSnippet + \"\\n            } else if (\" + (filterWidthVec4Remainder === 2) + \") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \" + dilationWidth + \", ch),\\n                initializationValue,\\n                initializationValue\\n              );\\n\\n              \" + updateSnippet + \"\\n            } else if (\" + (filterWidthVec4Remainder === 3) + \") {\\n              vec4 values = vec4(\\n                getValue(batch, xD, xR, xC, ch),\\n                getValue(batch, xD, xR, xC + \" + dilationWidth + \", ch),\\n                getValue(batch, xD, xR, xC + 2 * \" + dilationWidth + \", ch),\\n                initializationValue\\n              );\\n\\n              \" + updateSnippet + \"\\n            }\\n          }\\n          setOutput(\" + returnValue + \");\\n        }\\n      }\\n    \";\n    }\n    return Pool3DProgram;\n}());\nexports.Pool3DProgram = Pool3DProgram;\n//# sourceMappingURL=pool_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/pool_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reduce_gpu.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reduce_gpu.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ReduceProgram = /** @class */ (function () {\n    function ReduceProgram(reduceInfo, reduceType) {\n        this.variableNames = ['x'];\n        var windowSize = reduceInfo.windowSize;\n        var batchSize = reduceInfo.batchSize;\n        var inSize = reduceInfo.inSize;\n        var outSize = Math.ceil(inSize / windowSize);\n        this.outputShape = [batchSize, outSize];\n        var initializationValue = '0.0';\n        var compareOp = \"\";\n        if (reduceType === 'prod') {\n            initializationValue = '1.0';\n        }\n        else if (reduceType === 'min') {\n            // WebGL on Firefox Linux can't compile 1/0 so we do 1/eps.\n            initializationValue = '1.0 / 1e-20';\n            compareOp = \"min\";\n        }\n        else if (reduceType === 'max') {\n            // WebGL on Firefox Linux can't compile 1/0 so we do 1/eps.\n            initializationValue = '-1.0 / 1e-20';\n            compareOp = \"max\";\n        }\n        var returnValue = reduceType + \"(\" + reduceType + \"(\" + reduceType + \"(\" +\n            'minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])';\n        if (reduceType === 'sum') {\n            returnValue = \"sumValue\";\n        }\n        else if (reduceType === 'prod') {\n            returnValue = \"prodValue\";\n        }\n        else if (reduceType === 'all') {\n            returnValue = \"allValue\";\n        }\n        else if (reduceType === 'any') {\n            returnValue = \"anyValue\";\n        }\n        var windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;\n        var windowSizeVec4Remainder = windowSize % 4;\n        var updateSnippet = \"\\n      if (\" + (reduceType === 'sum') + \") {\\n        sumValue += dot(values, ones);\\n      } else if (\" + (reduceType === 'prod') + \") {\\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\\n        prodValue *= tmp[0] * tmp[1];\\n      } else {\\n        minMaxValue = \" + compareOp + \"(values, minMaxValue);\\n      }\\n    \";\n        var vecType = \"vec4\";\n        if (reduceType === 'all') {\n            initializationValue = '1.0';\n            updateSnippet = \"\\n        bool reducedAllValue = all(values);\\n        float floatedReducedAllValue = float(reducedAllValue);\\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\\n      \";\n            vecType = \"bvec4\";\n        }\n        else if (reduceType === 'any') {\n            initializationValue = '0.0';\n            updateSnippet = \"\\n        bool reducedAnyValue = any(values);\\n        float floatedReducedAnyValue = float(reducedAnyValue);\\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\\n      \";\n            vecType = \"bvec4\";\n        }\n        var checkOutOfBounds = '';\n        if (inSize % windowSize > 0) {\n            checkOutOfBounds = \"\\n        if (inIdx < 0 || inIdx >= \" + inSize + \") {\\n          return initializationValue;\\n        }\\n      \";\n        }\n        this.userCode = \"\\n      const float initializationValue = \" + initializationValue + \";\\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\\n\\n      float getValue(int batch, int inIdx) {\\n        \" + checkOutOfBounds + \"\\n        return getX(batch, inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = outIdx * \" + windowSize + \";\\n\\n        vec4 minMaxValue = vec4(\" + initializationValue + \");\\n        float prodValue = 1.0;\\n        float sumValue = 0.0;\\n        float allValue = 1.0;\\n        float anyValue = 0.0;\\n\\n        for (int i = 0; i < \" + windowSizeNearestVec4 + \"; i += 4) {\\n          int inIdx = inOffset + i;\\n          \" + vecType + \" values = \" + vecType + \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          \" + updateSnippet + \"\\n        }\\n\\n        int inIdx = inOffset + \" + windowSizeNearestVec4 + \";\\n        if (\" + (windowSizeVec4Remainder === 1) + \") {\\n          \" + vecType + \" values = \" + vecType + \"(\\n            getValue(batch, inIdx),\\n            initializationValue,\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          \" + updateSnippet + \"\\n        } else if (\" + (windowSizeVec4Remainder === 2) + \") {\\n          \" + vecType + \" values = \" + vecType + \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          \" + updateSnippet + \"\\n        } else if (\" + (windowSizeVec4Remainder === 3) + \") {\\n          \" + vecType + \" values = \" + vecType + \"(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            initializationValue\\n          );\\n\\n          \" + updateSnippet + \"\\n        }\\n        setOutput(\" + returnValue + \");\\n      }\\n    \";\n    }\n    return ReduceProgram;\n}());\nexports.ReduceProgram = ReduceProgram;\n//# sourceMappingURL=reduce_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reduce_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/register_all_kernels.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/register_all_kernels.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar kernel_registry_1 = __webpack_require__(/*! ../../kernel_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js\");\nvar FromPixels_1 = __webpack_require__(/*! ./kernels/FromPixels */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/FromPixels.js\");\nvar NonMaxSuppressionV5_1 = __webpack_require__(/*! ./kernels/NonMaxSuppressionV5 */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/NonMaxSuppressionV5.js\");\nvar Square_1 = __webpack_require__(/*! ./kernels/Square */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/Square.js\");\nvar SquaredDifference_1 = __webpack_require__(/*! ./kernels/SquaredDifference */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/kernels/SquaredDifference.js\");\n// List all kernel configs here\nvar kernelConfigs = [\n    FromPixels_1.fromPixelsConfig,\n    NonMaxSuppressionV5_1.nonMaxSuppressionV5Config,\n    Square_1.squareConfig,\n    SquaredDifference_1.squaredDifferenceConfig,\n];\nfor (var _i = 0, kernelConfigs_1 = kernelConfigs; _i < kernelConfigs_1.length; _i++) {\n    var kernelConfig = kernelConfigs_1[_i];\n    kernel_registry_1.registerKernel(kernelConfig);\n}\n//# sourceMappingURL=register_all_kernels.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/register_all_kernels.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reshape_packed_gpu.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reshape_packed_gpu.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_util = __webpack_require__(/*! ./shader_compiler_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js\");\nvar ReshapePackedProgram = /** @class */ (function () {\n    function ReshapePackedProgram(outputShape, inputShape) {\n        this.variableNames = ['A'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = outputShape;\n        var mainLoop = \"\";\n        for (var i = 0; i < 4; i++) {\n            var thisRC = \"thisRC = rc;\";\n            if (i % 2 === 1) {\n                thisRC += \"thisRC.z += 1;\";\n            }\n            if (i > 1) {\n                thisRC += \"thisRC.y += 1;\";\n            }\n            mainLoop += \"\\n        \" + thisRC + \"\\n        \" + (i > 0 ? \"if(thisRC.y < rows && thisRC.z < cols){\" : '') + \"\\n          int flatIndex = getFlatIndex(thisRC);\\n\\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\\n\\n          result[\" + i + \"] =\\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\\n        \" + (i > 0 ? '}' : '') + \"\\n      \";\n        }\n        this.userCode = \"\\n      \" + getReshapedInputCoords(inputShape) + \"\\n      \" + shader_util.getFlatIndexFrom3D(outputShape) + \"\\n\\n      void main() {\\n        ivec3 rc = getOutputCoords();\\n\\n        vec4 result = vec4(0.);\\n\\n        ivec3 thisRC;\\n        int rows = \" + outputShape[1] + \";\\n        int cols = \" + outputShape[2] + \";\\n\\n        \" + mainLoop + \"\\n\\n        setOutput(result);\\n      }\\n    \";\n    }\n    return ReshapePackedProgram;\n}());\nexports.ReshapePackedProgram = ReshapePackedProgram;\nfunction getReshapedInputCoords(shape) {\n    var coordsFromIndexSnippet = shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd'], shape);\n    return \"\\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\\n      \" + coordsFromIndexSnippet + \"\\n      return ivec3(r, c, d);\\n    }\\n  \";\n}\n//# sourceMappingURL=reshape_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reshape_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_backprop_gpu.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_backprop_gpu.js ***!
  \************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ResizeBilinearBackpropProgram = /** @class */ (function () {\n    function ResizeBilinearBackpropProgram(dy, x, alignCorners) {\n        this.variableNames = ['dy'];\n        this.outputShape = [];\n        this.outputShape = x.shape;\n        var _a = x.shape, xHeight = _a[1], xWidth = _a[2];\n        var _b = dy.shape, yHeight = _b[1], yWidth = _b[2];\n        // In the backwards pass, we want to find the pixels that were generated for\n        // each pixel in the input image the forward pass and add the corresponding\n        // coefficient from dy to the gradient (with some interpolation).\n        var effectiveXSize = [\n            (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n            (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n        ];\n        var effectiveYSize = [\n            (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n            (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n        ];\n        var heightScale = effectiveXSize[0] / effectiveYSize[0];\n        var widthScale = effectiveXSize[1] / effectiveYSize[1];\n        var invHeightScale = 1 / heightScale;\n        var invWidthScale = 1 / widthScale;\n        // This defines the size of the window of values around a particular\n        // index in dy that we want to search for contributions to dx.\n        var winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n        var winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float accumulator = 0.0;\\n\\n        const float heightScale = float(\" + heightScale + \");\\n        const float widthScale = float(\" + widthScale + \");\\n\\n        const float invHeightScale = float(\" + invHeightScale + \");\\n        const float invWidthScale = float(\" + invWidthScale + \");\\n\\n        const int winHeight = int(\" + winHeight + \");\\n        const int winWidth = int(\" + winWidth + \");\\n\\n        // Compute bounds for where in dy we will look\\n        float startRLerp = floor(float(r) * invHeightScale);\\n        int startDyR = int(startRLerp - float(winHeight / 2));\\n\\n        float startCLerp = floor(float(c) * invWidthScale);\\n        int startDyC = int(startCLerp - float(winWidth / 2));\\n\\n        // Loop over dy\\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\\n          int dyR = dyROffset + startDyR;\\n\\n          // Guard against the window exceeding the bounds of dy\\n          if (dyR < 0 || dyR >= \" + yHeight + \") {\\n            continue;\\n          }\\n\\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\\n            int dyC = dyCOffset + startDyC;\\n\\n            // Guard against the window exceeding the bounds of dy\\n            if (dyC < 0 || dyC >= \" + yWidth + \") {\\n              continue;\\n            }\\n\\n            float dxR = float(dyR) * heightScale;\\n            int topDxRIndex = int(floor(dxR));\\n            int bottomDxRIndex = int(min(ceil(dxR), \" + (xHeight - 1) + \".0));\\n            float dxRLerp = dxR - float(topDxRIndex);\\n            float inverseDxRLerp = 1.0 - dxRLerp;\\n\\n            float dxC = float(dyC) * widthScale;\\n            int leftDxCIndex = int(floor(dxC));\\n            int rightDxCIndex = int(min(ceil(dxC), \" + (xWidth - 1) + \".0));\\n            float dxCLerp = dxC - float(leftDxCIndex);\\n            float inverseDxCLerp = 1.0 - dxCLerp;\\n\\n            if (r == topDxRIndex && c == leftDxCIndex) {\\n              // topLeft\\n              accumulator +=\\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\\n            }\\n\\n            if (r == topDxRIndex && c == rightDxCIndex) {\\n              // topRight\\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\\n            }\\n\\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\\n              // bottomLeft\\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\\n            }\\n\\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\\n              // bottomRight\\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\\n            }\\n          }\\n        }\\n        // End loop over dy\\n\\n        setOutput(accumulator);\\n      }\\n    \";\n    }\n    return ResizeBilinearBackpropProgram;\n}());\nexports.ResizeBilinearBackpropProgram = ResizeBilinearBackpropProgram;\n//# sourceMappingURL=resize_bilinear_backprop_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_backprop_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_gpu.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_gpu.js ***!
  \***************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ResizeBilinearProgram = /** @class */ (function () {\n    function ResizeBilinearProgram(inputShape, newHeight, newWidth, alignCorners) {\n        this.variableNames = ['A'];\n        this.outputShape = [];\n        var batch = inputShape[0], oldHeight = inputShape[1], oldWidth = inputShape[2], depth = inputShape[3];\n        this.outputShape = [batch, newHeight, newWidth, depth];\n        var effectiveInSize = [\n            (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n            (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n        ];\n        var effectiveOutSize = [\n            (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n            (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n        ];\n        this.userCode = \"\\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\\n          \" + effectiveInSize[0] / effectiveOutSize[0] + \",\\n          \" + effectiveInSize[1] / effectiveOutSize[1] + \");\\n      const vec2 inputShapeRC = vec2(\" + oldHeight + \".0, \" + oldWidth + \".0);\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        ivec2 yRC = coords.yz;\\n\\n        // Fractional source index.\\n        vec2 sourceFracIndexRC = vec2(yRC) * effectiveInputOverOutputRatioRC;\\n\\n        // Compute the four integer indices.\\n        ivec2 sourceFloorRC = ivec2(sourceFracIndexRC);\\n        ivec2 sourceCeilRC = ivec2(\\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\\n\\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\\n\\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\\n\\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\\n        float newValue = top + (bottom - top) * fracRC.x;\\n\\n        setOutput(newValue);\\n      }\\n    \";\n    }\n    return ResizeBilinearProgram;\n}());\nexports.ResizeBilinearProgram = ResizeBilinearProgram;\n//# sourceMappingURL=resize_bilinear_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_packed_gpu.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_packed_gpu.js ***!
  \**********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ResizeBilinearPackedProgram = /** @class */ (function () {\n    function ResizeBilinearPackedProgram(inputShape, newHeight, newWidth, alignCorners) {\n        this.variableNames = ['A'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = [];\n        var batch = inputShape[0], oldHeight = inputShape[1], oldWidth = inputShape[2], depth = inputShape[3];\n        this.outputShape = [batch, newHeight, newWidth, depth];\n        var effectiveInSize = [\n            (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n            (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n        ];\n        var effectiveOutSize = [\n            (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n            (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n        ];\n        this.userCode = \"\\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\\n          \" + effectiveInSize[0] / effectiveOutSize[0] + \",\\n          \" + effectiveInSize[1] / effectiveOutSize[1] + \",\\n          \" + effectiveInSize[1] / effectiveOutSize[1] + \");\\n      const vec3 inputShapeRC = vec3(\" + oldHeight + \".0, \" + oldWidth + \".0,\\n                                     \" + oldWidth + \".0);\\n\\n      float getAValue(int b, int r, int c, int d) {\\n        return getChannel(getA(b, r, c, d), vec2(c, d));\\n      }\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        // Calculate values for next column in yRC.z.\\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\\n\\n        // Fractional source index.\\n        vec3 sourceFracIndexRC = vec3(yRC) * effectiveInputOverOutputRatioRC;\\n\\n        // Compute the four integer indices.\\n        ivec3 sourceFloorRC = ivec3(sourceFracIndexRC);\\n        ivec3 sourceCeilRC = ivec3(\\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\\n\\n        // Should we calculate next column and row elements in 2x2 packed cell.\\n        bool hasNextCol = d < \" + (depth - 1) + \";\\n        bool hasNextRow = coords.z < \" + (newWidth - 1) + \";\\n\\n        // In parallel, construct four corners for all four components in\\n        // packed 2x2 cell.\\n        vec4 topLeft = vec4(\\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\\n\\n        vec4 bottomLeft = vec4(\\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\\n\\n        vec4 topRight = vec4(\\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\\n\\n        vec4 bottomRight = vec4(\\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\\n                     : 0.0,\\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\\n                     : 0.0,\\n          (hasNextRow && hasNextCol) ?\\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\\n\\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\\n\\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\\n        vec4 newValue = mix(top, bottom, fracRC.x);\\n\\n        setOutput(newValue);\\n      }\\n    \";\n    }\n    return ResizeBilinearPackedProgram;\n}());\nexports.ResizeBilinearPackedProgram = ResizeBilinearPackedProgram;\n//# sourceMappingURL=resize_bilinear_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_bilinear_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_nearest_neighbor_backprop_gpu.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_nearest_neighbor_backprop_gpu.js ***!
  \********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ResizeNearestNeigborBackpropProgram = /** @class */ (function () {\n    function ResizeNearestNeigborBackpropProgram(dy, x, alignCorners) {\n        this.variableNames = ['dy'];\n        this.outputShape = [];\n        this.outputShape = x.shape;\n        var _a = x.shape, xHeight = _a[1], xWidth = _a[2];\n        var _b = dy.shape, yHeight = _b[1], yWidth = _b[2];\n        // In the backwards pass, we want to find the pixels that were generated for\n        // each pixel in the input image the forward pass and add the corresponding\n        // coefficient from dy to the gradient (with some interpolation).\n        var effectiveXSize = [\n            (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n            (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n        ];\n        var effectiveYSize = [\n            (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n            (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n        ];\n        var heightScale = effectiveXSize[0] / effectiveYSize[0];\n        var widthScale = effectiveXSize[1] / effectiveYSize[1];\n        var invHeightScale = 1 / heightScale;\n        var invWidthScale = 1 / widthScale;\n        // This defines the size of the window of values around a particular\n        // index in dy that we want to search for contributions to dx.\n        var winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n        var winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n        this.userCode = \"\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        int r = coords[1];\\n        int c = coords[2];\\n\\n        float accumulator = 0.0;\\n\\n        const float heightScale = float(\" + heightScale + \");\\n        const float widthScale = float(\" + widthScale + \");\\n\\n        const float invHeightScale = float(\" + invHeightScale + \");\\n        const float invWidthScale = float(\" + invWidthScale + \");\\n\\n        const int winHeight = int(\" + winHeight + \");\\n        const int winWidth = int(\" + winWidth + \");\\n\\n        // Compute bounds for where in dy we will look\\n        float startRLerp = floor(float(r) * invHeightScale);\\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\\n\\n        float startCLerp = floor(float(c) * invWidthScale);\\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\\n\\n        // Loop over dy\\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\\n          int dyR = dyROffset + startDyR;\\n\\n          // Guard against the window exceeding the bounds of dy\\n          if (dyR < 0 || dyR >= \" + yHeight + \") {\\n            continue;\\n          }\\n\\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\\n            int dyC = dyCOffset + startDyC;\\n\\n            // Guard against the window exceeding the bounds of dy\\n            if (dyC < 0 || dyC >= \" + yWidth + \") {\\n              continue;\\n            }\\n\\n            float sourceFracRow =\\n              float(\" + effectiveXSize[0] + \") *\\n                (float(dyR) / float(\" + effectiveYSize[0] + \"));\\n\\n            float sourceFracCol =\\n                float(\" + effectiveXSize[1] + \") *\\n                  (float(dyC) / float(\" + effectiveYSize[1] + \"));\\n\\n            int sourceNearestRow = int(min(\\n                float(int(\" + xHeight + \") - 1),\\n                \" + alignCorners + \" ? float(round(sourceFracRow)) :\\n                                  float(floor(sourceFracRow))));\\n\\n            int sourceNearestCol = int(min(\\n                float(int(\" + xWidth + \") - 1),\\n                \" + alignCorners + \" ? float(round(sourceFracCol)) :\\n                                  float(floor(sourceFracCol))));\\n\\n            if (r == sourceNearestRow && c == sourceNearestCol) {\\n              accumulator += getDy(b, dyR, dyC, d);\\n            }\\n          }\\n        }\\n        // End loop over dy\\n\\n        setOutput(accumulator);\\n      }\\n    \";\n    }\n    return ResizeNearestNeigborBackpropProgram;\n}());\nexports.ResizeNearestNeigborBackpropProgram = ResizeNearestNeigborBackpropProgram;\n//# sourceMappingURL=resize_nearest_neighbor_backprop_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_nearest_neighbor_backprop_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_nearest_neighbor_gpu.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_nearest_neighbor_gpu.js ***!
  \***********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar ResizeNearestNeighborProgram = /** @class */ (function () {\n    function ResizeNearestNeighborProgram(inputShape, newHeight, newWidth, alignCorners) {\n        this.variableNames = ['A'];\n        this.outputShape = [];\n        var batch = inputShape[0], oldHeight = inputShape[1], oldWidth = inputShape[2], depth = inputShape[3];\n        this.outputShape = [batch, newHeight, newWidth, depth];\n        var effectiveInSize = [\n            (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n            (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n        ];\n        var effectiveOutSize = [\n            (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n            (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n        ];\n        // When align corners is false, we rounds the value with floor.\n        var roundBase = alignCorners ? '0.5' : '0.0';\n        this.userCode = \"\\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\\n          \" + effectiveInSize[0] / effectiveOutSize[0] + \",\\n          \" + effectiveInSize[1] / effectiveOutSize[1] + \");\\n      const vec2 inputShapeRC = vec2(\" + oldHeight + \".0, \" + oldWidth + \".0);\\n\\n      void main() {\\n        ivec4 coords = getOutputCoords();\\n        int b = coords[0];\\n        int d = coords[3];\\n        ivec2 yRC = coords.yz;\\n\\n        // Fractional source index.\\n        vec2 sourceFracIndexRC = vec2(yRC) * effectiveInputOverOutputRatioRC;\\n\\n        // Compute the coordinators of nearest neighbor point.\\n        ivec2 sourceNearestRC = ivec2(\\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + \" + roundBase + \")));\\n\\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\\n\\n        setOutput(newValue);\\n      }\\n    \";\n    }\n    return ResizeNearestNeighborProgram;\n}());\nexports.ResizeNearestNeighborProgram = ResizeNearestNeighborProgram;\n//# sourceMappingURL=resize_nearest_neighbor_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/resize_nearest_neighbor_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reverse_gpu.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reverse_gpu.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar ReverseProgram = /** @class */ (function () {\n    function ReverseProgram(xShape, axis) {\n        this.variableNames = ['x'];\n        var rank = xShape.length;\n        if (rank > 4) {\n            throw new Error(\"WebGL backend: Reverse of rank-\" + rank + \" tensor is not yet supported\");\n        }\n        this.outputShape = xShape;\n        if (rank === 1) {\n            this.userCode = \"\\n        void main() {\\n          int coord = getOutputCoords();\\n          setOutput(getX(\" + xShape[0] + \" - coord - 1));\\n        }\\n      \";\n            return;\n        }\n        var getInCoord = function (i) {\n            if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {\n                return xShape[i] + \" - coords[\" + i + \"] - 1\";\n            }\n            return \"coords[\" + i + \"]\";\n        };\n        var inCoords = xShape.map(function (_, i) { return getInCoord(i); }).join(',');\n        var type = shader_compiler_1.getCoordsDataType(rank);\n        this.userCode = \"\\n      void main() {\\n        \" + type + \" coords = getOutputCoords();\\n        setOutput(getX(\" + inCoords + \"));\\n      }\\n    \";\n    }\n    return ReverseProgram;\n}());\nexports.ReverseProgram = ReverseProgram;\n//# sourceMappingURL=reverse_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reverse_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reverse_packed_gpu.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reverse_packed_gpu.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar packing_util_1 = __webpack_require__(/*! ../packing_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js\");\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar ReversePackedProgram = /** @class */ (function () {\n    function ReversePackedProgram(xShape, axis) {\n        this.variableNames = ['x'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        var rank = xShape.length;\n        if (rank > 4) {\n            throw new Error(\"WebGL backend: Reverse of rank-\" + rank + \" tensor is not yet supported\");\n        }\n        this.outputShape = xShape;\n        var channels = packing_util_1.getChannels('rc', rank);\n        var nextColumn = channels[rank - 1] + \" + 1 < \" + this.outputShape[rank - 1];\n        var nextRow = channels[rank - 2] + \" + 1 < \" + this.outputShape[rank - 2];\n        var type = shader_compiler_1.getCoordsDataType(rank);\n        if (rank === 1) {\n            this.userCode = \"\\n        void main(){\\n          int rc = getOutputCoords();\\n          vec4 result = vec4(0.);\\n          result.r = getChannel(getX(\" + xShape[0] + \" - rc - 1),\\n            \" + xShape[0] + \" - rc - 1);\\n          if(\" + nextColumn + \"){\\n              result.g = getChannel(getX(\" + xShape[0] + \" - (rc  + 1) - 1),\\n                \" + xShape[0] + \" - (rc  + 1) - 1);\\n          }\\n          setOutput(result);\\n        }\\n      \";\n        }\n        else {\n            this.userCode = \"\\n        void main() {\\n          \" + type + \" rc = getOutputCoords();\\n          vec4 result = vec4(0.);\\n          result.r = \" + getR(channels.slice()) + \";\\n          if(\" + nextColumn + \"){\\n            result.g = \" + getG(channels.slice()) + \";\\n          }\\n          if(\" + nextRow + \") {\\n            result.b = \" + getB(channels.slice()) + \";\\n            if(\" + nextColumn + \") {\\n              result.a = \" + getA(channels.slice()) + \";\\n            }\\n          }\\n          setOutput(result);\\n        }\\n    \";\n        }\n        function getR(channels) {\n            return getChannel(channels);\n        }\n        function getG(channels) {\n            channels[rank - 1] = '(' + channels[rank - 1] + \" + 1)\";\n            return getChannel(channels);\n        }\n        function getB(channels) {\n            channels[rank - 2] = '(' + channels[rank - 2] + \" + 1)\";\n            return getChannel(channels);\n        }\n        function getA(channels) {\n            channels[rank - 1] = '(' + channels[rank - 1] + \" + 1)\";\n            channels[rank - 2] = '(' + channels[rank - 2] + \" + 1)\";\n            return getChannel(channels);\n        }\n        function getChannel(channels) {\n            var inCoordsArray = xShape.map(function (_, i) { return getInCoord(i, channels); });\n            var inCoords = inCoordsArray.join(',');\n            var innerDims = inCoordsArray.slice(-2).join(',');\n            return \"getChannel(getX(\" + inCoords + \"), vec2(\" + innerDims + \"))\";\n        }\n        function getInCoord(i, channels1) {\n            if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {\n                return xShape[i] + \" - \" + channels1[i] + \" - 1\";\n            }\n            else {\n                return \"\" + channels1[i];\n            }\n        }\n    }\n    return ReversePackedProgram;\n}());\nexports.ReversePackedProgram = ReversePackedProgram;\n//# sourceMappingURL=reverse_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/reverse_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/scatter_gpu.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/scatter_gpu.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar ScatterProgram = /** @class */ (function () {\n    function ScatterProgram(updateSize, sliceDim, indicesRank, updatesRank, strides, shape, summingDupeIndex) {\n        if (summingDupeIndex === void 0) { summingDupeIndex = true; }\n        this.variableNames = ['updates', 'indices', 'defaultValue'];\n        this.outputShape = shape;\n        var stridesType = shader_compiler_1.getCoordsDataType(strides.length);\n        var dtype = shader_compiler_1.getCoordsDataType(shape.length);\n        var indicesString = '';\n        if (indicesRank === 1) {\n            indicesString = 'i';\n        }\n        else if (indicesRank === 2) {\n            indicesString = 'i, j';\n        }\n        var indicesSnippet = \"getIndices(\" + indicesString + \")\";\n        var updatesString = '';\n        if (updatesRank === 1) {\n            updatesString = 'i';\n        }\n        else if (updatesRank === 2) {\n            updatesString = 'i, coords[1]';\n        }\n        var updatesSnippet = \"getUpdates(\" + updatesString + \")\";\n        var strideString = sliceDim > 1 ? 'strides[j]' : 'strides';\n        this.userCode = \"\\n        \" + stridesType + \" strides = \" + stridesType + \"(\" + strides + \");\\n\\n        void main() {\\n          \" + dtype + \" coords = getOutputCoords();\\n          float sum = 0.0;\\n          bool found = false;\\n          for (int i = 0; i < \" + updateSize + \"; i++) {\\n            int flattenedIndex = 0;\\n            for (int j = 0; j < \" + sliceDim + \"; j++) {\\n              int index = round(\" + indicesSnippet + \");\\n              flattenedIndex += index * \" + strideString + \";\\n            }\\n            if (flattenedIndex == coords[0]) {\\n              sum += \" + updatesSnippet + \";\\n              found = true;\\n            }\\n          }\\n          setOutput(mix(getDefaultValue(), sum, float(found)));\\n        }\\n      \";\n    }\n    return ScatterProgram;\n}());\nexports.ScatterProgram = ScatterProgram;\n//# sourceMappingURL=scatter_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/scatter_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/segment_gpu.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/segment_gpu.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar SegmentOpProgram = /** @class */ (function () {\n    function SegmentOpProgram(segOpInfo, segOpType) {\n        this.variableNames = ['x', 'segmentIds'];\n        var windowSize = segOpInfo.windowSize;\n        var batchSize = segOpInfo.batchSize;\n        var inSize = segOpInfo.inSize;\n        var numSegments = segOpInfo.numSegments;\n        var outSize = numSegments * Math.ceil(inSize / windowSize);\n        this.outputShape = [batchSize, outSize];\n        var initializationValue = '0.0';\n        var returnValue = \"sumValue\";\n        var windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;\n        var windowSizeVec4Remainder = windowSize % 4;\n        var updateSnippet = \"\\n        sumValue += dot(values, segFilter);\\n    \";\n        var checkValueOutOfBounds = '';\n        if (inSize % windowSize > 0) {\n            checkValueOutOfBounds = \"\\n        if (inIdx < 0 || inIdx >= \" + inSize + \") {\\n          return initializationValue;\\n        }\\n      \";\n        }\n        var checkSegmentIdOutOfBounds = '';\n        if (inSize % windowSize > 0) {\n            checkSegmentIdOutOfBounds = \"\\n        if (inIdx < 0 || inIdx >= \" + inSize + \") {\\n          return -1.0;\\n        }\\n      \";\n        }\n        this.userCode = \"\\n      const float initializationValue = \" + initializationValue + \";\\n\\n      float getValue(int batch, int inIdx) {\\n        \" + checkValueOutOfBounds + \"\\n        return getX(batch, inIdx);\\n      }\\n\\n      float getSegmentIdAtIndex(int inIdx) {\\n        \" + checkSegmentIdOutOfBounds + \"\\n        return getSegmentIds(inIdx);\\n      }\\n\\n      void main() {\\n        ivec2 coords = getOutputCoords();\\n        int batch = coords[0];\\n        int outIdx = coords[1];\\n        int inOffset = int(floor(float(outIdx) / float(\\n          \" + numSegments + \")) * float(\" + windowSize + \"));\\n        int currentSeg = int(mod(float(outIdx), float(\" + numSegments + \")));\\n\\n        float sumValue = 0.0;\\n\\n        for (int i = 0; i < \" + windowSizeNearestVec4 + \"; i += 4) {\\n          int inIdx = inOffset + i;\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            getValue(batch, inIdx + 3)\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\\n          );\\n\\n          \" + updateSnippet + \"\\n        }\\n\\n        int inIdx = inOffset + \" + windowSizeNearestVec4 + \";\\n        if (\" + (windowSizeVec4Remainder === 1) + \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            initializationValue,\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            0,\\n            0,\\n            0\\n          );\\n\\n          \" + updateSnippet + \"\\n        } else if (\" + (windowSizeVec4Remainder === 2) + \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            initializationValue,\\n            initializationValue\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n              0,\\n              0\\n          );\\n\\n          \" + updateSnippet + \"\\n        } else if (\" + (windowSizeVec4Remainder === 3) + \") {\\n          vec4 values = vec4(\\n            getValue(batch, inIdx),\\n            getValue(batch, inIdx + 1),\\n            getValue(batch, inIdx + 2),\\n            initializationValue\\n          );\\n\\n          vec4 segFilter = vec4(\\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\\n            0\\n          );\\n\\n          \" + updateSnippet + \"\\n        }\\n        setOutput(\" + returnValue + \");\\n      }\\n    \";\n    }\n    return SegmentOpProgram;\n}());\nexports.SegmentOpProgram = SegmentOpProgram;\n//# sourceMappingURL=segment_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/segment_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/select_gpu.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/select_gpu.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar SelectProgram = /** @class */ (function () {\n    function SelectProgram(cRank, shape, rank) {\n        this.variableNames = ['c', 'a', 'b'];\n        this.outputShape = shape;\n        var cCoords;\n        var abCoords;\n        if (rank > 4) {\n            throw Error(\"Where for rank \" + rank + \" is not yet supported\");\n        }\n        if (rank === 1) {\n            abCoords = \"resRC\";\n            cCoords = \"resRC\";\n        }\n        else {\n            var currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w'];\n            var cCoordVars = [];\n            var abCoordVars = [];\n            for (var i = 0; i < shape.length; i++) {\n                abCoordVars.push(\"\" + currentCoords[i]);\n                if (i < cRank) {\n                    cCoordVars.push(\"\" + currentCoords[i]);\n                }\n            }\n            cCoords = cCoordVars.join();\n            abCoords = abCoordVars.join();\n        }\n        var dtype = shader_compiler_1.getCoordsDataType(rank);\n        this.userCode = \"\\n      void main() {\\n        \" + dtype + \" resRC = getOutputCoords();\\n        float cVal = getC(\" + cCoords + \");\\n        if (cVal >= 1.0) {\\n          setOutput(getA(\" + abCoords + \"));\\n        } else {\\n          setOutput(getB(\" + abCoords + \"));\\n        }\\n      }\\n    \";\n    }\n    return SelectProgram;\n}());\nexports.SelectProgram = SelectProgram;\n//# sourceMappingURL=select_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/select_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js ***!
  \***********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar broadcast_util_1 = __webpack_require__(/*! ../../ops/broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar util = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar glsl_version_1 = __webpack_require__(/*! ./glsl_version */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/glsl_version.js\");\nvar shader_util = __webpack_require__(/*! ./shader_compiler_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js\");\nfunction makeShader(inputsInfo, outputShape, userCode, usesPackedTextures) {\n    var prefixSnippets = [];\n    inputsInfo.forEach(function (x) {\n        var size = util.sizeFromShape(x.shapeInfo.logicalShape);\n        // Snippet when we decided to upload the values as uniform.\n        if (x.shapeInfo.isUniform) {\n            prefixSnippets.push(\"uniform float \" + x.name + (size > 1 ? \"[\" + size + \"]\" : '') + \";\");\n        }\n        else {\n            prefixSnippets.push(\"uniform sampler2D \" + x.name + \";\");\n            prefixSnippets.push(\"uniform int offset\" + x.name + \";\");\n        }\n    });\n    var inputPrefixSnippet = prefixSnippets.join('\\n');\n    var inputSamplingSnippet = inputsInfo\n        .map(function (x) { return getInputSamplingSnippet(x, outputShape, usesPackedTextures); })\n        .join('\\n');\n    var outTexShape = outputShape.texShape;\n    var glsl = glsl_version_1.getGlslDifferences();\n    var floatTextureSampleSnippet = getFloatTextureSampleSnippet(glsl);\n    var outputSamplingSnippet;\n    var floatTextureSetOutputSnippet;\n    var shaderPrefix = getShaderPrefix(glsl);\n    if (outputShape.isPacked) {\n        outputSamplingSnippet =\n            getPackedOutputSamplingSnippet(outputShape.logicalShape, outTexShape);\n        floatTextureSetOutputSnippet = getFloatTextureSetRGBASnippet(glsl);\n    }\n    else {\n        outputSamplingSnippet =\n            getOutputSamplingSnippet(outputShape.logicalShape, outTexShape);\n        floatTextureSetOutputSnippet = getFloatTextureSetRSnippet(glsl);\n    }\n    if (usesPackedTextures) {\n        shaderPrefix += SHADER_PACKED_PREFIX;\n    }\n    var source = [\n        shaderPrefix, floatTextureSampleSnippet, floatTextureSetOutputSnippet,\n        inputPrefixSnippet, outputSamplingSnippet, inputSamplingSnippet, userCode\n    ].join('\\n');\n    return source;\n}\nexports.makeShader = makeShader;\nfunction getSamplerFromInInfo(inInfo) {\n    var shape = inInfo.shapeInfo.logicalShape;\n    switch (shape.length) {\n        case 0:\n            return getSamplerScalar(inInfo);\n        case 1:\n            return getSampler1D(inInfo);\n        case 2:\n            return getSampler2D(inInfo);\n        case 3:\n            return getSampler3D(inInfo);\n        case 4:\n            return getSampler4D(inInfo);\n        case 5:\n            return getSampler5D(inInfo);\n        case 6:\n            return getSampler6D(inInfo);\n        default:\n            throw new Error(shape.length + \"-D input sampling\" +\n                \" is not yet supported\");\n    }\n}\nfunction getPackedSamplerFromInInfo(inInfo) {\n    var shape = inInfo.shapeInfo.logicalShape;\n    switch (shape.length) {\n        case 0:\n            return getPackedSamplerScalar(inInfo);\n        case 1:\n            return getPackedSampler1D(inInfo);\n        case 2:\n            return getPackedSampler2D(inInfo);\n        case 3:\n            return getPackedSampler3D(inInfo);\n        default:\n            return getPackedSamplerND(inInfo);\n    }\n}\nfunction getInputSamplingSnippet(inInfo, outShapeInfo, usesPackedTextures) {\n    if (usesPackedTextures === void 0) { usesPackedTextures = false; }\n    var res = '';\n    if (usesPackedTextures) {\n        res += getPackedSamplerFromInInfo(inInfo);\n    }\n    else {\n        res += getSamplerFromInInfo(inInfo);\n    }\n    var inShape = inInfo.shapeInfo.logicalShape;\n    var outShape = outShapeInfo.logicalShape;\n    if (inShape.length <= outShape.length) {\n        if (usesPackedTextures) {\n            res += getPackedSamplerAtOutputCoords(inInfo, outShapeInfo);\n        }\n        else {\n            res += getSamplerAtOutputCoords(inInfo, outShapeInfo);\n        }\n    }\n    return res;\n}\nfunction getPackedOutputSamplingSnippet(outShape, outTexShape) {\n    switch (outShape.length) {\n        case 0:\n            return getOutputScalarCoords();\n        case 1:\n            return getOutputPacked1DCoords(outShape, outTexShape);\n        case 2:\n            return getOutputPacked2DCoords(outShape, outTexShape);\n        case 3:\n            return getOutputPacked3DCoords(outShape, outTexShape);\n        default:\n            return getOutputPackedNDCoords(outShape, outTexShape);\n    }\n}\nfunction getOutputSamplingSnippet(outShape, outTexShape) {\n    switch (outShape.length) {\n        case 0:\n            return getOutputScalarCoords();\n        case 1:\n            return getOutput1DCoords(outShape, outTexShape);\n        case 2:\n            return getOutput2DCoords(outShape, outTexShape);\n        case 3:\n            return getOutput3DCoords(outShape, outTexShape);\n        case 4:\n            return getOutput4DCoords(outShape, outTexShape);\n        case 5:\n            return getOutput5DCoords(outShape, outTexShape);\n        case 6:\n            return getOutput6DCoords(outShape, outTexShape);\n        default:\n            throw new Error(outShape.length + \"-D output sampling is not yet supported\");\n    }\n}\nfunction getFloatTextureSampleSnippet(glsl) {\n    return \"\\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\\n      return \" + glsl.texture2D + \"(textureSampler, uv).r;\\n    }\\n  \";\n}\nfunction getFloatTextureSetRSnippet(glsl) {\n    return \"\\n    void setOutput(float val) {\\n      \" + glsl.output + \" = vec4(val, 0, 0, 0);\\n    }\\n  \";\n}\nfunction getFloatTextureSetRGBASnippet(glsl) {\n    return \"\\n    void setOutput(vec4 val) {\\n      \" + glsl.output + \" = val;\\n    }\\n  \";\n}\nfunction getShaderPrefix(glsl) {\n    var SHADER_PREFIX = glsl.version + \"\\n    precision highp float;\\n    precision highp int;\\n    precision highp sampler2D;\\n    \" + glsl.varyingFs + \" vec2 resultUV;\\n    \" + glsl.defineOutput + \"\\n    const vec2 halfCR = vec2(0.5, 0.5);\\n\\n    struct ivec5\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n    };\\n\\n    struct ivec6\\n    {\\n      int x;\\n      int y;\\n      int z;\\n      int w;\\n      int u;\\n      int v;\\n    };\\n\\n    uniform float NAN;\\n    \" + glsl.defineSpecialNaN + \"\\n    \" + glsl.defineSpecialInf + \"\\n    \" + glsl.defineRound + \"\\n\\n    int imod(int x, int y) {\\n      return x - y * (x / y);\\n    }\\n\\n    int idiv(int a, int b, float sign) {\\n      int res = a / b;\\n      int mod = imod(a, b);\\n      if (sign < 0. && mod != 0) {\\n        res -= 1;\\n      }\\n      return res;\\n    }\\n\\n    //Based on the work of Dave Hoskins\\n    //https://www.shadertoy.com/view/4djSRW\\n    #define HASHSCALE1 443.8975\\n    float random(float seed){\\n      vec2 p = resultUV * seed;\\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\\n      p3 += dot(p3, p3.yzx + 19.19);\\n      return fract((p3.x + p3.y) * p3.z);\\n    }\\n\\n    \" + SAMPLE_1D_SNIPPET + \"\\n    \" + SAMPLE_2D_SNIPPET + \"\\n    \" + SAMPLE_3D_SNIPPET + \"\\n  \";\n    return SHADER_PREFIX;\n}\nvar SAMPLE_1D_SNIPPET = \"\\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\\n  int texR = index / texNumC;\\n  int texC = index - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\\n  int texelIndex = index / 2;\\n  int texR = texelIndex / texNumC;\\n  int texC = texelIndex - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\";\nvar SAMPLE_2D_SNIPPET = \"\\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\\n  int texNumC, int row, int col) {\\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\\n  int texR = texelIndex / texNumC;\\n  int texC = texelIndex - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\";\nvar SAMPLE_3D_SNIPPET = \"\\nvec2 packedUVfrom3D(int texNumR, int texNumC,\\n    int texelsInBatch, int texelsInLogicalRow, int b,\\n    int row, int col) {\\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\\n  int texR = index / texNumC;\\n  int texC = index - texR * texNumC;\\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\\n}\\n\";\nvar SHADER_PACKED_PREFIX = \"\\n  float getChannel(vec4 frag, vec2 innerDims) {\\n    vec2 modCoord = mod(innerDims, 2.);\\n    return modCoord.x == 0. ?\\n      (modCoord.y == 0. ? frag.r : frag.g) :\\n      (modCoord.y == 0. ? frag.b : frag.a);\\n  }\\n  float getChannel(vec4 frag, int dim) {\\n    float modCoord = mod(float(dim), 2.);\\n    return modCoord == 0. ? frag.r : frag.g;\\n  }\\n\";\nfunction getOutputScalarCoords() {\n    return \"\\n    int getOutputCoords() {\\n      return 0;\\n    }\\n  \";\n}\nfunction getOutputPacked1DCoords(shape, texShape) {\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    if (packedTexShape[0] === 1) {\n        return \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.x * \" + packedTexShape[1] + \".0);\\n      }\\n    \";\n    }\n    if (packedTexShape[1] === 1) {\n        return \"\\n      int getOutputCoords() {\\n        return 2 * int(resultUV.y * \" + packedTexShape[0] + \".0);\\n      }\\n    \";\n    }\n    return \"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + packedTexShape[0] + \", \" + packedTexShape[1] + \"));\\n      return 2 * (resTexRC.x * \" + packedTexShape[1] + \" + resTexRC.y);\\n    }\\n  \";\n}\nfunction getOutput1DCoords(shape, texShape) {\n    if (texShape[0] === 1) {\n        return \"\\n      int getOutputCoords() {\\n        return int(resultUV.x * \" + texShape[1] + \".0);\\n      }\\n    \";\n    }\n    if (texShape[1] === 1) {\n        return \"\\n      int getOutputCoords() {\\n        return int(resultUV.y * \" + texShape[0] + \".0);\\n      }\\n    \";\n    }\n    return \"\\n    int getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      return resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n    }\\n  \";\n}\nfunction getOutputPacked3DCoords(shape, texShape) {\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    var texelsInLogicalRow = Math.ceil(shape[2] / 2);\n    var texelsInBatch = texelsInLogicalRow * Math.ceil(shape[1] / 2);\n    return \"\\n    ivec3 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + packedTexShape[0] + \", \" + packedTexShape[1] + \"));\\n      int index = resTexRC.x * \" + packedTexShape[1] + \" + resTexRC.y;\\n\\n      int b = index / \" + texelsInBatch + \";\\n      index -= b * \" + texelsInBatch + \";\\n\\n      int r = 2 * (index / \" + texelsInLogicalRow + \");\\n      int c = imod(index, \" + texelsInLogicalRow + \") * 2;\\n\\n      return ivec3(b, r, c);\\n    }\\n  \";\n}\nfunction getOutput3DCoords(shape, texShape) {\n    var coordsFromIndexSnippet = shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd'], shape);\n    return \"\\n    ivec3 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n      \" + coordsFromIndexSnippet + \"\\n      return ivec3(r, c, d);\\n    }\\n  \";\n}\nfunction getOutputPackedNDCoords(shape, texShape) {\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    var texelsInLogicalRow = Math.ceil(shape[shape.length - 1] / 2);\n    var texelsInBatch = texelsInLogicalRow * Math.ceil(shape[shape.length - 2] / 2);\n    var texelsInBatchN = texelsInBatch;\n    var batches = \"\";\n    var coords = 'b, r, c';\n    for (var b = 2; b < shape.length - 1; b++) {\n        texelsInBatchN *= shape[shape.length - b - 1];\n        batches = \"\\n      int b\" + b + \" = index / \" + texelsInBatchN + \";\\n      index -= b\" + b + \" * \" + texelsInBatchN + \";\\n    \" + batches;\n        coords = \"b\" + b + \", \" + coords;\n    }\n    return \"\\n    ivec\" + shape.length + \" getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + packedTexShape[0] + \", \" + packedTexShape[1] + \"));\\n      int index = resTexRC.x * \" + packedTexShape[1] + \" + resTexRC.y;\\n\\n      \" + batches + \"\\n\\n      int b = index / \" + texelsInBatch + \";\\n      index -= b * \" + texelsInBatch + \";\\n\\n      int r = 2 * (index / \" + texelsInLogicalRow + \");\\n      int c = imod(index, \" + texelsInLogicalRow + \") * 2;\\n\\n      return ivec\" + shape.length + \"(\" + coords + \");\\n    }\\n  \";\n}\nfunction getOutput4DCoords(shape, texShape) {\n    var coordsFromIndexSnippet = shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd', 'd2'], shape);\n    return \"\\n    ivec4 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n      \" + coordsFromIndexSnippet + \"\\n      return ivec4(r, c, d, d2);\\n    }\\n  \";\n}\nfunction getOutput5DCoords(shape, texShape) {\n    var coordsFromIndexSnippet = shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd', 'd2', 'd3'], shape);\n    return \"\\n    ivec5 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(\" + texShape[0] + \",\\n                             \" + texShape[1] + \"));\\n\\n      int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n\\n      \" + coordsFromIndexSnippet + \"\\n\\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\\n      return outShape;\\n    }\\n  \";\n}\nfunction getOutput6DCoords(shape, texShape) {\n    var coordsFromIndexSnippet = shader_util.getLogicalCoordinatesFromFlatIndex(['r', 'c', 'd', 'd2', 'd3', 'd4'], shape);\n    return \"\\n    ivec6 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n        vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n\\n      \" + coordsFromIndexSnippet + \"\\n\\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\\n      return result;\\n    }\\n  \";\n}\nfunction getOutputPacked2DCoords(shape, texShape) {\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    if (util.arraysEqual(shape, texShape)) {\n        return \"\\n      ivec2 getOutputCoords() {\\n        return 2 * ivec2(resultUV.yx * vec2(\" + packedTexShape[0] + \", \" + packedTexShape[1] + \"));\\n      }\\n    \";\n    }\n    // texels needed to accommodate a logical row\n    var texelsInLogicalRow = Math.ceil(shape[1] / 2);\n    /**\n     * getOutputCoords\n     *\n     * resTexRC: The rows and columns of the texels. If you move over one\n     * texel to the right in the packed texture, you are moving over one column\n     * (not two).\n     *\n     * index: The texel index\n     */\n    return \"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + packedTexShape[0] + \", \" + packedTexShape[1] + \"));\\n\\n      int index = resTexRC.x * \" + packedTexShape[1] + \" + resTexRC.y;\\n      int r = 2 * (index / \" + texelsInLogicalRow + \");\\n      int c = imod(index, \" + texelsInLogicalRow + \") * 2;\\n\\n      return ivec2(r, c);\\n    }\\n  \";\n}\nfunction getOutput2DCoords(shape, texShape) {\n    if (util.arraysEqual(shape, texShape)) {\n        return \"\\n      ivec2 getOutputCoords() {\\n        return ivec2(resultUV.yx * vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      }\\n    \";\n    }\n    if (shape[1] === 1) {\n        return \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n        int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n        return ivec2(index, 0);\\n      }\\n    \";\n    }\n    if (shape[0] === 1) {\n        return \"\\n      ivec2 getOutputCoords() {\\n        ivec2 resTexRC = ivec2(resultUV.yx *\\n                               vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n        int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n        return ivec2(0, index);\\n      }\\n    \";\n    }\n    return \"\\n    ivec2 getOutputCoords() {\\n      ivec2 resTexRC = ivec2(resultUV.yx *\\n                             vec2(\" + texShape[0] + \", \" + texShape[1] + \"));\\n      int index = resTexRC.x * \" + texShape[1] + \" + resTexRC.y;\\n      int r = index / \" + shape[1] + \";\\n      int c = index - r * \" + shape[1] + \";\\n      return ivec2(r, c);\\n    }\\n  \";\n}\nfunction getFlatOffsetUniformName(texName) {\n    return \"offset\" + texName;\n}\nfunction getPackedSamplerScalar(inputInfo) {\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var glsl = glsl_version_1.getGlslDifferences();\n    return \"\\n    vec4 \" + funcName + \"() {\\n      return \" + glsl.texture2D + \"(\" + texName + \", halfCR);\\n    }\\n  \";\n}\nfunction getSamplerScalar(inputInfo) {\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    if (inputInfo.shapeInfo.isUniform) {\n        return \"float \" + funcName + \"() {return \" + texName + \";}\";\n    }\n    var _a = inputInfo.shapeInfo.texShape, texNumR = _a[0], texNumC = _a[1];\n    if (texNumR === 1 && texNumC === 1) {\n        return \"\\n      float \" + funcName + \"() {\\n        return sampleTexture(\" + texName + \", halfCR);\\n      }\\n    \";\n    }\n    var _b = inputInfo.shapeInfo.texShape, tNumR = _b[0], tNumC = _b[1];\n    var offset = getFlatOffsetUniformName(texName);\n    return \"\\n    float \" + funcName + \"() {\\n      vec2 uv = uvFromFlat(\" + tNumR + \", \" + tNumC + \", \" + offset + \");\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getPackedSampler1D(inputInfo) {\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var texShape = inputInfo.shapeInfo.texShape;\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    var glsl = glsl_version_1.getGlslDifferences();\n    return \"\\n    vec4 \" + funcName + \"(int index) {\\n      vec2 uv = packedUVfrom1D(\\n        \" + packedTexShape[0] + \", \" + packedTexShape[1] + \", index);\\n      return \" + glsl.texture2D + \"(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler1D(inputInfo) {\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int index) {\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var texShape = inputInfo.shapeInfo.texShape;\n    var tNumR = texShape[0];\n    var tNumC = texShape[1];\n    if (tNumC === 1 && tNumR === 1) {\n        return \"\\n      float \" + funcName + \"(int index) {\\n        return sampleTexture(\" + texName + \", halfCR);\\n      }\\n    \";\n    }\n    var offset = getFlatOffsetUniformName(texName);\n    if (tNumC === 1) {\n        return \"\\n      float \" + funcName + \"(int index) {\\n        vec2 uv = vec2(0.5, (float(index + \" + offset + \") + 0.5) / \" + tNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    if (tNumR === 1) {\n        return \"\\n      float \" + funcName + \"(int index) {\\n        vec2 uv = vec2((float(index + \" + offset + \") + 0.5) / \" + tNumC + \".0, 0.5);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    return \"\\n    float \" + funcName + \"(int index) {\\n      vec2 uv = uvFromFlat(\" + tNumR + \", \" + tNumC + \", index + \" + offset + \");\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getPackedSampler2D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var texShape = inputInfo.shapeInfo.texShape;\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    var glsl = glsl_version_1.getGlslDifferences();\n    if (texShape != null && util.arraysEqual(shape, texShape)) {\n        return \"\\n      vec4 \" + funcName + \"(int row, int col) {\\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n\\n        return \" + glsl.texture2D + \"(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    var valuesPerRow = Math.ceil(shape[1] / 2);\n    return \"\\n    vec4 \" + funcName + \"(int row, int col) {\\n      vec2 uv = packedUVfrom2D(\" + valuesPerRow + \", \" + packedTexShape[0] + \", \" + packedTexShape[1] + \", row, col);\\n      return \" + glsl.texture2D + \"(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler2D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var texShape = inputInfo.shapeInfo.texShape;\n    if (texShape != null && util.arraysEqual(shape, texShape)) {\n        var texNumR_1 = texShape[0];\n        var texNumC_1 = texShape[1];\n        return \"\\n    float \" + funcName + \"(int row, int col) {\\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(\" + texNumC_1 + \".0, \" + texNumR_1 + \".0);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n    }\n    var _a = util.squeezeShape(shape), newShape = _a.newShape, keptDims = _a.keptDims;\n    var squeezedShape = newShape;\n    if (squeezedShape.length < shape.length) {\n        var newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);\n        var params = ['row', 'col'];\n        return \"\\n      \" + getSamplerFromInInfo(newInputInfo) + \"\\n      float \" + funcName + \"(int row, int col) {\\n        return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n      }\\n    \";\n    }\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col) {\\n        int index = round(dot(vec2(row, col), vec2(\" + shape[1] + \", 1)));\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    var offset = getFlatOffsetUniformName(texName);\n    if (texNumC === 1) {\n        // index is used directly as physical (no risk of float16 overflow).\n        return \"\\n    float \" + funcName + \"(int row, int col) {\\n      float index = dot(vec3(row, col, \" + offset + \"), vec3(\" + shape[1] + \", 1, 1));\\n      vec2 uv = vec2(0.5, (index + 0.5) / \" + texNumR + \".0);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n    }\n    if (texNumR === 1) {\n        // index is used directly as physical (no risk of float16 overflow).\n        return \"\\n    float \" + funcName + \"(int row, int col) {\\n      float index = dot(vec3(row, col, \" + offset + \"), vec3(\" + shape[1] + \", 1, 1));\\n      vec2 uv = vec2((index + 0.5) / \" + texNumC + \".0, 0.5);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n    }\n    return \"\\n  float \" + funcName + \"(int row, int col) {\\n    // Explicitly use integer operations as dot() only works on floats.\\n    int index = row * \" + shape[1] + \" + col + \" + offset + \";\\n    vec2 uv = uvFromFlat(\" + texNumR + \", \" + texNumC + \", index);\\n    return sampleTexture(\" + texName + \", uv);\\n  }\\n\";\n}\nfunction getPackedSampler3D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var texShape = inputInfo.shapeInfo.texShape;\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    if (shape[0] === 1) {\n        var squeezedShape = shape.slice(1);\n        var keptDims = [1, 2];\n        var newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);\n        var params = ['b', 'row', 'col'];\n        return \"\\n        \" + getPackedSamplerFromInInfo(newInputInfo) + \"\\n        vec4 \" + funcName + \"(int b, int row, int col) {\\n          return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n        }\\n      \";\n    }\n    var texNumR = packedTexShape[0];\n    var texNumC = packedTexShape[1];\n    var valuesPerRow = Math.ceil(shape[2] / 2);\n    var texelsInBatch = valuesPerRow * Math.ceil(shape[1] / 2);\n    var glsl = glsl_version_1.getGlslDifferences();\n    return \"\\n    vec4 \" + funcName + \"(int b, int row, int col) {\\n      vec2 uv = packedUVfrom3D(\\n        \" + texNumR + \", \" + texNumC + \", \" + texelsInBatch + \", \" + valuesPerRow + \", b, row, col);\\n      return \" + glsl.texture2D + \"(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler3D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var stride0 = shape[1] * shape[2];\n    var stride1 = shape[2];\n    var _a = util.squeezeShape(shape), newShape = _a.newShape, keptDims = _a.keptDims;\n    var squeezedShape = newShape;\n    if (squeezedShape.length < shape.length) {\n        var newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);\n        var params = ['row', 'col', 'depth'];\n        return \"\\n        \" + getSamplerFromInInfo(newInputInfo) + \"\\n        float \" + funcName + \"(int row, int col, int depth) {\\n          return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n        }\\n      \";\n    }\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth) {\\n        int index = round(dot(vec3(row, col, depth),\\n                          vec3(\" + stride0 + \", \" + stride1 + \", 1)));\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var texShape = inputInfo.shapeInfo.texShape;\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    var flatOffset = inputInfo.shapeInfo.flatOffset;\n    if (texNumC === stride0 && flatOffset == null) {\n        // texC is used directly as physical (no risk of float16 overflow).\n        return \"\\n        float \" + funcName + \"(int row, int col, int depth) {\\n          float texR = float(row);\\n          float texC = dot(vec2(col, depth), vec2(\" + stride1 + \", 1));\\n          vec2 uv = (vec2(texC, texR) + halfCR) /\\n                     vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n          return sampleTexture(\" + texName + \", uv);\\n        }\\n      \";\n    }\n    if (texNumC === stride1 && flatOffset == null) {\n        // texR is used directly as physical (no risk of float16 overflow).\n        return \"\\n    float \" + funcName + \"(int row, int col, int depth) {\\n      float texR = dot(vec2(row, col), vec2(\" + shape[1] + \", 1));\\n      float texC = float(depth);\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n    }\n    var offset = getFlatOffsetUniformName(texName);\n    return \"\\n      float \" + funcName + \"(int row, int col, int depth) {\\n        // Explicitly use integer operations as dot() only works on floats.\\n        int index = row * \" + stride0 + \" + col * \" + stride1 + \" + depth + \" + offset + \";\\n        vec2 uv = uvFromFlat(\" + texNumR + \", \" + texNumC + \", index);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n  \";\n}\nfunction getPackedSamplerND(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var rank = shape.length;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var texShape = inputInfo.shapeInfo.texShape;\n    var packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];\n    var texNumR = packedTexShape[0];\n    var texNumC = packedTexShape[1];\n    var valuesPerRow = Math.ceil(shape[rank - 1] / 2);\n    var texelsInBatch = valuesPerRow * Math.ceil(shape[rank - 2] / 2);\n    var params = \"int b, int row, int col\";\n    var index = \"b * \" + texelsInBatch + \" + (row / 2) * \" + valuesPerRow + \" + (col / 2)\";\n    for (var b = 2; b < rank - 1; b++) {\n        params = \"int b\" + b + \", \" + params;\n        texelsInBatch *= shape[rank - b - 1];\n        index = \"b\" + b + \" * \" + texelsInBatch + \" + \" + index;\n    }\n    var glsl = glsl_version_1.getGlslDifferences();\n    return \"\\n    vec4 \" + funcName + \"(\" + params + \") {\\n      int index = \" + index + \";\\n      int texR = index / \" + texNumC + \";\\n      int texC = index - texR * \" + texNumC + \";\\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(\" + texNumC + \", \" + texNumR + \");\\n      return \" + glsl.texture2D + \"(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler4D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var stride2 = shape[3];\n    var stride1 = shape[2] * stride2;\n    var stride0 = shape[1] * stride1;\n    var _a = util.squeezeShape(shape), newShape = _a.newShape, keptDims = _a.keptDims;\n    if (newShape.length < shape.length) {\n        var newInputInfo = squeezeInputInfo(inputInfo, newShape);\n        var params = ['row', 'col', 'depth', 'depth2'];\n        return \"\\n      \" + getSamplerFromInInfo(newInputInfo) + \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2) {\\n        return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n      }\\n    \";\n    }\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2) {\\n        int index = round(dot(vec4(row, col, depth, depth2),\\n                          vec4(\" + stride0 + \", \" + stride1 + \", \" + stride2 + \", 1)));\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var flatOffset = inputInfo.shapeInfo.flatOffset;\n    var texShape = inputInfo.shapeInfo.texShape;\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    if (texNumC === stride0 && flatOffset == null) {\n        // texC is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2) {\\n        float texR = float(row);\\n        float texC =\\n            dot(vec3(col, depth, depth2),\\n                vec3(\" + stride1 + \", \" + stride2 + \", 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    if (texNumC === stride2 && flatOffset == null) {\n        // texR is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2) {\\n        float texR = dot(vec3(row, col, depth),\\n                         vec3(\" + shape[1] * shape[2] + \", \" + shape[2] + \", 1));\\n        float texC = float(depth2);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    var offset = getFlatOffsetUniformName(texName);\n    return \"\\n    float \" + funcName + \"(int row, int col, int depth, int depth2) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \" + stride0 + \" + col * \" + stride1 + \" +\\n          depth * \" + stride2 + \" + depth2;\\n      vec2 uv = uvFromFlat(\" + texNumR + \", \" + texNumC + \", index + \" + offset + \");\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler5D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var stride3 = shape[4];\n    var stride2 = shape[3] * stride3;\n    var stride1 = shape[2] * stride2;\n    var stride0 = shape[1] * stride1;\n    var _a = util.squeezeShape(shape), newShape = _a.newShape, keptDims = _a.keptDims;\n    if (newShape.length < shape.length) {\n        var newInputInfo = squeezeInputInfo(inputInfo, newShape);\n        var params = ['row', 'col', 'depth', 'depth2', 'depth3'];\n        return \"\\n      \" + getSamplerFromInInfo(newInputInfo) + \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2, int depth3) {\\n        return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n      }\\n    \";\n    }\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2, int depth3) {\\n        float index = dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\" + stride0 + \", \" + stride1 + \", \" + stride2 + \", \" + stride3 + \")) +\\n          depth3;\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var flatOffset = inputInfo.shapeInfo.flatOffset;\n    var texShape = inputInfo.shapeInfo.texShape;\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    if (texNumC === stride0 && flatOffset == null) {\n        // texC is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2, int depth3) {\\n        int texR = row;\\n        float texC = dot(vec4(col, depth, depth2, depth3),\\n                         vec4(\" + stride1 + \", \" + stride2 + \", \" + stride3 + \", 1));\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    if (texNumC === stride3 && flatOffset == null) {\n        // texR is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth, int depth2, int depth3) {\\n        float texR = dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\" + shape[1] * shape[2] * shape[3] + \",\\n               \" + shape[2] * shape[3] + \", \" + shape[3] + \", 1));\\n        int texC = depth3;\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    var offset = getFlatOffsetUniformName(texName);\n    return \"\\n    float \" + funcName + \"(int row, int col, int depth, int depth2, int depth3) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \" + stride0 + \" + col * \" + stride1 + \" + depth * \" + stride2 + \" +\\n          depth2 * \" + stride3 + \" + depth3 + \" + offset + \";\\n      vec2 uv = uvFromFlat(\" + texNumR + \", \" + texNumC + \", index);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getSampler6D(inputInfo) {\n    var shape = inputInfo.shapeInfo.logicalShape;\n    var texName = inputInfo.name;\n    var funcName = 'get' + texName.charAt(0).toUpperCase() + texName.slice(1);\n    var _a = util.squeezeShape(shape), newShape = _a.newShape, keptDims = _a.keptDims;\n    if (newShape.length < shape.length) {\n        var newInputInfo = squeezeInputInfo(inputInfo, newShape);\n        var params = ['row', 'col', 'depth', 'depth2', 'depth3', 'depth4'];\n        return \"\\n      \" + getSamplerFromInInfo(newInputInfo) + \"\\n      float \" + funcName + \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        return \" + funcName + \"(\" + getSqueezedParams(params, keptDims) + \");\\n      }\\n    \";\n    }\n    var stride4 = shape[5];\n    var stride3 = shape[4] * stride4;\n    var stride2 = shape[3] * stride3;\n    var stride1 = shape[2] * stride2;\n    var stride0 = shape[1] * stride1;\n    if (inputInfo.shapeInfo.isUniform) {\n        // Uniform arrays will be less than 65505 (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth,\\n                  int depth2, int depth3, int depth4) {\\n        int index = round(dot(\\n          vec4(row, col, depth, depth2),\\n          vec4(\" + stride0 + \", \" + stride1 + \", \" + stride2 + \", \" + stride3 + \")) +\\n          dot(\\n            vec2(depth3, depth4),\\n            vec2(\" + stride4 + \", 1)));\\n        \" + getUniformSampler(inputInfo) + \"\\n      }\\n    \";\n    }\n    var flatOffset = inputInfo.shapeInfo.flatOffset;\n    var texShape = inputInfo.shapeInfo.texShape;\n    var texNumR = texShape[0];\n    var texNumC = texShape[1];\n    if (texNumC === stride0 && flatOffset == null) {\n        // texC is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        int texR = row;\\n        float texC = dot(vec4(col, depth, depth2, depth3),\\n          vec4(\" + stride1 + \", \" + stride2 + \", \" + stride3 + \", \" + stride4 + \")) +\\n               float(depth4);\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                   vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    if (texNumC === stride4 && flatOffset == null) {\n        // texR is used directly as physical (no risk of float16 overflow).\n        return \"\\n      float \" + funcName + \"(int row, int col, int depth,\\n                    int depth2, int depth3, int depth4) {\\n        float texR = dot(vec4(row, col, depth, depth2),\\n          vec4(\" + shape[1] * shape[2] * shape[3] * shape[4] + \",\\n               \" + shape[2] * shape[3] * shape[4] + \",\\n               \" + shape[3] * shape[4] + \",\\n               \" + shape[4] + \")) + float(depth3);\\n        int texC = depth4;\\n        vec2 uv = (vec2(texC, texR) + halfCR) /\\n                  vec2(\" + texNumC + \".0, \" + texNumR + \".0);\\n        return sampleTexture(\" + texName + \", uv);\\n      }\\n    \";\n    }\n    var offset = getFlatOffsetUniformName(texName);\n    return \"\\n    float \" + funcName + \"(int row, int col, int depth,\\n                  int depth2, int depth3, int depth4) {\\n      // Explicitly use integer operations as dot() only works on floats.\\n      int index = row * \" + stride0 + \" + col * \" + stride1 + \" + depth * \" + stride2 + \" +\\n          depth2 * \" + stride3 + \" + depth3 * \" + stride4 + \" + depth4 + \" + offset + \";\\n      vec2 uv = uvFromFlat(\" + texNumR + \", \" + texNumC + \", index);\\n      return sampleTexture(\" + texName + \", uv);\\n    }\\n  \";\n}\nfunction getUniformSampler(inputInfo) {\n    var texName = inputInfo.name;\n    var inSize = util.sizeFromShape(inputInfo.shapeInfo.logicalShape);\n    if (inSize < 2) {\n        return \"return \" + texName + \";\";\n    }\n    return \"\\n    for (int i = 0; i < \" + inSize + \"; i++) {\\n      if (i == index) {\\n        return \" + texName + \"[i];\\n      }\\n    }\\n  \";\n}\nfunction getPackedSamplerAtOutputCoords(inputInfo, outShapeInfo) {\n    var texName = inputInfo.name;\n    var texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);\n    var funcName = 'get' + texFuncSnippet + 'AtOutCoords';\n    var inRank = inputInfo.shapeInfo.logicalShape.length;\n    var outRank = outShapeInfo.logicalShape.length;\n    var broadcastDims = broadcast_util_1.getBroadcastDims(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);\n    var type = getCoordsDataType(outRank);\n    var rankDiff = outRank - inRank;\n    var coordsSnippet;\n    var fields = ['x', 'y', 'z', 'w', 'u', 'v'];\n    if (inRank === 0) {\n        coordsSnippet = '';\n    }\n    else if (outRank < 2 && broadcastDims.length >= 1) {\n        coordsSnippet = 'coords = 0;';\n    }\n    else {\n        coordsSnippet =\n            broadcastDims.map(function (d) { return \"coords.\" + fields[d + rankDiff] + \" = 0;\"; })\n                .join('\\n');\n    }\n    var unpackedCoordsSnippet = '';\n    if (outRank < 2 && inRank > 0) {\n        unpackedCoordsSnippet = 'coords';\n    }\n    else {\n        unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape\n            .map(function (s, i) { return \"coords.\" + fields[i + rankDiff]; })\n            .join(', ');\n    }\n    var output = \"return outputValue;\";\n    var inSize = util.sizeFromShape(inputInfo.shapeInfo.logicalShape);\n    var isInputScalar = inSize === 1;\n    var outSize = util.sizeFromShape(outShapeInfo.logicalShape);\n    var isOutputScalar = outSize === 1;\n    if (inRank === 1 && !isInputScalar && !isOutputScalar) {\n        output = \"\\n      return vec4(outputValue.xy, outputValue.xy);\\n    \";\n    }\n    else if (isInputScalar && !isOutputScalar) {\n        if (outRank === 1) {\n            output = \"\\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\\n      \";\n        }\n        else {\n            output = \"\\n        return vec4(outputValue.x);\\n      \";\n        }\n    }\n    else if (broadcastDims.length) {\n        var rows = inRank - 2;\n        var cols = inRank - 1;\n        if (broadcastDims.indexOf(rows) > -1 && broadcastDims.indexOf(cols) > -1) {\n            output = \"return vec4(outputValue.x);\";\n        }\n        else if (broadcastDims.indexOf(rows) > -1) {\n            output = \"return vec4(outputValue.x, outputValue.y, \" +\n                \"outputValue.x, outputValue.y);\";\n        }\n        else if (broadcastDims.indexOf(cols) > -1) {\n            output = \"return vec4(outputValue.xx, outputValue.zz);\";\n        }\n    }\n    return \"\\n    vec4 \" + funcName + \"() {\\n      \" + type + \" coords = getOutputCoords();\\n      \" + coordsSnippet + \"\\n      vec4 outputValue = get\" + texFuncSnippet + \"(\" + unpackedCoordsSnippet + \");\\n      \" + output + \"\\n    }\\n  \";\n}\nfunction getSamplerAtOutputCoords(inputInfo, outShapeInfo) {\n    var texName = inputInfo.name;\n    var texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);\n    var funcName = 'get' + texFuncSnippet + 'AtOutCoords';\n    var outTexShape = outShapeInfo.texShape;\n    var inTexShape = inputInfo.shapeInfo.texShape;\n    var inRank = inputInfo.shapeInfo.logicalShape.length;\n    var outRank = outShapeInfo.logicalShape.length;\n    if (!inputInfo.shapeInfo.isUniform && inRank === outRank &&\n        inputInfo.shapeInfo.flatOffset == null &&\n        util.arraysEqual(inTexShape, outTexShape)) {\n        return \"\\n      float \" + funcName + \"() {\\n        return sampleTexture(\" + texName + \", resultUV);\\n      }\\n    \";\n    }\n    var type = getCoordsDataType(outRank);\n    var broadcastDims = broadcast_util_1.getBroadcastDims(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);\n    var rankDiff = outRank - inRank;\n    var coordsSnippet;\n    var fields = ['x', 'y', 'z', 'w', 'u', 'v'];\n    if (inRank === 0) {\n        coordsSnippet = '';\n    }\n    else if (outRank < 2 && broadcastDims.length >= 1) {\n        coordsSnippet = 'coords = 0;';\n    }\n    else {\n        coordsSnippet =\n            broadcastDims.map(function (d) { return \"coords.\" + fields[d + rankDiff] + \" = 0;\"; })\n                .join('\\n');\n    }\n    var unpackedCoordsSnippet = '';\n    if (outRank < 2 && inRank > 0) {\n        unpackedCoordsSnippet = 'coords';\n    }\n    else {\n        unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape\n            .map(function (s, i) { return \"coords.\" + fields[i + rankDiff]; })\n            .join(', ');\n    }\n    return \"\\n    float \" + funcName + \"() {\\n      \" + type + \" coords = getOutputCoords();\\n      \" + coordsSnippet + \"\\n      return get\" + texFuncSnippet + \"(\" + unpackedCoordsSnippet + \");\\n    }\\n  \";\n}\nfunction getCoordsDataType(rank) {\n    if (rank <= 1) {\n        return 'int';\n    }\n    else if (rank === 2) {\n        return 'ivec2';\n    }\n    else if (rank === 3) {\n        return 'ivec3';\n    }\n    else if (rank === 4) {\n        return 'ivec4';\n    }\n    else if (rank === 5) {\n        return 'ivec5';\n    }\n    else if (rank === 6) {\n        return 'ivec6';\n    }\n    else {\n        throw Error(\"GPU for rank \" + rank + \" is not yet supported\");\n    }\n}\nexports.getCoordsDataType = getCoordsDataType;\n/** Returns a new input info (a copy) that has a squeezed logical shape. */\nfunction squeezeInputInfo(inInfo, squeezedShape) {\n    // Deep copy.\n    var newInputInfo = JSON.parse(JSON.stringify(inInfo));\n    newInputInfo.shapeInfo.logicalShape = squeezedShape;\n    return newInputInfo;\n}\nfunction getSqueezedParams(params, keptDims) {\n    return keptDims.map(function (d) { return params[d]; }).join(', ');\n}\n//# sourceMappingURL=shader_compiler.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n/**\n * Produces GLSL code that derives logical coordinates from a flat\n * index. The code performs integer division with each stride and decrements\n * the index until the index equals the final dimension coordinate.\n */\nfunction getLogicalCoordinatesFromFlatIndex(coords, shape, index) {\n    if (index === void 0) { index = 'index'; }\n    var strides = util.computeStrides(shape);\n    return strides\n        .map(function (stride, i) {\n        var line1 = \"int \" + coords[i] + \" = \" + index + \" / \" + stride;\n        var line2 = i === strides.length - 1 ?\n            \"int \" + coords[i + 1] + \" = \" + index + \" - \" + coords[i] + \" * \" + stride :\n            \"index -= \" + coords[i] + \" * \" + stride;\n        return line1 + \"; \" + line2 + \";\";\n    })\n        .join('');\n}\nexports.getLogicalCoordinatesFromFlatIndex = getLogicalCoordinatesFromFlatIndex;\nfunction buildVec(x) {\n    if (x.length === 1) {\n        return \"\" + x[0];\n    }\n    return \"vec\" + x.length + \"(\" + x.join(',') + \")\";\n}\n/**\n * Produces GLSL code that computes the dot product of the input x and y\n * vectors. Handles splitting inputs into increments of vec4s when necessary.\n */\nfunction dotify(x, y) {\n    if (x.length !== y.length) {\n        throw new Error(\"Vectors to be dotted must be of the same length -\" +\n            (\"got \" + x.length + \" and \" + y.length));\n    }\n    var slices = [];\n    var nearestVec4 = Math.floor(x.length / 4);\n    var nearestVec4Remainder = x.length % 4;\n    for (var i = 0; i < nearestVec4; i++) {\n        var xSlice = x.slice(i * 4, i * 4 + 4);\n        var ySlice = y.slice(i * 4, i * 4 + 4);\n        slices.push(buildVec(xSlice) + \", \" + buildVec(ySlice));\n    }\n    if (nearestVec4Remainder !== 0) {\n        var xSlice = x.slice(nearestVec4 * 4);\n        var ySlice = y.slice(nearestVec4 * 4);\n        if (xSlice.length === 1) {\n            xSlice = xSlice.map(function (d) { return \"float(\" + d + \")\"; });\n            ySlice = ySlice.map(function (d) { return \"float(\" + d + \")\"; });\n        }\n        slices.push(buildVec(xSlice) + \", \" + buildVec(ySlice));\n    }\n    return slices.map(function (d, i) { return \"dot(\" + d + \")\"; }).join('+');\n}\nexports.dotify = dotify;\n/**\n * Produces GLSL that computes the flat index from 3D coordinates.\n */\nfunction getFlatIndexFrom3D(shape) {\n    var strides = util.computeStrides(shape).map(function (d) { return d.toString(); });\n    return \"\\n  int getFlatIndex(ivec3 coords) {\\n    return coords.x * \" + strides[0] + \" + coords.y * \" + strides[1] + \" + coords.z;\\n  }\\n\";\n}\nexports.getFlatIndexFrom3D = getFlatIndexFrom3D;\nexports.ENCODE_FLOAT_SNIPPET = \"\\n  const float FLOAT_MAX = 1.70141184e38;\\n  const float FLOAT_MIN = 1.17549435e-38;\\n\\n  lowp vec4 encode_float(highp float v) {\\n    if (isnan(v)) {\\n      return vec4(255, 255, 255, 255);\\n    }\\n\\n    highp float av = abs(v);\\n\\n    if(av < FLOAT_MIN) {\\n      return vec4(0.0, 0.0, 0.0, 0.0);\\n    } else if(v > FLOAT_MAX) {\\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\\n    } else if(v < -FLOAT_MAX) {\\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\\n    }\\n\\n    highp vec4 c = vec4(0,0,0,0);\\n\\n    highp float e = floor(log2(av));\\n    highp float m = exp2(fract(log2(av))) - 1.0;\\n\\n    c[2] = floor(128.0 * m);\\n    m -= c[2] / 128.0;\\n    c[1] = floor(32768.0 * m);\\n    m -= c[1] / 32768.0;\\n    c[0] = floor(8388608.0 * m);\\n\\n    highp float ebias = e + 127.0;\\n    c[3] = floor(ebias / 2.0);\\n    ebias -= c[3] * 2.0;\\n    c[2] += floor(ebias) * 128.0;\\n\\n    c[3] += 128.0 * step(0.0, -v);\\n\\n    return c / 255.0;\\n  }\\n\";\n//# sourceMappingURL=shader_compiler_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/slice_gpu.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/slice_gpu.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar SliceProgram = /** @class */ (function () {\n    function SliceProgram(destSize) {\n        this.variableNames = ['source'];\n        this.outputShape = destSize;\n        this.rank = destSize.length;\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var uniformPart = \"uniform int start[\" + this.rank + \"];\";\n        var sourceCoords = getCoords(this.rank);\n        var body;\n        var coordSum = destSize.map(function (_, i) {\n            return \"sourceLoc.\" + coords[i] + \" = start[\" + i + \"] + coords.\" + coords[i] + \";\";\n        });\n        body = \"\\n        \" + dtype + \" sourceLoc;\\n        \" + dtype + \" coords = getOutputCoords();\\n        \" + coordSum.join('\\n') + \"\\n      \";\n        this.userCode = \"\\n      \" + uniformPart + \"\\n      void main() {\\n        \" + body + \"\\n        setOutput(getSource(\" + sourceCoords + \"));\\n      }\\n    \";\n    }\n    SliceProgram.prototype.getCustomSetupFunc = function (start) {\n        var _this = this;\n        if (start.length !== this.rank) {\n            throw Error(\"The rank (\" + this.rank + \") of the program must match the \" +\n                (\"length of start (\" + start.length + \")\"));\n        }\n        return function (gpgpu, webGLProgram) {\n            if (_this.startLoc == null) {\n                _this.startLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'start');\n                if (_this.startLoc == null) {\n                    // This means the compiler has optimized and realized it doesn't need\n                    // the uniform.\n                    return;\n                }\n            }\n            gpgpu.gl.uniform1iv(_this.startLoc, start);\n        };\n    };\n    return SliceProgram;\n}());\nexports.SliceProgram = SliceProgram;\nvar coords = ['x', 'y', 'z', 'w', 'u', 'v'];\nfunction getCoords(rank) {\n    if (rank === 1) {\n        return 'sourceLoc';\n    }\n    else if (rank <= 6) {\n        return coords.slice(0, rank).map(function (x) { return 'sourceLoc.' + x; }).join(',');\n    }\n    else {\n        throw Error(\"Slicing for rank \" + rank + \" is not yet supported\");\n    }\n}\n//# sourceMappingURL=slice_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/slice_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/slice_packed_gpu.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/slice_packed_gpu.js ***!
  \************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar packing_util_1 = __webpack_require__(/*! ../packing_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js\");\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar SlicePackedProgram = /** @class */ (function () {\n    function SlicePackedProgram(destSize) {\n        this.variableNames = ['source'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = destSize;\n        this.rank = destSize.length;\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var coords = packing_util_1.getChannels('coords', this.rank);\n        var sourceLoc = packing_util_1.getChannels('sourceLoc', this.rank);\n        var innerDims = this.rank === 1 ? 'sourceLoc' : \"vec2(\" + sourceLoc.slice(-2).join() + \")\";\n        var getChannel = \"getChannel(getSource(\" + sourceLoc.join() + \"), \" + innerDims + \")\";\n        var upperRow = \"\\n      result.x = \" + getChannel + \";\\n      if (++\" + coords[this.rank - 1] + \" < \" + destSize[this.rank - 1] + \") {\\n        ++\" + sourceLoc[this.rank - 1] + \";\\n        result.y = \" + getChannel + \";\\n        --\" + sourceLoc[this.rank - 1] + \";\\n      }\\n    \";\n        var lowerRow = this.rank === 1 ? '' : \"\\n      --\" + coords[this.rank - 1] + \";\\n      if (++\" + coords[this.rank - 2] + \" < \" + destSize[this.rank - 2] + \") {\\n        ++\" + sourceLoc[this.rank - 2] + \";\\n        result.z = \" + getChannel + \";\\n        if (++\" + coords[this.rank - 1] + \" < \" + destSize[this.rank - 1] + \") {\\n          ++\" + sourceLoc[this.rank - 1] + \";\\n          result.w = \" + getChannel + \";\\n        }\\n      }\\n    \";\n        var sourceLocSetup = this.rank <= 4 ?\n            \"sourceLoc = coords +\\n            \" + dtype + \"(\" + destSize.map(function (_, i) { return \"start[\" + i + \"]\"; }).join() + \");\" :\n            destSize.map(function (_, i) { return sourceLoc[i] + \" = \" + coords[i] + \" + start[\" + i + \"];\"; })\n                .join('\\n');\n        this.userCode = \"\\n      uniform int start[\" + this.rank + \"];\\n      void main() {\\n        \" + dtype + \" coords = getOutputCoords();\\n        \" + dtype + \" sourceLoc;\\n        \" + sourceLocSetup + \"\\n        vec4 result = vec4(0.);\\n        \" + upperRow + \"\\n        \" + lowerRow + \"\\n        setOutput(result);\\n      }\\n    \";\n    }\n    SlicePackedProgram.prototype.getCustomSetupFunc = function (start) {\n        var _this = this;\n        if (start.length !== this.rank) {\n            throw Error(\"The rank (\" + this.rank + \") of the program must match the \" +\n                (\"length of start (\" + start.length + \")\"));\n        }\n        return function (gpgpu, webGLProgram) {\n            if (_this.startLoc == null) {\n                _this.startLoc = gpgpu.getUniformLocationNoThrow(webGLProgram, 'start');\n                if (_this.startLoc == null) {\n                    // This means the compiler has optimized and realized it doesn't need\n                    // the uniform.\n                    return;\n                }\n            }\n            gpgpu.gl.uniform1iv(_this.startLoc, start);\n        };\n    };\n    return SlicePackedProgram;\n}());\nexports.SlicePackedProgram = SlicePackedProgram;\n//# sourceMappingURL=slice_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/slice_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/strided_slice_gpu.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/strided_slice_gpu.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar StridedSliceProgram = /** @class */ (function () {\n    function StridedSliceProgram(begin, strides, size) {\n        this.variableNames = ['x'];\n        this.outputShape = size;\n        var rank = size.length;\n        var inputDtype = shader_compiler_1.getCoordsDataType(size.length);\n        var dtype = shader_compiler_1.getCoordsDataType(size.length);\n        var newCoords = '';\n        if (rank === 1) {\n            newCoords = 'coords * strides + begin';\n        }\n        else {\n            var outputAxis_1 = 0;\n            newCoords =\n                size.map(function (_, i) {\n                    outputAxis_1++;\n                    return size.length === 1 ?\n                        \"coords * strides[\" + i + \"] + begin[\" + i + \"]\" :\n                        \"coords[\" + (outputAxis_1 - 1) + \"] * strides[\" + i + \"] + begin[\" + i + \"]\";\n                })\n                    .join(',');\n        }\n        this.userCode = \"\\n      \" + inputDtype + \" begin = \" + inputDtype + \"(\" + begin + \");\\n      \" + inputDtype + \" strides = \" + inputDtype + \"(\" + strides + \");\\n\\n      void main() {\\n        \" + dtype + \" coords = getOutputCoords();\\n        setOutput(getX(\" + newCoords + \"));\\n      }\\n    \";\n    }\n    return StridedSliceProgram;\n}());\nexports.StridedSliceProgram = StridedSliceProgram;\n//# sourceMappingURL=strided_slice_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/strided_slice_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar util = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar PackingScheme;\n(function (PackingScheme) {\n    /**\n     * All values in a single texel are densely packed without any constraints.\n     *\n     * This is how the shader encodes a tensor with shape = [2, 3, 4]\n     * (indices are [batch, row, col]).\n     *\n     * 000|001   010|011   020|021\n     * -------   -------   -------\n     * 002|003   012|013   022|023\n     *\n     * 100|101   110|111   120|121\n     * -------   -------   -------\n     * 102|103   112|113   122|123\n     *\n     */\n    PackingScheme[PackingScheme[\"DENSE\"] = 0] = \"DENSE\";\n    /**\n     * Single texels contain only values from the same batch, and from adjacent\n     * rows and columns.\n     *\n     * This is how the shader encodes a tensor with shape = [2, 3, 5]\n     * (indices are [batch, row, col]).\n     *\n     * 000|001   002|003   004|xxx   020|021   022|023   024|xxx\n     * -------   -------   -------   -------   -------   -------\n     * 010|011   012|013   014|xxx   xxx|xxx   xxx|xxx   xxx|xxx\n     *\n     * 100|101   102|103   104|xxx   120|121   122|123   124|xxx\n     * -------   -------   -------   -------   -------   -------\n     * 110|111   112|113   114|xxx   xxx|xxx   xxx|xxx   xxx|xxx\n     *\n     */\n    PackingScheme[PackingScheme[\"SHARED_BATCH\"] = 1] = \"SHARED_BATCH\";\n})(PackingScheme = exports.PackingScheme || (exports.PackingScheme = {}));\nvar TextureUsage;\n(function (TextureUsage) {\n    TextureUsage[TextureUsage[\"RENDER\"] = 0] = \"RENDER\";\n    TextureUsage[TextureUsage[\"UPLOAD\"] = 1] = \"UPLOAD\";\n    TextureUsage[TextureUsage[\"PIXELS\"] = 2] = \"PIXELS\";\n    TextureUsage[TextureUsage[\"DOWNLOAD\"] = 3] = \"DOWNLOAD\";\n})(TextureUsage = exports.TextureUsage || (exports.TextureUsage = {}));\nvar PhysicalTextureType;\n(function (PhysicalTextureType) {\n    PhysicalTextureType[PhysicalTextureType[\"UNPACKED_FLOAT16\"] = 0] = \"UNPACKED_FLOAT16\";\n    PhysicalTextureType[PhysicalTextureType[\"UNPACKED_FLOAT32\"] = 1] = \"UNPACKED_FLOAT32\";\n    PhysicalTextureType[PhysicalTextureType[\"PACKED_4X1_UNSIGNED_BYTE\"] = 2] = \"PACKED_4X1_UNSIGNED_BYTE\";\n    PhysicalTextureType[PhysicalTextureType[\"PACKED_2X2_FLOAT32\"] = 3] = \"PACKED_2X2_FLOAT32\";\n    PhysicalTextureType[PhysicalTextureType[\"PACKED_2X2_FLOAT16\"] = 4] = \"PACKED_2X2_FLOAT16\";\n})(PhysicalTextureType = exports.PhysicalTextureType || (exports.PhysicalTextureType = {}));\nfunction getUnpackedMatrixTextureShapeWidthHeight(rows, columns) {\n    return [columns, rows];\n}\nexports.getUnpackedMatrixTextureShapeWidthHeight = getUnpackedMatrixTextureShapeWidthHeight;\nfunction getUnpackedArraySizeFromMatrixSize(matrixSize, channelsPerTexture) {\n    return matrixSize * channelsPerTexture;\n}\nexports.getUnpackedArraySizeFromMatrixSize = getUnpackedArraySizeFromMatrixSize;\nfunction getColorMatrixTextureShapeWidthHeight(rows, columns) {\n    return [columns * 4, rows];\n}\nexports.getColorMatrixTextureShapeWidthHeight = getColorMatrixTextureShapeWidthHeight;\n/**\n * Get shape for densely packed RGBA texture.\n */\nfunction getDenseTexShape(shape) {\n    var size = util.sizeFromShape(shape);\n    var texelsNeeded = Math.ceil(size / 4);\n    return util.sizeToSquarishShape(texelsNeeded);\n}\nexports.getDenseTexShape = getDenseTexShape;\nfunction getMatrixSizeFromUnpackedArraySize(unpackedSize, channelsPerTexture) {\n    if (unpackedSize % channelsPerTexture !== 0) {\n        throw new Error(\"unpackedSize (\" + unpackedSize + \") must be a multiple of \" +\n            (\"\" + channelsPerTexture));\n    }\n    return unpackedSize / channelsPerTexture;\n}\nexports.getMatrixSizeFromUnpackedArraySize = getMatrixSizeFromUnpackedArraySize;\nfunction decodeMatrixFromUnpackedColorRGBAArray(unpackedArray, matrix, channels) {\n    var requiredSize = unpackedArray.length * channels / 4;\n    if (matrix.length < requiredSize) {\n        throw new Error(\"matrix length (\" + matrix.length + \") must be >= \" + requiredSize);\n    }\n    var dst = 0;\n    for (var src = 0; src < unpackedArray.length; src += 4) {\n        for (var c = 0; c < channels; c++) {\n            matrix[dst++] = unpackedArray[src + c];\n        }\n    }\n}\nexports.decodeMatrixFromUnpackedColorRGBAArray = decodeMatrixFromUnpackedColorRGBAArray;\nfunction getPackedMatrixTextureShapeWidthHeight(rows, columns) {\n    return [\n        Math.max(1, Math.ceil(columns / 2)), Math.max(1, Math.ceil(rows / 2))\n    ];\n}\nexports.getPackedMatrixTextureShapeWidthHeight = getPackedMatrixTextureShapeWidthHeight;\nfunction getPackedRGBAArraySizeFromMatrixShape(rows, columns) {\n    var _a = getPackedMatrixTextureShapeWidthHeight(rows, columns), w = _a[0], h = _a[1];\n    return w * h * 4;\n}\nexports.getPackedRGBAArraySizeFromMatrixShape = getPackedRGBAArraySizeFromMatrixShape;\nfunction getTextureConfig(\n// tslint:disable-next-line:no-any\ngl, textureHalfFloatExtension) {\n    // tslint:disable-next-line:no-any\n    var glany = gl;\n    var internalFormatFloat;\n    var internalFormatHalfFloat;\n    var internalFormatPackedHalfFloat;\n    var internalFormatPackedFloat;\n    var textureFormatFloat;\n    var downloadTextureFormat;\n    var downloadUnpackNumChannels;\n    var defaultNumChannels;\n    var textureTypeHalfFloat;\n    var textureTypeFloat;\n    if (environment_1.env().getNumber('WEBGL_VERSION') === 2) {\n        internalFormatFloat = glany.R32F;\n        internalFormatHalfFloat = glany.R16F;\n        internalFormatPackedHalfFloat = glany.RGBA16F;\n        internalFormatPackedFloat = glany.RGBA32F;\n        textureFormatFloat = glany.RED;\n        downloadUnpackNumChannels = 4;\n        defaultNumChannels = 1;\n        textureTypeHalfFloat = glany.HALF_FLOAT;\n        textureTypeFloat = glany.FLOAT;\n    }\n    else {\n        internalFormatFloat = gl.RGBA;\n        internalFormatHalfFloat = gl.RGBA;\n        internalFormatPackedHalfFloat = gl.RGBA;\n        internalFormatPackedFloat = glany.RGBA;\n        textureFormatFloat = gl.RGBA;\n        downloadUnpackNumChannels = 4;\n        defaultNumChannels = 4;\n        textureTypeHalfFloat = textureHalfFloatExtension != null ?\n            textureHalfFloatExtension.HALF_FLOAT_OES :\n            null;\n        textureTypeFloat = gl.FLOAT;\n    }\n    downloadTextureFormat = gl.RGBA;\n    return {\n        internalFormatFloat: internalFormatFloat,\n        internalFormatHalfFloat: internalFormatHalfFloat,\n        internalFormatPackedHalfFloat: internalFormatPackedHalfFloat,\n        internalFormatPackedFloat: internalFormatPackedFloat,\n        textureFormatFloat: textureFormatFloat,\n        downloadTextureFormat: downloadTextureFormat,\n        downloadUnpackNumChannels: downloadUnpackNumChannels,\n        defaultNumChannels: defaultNumChannels,\n        textureTypeHalfFloat: textureTypeHalfFloat,\n        textureTypeFloat: textureTypeFloat\n    };\n}\nexports.getTextureConfig = getTextureConfig;\n//# sourceMappingURL=tex_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/texture_manager.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/texture_manager.js ***!
  \***********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar tex_util_1 = __webpack_require__(/*! ./tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nvar TextureManager = /** @class */ (function () {\n    function TextureManager(gpgpu) {\n        this.gpgpu = gpgpu;\n        this.numUsedTextures = 0;\n        this.numFreeTextures = 0;\n        this.freeTextures = {};\n        this.logEnabled = false;\n        this.usedTextures = {};\n    }\n    TextureManager.prototype.acquireTexture = function (shapeRC, usage, isPacked) {\n        var physicalTexType = getPhysicalFromLogicalTextureType(usage, isPacked);\n        var shapeKey = getKeyFromTextureShape(shapeRC, physicalTexType, isPacked);\n        if (!(shapeKey in this.freeTextures)) {\n            this.freeTextures[shapeKey] = [];\n        }\n        if (!(shapeKey in this.usedTextures)) {\n            this.usedTextures[shapeKey] = [];\n        }\n        if (this.freeTextures[shapeKey].length > 0) {\n            this.numFreeTextures--;\n            this.numUsedTextures++;\n            this.log();\n            var newTexture_1 = this.freeTextures[shapeKey].shift();\n            this.usedTextures[shapeKey].push(newTexture_1);\n            return newTexture_1;\n        }\n        this.numUsedTextures++;\n        this.log();\n        var newTexture;\n        if (physicalTexType === tex_util_1.PhysicalTextureType.PACKED_2X2_FLOAT32) {\n            newTexture = this.gpgpu.createPackedMatrixTexture(shapeRC[0], shapeRC[1]);\n        }\n        else if (physicalTexType === tex_util_1.PhysicalTextureType.PACKED_2X2_FLOAT16) {\n            newTexture =\n                this.gpgpu.createFloat16PackedMatrixTexture(shapeRC[0], shapeRC[1]);\n        }\n        else if (physicalTexType === tex_util_1.PhysicalTextureType.UNPACKED_FLOAT32) {\n            newTexture =\n                this.gpgpu.createFloat32MatrixTexture(shapeRC[0], shapeRC[1]);\n        }\n        else if (physicalTexType === tex_util_1.PhysicalTextureType.UNPACKED_FLOAT16) {\n            newTexture =\n                this.gpgpu.createFloat16MatrixTexture(shapeRC[0], shapeRC[1]);\n        }\n        else if (physicalTexType === tex_util_1.PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE) {\n            newTexture =\n                this.gpgpu.createUnsignedBytesMatrixTexture(shapeRC[0], shapeRC[1]);\n        }\n        this.usedTextures[shapeKey].push(newTexture);\n        return newTexture;\n    };\n    TextureManager.prototype.releaseTexture = function (texture, shape, logicalTexType, isPacked) {\n        if (this.freeTextures == null) {\n            // Already disposed.\n            return;\n        }\n        var physicalTexType = getPhysicalFromLogicalTextureType(logicalTexType, isPacked);\n        var shapeKey = getKeyFromTextureShape(shape, physicalTexType, isPacked);\n        if (!(shapeKey in this.freeTextures)) {\n            this.freeTextures[shapeKey] = [];\n        }\n        this.freeTextures[shapeKey].push(texture);\n        this.numFreeTextures++;\n        this.numUsedTextures--;\n        var texList = this.usedTextures[shapeKey];\n        var texIndex = texList.indexOf(texture);\n        if (texIndex < 0) {\n            throw new Error('Cannot release a texture that was never provided by this ' +\n                'texture manager');\n        }\n        texList.splice(texIndex, 1);\n        this.log();\n    };\n    TextureManager.prototype.log = function () {\n        if (!this.logEnabled) {\n            return;\n        }\n        var total = this.numFreeTextures + this.numUsedTextures;\n        console.log('Free/Used', this.numFreeTextures + \" / \" + this.numUsedTextures, \"(\" + total + \")\");\n    };\n    TextureManager.prototype.getNumUsedTextures = function () {\n        return this.numUsedTextures;\n    };\n    TextureManager.prototype.getNumFreeTextures = function () {\n        return this.numFreeTextures;\n    };\n    TextureManager.prototype.dispose = function () {\n        var _this = this;\n        if (this.freeTextures == null) {\n            // Already disposed.\n            return;\n        }\n        for (var texShape in this.freeTextures) {\n            this.freeTextures[texShape].forEach(function (tex) {\n                _this.gpgpu.deleteMatrixTexture(tex);\n            });\n        }\n        for (var texShape in this.usedTextures) {\n            this.usedTextures[texShape].forEach(function (tex) {\n                _this.gpgpu.deleteMatrixTexture(tex);\n            });\n        }\n        this.freeTextures = null;\n        this.usedTextures = null;\n        this.numUsedTextures = 0;\n        this.numFreeTextures = 0;\n    };\n    return TextureManager;\n}());\nexports.TextureManager = TextureManager;\nfunction getPhysicalTextureForRendering(isPacked) {\n    if (environment_1.env().getBool('WEBGL_RENDER_FLOAT32_ENABLED')) {\n        if (isPacked) {\n            return tex_util_1.PhysicalTextureType.PACKED_2X2_FLOAT32;\n        }\n        return tex_util_1.PhysicalTextureType.UNPACKED_FLOAT32;\n    }\n    if (isPacked) {\n        return tex_util_1.PhysicalTextureType.PACKED_2X2_FLOAT16;\n    }\n    return tex_util_1.PhysicalTextureType.UNPACKED_FLOAT16;\n}\nfunction getPhysicalFromLogicalTextureType(logicalTexType, isPacked) {\n    if (logicalTexType === tex_util_1.TextureUsage.UPLOAD) {\n        return tex_util_1.PhysicalTextureType.PACKED_2X2_FLOAT32;\n    }\n    else if (logicalTexType === tex_util_1.TextureUsage.RENDER || logicalTexType == null) {\n        return getPhysicalTextureForRendering(isPacked);\n    }\n    else if (logicalTexType === tex_util_1.TextureUsage.DOWNLOAD ||\n        logicalTexType === tex_util_1.TextureUsage.PIXELS) {\n        return tex_util_1.PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE;\n    }\n    throw new Error(\"Unknown logical texture type \" + logicalTexType);\n}\nfunction getKeyFromTextureShape(shapeRowsCol, physicalTexType, isPacked) {\n    return shapeRowsCol[0] + \"_\" + shapeRowsCol[1] + \"_\" + physicalTexType + \"_\" + isPacked;\n}\n//# sourceMappingURL=texture_manager.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/texture_manager.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tile_gpu.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tile_gpu.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar TileProgram = /** @class */ (function () {\n    function TileProgram(aShape, reps) {\n        this.variableNames = ['A'];\n        var outputShape = new Array(aShape.length);\n        for (var i = 0; i < outputShape.length; i++) {\n            outputShape[i] = aShape[i] * reps[i];\n        }\n        this.outputShape = outputShape;\n        this.rank = outputShape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var sourceCoords = getSourceCoords(aShape);\n        this.userCode = \"\\n      void main() {\\n        \" + dtype + \" resRC = getOutputCoords();\\n        setOutput(getA(\" + sourceCoords + \"));\\n      }\\n    \";\n    }\n    return TileProgram;\n}());\nexports.TileProgram = TileProgram;\nfunction getSourceCoords(aShape) {\n    var rank = aShape.length;\n    if (rank > 5) {\n        throw Error(\"Tile for rank \" + rank + \" is not yet supported\");\n    }\n    if (rank === 1) {\n        return \"imod(resRC, \" + aShape[0] + \")\";\n    }\n    var currentCoords = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w', 'resRC.u'];\n    var sourceCoords = [];\n    for (var i = 0; i < aShape.length; i++) {\n        sourceCoords.push(\"imod(\" + currentCoords[i] + \", \" + aShape[i] + \")\");\n    }\n    return sourceCoords.join();\n}\n//# sourceMappingURL=tile_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tile_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/transpose_gpu.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/transpose_gpu.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar TransposeProgram = /** @class */ (function () {\n    function TransposeProgram(aShape, newDim) {\n        this.variableNames = ['A'];\n        var outputShape = new Array(aShape.length);\n        for (var i = 0; i < outputShape.length; i++) {\n            outputShape[i] = aShape[newDim[i]];\n        }\n        this.outputShape = outputShape;\n        this.rank = outputShape.length;\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var switched = getSwitchedCoords(newDim);\n        this.userCode = \"\\n    void main() {\\n      \" + dtype + \" resRC = getOutputCoords();\\n      setOutput(getA(\" + switched + \"));\\n    }\\n    \";\n    }\n    return TransposeProgram;\n}());\nexports.TransposeProgram = TransposeProgram;\nfunction getSwitchedCoords(newDim) {\n    var rank = newDim.length;\n    if (rank > 6) {\n        throw Error(\"Transpose for rank \" + rank + \" is not yet supported\");\n    }\n    var originalOrder = ['resRC.x', 'resRC.y', 'resRC.z', 'resRC.w', 'resRC.u', 'resRC.v'];\n    var switchedCoords = new Array(rank);\n    for (var i = 0; i < newDim.length; i++) {\n        switchedCoords[newDim[i]] = originalOrder[i];\n    }\n    return switchedCoords.join();\n}\n//# sourceMappingURL=transpose_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/transpose_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/transpose_packed_gpu.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/transpose_packed_gpu.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar packing_util_1 = __webpack_require__(/*! ../packing_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js\");\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar TransposePackedProgram = /** @class */ (function () {\n    function TransposePackedProgram(aShape, newDim) {\n        this.variableNames = ['A'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        var outputShape = new Array(aShape.length);\n        for (var i = 0; i < outputShape.length; i++) {\n            outputShape[i] = aShape[newDim[i]];\n        }\n        this.outputShape = outputShape;\n        this.rank = outputShape.length;\n        if (this.rank > 6) {\n            throw Error(\"Packed transpose for rank \" + this.rank + \" is not yet supported.\");\n        }\n        var dtype = shader_compiler_1.getCoordsDataType(this.rank);\n        var outputOrder = packing_util_1.getVecChannels('rc', this.rank);\n        var switchedOrder = new Array(this.rank);\n        for (var i = 0; i < newDim.length; i++) {\n            switchedOrder[newDim[i]] = outputOrder[i];\n        }\n        var innerDims = \"vec2(\" + switchedOrder.slice(-2).join() + \")\";\n        var nextColumn = \"++\" + outputOrder[this.rank - 1] + \" < \" + outputShape[this.rank - 1];\n        var getc = \"getChannel(getA(\" + switchedOrder.join() + \"), \" + innerDims + \")\";\n        this.userCode = \"\\n    void main() {\\n      \" + dtype + \" rc = getOutputCoords();\\n      vec4 result = vec4(0.);\\n      result[0] = \" + getc + \";\\n      if(\" + nextColumn + \") {\\n        result[1] = \" + getc + \";\\n      }\\n      --\" + outputOrder[this.rank - 1] + \";\\n      if(++\" + outputOrder[this.rank - 2] + \" < \" + outputShape[this.rank - 2] + \") {\\n        result[2] = \" + getc + \";\\n        if(\" + nextColumn + \") {\\n          result[3] = \" + getc + \";\\n        }\\n      }\\n      setOutput(result);\\n    }\\n    \";\n    }\n    return TransposePackedProgram;\n}());\nexports.TransposePackedProgram = TransposePackedProgram;\n//# sourceMappingURL=transpose_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/transpose_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_gpu.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_gpu.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar erf_util = __webpack_require__(/*! ../../ops/erf_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js\");\nvar selu_util = __webpack_require__(/*! ../../ops/selu_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js\");\nvar UnaryOpProgram = /** @class */ (function () {\n    function UnaryOpProgram(aShape, opSnippet) {\n        this.variableNames = ['A'];\n        this.outputShape = aShape;\n        this.userCode = \"\\n      float unaryOperation(float x) {\\n        \" + opSnippet + \"\\n      }\\n\\n      void main() {\\n        float x = getAAtOutCoords();\\n        float y = unaryOperation(x);\\n\\n        setOutput(y);\\n      }\\n    \";\n    }\n    return UnaryOpProgram;\n}());\nexports.UnaryOpProgram = UnaryOpProgram;\nvar CHECK_NAN_SNIPPET = \"if (isnan(x)) return x;\";\nexports.LINEAR = \"return x;\";\nexports.ABS = \"return abs(x);\";\nexports.RELU = CHECK_NAN_SNIPPET + \"\\n  return (x < 0.0) ? 0.0 : x;\\n\";\nexports.RELU6 = CHECK_NAN_SNIPPET + \"\\n  return (x < 0.0) ? 0.0 : min(6.0, x);\\n\";\nexports.ELU = \"return (x >= 0.0) ? x : (exp(x) - 1.0);\";\nexports.SELU = \"\\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\\n  // see: https://arxiv.org/abs/1706.02515\\n  float scaleAlpha = \" + selu_util.SELU_SCALEALPHA + \";\\n  float scale = \" + selu_util.SELU_SCALE + \";\\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\\n\";\nfunction STEP(alpha) {\n    if (alpha === void 0) { alpha = 0.0; }\n    return CHECK_NAN_SNIPPET + (\"\\n    return x > 0.0 ? 1.0 : float(\" + alpha + \");\\n  \");\n}\nexports.STEP = STEP;\nexports.NEG = \"return -x;\";\nexports.CEIL = \"return ceil(x);\";\nexports.FLOOR = \"return floor(x);\";\nexports.SIGN = \"\\n  if (isnan(x)) { return 0.0; }\\n  return sign(x);\\n\";\nexports.IS_NAN = \"return float(isnan(x));\";\nexports.IS_INF = \"return float(isinf(x));\";\nexports.IS_FINITE = \"return float(!isnan(x) && !isinf(x));\";\nexports.ROUND = \"\\n  // OpenGL ES does not support round function.\\n  // The algorithm is based on banker's rounding.\\n  float base = floor(x);\\n  if ((x - base) < 0.5) {\\n    return floor(x);\\n  } else if ((x - base) > 0.5) {\\n    return ceil(x);\\n  } else {\\n    if (mod(base, 2.0) == 0.0) {\\n      return base;\\n    } else {\\n      return base + 1.0;\\n    }\\n  }\\n\";\nexports.EXP = \"return exp(x);\";\nexports.EXPM1 = \"return exp(x) - 1.0;\";\nexports.LOG = \"if (x < 0.0) return NAN;\\n  return log(x);\";\nexports.LOG1P = \"return log(1.0 + x);\";\nexports.SQRT = \"return sqrt(x);\";\nexports.RSQRT = \"return inversesqrt(x);\";\nexports.SIGMOID = \"return 1.0 / (1.0 + exp(-1.0 * x));\";\n/**\n * mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n *\n * epsilon is the difference between 1.0 and the next representable\n * float. For a single precision 32 bit float this should be 2^-23, see:\n * https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\n *\n * too_large = (x > -threshold) is value above which exp(x) may overflow\n * but softplus(x) == x is within machine epsilon\n *\n * too_small = (x < threshold) is value below which exp(x) may underflow,\n * but softplus(x) == exp(x) is within machine epsilon.\n */\nexports.SOFTPLUS = \"\\n  float epsilon = 1.1920928955078125e-7;\\n  float threshold = log(epsilon) + 2.0;\\n\\n  bool too_large = x > -threshold;\\n  bool too_small = x < threshold;\\n\\n  float result;\\n  float exp_x = exp(x);\\n\\n  if (too_large){\\n    result = x;\\n  }\\n  else if (too_small){\\n    result = exp_x;\\n  }\\n  else{\\n    result = log(exp_x + 1.0);\\n  }\\n  return result;\\n\";\nexports.SIN = CHECK_NAN_SNIPPET + \"\\n  return sin(x);\\n\";\nexports.COS = CHECK_NAN_SNIPPET + \"\\n  return cos(x);\\n\";\nexports.TAN = \"return tan(x);\";\nexports.ASIN = CHECK_NAN_SNIPPET + \"\\n  if (abs(x) > 1.) {\\n    return NAN;\\n  }\\n  return asin(x);\\n\";\nexports.ACOS = CHECK_NAN_SNIPPET + \"\\n  if (abs(x) > 1.) {\\n    return NAN;\\n  }\\n  return acos(x);\\n\";\nexports.ATAN = CHECK_NAN_SNIPPET + \"\\n  return atan(x);\\n\";\nexports.SINH = \"\\n  float e2x = exp(x);\\n  return (e2x - 1.0 / e2x) / 2.0;\\n\";\nexports.COSH = \"\\n  float e2x = exp(-x);\\n  return (e2x + 1.0 / e2x) / 2.0;\\n\";\nexports.TANH = \"\\n  float e2x = exp(-2.0 * abs(x));\\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\\n\";\nexports.ASINH = CHECK_NAN_SNIPPET + \"return log(x + sqrt(x * x + 1.0));\";\nexports.ACOSH = CHECK_NAN_SNIPPET + \"\\n  if (x < 1.0) return NAN;\\n  return log(x + sqrt(x * x - 1.0));\";\nexports.ATANH = CHECK_NAN_SNIPPET + \"\\n  if ((x < -1.0) || (x > 1.0)) return NAN;\\n  return (log(1.0 + x) - log(1.0 - x)) / 2.0;\";\nexports.ERF = \"\\n  // Error function is calculated approximately with elementary function.\\n  // See \\\"Handbook of Mathematical Functions with Formulas,\\n  // Graphs, and Mathematical Tables\\\", Abramowitz and Stegun.\\n  float p = \" + erf_util.ERF_P + \";\\n  float a1 = \" + erf_util.ERF_A1 + \";\\n  float a2 = \" + erf_util.ERF_A2 + \";\\n  float a3 = \" + erf_util.ERF_A3 + \";\\n  float a4 = \" + erf_util.ERF_A4 + \";\\n  float a5 = \" + erf_util.ERF_A5 + \";\\n\\n  float sign = sign(x);\\n  x = abs(x);\\n  float t = 1.0 / (1.0 + p * x);\\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\\n\";\nexports.SQUARE = \"return x * x;\";\nexports.RECIPROCAL = \"return 1.0 / x;\";\nexports.LOGICAL_NOT = \"return float(!(x >= 1.0));\";\nexports.TO_INT = \"return float(int(x));\";\nexports.CLONE = 'return x;';\n//# sourceMappingURL=unaryop_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_packed_gpu.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_packed_gpu.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.LINEAR = \"return x;\";\nexports.LOG = \"\\n  vec4 result = log(x);\\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\\n\\n  return result;\\n\";\nexports.RELU = \"\\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\";\nexports.RELU6 = \"\\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\\n  bvec4 isNaN = isnan(x);\\n\\n  result.r = isNaN.r ? x.r : result.r;\\n  result.g = isNaN.g ? x.g : result.g;\\n  result.b = isNaN.b ? x.b : result.b;\\n  result.a = isNaN.a ? x.a : result.a;\\n\\n  return result;\\n\";\nexports.ELU = \"\\n  vec4 result;\\n\\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\\n\\n  return result;\\n\";\nvar UnaryOpPackedProgram = /** @class */ (function () {\n    function UnaryOpPackedProgram(aShape, opSnippet) {\n        this.variableNames = ['A'];\n        this.packedInputs = true;\n        this.packedOutput = true;\n        this.outputShape = aShape;\n        this.userCode = \"\\n      vec4 unaryOperation(vec4 x) {\\n        \" + opSnippet + \"\\n      }\\n\\n      void main() {\\n        vec4 x = getAAtOutCoords();\\n        vec4 y = unaryOperation(x);\\n\\n        setOutput(y);\\n      }\\n    \";\n    }\n    return UnaryOpPackedProgram;\n}());\nexports.UnaryOpPackedProgram = UnaryOpPackedProgram;\n//# sourceMappingURL=unaryop_packed_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unaryop_packed_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unpack_gpu.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unpack_gpu.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar packing_util_1 = __webpack_require__(/*! ../packing_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/packing_util.js\");\nvar shader_compiler_1 = __webpack_require__(/*! ./shader_compiler */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/shader_compiler.js\");\nvar UnpackProgram = /** @class */ (function () {\n    function UnpackProgram(outputShape) {\n        this.variableNames = ['A'];\n        this.packedInputs = true;\n        this.packedOutput = false;\n        this.outputShape = outputShape;\n        var rank = outputShape.length;\n        var channels = packing_util_1.getChannels('rc', rank);\n        var dtype = shader_compiler_1.getCoordsDataType(rank);\n        var sourceCoords = packing_util_1.getSourceCoords(rank, channels);\n        var innerDims = channels.slice(-2);\n        var coords = rank <= 1 ? 'rc' : \"vec2(\" + innerDims.join(',') + \")\";\n        this.userCode = \"\\n      void main() {\\n        \" + dtype + \" rc = getOutputCoords();\\n        vec4 packedInput = getA(\" + sourceCoords + \");\\n\\n        setOutput(getChannel(packedInput, \" + coords + \"));\\n      }\\n    \";\n    }\n    return UnpackProgram;\n}());\nexports.UnpackProgram = UnpackProgram;\n//# sourceMappingURL=unpack_gpu.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/unpack_gpu.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/webgl_util.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/webgl_util.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar util = __webpack_require__(/*! ../../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar canvas_util_1 = __webpack_require__(/*! ./canvas_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/canvas_util.js\");\nvar tex_util_1 = __webpack_require__(/*! ./tex_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/tex_util.js\");\nfunction callAndCheck(gl, debugMode, func) {\n    var returnValue = func();\n    if (debugMode) {\n        checkWebGLError(gl);\n    }\n    return returnValue;\n}\nexports.callAndCheck = callAndCheck;\nfunction checkWebGLError(gl) {\n    var error = gl.getError();\n    if (error !== gl.NO_ERROR) {\n        throw new Error('WebGL Error: ' + getWebGLErrorMessage(gl, error));\n    }\n}\n// https://en.wikipedia.org/wiki/Half-precision_floating-point_format\nvar MIN_FLOAT16 = 5.96e-8;\nvar MAX_FLOAT16 = 65504;\nfunction canBeRepresented(num) {\n    if (environment_1.env().getBool('WEBGL_RENDER_FLOAT32_ENABLED') || num === 0 ||\n        (MIN_FLOAT16 < Math.abs(num) && Math.abs(num) < MAX_FLOAT16)) {\n        return true;\n    }\n    return false;\n}\nexports.canBeRepresented = canBeRepresented;\nfunction getWebGLErrorMessage(gl, status) {\n    switch (status) {\n        case gl.NO_ERROR:\n            return 'NO_ERROR';\n        case gl.INVALID_ENUM:\n            return 'INVALID_ENUM';\n        case gl.INVALID_VALUE:\n            return 'INVALID_VALUE';\n        case gl.INVALID_OPERATION:\n            return 'INVALID_OPERATION';\n        case gl.INVALID_FRAMEBUFFER_OPERATION:\n            return 'INVALID_FRAMEBUFFER_OPERATION';\n        case gl.OUT_OF_MEMORY:\n            return 'OUT_OF_MEMORY';\n        case gl.CONTEXT_LOST_WEBGL:\n            return 'CONTEXT_LOST_WEBGL';\n        default:\n            return \"Unknown error code \" + status;\n    }\n}\nexports.getWebGLErrorMessage = getWebGLErrorMessage;\nfunction getExtensionOrThrow(gl, debug, extensionName) {\n    return throwIfNull(gl, debug, function () { return gl.getExtension(extensionName); }, 'Extension \"' + extensionName + '\" not supported on this browser.');\n}\nexports.getExtensionOrThrow = getExtensionOrThrow;\nfunction createVertexShader(gl, debug, vertexShaderSource) {\n    var vertexShader = throwIfNull(gl, debug, function () { return gl.createShader(gl.VERTEX_SHADER); }, 'Unable to create vertex WebGLShader.');\n    callAndCheck(gl, debug, function () { return gl.shaderSource(vertexShader, vertexShaderSource); });\n    callAndCheck(gl, debug, function () { return gl.compileShader(vertexShader); });\n    if (gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS) === false) {\n        console.log(gl.getShaderInfoLog(vertexShader));\n        throw new Error('Failed to compile vertex shader.');\n    }\n    return vertexShader;\n}\nexports.createVertexShader = createVertexShader;\nfunction createFragmentShader(gl, debug, fragmentShaderSource) {\n    var fragmentShader = throwIfNull(gl, debug, function () { return gl.createShader(gl.FRAGMENT_SHADER); }, 'Unable to create fragment WebGLShader.');\n    callAndCheck(gl, debug, function () { return gl.shaderSource(fragmentShader, fragmentShaderSource); });\n    callAndCheck(gl, debug, function () { return gl.compileShader(fragmentShader); });\n    if (gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS) === false) {\n        logShaderSourceAndInfoLog(fragmentShaderSource, gl.getShaderInfoLog(fragmentShader));\n        throw new Error('Failed to compile fragment shader.');\n    }\n    return fragmentShader;\n}\nexports.createFragmentShader = createFragmentShader;\nvar lineNumberRegex = /ERROR: [0-9]+:([0-9]+):/g;\nfunction logShaderSourceAndInfoLog(shaderSource, shaderInfoLog) {\n    var lineNumberRegexResult = lineNumberRegex.exec(shaderInfoLog);\n    if (lineNumberRegexResult == null) {\n        console.log(\"Couldn't parse line number in error: \" + shaderInfoLog);\n        console.log(shaderSource);\n        return;\n    }\n    var lineNumber = +lineNumberRegexResult[1];\n    var shaderLines = shaderSource.split('\\n');\n    var pad = shaderLines.length.toString().length + 2;\n    var linesWithLineNumbers = shaderLines.map(function (line, lineNumber) {\n        return util.rightPad((lineNumber + 1).toString(), pad) + line;\n    });\n    var maxLineLength = 0;\n    for (var i = 0; i < linesWithLineNumbers.length; i++) {\n        maxLineLength = Math.max(linesWithLineNumbers[i].length, maxLineLength);\n    }\n    var beforeErrorLines = linesWithLineNumbers.slice(0, lineNumber - 1);\n    var errorLine = linesWithLineNumbers.slice(lineNumber - 1, lineNumber);\n    var afterErrorLines = linesWithLineNumbers.slice(lineNumber);\n    console.log(beforeErrorLines.join('\\n'));\n    console.log(shaderInfoLog.split('\\n')[0]);\n    console.log(\"%c \" + util.rightPad(errorLine[0], maxLineLength), 'border:1px solid red; background-color:#e3d2d2; color:#a61717');\n    console.log(afterErrorLines.join('\\n'));\n}\nfunction createProgram(gl, debug) {\n    return throwIfNull(gl, debug, function () { return gl.createProgram(); }, 'Unable to create WebGLProgram.');\n}\nexports.createProgram = createProgram;\nfunction linkProgram(gl, debug, program) {\n    callAndCheck(gl, debug, function () { return gl.linkProgram(program); });\n    if (gl.getProgramParameter(program, gl.LINK_STATUS) === false) {\n        console.log(gl.getProgramInfoLog(program));\n        throw new Error('Failed to link vertex and fragment shaders.');\n    }\n}\nexports.linkProgram = linkProgram;\nfunction validateProgram(gl, debug, program) {\n    callAndCheck(gl, debug, function () { return gl.validateProgram(program); });\n    if (gl.getProgramParameter(program, gl.VALIDATE_STATUS) === false) {\n        console.log(gl.getProgramInfoLog(program));\n        throw new Error('Shader program validation failed.');\n    }\n}\nexports.validateProgram = validateProgram;\nfunction createStaticVertexBuffer(gl, debug, data) {\n    var buffer = throwIfNull(gl, debug, function () { return gl.createBuffer(); }, 'Unable to create WebGLBuffer');\n    callAndCheck(gl, debug, function () { return gl.bindBuffer(gl.ARRAY_BUFFER, buffer); });\n    callAndCheck(gl, debug, function () { return gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW); });\n    return buffer;\n}\nexports.createStaticVertexBuffer = createStaticVertexBuffer;\nfunction createStaticIndexBuffer(gl, debug, data) {\n    var buffer = throwIfNull(gl, debug, function () { return gl.createBuffer(); }, 'Unable to create WebGLBuffer');\n    callAndCheck(gl, debug, function () { return gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffer); });\n    callAndCheck(gl, debug, function () { return gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, data, gl.STATIC_DRAW); });\n    return buffer;\n}\nexports.createStaticIndexBuffer = createStaticIndexBuffer;\nfunction getNumChannels() {\n    if (environment_1.env().getNumber('WEBGL_VERSION') === 2) {\n        return 1;\n    }\n    return 4;\n}\nexports.getNumChannels = getNumChannels;\nfunction createTexture(gl, debug) {\n    return throwIfNull(gl, debug, function () { return gl.createTexture(); }, 'Unable to create WebGLTexture.');\n}\nexports.createTexture = createTexture;\nfunction validateTextureSize(width, height) {\n    var maxTextureSize = environment_1.env().getNumber('WEBGL_MAX_TEXTURE_SIZE');\n    if ((width <= 0) || (height <= 0)) {\n        var requested = \"[\" + width + \"x\" + height + \"]\";\n        throw new Error('Requested texture size ' + requested + ' is invalid.');\n    }\n    if ((width > maxTextureSize) || (height > maxTextureSize)) {\n        var requested = \"[\" + width + \"x\" + height + \"]\";\n        var max = \"[\" + maxTextureSize + \"x\" + maxTextureSize + \"]\";\n        throw new Error('Requested texture size ' + requested +\n            ' greater than WebGL maximum on this browser / GPU ' + max + '.');\n    }\n}\nexports.validateTextureSize = validateTextureSize;\nfunction createFramebuffer(gl, debug) {\n    return throwIfNull(gl, debug, function () { return gl.createFramebuffer(); }, 'Unable to create WebGLFramebuffer.');\n}\nexports.createFramebuffer = createFramebuffer;\nfunction bindVertexBufferToProgramAttribute(gl, debug, program, attribute, buffer, arrayEntriesPerItem, itemStrideInBytes, itemOffsetInBytes) {\n    var loc = gl.getAttribLocation(program, attribute);\n    if (loc === -1) {\n        // The GPU compiler decided to strip out this attribute because it's unused,\n        // thus no need to bind.\n        return false;\n    }\n    callAndCheck(gl, debug, function () { return gl.bindBuffer(gl.ARRAY_BUFFER, buffer); });\n    callAndCheck(gl, debug, function () { return gl.vertexAttribPointer(loc, arrayEntriesPerItem, gl.FLOAT, false, itemStrideInBytes, itemOffsetInBytes); });\n    callAndCheck(gl, debug, function () { return gl.enableVertexAttribArray(loc); });\n    return true;\n}\nexports.bindVertexBufferToProgramAttribute = bindVertexBufferToProgramAttribute;\nfunction bindTextureUnit(gl, debug, texture, textureUnit) {\n    validateTextureUnit(gl, textureUnit);\n    callAndCheck(gl, debug, function () { return gl.activeTexture(gl.TEXTURE0 + textureUnit); });\n    callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, texture); });\n}\nexports.bindTextureUnit = bindTextureUnit;\nfunction unbindTextureUnit(gl, debug, textureUnit) {\n    validateTextureUnit(gl, textureUnit);\n    callAndCheck(gl, debug, function () { return gl.activeTexture(gl.TEXTURE0 + textureUnit); });\n    callAndCheck(gl, debug, function () { return gl.bindTexture(gl.TEXTURE_2D, null); });\n}\nexports.unbindTextureUnit = unbindTextureUnit;\nfunction getProgramUniformLocationOrThrow(gl, debug, program, uniformName) {\n    return throwIfNull(gl, debug, function () { return gl.getUniformLocation(program, uniformName); }, 'uniform \"' + uniformName + '\" not present in program.');\n}\nexports.getProgramUniformLocationOrThrow = getProgramUniformLocationOrThrow;\nfunction getProgramUniformLocation(gl, program, uniformName) {\n    return gl.getUniformLocation(program, uniformName);\n}\nexports.getProgramUniformLocation = getProgramUniformLocation;\nfunction bindTextureToProgramUniformSampler(gl, debug, program, texture, uniformSamplerLocation, textureUnit) {\n    callAndCheck(gl, debug, function () { return bindTextureUnit(gl, debug, texture, textureUnit); });\n    callAndCheck(gl, debug, function () { return gl.uniform1i(uniformSamplerLocation, textureUnit); });\n}\nexports.bindTextureToProgramUniformSampler = bindTextureToProgramUniformSampler;\nfunction bindCanvasToFramebuffer(gl, debug) {\n    callAndCheck(gl, debug, function () { return gl.bindFramebuffer(gl.FRAMEBUFFER, null); });\n    callAndCheck(gl, debug, function () { return gl.viewport(0, 0, gl.canvas.width, gl.canvas.height); });\n    callAndCheck(gl, debug, function () { return gl.scissor(0, 0, gl.canvas.width, gl.canvas.height); });\n}\nexports.bindCanvasToFramebuffer = bindCanvasToFramebuffer;\nfunction bindColorTextureToFramebuffer(gl, debug, texture, framebuffer) {\n    callAndCheck(gl, debug, function () { return gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer); });\n    callAndCheck(gl, debug, function () { return gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0); });\n}\nexports.bindColorTextureToFramebuffer = bindColorTextureToFramebuffer;\nfunction unbindColorTextureFromFramebuffer(gl, debug, framebuffer) {\n    callAndCheck(gl, debug, function () { return gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer); });\n    callAndCheck(gl, debug, function () { return gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, null, 0); });\n}\nexports.unbindColorTextureFromFramebuffer = unbindColorTextureFromFramebuffer;\nfunction validateFramebuffer(gl) {\n    var status = gl.checkFramebufferStatus(gl.FRAMEBUFFER);\n    if (status !== gl.FRAMEBUFFER_COMPLETE) {\n        throw new Error('Error binding framebuffer: ' + getFramebufferErrorMessage(gl, status));\n    }\n}\nexports.validateFramebuffer = validateFramebuffer;\nfunction getFramebufferErrorMessage(gl, status) {\n    switch (status) {\n        case gl.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:\n            return 'FRAMEBUFFER_INCOMPLETE_ATTACHMENT';\n        case gl.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:\n            return 'FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT';\n        case gl.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:\n            return 'FRAMEBUFFER_INCOMPLETE_DIMENSIONS';\n        case gl.FRAMEBUFFER_UNSUPPORTED:\n            return 'FRAMEBUFFER_UNSUPPORTED';\n        default:\n            return \"unknown error \" + status;\n    }\n}\nexports.getFramebufferErrorMessage = getFramebufferErrorMessage;\nfunction throwIfNull(gl, debug, returnTOrNull, failureMessage) {\n    var tOrNull = callAndCheck(gl, debug, function () { return returnTOrNull(); });\n    if (tOrNull == null) {\n        throw new Error(failureMessage);\n    }\n    return tOrNull;\n}\nfunction validateTextureUnit(gl, textureUnit) {\n    var maxTextureUnit = gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1;\n    var glTextureUnit = textureUnit + gl.TEXTURE0;\n    if (glTextureUnit < gl.TEXTURE0 || glTextureUnit > maxTextureUnit) {\n        var textureUnitRange = \"[gl.TEXTURE0, gl.TEXTURE\" + maxTextureUnit + \"]\";\n        throw new Error(\"textureUnit must be in \" + textureUnitRange + \".\");\n    }\n}\nfunction getBatchDim(shape, dimsToSkip) {\n    if (dimsToSkip === void 0) { dimsToSkip = 2; }\n    return util.sizeFromShape(shape.slice(0, shape.length - dimsToSkip));\n}\nexports.getBatchDim = getBatchDim;\nfunction getRowsCols(shape) {\n    if (shape.length === 0) {\n        throw Error('Cannot get rows and columns of an empty shape array.');\n    }\n    return [\n        shape.length > 1 ? shape[shape.length - 2] : 1, shape[shape.length - 1]\n    ];\n}\nexports.getRowsCols = getRowsCols;\nfunction getShapeAs3D(shape) {\n    var shapeAs3D = [1, 1, 1];\n    var isScalar = shape.length === 0 || (shape.length === 1 && shape[0] === 1);\n    if (!isScalar) {\n        shapeAs3D =\n            [getBatchDim(shape)].concat(getRowsCols(shape));\n    }\n    return shapeAs3D;\n}\nexports.getShapeAs3D = getShapeAs3D;\nfunction getTextureShapeFromLogicalShape(logShape, isPacked) {\n    var _a;\n    if (isPacked === void 0) { isPacked = false; }\n    var maxTexSize = environment_1.env().getNumber('WEBGL_MAX_TEXTURE_SIZE');\n    if (isPacked) {\n        maxTexSize = maxTexSize * 2;\n        // This logic ensures we accurately count the number of packed texels needed\n        // to accommodate the tensor. We can only pack values in the same texel if\n        // they are from adjacent pairs of rows/cols within the same batch. So if a\n        // tensor has 3 rows, we pretend it has 4 rows in order to account for the\n        // fact that the texels containing the third row are half empty.\n        logShape = logShape.map(function (d, i) { return i >= logShape.length - 2 ?\n            util.nearestLargerEven(logShape[i]) :\n            logShape[i]; });\n        // Packed texture height is at least 2 (the channel height of a single\n        // texel).\n        if (logShape.length === 1) {\n            logShape = [2, logShape[0]];\n        }\n    }\n    // If logical shape is 2, we don't squeeze, since we want to match physical.\n    if (logShape.length !== 2) {\n        var squeezeResult = util.squeezeShape(logShape);\n        logShape = squeezeResult.newShape;\n    }\n    var size = util.sizeFromShape(logShape);\n    if (logShape.length <= 1 && size <= maxTexSize) {\n        return [1, size];\n    }\n    else if (logShape.length === 2 && logShape[0] <= maxTexSize &&\n        logShape[1] <= maxTexSize) {\n        return logShape;\n    }\n    else if (logShape.length === 3 && logShape[0] * logShape[1] <= maxTexSize &&\n        logShape[2] <= maxTexSize) {\n        return [logShape[0] * logShape[1], logShape[2]];\n    }\n    else if (logShape.length === 3 && logShape[0] <= maxTexSize &&\n        logShape[1] * logShape[2] <= maxTexSize) {\n        return [logShape[0], logShape[1] * logShape[2]];\n    }\n    else if (logShape.length === 4 &&\n        logShape[0] * logShape[1] * logShape[2] <= maxTexSize &&\n        logShape[3] <= maxTexSize) {\n        return [logShape[0] * logShape[1] * logShape[2], logShape[3]];\n    }\n    else if (logShape.length === 4 && logShape[0] <= maxTexSize &&\n        logShape[1] * logShape[2] * logShape[3] <= maxTexSize) {\n        return [logShape[0], logShape[1] * logShape[2] * logShape[3]];\n    }\n    else {\n        if (isPacked) {\n            // For packed textures size equals the number of channels required to\n            // accommodate the texture data. However in order to squarify such that\n            // inner dimensions stay even, we rewrite size to equal the number of\n            // texels. Then in the return statement we rehydrate the squarified\n            // dimensions to channel units.\n            var batchDim = getBatchDim(logShape);\n            var rows = 2, cols = 2;\n            if (logShape.length) {\n                _a = getRowsCols(logShape), rows = _a[0], cols = _a[1];\n            }\n            size = batchDim * (rows / 2) * (cols / 2);\n            return util.sizeToSquarishShape(size).map(function (d) { return d * 2; });\n        }\n        return util.sizeToSquarishShape(size);\n    }\n}\nexports.getTextureShapeFromLogicalShape = getTextureShapeFromLogicalShape;\nfunction isEven(n) {\n    return n % 2 === 0;\n}\n/**\n * This determines whether reshaping a packed texture requires rearranging\n * the data within the texture, assuming 2x2 packing.\n */\nfunction isReshapeFree(shape1, shape2) {\n    shape1 = shape1.slice(-2);\n    shape2 = shape2.slice(-2);\n    if (util.arraysEqual(shape1, shape2)) {\n        return true;\n    }\n    if (!shape1.length || !shape2.length) { // One of the shapes is a scalar.\n        return true;\n    }\n    if (shape1[0] === 0 || shape1[1] === 0 || shape2[0] === 0 ||\n        shape2[1] === 0) {\n        return true;\n    }\n    if (shape1.length !== shape2.length) { // One of the shapes is a vector.\n        var shape1Cols = shape1.slice(-1)[0];\n        var shape2Cols = shape2.slice(-1)[0];\n        if (shape1Cols === shape2Cols) {\n            return true;\n        }\n        if (isEven(shape1Cols) && isEven(shape2Cols) &&\n            (shape1[0] === 1 || shape2[0] === 1)) {\n            return true;\n        }\n    }\n    return shape1[1] === shape2[1] && isEven(shape1[0]) && isEven(shape2[0]);\n}\nexports.isReshapeFree = isReshapeFree;\n// We cache webgl params because the environment gets reset between\n// unit tests and we don't want to constantly query the WebGLContext for\n// MAX_TEXTURE_SIZE.\nvar MAX_TEXTURE_SIZE;\nvar MAX_TEXTURES_IN_SHADER;\nfunction getWebGLMaxTextureSize(webGLVersion) {\n    if (MAX_TEXTURE_SIZE == null) {\n        var gl = canvas_util_1.getWebGLContext(webGLVersion);\n        MAX_TEXTURE_SIZE = gl.getParameter(gl.MAX_TEXTURE_SIZE);\n    }\n    return MAX_TEXTURE_SIZE;\n}\nexports.getWebGLMaxTextureSize = getWebGLMaxTextureSize;\nfunction resetMaxTextureSize() {\n    MAX_TEXTURE_SIZE = null;\n}\nexports.resetMaxTextureSize = resetMaxTextureSize;\nfunction resetMaxTexturesInShader() {\n    MAX_TEXTURES_IN_SHADER = null;\n}\nexports.resetMaxTexturesInShader = resetMaxTexturesInShader;\nfunction getMaxTexturesInShader(webGLVersion) {\n    if (MAX_TEXTURES_IN_SHADER == null) {\n        var gl = canvas_util_1.getWebGLContext(webGLVersion);\n        MAX_TEXTURES_IN_SHADER = gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS);\n    }\n    // We cap at 16 to avoid spurious runtime \"memory exhausted\" error.\n    return Math.min(16, MAX_TEXTURES_IN_SHADER);\n}\nexports.getMaxTexturesInShader = getMaxTexturesInShader;\nfunction getWebGLDisjointQueryTimerVersion(webGLVersion) {\n    if (webGLVersion === 0) {\n        return 0;\n    }\n    var queryTimerVersion;\n    var gl = canvas_util_1.getWebGLContext(webGLVersion);\n    if (hasExtension(gl, 'EXT_disjoint_timer_query_webgl2') &&\n        webGLVersion === 2) {\n        queryTimerVersion = 2;\n    }\n    else if (hasExtension(gl, 'EXT_disjoint_timer_query')) {\n        queryTimerVersion = 1;\n    }\n    else {\n        queryTimerVersion = 0;\n    }\n    return queryTimerVersion;\n}\nexports.getWebGLDisjointQueryTimerVersion = getWebGLDisjointQueryTimerVersion;\nfunction hasExtension(gl, extensionName) {\n    var ext = gl.getExtension(extensionName);\n    return ext != null;\n}\nexports.hasExtension = hasExtension;\nfunction isWebGLVersionEnabled(webGLVersion) {\n    try {\n        var gl = canvas_util_1.getWebGLContext(webGLVersion);\n        if (gl != null) {\n            return true;\n        }\n    }\n    catch (e) {\n        return false;\n    }\n    return false;\n}\nexports.isWebGLVersionEnabled = isWebGLVersionEnabled;\nfunction isCapableOfRenderingToFloatTexture(webGLVersion) {\n    if (webGLVersion === 0) {\n        return false;\n    }\n    var gl = canvas_util_1.getWebGLContext(webGLVersion);\n    if (webGLVersion === 1) {\n        if (!hasExtension(gl, 'OES_texture_float')) {\n            return false;\n        }\n    }\n    else {\n        if (!hasExtension(gl, 'EXT_color_buffer_float')) {\n            return false;\n        }\n    }\n    var isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl);\n    return isFrameBufferComplete;\n}\nexports.isCapableOfRenderingToFloatTexture = isCapableOfRenderingToFloatTexture;\n/**\n * Check if we can download values from a float/half-float texture.\n *\n * Note that for performance reasons we use binding a texture to a framebuffer\n * as a proxy for ability to download float values later using readPixels. The\n * texture params of this texture will not match those in readPixels exactly\n * but if we are unable to bind some kind of float texture to the frameBuffer\n * then we definitely will not be able to read float values from it.\n */\nfunction isDownloadFloatTextureEnabled(webGLVersion) {\n    if (webGLVersion === 0) {\n        return false;\n    }\n    var gl = canvas_util_1.getWebGLContext(webGLVersion);\n    if (webGLVersion === 1) {\n        if (!hasExtension(gl, 'OES_texture_float')) {\n            return false;\n        }\n        if (!hasExtension(gl, 'WEBGL_color_buffer_float')) {\n            return false;\n        }\n    }\n    else {\n        if (hasExtension(gl, 'EXT_color_buffer_float')) {\n            return createFloatTextureAndBindToFramebuffer(gl);\n        }\n        var COLOR_BUFFER_HALF_FLOAT = 'EXT_color_buffer_half_float';\n        if (hasExtension(gl, COLOR_BUFFER_HALF_FLOAT)) {\n            var textureHalfFloatExtension = gl.getExtension(COLOR_BUFFER_HALF_FLOAT);\n            return createHalfFloatTextureAndBindToFramebuffer(gl, textureHalfFloatExtension);\n        }\n        return false;\n    }\n    var isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl);\n    return isFrameBufferComplete;\n}\nexports.isDownloadFloatTextureEnabled = isDownloadFloatTextureEnabled;\nfunction createFloatTextureAndBindToFramebuffer(gl) {\n    var texConfig = tex_util_1.getTextureConfig(gl);\n    var texture = gl.createTexture();\n    gl.bindTexture(gl.TEXTURE_2D, texture);\n    var width = 1;\n    var height = 1;\n    gl.texImage2D(gl.TEXTURE_2D, 0, texConfig.internalFormatFloat, width, height, 0, texConfig.textureFormatFloat, texConfig.textureTypeFloat, null);\n    var frameBuffer = gl.createFramebuffer();\n    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);\n    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);\n    var isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;\n    gl.bindTexture(gl.TEXTURE_2D, null);\n    gl.bindFramebuffer(gl.FRAMEBUFFER, null);\n    gl.deleteTexture(texture);\n    gl.deleteFramebuffer(frameBuffer);\n    return isFrameBufferComplete;\n}\nfunction createHalfFloatTextureAndBindToFramebuffer(\n// tslint:disable-next-line:no-any\ngl, textureHalfFloatExtension) {\n    var texConfig = tex_util_1.getTextureConfig(gl, textureHalfFloatExtension);\n    var texture = gl.createTexture();\n    gl.bindTexture(gl.TEXTURE_2D, texture);\n    var width = 1;\n    var height = 1;\n    gl.texImage2D(gl.TEXTURE_2D, 0, texConfig.internalFormatHalfFloat, width, height, 0, texConfig.textureFormatFloat, texConfig.textureTypeHalfFloat, null);\n    var frameBuffer = gl.createFramebuffer();\n    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);\n    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);\n    var isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;\n    gl.bindTexture(gl.TEXTURE_2D, null);\n    gl.bindFramebuffer(gl.FRAMEBUFFER, null);\n    gl.deleteTexture(texture);\n    gl.deleteFramebuffer(frameBuffer);\n    return isFrameBufferComplete;\n}\nfunction isWebGLFenceEnabled(webGLVersion) {\n    if (webGLVersion !== 2) {\n        return false;\n    }\n    var gl = canvas_util_1.getWebGLContext(webGLVersion);\n    // tslint:disable-next-line:no-any\n    var isEnabled = gl.fenceSync != null;\n    return isEnabled;\n}\nexports.isWebGLFenceEnabled = isWebGLFenceEnabled;\n//# sourceMappingURL=webgl_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/webgl_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js":
/*!************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** An implementation of the Where kernel shared between cpu and webgl */\nvar array_ops_1 = __webpack_require__(/*! ../ops/array_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js\");\nfunction whereImpl(condShape, condVals) {\n    var indices = [];\n    for (var i = 0; i < condVals.length; i++) {\n        if (condVals[i]) {\n            indices.push(i);\n        }\n    }\n    var inBuffer = array_ops_1.buffer(condShape, 'int32');\n    var out = array_ops_1.buffer([indices.length, condShape.length], 'int32');\n    for (var i = 0; i < indices.length; i++) {\n        var loc = inBuffer.indexToLoc(indices[i]);\n        var offset = i * condShape.length;\n        out.values.set(loc, offset);\n    }\n    return out.toTensor();\n}\nexports.whereImpl = whereImpl;\n//# sourceMappingURL=where_impl.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/browser_util.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/browser_util.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(setImmediate) {\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar delayCallback = (function () {\n    if (typeof requestAnimationFrame !== 'undefined') {\n        return requestAnimationFrame;\n    }\n    else if (typeof setImmediate !== 'undefined') {\n        return setImmediate;\n    }\n    return function (f) { return f(); }; // no delays\n})();\n/**\n * Returns a promise that resolve when a requestAnimationFrame has completed.\n *\n * On Node.js this uses setImmediate instead of requestAnimationFrame.\n *\n * This is simply a sugar method so that users can do the following:\n * `await tf.nextFrame();`\n */\n/** @doc {heading: 'Performance', subheading: 'Timing'} */\nfunction nextFrame() {\n    return new Promise(function (resolve) { return delayCallback(function () { return resolve(); }); });\n}\nexports.nextFrame = nextFrame;\n//# sourceMappingURL=browser_util.js.map\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../timers-browserify/main.js */ \"./node_modules/timers-browserify/main.js\").setImmediate))\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/browser_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/device_util.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/device_util.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction isMobile() {\n    // tslint:disable-next-line:no-any\n    var a = navigator.userAgent || navigator.vendor || window.opera;\n    // tslint:disable-next-line:max-line-length\n    return /(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i\n        .test(a) ||\n        // tslint:disable-next-line:max-line-length\n        /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i\n            .test(a.substr(0, 4));\n}\nexports.isMobile = isMobile;\nfunction isBrowser() {\n    return (typeof window !== 'undefined' && window.document != null) ||\n        //@ts-ignore\n        (typeof WorkerGlobalScope !== 'undefined');\n}\nexports.isBrowser = isBrowser;\n//# sourceMappingURL=device_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/device_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/engine.js":
/*!***********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/engine.js ***!
  \***********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(global, process) {\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ./environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar kernel_registry_1 = __webpack_require__(/*! ./kernel_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js\");\nvar profiler_1 = __webpack_require__(/*! ./profiler */ \"./node_modules/@tensorflow/tfjs-core/dist/profiler.js\");\nvar tape_1 = __webpack_require__(/*! ./tape */ \"./node_modules/@tensorflow/tfjs-core/dist/tape.js\");\nvar tensor_1 = __webpack_require__(/*! ./tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nvar tensor_util_1 = __webpack_require__(/*! ./tensor_util */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js\");\nvar util = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar util_1 = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar EngineState = /** @class */ (function () {\n    function EngineState() {\n        // Public since optimizers will use it.\n        this.registeredVariables = {};\n        this.nextTapeNodeId = 0;\n        this.numBytes = 0;\n        this.numTensors = 0;\n        this.numStringTensors = 0;\n        this.numDataBuffers = 0;\n        // Number of nested tf.grad() statements when computing higher-order\n        // gradients. E.g. `1` for first-order gradients and `2` for second-order\n        // gradients. Used to track if the tape should be removed after a backprop.\n        this.gradientDepth = 0;\n        // Number of nested kernel calls. When kernel depth is greater than 1, we turn\n        // off the tape.\n        this.kernelDepth = 0;\n        this.scopeStack = [];\n        /**\n         * Keeps track of the number of data moves during a kernel execution. We\n         * maintain a stack since kernels can call other kernels, recursively.\n         */\n        this.numDataMovesStack = [];\n        this.nextScopeId = 0;\n        this.tensorInfo = new WeakMap();\n        this.profiling = false;\n        this.activeProfile = { newBytes: 0, newTensors: 0, peakBytes: 0, kernels: [], result: null };\n    }\n    EngineState.prototype.dispose = function () {\n        for (var variableName in this.registeredVariables) {\n            this.registeredVariables[variableName].dispose();\n        }\n    };\n    return EngineState;\n}());\nvar Engine = /** @class */ (function () {\n    function Engine(ENV) {\n        this.ENV = ENV;\n        this.registry = {};\n        this.registryFactory = {};\n        this.pendingBackendInitId = 0;\n        this.state = new EngineState();\n    }\n    Engine.prototype.ready = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var sortedBackends, i, backendName, success;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (this.pendingBackendInit != null) {\n                            return [2 /*return*/, this.pendingBackendInit.then(function () { })];\n                        }\n                        if (this.backendInstance != null) {\n                            return [2 /*return*/];\n                        }\n                        sortedBackends = this.getSortedBackends();\n                        i = 0;\n                        _a.label = 1;\n                    case 1:\n                        if (!(i < sortedBackends.length)) return [3 /*break*/, 5];\n                        backendName = sortedBackends[i];\n                        return [4 /*yield*/, this.initializeBackend(backendName).success];\n                    case 2:\n                        success = _a.sent();\n                        if (!success) return [3 /*break*/, 4];\n                        return [4 /*yield*/, this.setBackend(backendName)];\n                    case 3:\n                        _a.sent();\n                        return [2 /*return*/];\n                    case 4:\n                        i++;\n                        return [3 /*break*/, 1];\n                    case 5: throw new Error(\"Could not initialize any backends, all backend initializations \" +\n                        \"failed.\");\n                }\n            });\n        });\n    };\n    Object.defineProperty(Engine.prototype, \"backend\", {\n        get: function () {\n            if (this.pendingBackendInit != null) {\n                throw new Error(\"Backend '\" + this.backendName + \"' has not yet been initialized. Make \" +\n                    \"sure to await tf.ready() or await tf.setBackend() before calling \" +\n                    \"other methods\");\n            }\n            if (this.backendInstance == null) {\n                var _a = this.initializeBackendsAndReturnBest(), name_1 = _a.name, asyncInit = _a.asyncInit;\n                if (asyncInit) {\n                    throw new Error(\"The highest priority backend '\" + name_1 + \"' has not yet been \" +\n                        \"initialized. Make sure to await tf.ready() or \" +\n                        \"await tf.setBackend() before calling other methods\");\n                }\n                this.setBackend(name_1);\n            }\n            return this.backendInstance;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Engine.prototype.backendNames = function () {\n        return Object.keys(this.registryFactory);\n    };\n    Engine.prototype.findBackend = function (backendName) {\n        if (!(backendName in this.registry)) {\n            // If the backend hasn't been initialized but we have a registry entry for\n            // it, initialize it and return it.\n            if (backendName in this.registryFactory) {\n                var asyncInit = this.initializeBackend(backendName).asyncInit;\n                if (asyncInit) {\n                    // Backend is not ready yet.\n                    return null;\n                }\n            }\n            else {\n                return null;\n            }\n        }\n        return this.registry[backendName];\n    };\n    Engine.prototype.findBackendFactory = function (backendName) {\n        if (!(backendName in this.registryFactory)) {\n            return null;\n        }\n        return this.registryFactory[backendName].factory;\n    };\n    Engine.prototype.registerBackend = function (backendName, factory, priority) {\n        if (priority === void 0) { priority = 1; }\n        if (backendName in this.registryFactory) {\n            console.warn(backendName + \" backend was already registered. \" +\n                \"Reusing existing backend factory.\");\n            return false;\n        }\n        this.registryFactory[backendName] = { factory: factory, priority: priority };\n        return true;\n    };\n    Engine.prototype.setBackend = function (backendName) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _a, success, asyncInit, result, _b;\n            return __generator(this, function (_c) {\n                switch (_c.label) {\n                    case 0:\n                        if (this.registryFactory[backendName] == null) {\n                            throw new Error(\"Backend name '\" + backendName + \"' not found in registry\");\n                        }\n                        this.backendName = backendName;\n                        if (!(this.registry[backendName] == null)) return [3 /*break*/, 4];\n                        this.backendInstance = null;\n                        _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;\n                        if (!asyncInit) return [3 /*break*/, 2];\n                        return [4 /*yield*/, success];\n                    case 1:\n                        _b = _c.sent();\n                        return [3 /*break*/, 3];\n                    case 2:\n                        _b = success;\n                        _c.label = 3;\n                    case 3:\n                        result = _b;\n                        if (!result) {\n                            return [2 /*return*/, false];\n                        }\n                        _c.label = 4;\n                    case 4:\n                        this.backendInstance = this.registry[backendName];\n                        this.setupRegisteredKernels();\n                        // Reset the profiler.\n                        this.profiler = new profiler_1.Profiler(this.backendInstance);\n                        return [2 /*return*/, true];\n                }\n            });\n        });\n    };\n    Engine.prototype.setupRegisteredKernels = function () {\n        var _this = this;\n        var kernels = kernel_registry_1.getKernelsForBackend(this.backendName);\n        kernels.forEach(function (kernel) {\n            if (kernel.setupFunc != null) {\n                kernel.setupFunc(_this.backendInstance);\n            }\n        });\n    };\n    Engine.prototype.disposeRegisteredKernels = function (backendName) {\n        var _this = this;\n        var kernels = kernel_registry_1.getKernelsForBackend(backendName);\n        kernels.forEach(function (kernel) {\n            if (kernel.disposeFunc != null) {\n                kernel.disposeFunc(_this.registry[backendName]);\n            }\n        });\n    };\n    /**\n     * Initializes a backend by looking up the backend name in the factory\n     * registry and calling the factory method. Returns a boolean representing\n     * whether the initialization of the backend suceeded. Throws an error if\n     * there is no backend in the factory registry.\n     */\n    Engine.prototype.initializeBackend = function (backendName) {\n        var _this = this;\n        var registryFactoryEntry = this.registryFactory[backendName];\n        if (registryFactoryEntry == null) {\n            throw new Error(\"Cannot initialize backend \" + backendName + \", no registration found.\");\n        }\n        try {\n            var backend = registryFactoryEntry.factory();\n            // Test if the factory returns a promise.\n            if (Promise.resolve(backend) === backend) {\n                var promiseId_1 = ++this.pendingBackendInitId;\n                var success = backend\n                    .then(function (backendInstance) {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId_1 < _this.pendingBackendInitId) {\n                        return false;\n                    }\n                    _this.registry[backendName] = backendInstance;\n                    _this.pendingBackendInit = null;\n                    return true;\n                })\n                    .catch(function (err) {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId_1 < _this.pendingBackendInitId) {\n                        return false;\n                    }\n                    _this.pendingBackendInit = null;\n                    console.warn(\"Initialization of backend \" + backendName + \" failed\");\n                    console.warn(err.stack || err.message);\n                    return false;\n                });\n                this.pendingBackendInit = success;\n                return { success: success, asyncInit: true };\n            }\n            else {\n                this.registry[backendName] = backend;\n                return { success: true, asyncInit: false };\n            }\n        }\n        catch (err) {\n            console.warn(\"Initialization of backend \" + backendName + \" failed\");\n            console.warn(err.stack || err.message);\n            return { success: false, asyncInit: false };\n        }\n    };\n    Engine.prototype.removeBackend = function (backendName) {\n        if (!(backendName in this.registryFactory)) {\n            throw new Error(backendName + \" backend not found in registry\");\n        }\n        if (this.backendName === backendName && this.pendingBackendInit != null) {\n            // There is a pending promise of the backend we want to remove. Make it\n            // obsolete.\n            this.pendingBackendInitId++;\n        }\n        if (backendName in this.registry) {\n            this.disposeRegisteredKernels(backendName);\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        delete this.registryFactory[backendName];\n        // Unset the backend if it is active.\n        if (this.backendName === backendName) {\n            this.pendingBackendInit = null;\n            this.backendName = null;\n            this.backendInstance = null;\n        }\n    };\n    Engine.prototype.getSortedBackends = function () {\n        var _this = this;\n        if (Object.keys(this.registryFactory).length === 0) {\n            throw new Error('No backend found in registry.');\n        }\n        return Object.keys(this.registryFactory).sort(function (a, b) {\n            // Highest priority comes first.\n            return _this.registryFactory[b].priority -\n                _this.registryFactory[a].priority;\n        });\n    };\n    Engine.prototype.initializeBackendsAndReturnBest = function () {\n        var sortedBackends = this.getSortedBackends();\n        for (var i = 0; i < sortedBackends.length; i++) {\n            var backendName = sortedBackends[i];\n            var _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;\n            if (asyncInit || success) {\n                return { name: backendName, asyncInit: asyncInit };\n            }\n        }\n        throw new Error(\"Could not initialize any backends, all backend initializations \" +\n            \"failed.\");\n    };\n    Engine.prototype.moveData = function (destBackend, dataId) {\n        var info = this.state.tensorInfo.get(dataId);\n        var srcBackend = info.backend;\n        var values = this.readSync(dataId);\n        // Delete the tensor from the old backend and move it to the new\n        // backend.\n        srcBackend.disposeData(dataId);\n        info.backend = destBackend;\n        destBackend.move(dataId, values, info.shape, info.dtype);\n        if (this.shouldCheckForMemLeaks()) {\n            // Track the number of moves during a kernel execution to correctly\n            // detect memory leaks.\n            this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;\n        }\n    };\n    Engine.prototype.tidy = function (nameOrFn, fn) {\n        var _this = this;\n        var name = null;\n        if (fn == null) {\n            // Called with only 1 argument.\n            if (typeof nameOrFn !== 'function') {\n                throw new Error('Please provide a function to tidy()');\n            }\n            fn = nameOrFn;\n        }\n        else {\n            // Called with 2 arguments.\n            if (typeof nameOrFn !== 'string' && !(nameOrFn instanceof String)) {\n                throw new Error('When calling with two arguments, the first argument ' +\n                    'to tidy() must be a string');\n            }\n            if (typeof fn !== 'function') {\n                throw new Error('When calling with two arguments, the 2nd argument ' +\n                    'to tidy() must be a function');\n            }\n            name = nameOrFn;\n            // TODO(nsthorat,smilkov): Do operation logging and performance\n            // profiling.\n        }\n        var result;\n        return this.scopedRun(function () { return _this.startScope(name); }, function () { return _this.endScope(result); }, function () {\n            result = fn();\n            if (result instanceof Promise) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            return result;\n        });\n    };\n    Engine.prototype.scopedRun = function (start, end, f) {\n        start();\n        try {\n            var res = f();\n            end();\n            return res;\n        }\n        catch (ex) {\n            end();\n            throw ex;\n        }\n    };\n    Engine.prototype.nextTensorId = function () {\n        return Engine.nextTensorId++;\n    };\n    Engine.prototype.nextVariableId = function () {\n        return Engine.nextVariableId++;\n    };\n    /**\n     * This method is called instead of the public-facing tensor.clone() when\n     * saving a tensor for backwards pass. It makes sure to add the clone\n     * operation to the tape regardless of being called inside a kernel\n     * execution.\n     *\n     * This method will go away once all kernels are modularized since we won't\n     * need to turn off the tape inside runKernel().\n     */\n    Engine.prototype.clone = function (x) {\n        var y = this.makeTensorFromDataId(x.dataId, x.shape, x.dtype);\n        var inputs = { x: x };\n        var grad = function (dy) { return ({ x: function () { return dy.toFloat(); } }); };\n        var saved = [];\n        this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved);\n        return y;\n    };\n    /**\n     * Execute a kernel with the given name and return the output tensor.\n     *\n     * @param kernelName The name of the kernel to execute.\n     * @param inputs A map of input names to tensors.\n     * @param attrs A map of attribute names to their values. An attribute is a\n     *     primitive (non-tensor) input to the kernel.\n     * @param inputsToSave A list of tensors, inputs to save for the backprop\n     *     computation.\n     * @param outputsToSave A list of booleans, specifying which output to save\n     *     for the backprop computation. These are booleans since the output\n     * tensors are not visible to the user.\n     */\n    Engine.prototype.runKernel = function (kernelName, inputs, attrs, inputsToSave, outputsToSave) {\n        var forwardFunc = null;\n        var backwardsFunc = null;\n        // Call runKernel as a stop-gap until we modularize all kernels.\n        // Once we modularize all kernels, we will remove the existing\n        // `runKernelFunc`.\n        return this.runKernelFunc(forwardFunc, inputs, backwardsFunc, kernelName, attrs, inputsToSave, outputsToSave);\n    };\n    Engine.prototype.shouldCheckForMemLeaks = function () {\n        return this.ENV.getBool('IS_TEST');\n    };\n    Engine.prototype.checkKernelForMemLeak = function (kernelName, numDataIdsBefore, outInfos) {\n        var numDataIdsAfter = this.backend.numDataIds();\n        // Count the number of data ids associated with the result of the kernel.\n        var numOutputDataIds = 0;\n        outInfos.forEach(function (info) {\n            // Complex numbers allocate 3 data ids, one for 'real', one for\n            // 'imaginary', and one for the container that holds the former two.\n            numOutputDataIds += (info.dtype === 'complex64' ? 3 : 1);\n        });\n        // Account for the number of moves during kernel execution. A \"data move\"\n        // can happen in the middle of a kernel execution, placing a new (key,value)\n        // pair in the data storage. Since data moves have net zero effect (we\n        // always remove the data from the old backend), we have to cancel them out\n        // when detecting memory leaks.\n        var numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];\n        var dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;\n        if (dataIdsLeaked > 0) {\n            throw new Error(\"Backend '\" + this.backendName + \"' has an internal memory leak \" +\n                (\"(\" + dataIdsLeaked + \" data ids) after running '\" + kernelName + \"'\"));\n        }\n    };\n    /**\n     * @deprecated Use `runKernel` for newly added kernels. Keep using this method\n     *     only for kernels that are not yet fully modularized.\n     */\n    Engine.prototype.runKernelFunc = function (forwardFunc, inputs, backwardsFunc, kernelName, attrs, inputsToSave, outputsToSave) {\n        var _this = this;\n        if (inputsToSave === void 0) { inputsToSave = []; }\n        if (outputsToSave === void 0) { outputsToSave = []; }\n        var outputs;\n        var saved = [];\n        var isTapeOn = this.isTapeOn();\n        if (kernelName == null) {\n            kernelName =\n                this.state.activeScope != null ? this.state.activeScope.name : '';\n        }\n        var saveFunc = function (tensors) {\n            // Do not save unless we are recording to the tape. Otherwise it would\n            // cause a mem leak since we would never run backprop, which disposes\n            // the kept tensors.\n            if (!isTapeOn) {\n                return;\n            }\n            saved = tensors.map(function (tensor) { return _this.keep(_this.clone(tensor)); });\n        };\n        var startingBytecount = this.state.numBytes;\n        var startingNumTensors = this.state.numTensors;\n        if (this.shouldCheckForMemLeaks()) {\n            this.state.numDataMovesStack.push(0);\n        }\n        var kernelFunc;\n        var kernel = kernel_registry_1.getKernel(kernelName, this.backendName);\n        var out;\n        if (kernel != null) {\n            kernelFunc = function () {\n                var numDataIdsBefore = _this.backend.numDataIds();\n                out = kernel.kernelFunc({ inputs: inputs, attrs: attrs, backend: _this.backend });\n                var outInfos = Array.isArray(out) ? out : [out];\n                if (_this.shouldCheckForMemLeaks()) {\n                    _this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);\n                }\n                var outTensors = outInfos.map(function (_a) {\n                    var dataId = _a.dataId, shape = _a.shape, dtype = _a.dtype;\n                    return _this.makeTensorFromDataId(dataId, shape, dtype);\n                });\n                var outsToSave = outTensors.filter(function (_, i) { return outputsToSave[i]; });\n                // Save the inputs and outputs.\n                saveFunc((inputsToSave || []).slice().concat(outsToSave));\n                return outTensors;\n            };\n        }\n        else {\n            kernelFunc = function () {\n                var numDataIdsBefore = _this.backend.numDataIds();\n                out = _this.tidy(function () { return forwardFunc(_this.backend, saveFunc); });\n                var outs = (Array.isArray(out) ? out : [out]);\n                if (_this.shouldCheckForMemLeaks()) {\n                    _this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outs);\n                }\n                return outs;\n            };\n        }\n        // Stop recording to a tape when running a kernel.\n        this.scopedRun(function () { return _this.state.kernelDepth++; }, function () { return _this.state.kernelDepth--; }, function () {\n            if (!_this.ENV.getBool('DEBUG')) {\n                outputs = kernelFunc();\n            }\n            else {\n                outputs = _this.profiler.profileKernel(kernelName, inputs, function () { return kernelFunc(); });\n            }\n        });\n        if (isTapeOn) {\n            this.addTapeNode(kernelName, inputs, outputs, backwardsFunc, saved);\n        }\n        if (this.state.profiling) {\n            this.state.activeProfile.kernels.push({\n                name: kernelName,\n                bytesAdded: this.state.numBytes - startingBytecount,\n                totalBytesSnapshot: this.state.numBytes,\n                tensorsAdded: this.state.numTensors - startingNumTensors,\n                totalTensorsSnapshot: this.state.numTensors,\n                inputShapes: Object.keys(inputs).map(function (key) { return inputs[key].shape; }),\n                outputShapes: outputs.map(function (item) { return item.shape; })\n            });\n        }\n        return (Array.isArray(out) ? outputs : outputs[0]);\n    };\n    /**\n     * Internal method used by public APIs for tensor creation. Makes a new\n     * tensor with the provided shape, dtype and values. It always\n     * creates a new data id and writes the values to the underlying backend.\n     */\n    Engine.prototype.makeTensor = function (values, shape, dtype, backend) {\n        if (values == null) {\n            throw new Error('Values passed to engine.makeTensor() are null');\n        }\n        dtype = dtype || 'float32';\n        backend = backend || this.backend;\n        var backendVals = values;\n        if (dtype === 'string' && util.isString(values[0])) {\n            backendVals = values.map(function (d) { return util.encodeString(d); });\n        }\n        var dataId = backend.write(backendVals, shape, dtype);\n        var t = new tensor_1.Tensor(shape, dtype, dataId, this.nextTensorId());\n        this.incRef(t, backend);\n        // Count bytes for string tensors.\n        if (dtype === 'string') {\n            var info = this.state.tensorInfo.get(dataId);\n            var newBytes = util_1.bytesFromStringArray(backendVals);\n            this.state.numBytes += newBytes - info.bytes;\n            info.bytes = newBytes;\n        }\n        return t;\n    };\n    /**\n     * Internal method used by backends. Makes a new tensor\n     * that is a wrapper around an existing data id. It doesn't create\n     * a new data id, only increments the ref count used in memory tracking.\n     */\n    Engine.prototype.makeTensorFromDataId = function (dataId, shape, dtype, backend) {\n        dtype = dtype || 'float32';\n        var t = new tensor_1.Tensor(shape, dtype, dataId, this.nextTensorId());\n        this.incRef(t, backend);\n        return t;\n    };\n    Engine.prototype.makeVariable = function (initialValue, trainable, name, dtype) {\n        if (trainable === void 0) { trainable = true; }\n        name = name || this.nextVariableId().toString();\n        if (dtype != null && dtype !== initialValue.dtype) {\n            initialValue = initialValue.asType(dtype);\n        }\n        var v = new tensor_1.Variable(initialValue, trainable, name, this.nextTensorId());\n        if (this.state.registeredVariables[v.name] != null) {\n            throw new Error(\"Variable with name \" + v.name + \" was already registered\");\n        }\n        this.state.registeredVariables[v.name] = v;\n        this.incRef(v, this.backend);\n        return v;\n    };\n    Engine.prototype.incRef = function (a, backend) {\n        var refCount = this.state.tensorInfo.has(a.dataId) ?\n            this.state.tensorInfo.get(a.dataId).refCount :\n            0;\n        this.state.numTensors++;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors++;\n        }\n        if (refCount === 0) {\n            this.state.numDataBuffers++;\n            // Bytes for complex numbers are counted by their components. Bytes for\n            // string tensors are counted when writing values.\n            var bytes = 0;\n            if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n                bytes = a.size * util.bytesPerElement(a.dtype);\n            }\n            this.state.tensorInfo.set(a.dataId, {\n                backend: backend || this.backend,\n                dtype: a.dtype,\n                shape: a.shape,\n                bytes: bytes,\n                refCount: 0\n            });\n            this.state.numBytes += bytes;\n        }\n        this.state.tensorInfo.get(a.dataId).refCount++;\n        if (!(a instanceof tensor_1.Variable)) {\n            this.track(a);\n        }\n    };\n    Engine.prototype.disposeTensor = function (a) {\n        if (!this.state.tensorInfo.has(a.dataId)) {\n            return;\n        }\n        this.state.numTensors--;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors--;\n        }\n        var info = this.state.tensorInfo.get(a.dataId);\n        var refCount = info.refCount;\n        if (refCount <= 1) {\n            // Don't count bytes for complex numbers as they are counted by their\n            // components.\n            if (a.dtype !== 'complex64') {\n                this.state.numBytes -= info.bytes;\n            }\n            this.state.numDataBuffers--;\n            info.backend.disposeData(a.dataId);\n            this.state.tensorInfo.delete(a.dataId);\n        }\n        else {\n            this.state.tensorInfo.get(a.dataId).refCount--;\n        }\n        // TODO(nsthorat): Construct an error and save the stack trace for\n        // debugging when in debug mode. Creating a stack trace is too expensive\n        // to do unconditionally.\n    };\n    Engine.prototype.disposeVariables = function () {\n        for (var varName in this.state.registeredVariables) {\n            var v = this.state.registeredVariables[varName];\n            this.disposeVariable(v);\n        }\n    };\n    Engine.prototype.disposeVariable = function (v) {\n        this.disposeTensor(v);\n        if (this.state.registeredVariables[v.name] != null) {\n            delete this.state.registeredVariables[v.name];\n        }\n    };\n    Engine.prototype.memory = function () {\n        var info = this.backend.memory();\n        info.numTensors = this.state.numTensors;\n        info.numDataBuffers = this.state.numDataBuffers;\n        info.numBytes = this.state.numBytes;\n        if (this.state.numStringTensors > 0) {\n            info.unreliable = true;\n            if (info.reasons == null) {\n                info.reasons = [];\n            }\n            info.reasons.push('Memory usage by string tensors is approximate ' +\n                '(2 bytes per character)');\n        }\n        return info;\n    };\n    Engine.prototype.profile = function (query) {\n        return __awaiter(this, void 0, void 0, function () {\n            var startBytes, startNumTensors;\n            return __generator(this, function (_a) {\n                this.state.profiling = true;\n                startBytes = this.state.numBytes;\n                startNumTensors = this.state.numTensors;\n                this.state.activeProfile.kernels = [];\n                this.state.activeProfile.result = query();\n                this.state.profiling = false;\n                this.state.activeProfile.peakBytes = Math.max.apply(Math, this.state.activeProfile.kernels.map(function (d) { return d.totalBytesSnapshot; }));\n                this.state.activeProfile.newBytes = this.state.numBytes - startBytes;\n                this.state.activeProfile.newTensors =\n                    this.state.numTensors - startNumTensors;\n                return [2 /*return*/, this.state.activeProfile];\n            });\n        });\n    };\n    Engine.prototype.isTapeOn = function () {\n        return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;\n    };\n    Engine.prototype.addTapeNode = function (kernelName, inputs, outputs, gradientsFunc, saved) {\n        var _this = this;\n        var tapeNode = { id: this.state.nextTapeNodeId++, kernelName: kernelName, inputs: inputs, outputs: outputs, saved: saved };\n        var gradConfig = kernel_registry_1.getGradient(kernelName);\n        if (gradConfig != null) {\n            gradientsFunc = gradConfig.gradFunc;\n        }\n        if (gradientsFunc != null) {\n            tapeNode.gradient = function (dys) {\n                // TODO(smilkov): To optimize back-prop, pass dys that are not used in\n                // the backprop graph to the user as null instead of zeros\n                dys = dys.map(function (dy, i) {\n                    if (dy == null) {\n                        var output = outputs[i];\n                        var vals = util.makeZerosTypedArray(output.size, output.dtype);\n                        return _this.makeTensor(vals, output.shape, output.dtype);\n                    }\n                    return dy;\n                });\n                // Grad functions of ops with single outputs expect a dy, while ops\n                // with multiple outputs expect dys (array of dy).\n                return gradientsFunc(dys.length > 1 ? dys : dys[0], saved);\n            };\n        }\n        this.state.activeTape.push(tapeNode);\n    };\n    Engine.prototype.keep = function (result) {\n        result.kept = true;\n        return result;\n    };\n    Engine.prototype.startTape = function () {\n        if (this.state.gradientDepth === 0) {\n            this.state.activeTape = [];\n        }\n        this.state.gradientDepth++;\n    };\n    Engine.prototype.endTape = function () {\n        this.state.gradientDepth--;\n    };\n    /**\n     * Start a scope. Use this with endScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    Engine.prototype.startScope = function (name) {\n        var scopeInfo = {\n            track: [],\n            name: 'unnamed scope',\n            id: this.state.nextScopeId++\n        };\n        if (name) {\n            scopeInfo.name = name;\n        }\n        this.state.scopeStack.push(scopeInfo);\n        this.state.activeScope = scopeInfo;\n    };\n    /**\n     * End a scope. Use this with startScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    Engine.prototype.endScope = function (result) {\n        var _this = this;\n        var tensorsToTrackInParent = tensor_util_1.getTensorsInContainer(result);\n        var tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map(function (t) { return t.id; }));\n        // Dispose the arrays tracked in this scope.\n        for (var i = 0; i < this.state.activeScope.track.length; i++) {\n            var tensor = this.state.activeScope.track[i];\n            if (!tensor.kept && !tensorsToTrackInParentSet.has(tensor.id)) {\n                tensor.dispose();\n            }\n        }\n        var oldScope = this.state.scopeStack.pop();\n        this.state.activeScope = this.state.scopeStack.length === 0 ?\n            null :\n            this.state.scopeStack[this.state.scopeStack.length - 1];\n        // Track the current result in the parent scope.\n        tensorsToTrackInParent.forEach(function (tensor) {\n            // Only track the tensor if was allocated in the inner scope and is not\n            // globally kept.\n            if (!tensor.kept && tensor.scopeId === oldScope.id) {\n                _this.track(tensor);\n            }\n        });\n    };\n    /**\n     * Returns gradients of `f` with respect to each of the `xs`. The gradients\n     * returned are of the same length as `xs`, but some might be null if `f`\n     * was not a function of that `x`. It also takes optional dy to multiply the\n     * gradient, which defaults to `1`.\n     */\n    Engine.prototype.gradients = function (f, xs, dy, allowNoGradients) {\n        var _this = this;\n        if (allowNoGradients === void 0) { allowNoGradients = false; }\n        util.assert(xs.length > 0, function () { return 'gradients() received an empty list of xs.'; });\n        if (dy != null && dy.dtype !== 'float32') {\n            throw new Error(\"dy must have 'float32' dtype, but has '\" + dy.dtype + \"'\");\n        }\n        var y = this.scopedRun(function () { return _this.startTape(); }, function () { return _this.endTape(); }, function () { return _this.tidy('forward', f); });\n        util.assert(y instanceof tensor_1.Tensor, function () { return 'The result y returned by f() must be a tensor.'; });\n        // Filter out the nodes that don't connect x => y.\n        var filteredTape = tape_1.getFilteredNodesXToY(this.state.activeTape, xs, y);\n        if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {\n            throw new Error('Cannot compute gradient of y=f(x) with respect to x. Make sure ' +\n                'that the f you passed encloses all operations that lead from x ' +\n                'to y.');\n        }\n        return this.tidy('backward', function () {\n            var accumulatedGradientMap = {};\n            accumulatedGradientMap[y.id] = (dy == null) ? ones(y.shape) : dy;\n            // Backprop gradients through the filtered nodes.\n            tape_1.backpropagateGradients(accumulatedGradientMap, filteredTape, \n            // Pass the tidy function to avoid circular dep with `tape.ts`.\n            function (f) { return _this.tidy(f); });\n            var grads = xs.map(function (x) { return accumulatedGradientMap[x.id]; });\n            if (_this.state.gradientDepth === 0) {\n                // This means that we are not computing higher-order gradients\n                // and can clean up the tape.\n                _this.state.activeTape.forEach(function (node) {\n                    for (var _i = 0, _a = node.saved; _i < _a.length; _i++) {\n                        var tensor = _a[_i];\n                        tensor.dispose();\n                    }\n                });\n                _this.state.activeTape = null;\n            }\n            return { value: y, grads: grads };\n        });\n    };\n    Engine.prototype.customGrad = function (f) {\n        var _this = this;\n        util.assert(util.isFunction(f), function () { return 'The f passed in customGrad(f) must be a function.'; });\n        return function () {\n            var inputs = [];\n            for (var _i = 0; _i < arguments.length; _i++) {\n                inputs[_i] = arguments[_i];\n            }\n            util.assert(inputs.every(function (t) { return t instanceof tensor_1.Tensor; }), function () { return 'The args passed in customGrad(f)(x1, x2,...) must all be ' +\n                'tensors'; });\n            var res;\n            var inputMap = {};\n            inputs.forEach(function (input, i) {\n                inputMap[i] = input;\n            });\n            return _this.runKernelFunc(function (_, save) {\n                res = f.apply(void 0, inputs.concat([save]));\n                util.assert(res.value instanceof tensor_1.Tensor, function () { return 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.value` is a tensor'; });\n                util.assert(util.isFunction(res.gradFunc), function () { return 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function.'; });\n                return res.value;\n            }, inputMap, function (dy, saved) {\n                var gradRes = res.gradFunc(dy, saved);\n                var grads = Array.isArray(gradRes) ? gradRes : [gradRes];\n                util.assert(grads.length === inputs.length, function () { return 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'the same number of tensors as inputs passed to f(...).'; });\n                util.assert(grads.every(function (t) { return t instanceof tensor_1.Tensor; }), function () { return 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'a list of only tensors.'; });\n                var gradMap = {};\n                grads.forEach(function (grad, i) {\n                    gradMap[i] = function () { return grad; };\n                });\n                return gradMap;\n            });\n        };\n    };\n    Engine.prototype.readSync = function (dataId) {\n        // Route the read to the correct backend.\n        var info = this.state.tensorInfo.get(dataId);\n        return info.backend.readSync(dataId);\n    };\n    Engine.prototype.read = function (dataId) {\n        // Route the read to the correct backend.\n        var info = this.state.tensorInfo.get(dataId);\n        return info.backend.read(dataId);\n    };\n    Engine.prototype.time = function (query) {\n        return __awaiter(this, void 0, void 0, function () {\n            var start, timingInfo;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        start = util_1.now();\n                        return [4 /*yield*/, this.backend.time(query)];\n                    case 1:\n                        timingInfo = _a.sent();\n                        timingInfo.wallMs = util_1.now() - start;\n                        return [2 /*return*/, timingInfo];\n                }\n            });\n        });\n    };\n    /**\n     * Tracks a Tensor in the current scope to be automatically cleaned up\n     * when the current scope ends, and returns the value.\n     *\n     * @param result The Tensor to track in the current scope.\n     */\n    Engine.prototype.track = function (result) {\n        if (this.state.activeScope != null) {\n            result.scopeId = this.state.activeScope.id;\n            this.state.activeScope.track.push(result);\n        }\n        return result;\n    };\n    Object.defineProperty(Engine.prototype, \"registeredVariables\", {\n        get: function () {\n            return this.state.registeredVariables;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    /**\n     * Resets the engine state. Removes all backends but does not remove\n     * registered backend factories.\n     */\n    Engine.prototype.reset = function () {\n        // Make any pending promise obsolete.\n        this.pendingBackendInitId++;\n        this.state.dispose();\n        this.ENV.reset();\n        this.state = new EngineState();\n        for (var backendName in this.registry) {\n            this.disposeRegisteredKernels(backendName);\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        this.backendName = null;\n        this.backendInstance = null;\n        this.pendingBackendInit = null;\n    };\n    Engine.nextTensorId = 0;\n    Engine.nextVariableId = 0;\n    return Engine;\n}());\nexports.Engine = Engine;\nfunction ones(shape) {\n    var values = util_1.makeOnesTypedArray(util_1.sizeFromShape(shape), 'float32');\n    return exports.ENGINE.makeTensor(values, shape, 'float32');\n}\nvar GLOBAL;\nfunction getGlobalNamespace() {\n    if (GLOBAL == null) {\n        // tslint:disable-next-line:no-any\n        var ns = void 0;\n        if (typeof (window) !== 'undefined') {\n            ns = window;\n        }\n        else if (typeof (global) !== 'undefined') {\n            ns = global;\n        }\n        else if (typeof (process) !== 'undefined') {\n            ns = process;\n        }\n        else if (typeof (self) !== 'undefined') {\n            ns = self;\n        }\n        else {\n            throw new Error('Could not find a global object');\n        }\n        GLOBAL = ns;\n    }\n    return GLOBAL;\n}\nfunction getOrMakeEngine() {\n    var ns = getGlobalNamespace();\n    if (ns._tfengine == null) {\n        var environment = new environment_1.Environment(ns);\n        ns._tfengine = new Engine(environment);\n    }\n    environment_1.setEnvironmentGlobal(ns._tfengine.ENV);\n    // Tell the current tensor interface that the global engine is responsible\n    // for tracking.\n    tensor_1.setTensorTracker(function () { return ns._tfengine; });\n    return ns._tfengine;\n}\nexports.ENGINE = getOrMakeEngine();\n//# sourceMappingURL=engine.js.map\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\"), __webpack_require__(/*! ./../../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/engine.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/environment.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/environment.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Expects flags from URL in the format ?tfjsflags=FLAG1:1,FLAG2:true.\nvar TENSORFLOWJS_FLAGS_PREFIX = 'tfjsflags';\n/**\n * The environment contains evaluated flags as well as the registered platform.\n * This is always used as a global singleton and can be retrieved with\n * `tf.env()`.\n */\n/** @doc {heading: 'Environment'} */\nvar Environment = /** @class */ (function () {\n    // tslint:disable-next-line: no-any\n    function Environment(global) {\n        this.global = global;\n        this.flags = {};\n        this.flagRegistry = {};\n        this.urlFlags = {};\n        this.populateURLFlags();\n    }\n    Environment.prototype.setPlatform = function (platformName, platform) {\n        if (this.platform != null) {\n            console.warn(\"Platform \" + this.platformName + \" has already been set. \" +\n                (\"Overwriting the platform with \" + platform + \".\"));\n        }\n        this.platformName = platformName;\n        this.platform = platform;\n    };\n    Environment.prototype.registerFlag = function (flagName, evaluationFn, setHook) {\n        this.flagRegistry[flagName] = { evaluationFn: evaluationFn, setHook: setHook };\n        // Override the flag value from the URL. This has to happen here because the\n        // environment is initialized before flags get registered.\n        if (this.urlFlags[flagName] != null) {\n            var flagValue = this.urlFlags[flagName];\n            console.warn(\"Setting feature override from URL \" + flagName + \": \" + flagValue + \".\");\n            this.set(flagName, flagValue);\n        }\n    };\n    Environment.prototype.get = function (flagName) {\n        if (flagName in this.flags) {\n            return this.flags[flagName];\n        }\n        this.flags[flagName] = this.evaluateFlag(flagName);\n        return this.flags[flagName];\n    };\n    Environment.prototype.getNumber = function (flagName) {\n        return this.get(flagName);\n    };\n    Environment.prototype.getBool = function (flagName) {\n        return this.get(flagName);\n    };\n    Environment.prototype.getFlags = function () {\n        return this.flags;\n    };\n    Object.defineProperty(Environment.prototype, \"features\", {\n        // For backwards compatibility.\n        get: function () {\n            return this.flags;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Environment.prototype.set = function (flagName, value) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(\"Cannot set flag \" + flagName + \" as it has not been registered.\");\n        }\n        this.flags[flagName] = value;\n        if (this.flagRegistry[flagName].setHook != null) {\n            this.flagRegistry[flagName].setHook(value);\n        }\n    };\n    Environment.prototype.evaluateFlag = function (flagName) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(\"Cannot evaluate flag '\" + flagName + \"': no evaluation function found.\");\n        }\n        return this.flagRegistry[flagName].evaluationFn();\n    };\n    Environment.prototype.setFlags = function (flags) {\n        this.flags = Object.assign({}, flags);\n    };\n    Environment.prototype.reset = function () {\n        this.flags = {};\n        this.urlFlags = {};\n        this.populateURLFlags();\n    };\n    Environment.prototype.populateURLFlags = function () {\n        var _this = this;\n        if (typeof this.global === 'undefined' ||\n            typeof this.global.location === 'undefined' ||\n            typeof this.global.location.search === 'undefined') {\n            return;\n        }\n        var urlParams = getQueryParams(this.global.location.search);\n        if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {\n            var keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(',');\n            keyValues.forEach(function (keyValue) {\n                var _a = keyValue.split(':'), key = _a[0], value = _a[1];\n                _this.urlFlags[key] = parseValue(key, value);\n            });\n        }\n    };\n    return Environment;\n}());\nexports.Environment = Environment;\nfunction getQueryParams(queryString) {\n    var params = {};\n    queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, function (s) {\n        var t = [];\n        for (var _i = 1; _i < arguments.length; _i++) {\n            t[_i - 1] = arguments[_i];\n        }\n        decodeParam(params, t[0], t[1]);\n        return t.join('=');\n    });\n    return params;\n}\nexports.getQueryParams = getQueryParams;\nfunction decodeParam(params, name, value) {\n    params[decodeURIComponent(name)] = decodeURIComponent(value || '');\n}\nfunction parseValue(flagName, value) {\n    value = value.toLowerCase();\n    if (value === 'true' || value === 'false') {\n        return value === 'true';\n    }\n    else if (\"\" + +value === value) {\n        return +value;\n    }\n    throw new Error(\"Could not parse value flag value \" + value + \" for flag \" + flagName + \".\");\n}\n/**\n * Returns the current environment (a global singleton).\n *\n * The environment object contains the evaluated feature values as well as the\n * active platform.\n */\n/** @doc {heading: 'Environment'} */\nfunction env() {\n    return exports.ENV;\n}\nexports.env = env;\nexports.ENV = null;\nfunction setEnvironmentGlobal(environment) {\n    exports.ENV = environment;\n}\nexports.setEnvironmentGlobal = setEnvironmentGlobal;\n//# sourceMappingURL=environment.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/environment.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/flags.js":
/*!**********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/flags.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar device_util = __webpack_require__(/*! ./device_util */ \"./node_modules/@tensorflow/tfjs-core/dist/device_util.js\");\nvar environment_1 = __webpack_require__(/*! ./environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar ENV = environment_1.env();\n/**\n * This file contains environment-related flag registrations.\n */\n/** Whether to enable debug mode. */\nENV.registerFlag('DEBUG', function () { return false; }, function (debugValue) {\n    if (debugValue) {\n        console.warn('Debugging mode is ON. The output of every math call will ' +\n            'be downloaded to CPU and checked for NaNs. ' +\n            'This significantly impacts performance.');\n    }\n});\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_BROWSER', function () { return device_util.isBrowser(); });\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_NODE', function () { return (typeof process !== 'undefined') &&\n    (typeof process.versions !== 'undefined') &&\n    (typeof process.versions.node !== 'undefined'); });\n/** Whether this browser is Chrome. */\nENV.registerFlag('IS_CHROME', function () { return typeof navigator !== 'undefined' && navigator != null &&\n    navigator.userAgent != null && /Chrome/.test(navigator.userAgent) &&\n    /Google Inc/.test(navigator.vendor); });\n/**\n * True when the environment is \"production\" where we disable safety checks\n * to gain performance.\n */\nENV.registerFlag('PROD', function () { return false; });\n/**\n * Whether to do sanity checks when inferring a shape from user-provided\n * values, used when creating a new tensor.\n */\nENV.registerFlag('TENSORLIKE_CHECK_SHAPE_CONSISTENCY', function () { return ENV.getBool('DEBUG'); });\n/** Whether deprecation warnings are enabled. */\nENV.registerFlag('DEPRECATION_WARNINGS_ENABLED', function () { return true; });\n/** True if running unit tests. */\nENV.registerFlag('IS_TEST', function () { return false; });\n//# sourceMappingURL=flags.js.map\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/flags.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/globals.js":
/*!************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/globals.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ./engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar environment_1 = __webpack_require__(/*! ./environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar tensor_1 = __webpack_require__(/*! ./tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nvar tensor_util_1 = __webpack_require__(/*! ./tensor_util */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js\");\n/**\n * Enables production mode which disables correctness checks in favor of\n * performance.\n */\n/** @doc {heading: 'Environment'} */\nfunction enableProdMode() {\n    environment_1.env().set('PROD', true);\n}\nexports.enableProdMode = enableProdMode;\n/**\n * Enables debug mode which will log information about all executed kernels:\n * the elapsed time of the kernel execution, as well as the rank, shape, and\n * size of the output tensor.\n *\n * Debug mode will significantly slow down your application as it will\n * download the result of every operation to the CPU. This should not be used in\n * production. Debug mode does not affect the timing information of the kernel\n * execution as we do not measure download time in the kernel execution time.\n *\n * See also: `tf.profile`, `tf.memory`.\n */\n/** @doc {heading: 'Environment'} */\nfunction enableDebugMode() {\n    environment_1.env().set('DEBUG', true);\n}\nexports.enableDebugMode = enableDebugMode;\n/** Globally disables deprecation warnings */\nfunction disableDeprecationWarnings() {\n    environment_1.env().set('DEPRECATION_WARNINGS_ENABLED', false);\n    console.warn(\"TensorFlow.js deprecation warnings have been disabled.\");\n}\nexports.disableDeprecationWarnings = disableDeprecationWarnings;\n/** Warn users about deprecated functionality. */\nfunction deprecationWarn(msg) {\n    if (environment_1.env().getBool('DEPRECATION_WARNINGS_ENABLED')) {\n        console.warn(msg + ' You can disable deprecation warnings with ' +\n            'tf.disableDeprecationWarnings().');\n    }\n}\nexports.deprecationWarn = deprecationWarn;\ntensor_1.setDeprecationWarningFn(deprecationWarn);\n/**\n * Dispose all variables kept in backend engine.\n */\n/** @doc {heading: 'Environment'} */\nfunction disposeVariables() {\n    engine_1.ENGINE.disposeVariables();\n}\nexports.disposeVariables = disposeVariables;\n/**\n * It returns the global engine that keeps track of all tensors and backends.\n */\n/** @doc {heading: 'Environment'} */\nfunction engine() {\n    return engine_1.ENGINE;\n}\nexports.engine = engine;\n/**\n * Returns memory info at the current time in the program. The result is an\n * object with the following properties:\n *\n * - `numBytes`: Number of bytes allocated (undisposed) at this time.\n * - `numTensors`: Number of unique tensors allocated.\n * - `numDataBuffers`: Number of unique data buffers allocated\n *   (undisposed) at this time, which is ≤ the number of tensors\n *   (e.g. `a.reshape(newShape)` makes a new Tensor that shares the same\n *   data buffer with `a`).\n * - `unreliable`: True if the memory usage is unreliable. See `reasons` when\n *    `unreliable` is true.\n * - `reasons`: `string[]`, reasons why the memory is unreliable, present if\n *    `unreliable` is true.\n *\n * WebGL Properties:\n * - `numBytesInGPU`: Number of bytes allocated (undisposed) in the GPU only at\n *     this time.\n */\n/** @doc {heading: 'Performance', subheading: 'Memory'} */\nfunction memory() {\n    return engine_1.ENGINE.memory();\n}\nexports.memory = memory;\n/**\n * Executes the provided function `f()` and returns a promise that resolves\n * with information about the function's memory use:\n * - `newBytes`: the number of new bytes allocated\n * - `newTensors`: the number of new tensors created\n * - `peakBytes`: the peak number of bytes allocated\n * - `kernels`: an array of objects for each kernel involved that reports\n * their input and output shapes, number of bytes used, and number of new\n * tensors created.\n *\n * ```js\n * const profile = await tf.profile(() => {\n *   const x = tf.tensor1d([1, 2, 3]);\n *   let x2 = x.square();\n *   x2.dispose();\n *   x2 = x.square();\n *   x2.dispose();\n *   return x;\n * });\n *\n * console.log(`newBytes: ${profile.newBytes}`);\n * console.log(`newTensors: ${profile.newTensors}`);\n * console.log(`byte usage over all kernels: ${profile.kernels.map(k =>\n * k.totalBytesSnapshot)}`);\n * ```\n *\n */\n/** @doc {heading: 'Performance', subheading: 'Profile'} */\nfunction profile(f) {\n    return engine_1.ENGINE.profile(f);\n}\nexports.profile = profile;\n/**\n * Executes the provided function `fn` and after it is executed, cleans up all\n * intermediate tensors allocated by `fn` except those returned by `fn`.\n * `fn` must not return a Promise (async functions not allowed). The returned\n * result can be a complex object.\n *\n * Using this method helps avoid memory leaks. In general, wrap calls to\n * operations in `tf.tidy` for automatic memory cleanup.\n *\n * NOTE: Variables do *not* get cleaned up when inside a tidy(). If you want to\n * dispose variables, please use `tf.disposeVariables` or call dispose()\n * directly on variables.\n *\n * ```js\n * // y = 2 ^ 2 + 1\n * const y = tf.tidy(() => {\n *   // a, b, and one will be cleaned up when the tidy ends.\n *   const one = tf.scalar(1);\n *   const a = tf.scalar(2);\n *   const b = a.square();\n *\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\n *\n *   // The value returned inside the tidy function will return\n *   // through the tidy, in this case to the variable y.\n *   return b.add(one);\n * });\n *\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\n * y.print();\n * ```\n *\n * @param nameOrFn The name of the closure, or the function to execute.\n *     If a name is provided, the 2nd argument should be the function.\n *     If debug mode is on, the timing and the memory usage of the function\n *     will be tracked and displayed on the console using the provided name.\n * @param fn The function to execute.\n */\n/** @doc {heading: 'Performance', subheading: 'Memory'} */\nfunction tidy(nameOrFn, fn) {\n    return engine_1.ENGINE.tidy(nameOrFn, fn);\n}\nexports.tidy = tidy;\n/**\n * Disposes any `tf.Tensor`s found within the provided object.\n *\n * @param container an object that may be a `tf.Tensor` or may directly\n *     contain `tf.Tensor`s, such as a `Tensor[]` or `{key: Tensor, ...}`. If\n *     the object is not a `tf.Tensor` or does not contain `Tensors`, nothing\n *     happens. In general it is safe to pass any object here, except that\n *     `Promise`s are not supported.\n */\n/** @doc {heading: 'Performance', subheading: 'Memory'} */\nfunction dispose(container) {\n    var tensors = tensor_util_1.getTensorsInContainer(container);\n    tensors.forEach(function (tensor) { return tensor.dispose(); });\n}\nexports.dispose = dispose;\n/**\n * Keeps a `tf.Tensor` generated inside a `tf.tidy` from being disposed\n * automatically.\n *\n * ```js\n * let b;\n * const y = tf.tidy(() => {\n *   const one = tf.scalar(1);\n *   const a = tf.scalar(2);\n *\n *   // b will not be cleaned up by the tidy. a and one will be cleaned up\n *   // when the tidy ends.\n *   b = tf.keep(a.square());\n *\n *   console.log('numTensors (in tidy): ' + tf.memory().numTensors);\n *\n *   // The value returned inside the tidy function will return\n *   // through the tidy, in this case to the variable y.\n *   return b.add(one);\n * });\n *\n * console.log('numTensors (outside tidy): ' + tf.memory().numTensors);\n * console.log('y:');\n * y.print();\n * console.log('b:');\n * b.print();\n * ```\n *\n * @param result The tensor to keep from being disposed.\n */\n/** @doc {heading: 'Performance', subheading: 'Memory'} */\nfunction keep(result) {\n    return engine_1.ENGINE.keep(result);\n}\nexports.keep = keep;\n/**\n * Executes `f()` and returns a promise that resolves with timing\n * information.\n *\n * The result is an object with the following properties:\n *\n * - `wallMs`: Wall execution time.\n * - `kernelMs`: Kernel execution time, ignoring data transfer. If using the\n * WebGL backend and the query timer extension is not available, this will\n * return an error object.\n * - On `WebGL` The following additional properties exist:\n *   - `uploadWaitMs`: CPU blocking time on texture uploads.\n *   - `downloadWaitMs`: CPU blocking time on texture downloads (readPixels).\n *\n * ```js\n * const x = tf.randomNormal([20, 20]);\n * const time = await tf.time(() => x.matMul(x));\n *\n * console.log(`kernelMs: ${time.kernelMs}, wallTimeMs: ${time.wallMs}`);\n * ```\n *\n * @param f The function to execute and time.\n */\n/** @doc {heading: 'Performance', subheading: 'Timing'} */\nfunction time(f) {\n    return engine_1.ENGINE.time(f);\n}\nexports.time = time;\n/**\n * Sets the backend (cpu, webgl, wasm, etc) responsible for creating tensors and\n * executing operations on those tensors. Returns a promise that resolves\n * to a boolean if the backend initialization was successful.\n *\n * Note this disposes the current backend, if any, as well as any tensors\n * associated with it. A new backend is initialized, even if it is of the\n * same type as the previous one.\n *\n * @param backendName The name of the backend. Currently supports\n *     `'webgl'|'cpu'` in the browser, `'tensorflow'` under node.js\n *     (requires tfjs-node), and `'wasm'` (requires tfjs-backend-wasm).\n */\n/** @doc {heading: 'Backends'} */\nfunction setBackend(backendName) {\n    return engine_1.ENGINE.setBackend(backendName);\n}\nexports.setBackend = setBackend;\n/**\n * Returns a promise that resolves when the currently selected backend (or the\n * highest priority one) has initialized. Await this promise when you are using\n * a backend that has async initialization.\n */\n/** @doc {heading: 'Backends'} */\nfunction ready() {\n    return engine_1.ENGINE.ready();\n}\nexports.ready = ready;\n/**\n * Returns the current backend name (cpu, webgl, etc). The backend is\n * responsible for creating tensors and executing operations on those tensors.\n */\n/** @doc {heading: 'Backends'} */\nfunction getBackend() {\n    return engine_1.ENGINE.backendName;\n}\nexports.getBackend = getBackend;\n/**\n * Removes a backend and the registered factory.\n */\n/** @doc {heading: 'Backends'} */\nfunction removeBackend(name) {\n    engine_1.ENGINE.removeBackend(name);\n}\nexports.removeBackend = removeBackend;\n/**\n * Finds the backend registered under the provided name. Returns null if the\n * name is not in the registry, or the registration hasn't finished yet.\n */\nfunction findBackend(name) {\n    return engine_1.ENGINE.findBackend(name);\n}\nexports.findBackend = findBackend;\n/**\n * Finds the backend factory registered under the provided name. Returns a\n * function that produces a new backend when called. Returns null if the name\n * is not in the registry.\n */\nfunction findBackendFactory(name) {\n    return engine_1.ENGINE.findBackendFactory(name);\n}\nexports.findBackendFactory = findBackendFactory;\n/**\n * Registers a global backend. The registration should happen when importing\n * a module file (e.g. when importing `backend_webgl.ts`), and is used for\n * modular builds (e.g. custom tfjs bundle with only webgl support).\n *\n * @param factory The backend factory function. When called, it should\n * return a backend instance, or a promise of an instance.\n * @param priority The priority of the backend (higher = more important).\n *     In case multiple backends are registered, the priority is used to find\n *     the best backend. Defaults to 1.\n * @return False if there is already a registered backend under this name, true\n *     if not.\n */\n/** @doc {heading: 'Backends'} */\nfunction registerBackend(name, factory, priority) {\n    if (priority === void 0) { priority = 1; }\n    return engine_1.ENGINE.registerBackend(name, factory, priority);\n}\nexports.registerBackend = registerBackend;\n/**\n * Gets the current backend. If no backends have been initialized, this will\n * attempt to initialize the best backend. Will throw an error if the highest\n * priority backend has async initialization, in which case, you should call\n * 'await tf.ready()' before running other code.\n */\n/** @doc {heading: 'Backends'} */\nfunction backend() {\n    return engine_1.ENGINE.backend;\n}\nexports.backend = backend;\n/**\n * Sets the global platform.\n *\n * @param platformName The name of this platform.\n * @param platform A platform implementation.\n */\nfunction setPlatform(platformName, platform) {\n    environment_1.env().setPlatform(platformName, platform);\n}\nexports.setPlatform = setPlatform;\n//# sourceMappingURL=globals.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/globals.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/gradients.js":
/*!**************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/gradients.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ./engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_1 = __webpack_require__(/*! ./tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ./tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n/**\n * Provided `f(x)`, returns another function `g(x, dy?)`, which gives the\n * gradient of `f(x)` with respect to `x`.\n *\n * If `dy` is provided, the gradient of `f(x).mul(dy).sum()` with respect to\n * `x` is computed instead. `f(x)` must take a single tensor `x` and return a\n * single tensor `y`. If `f()` takes multiple inputs, use `tf.grads` instead.\n *\n * ```js\n * // f(x) = x ^ 2\n * const f = x => x.square();\n * // f'(x) = 2x\n * const g = tf.grad(f);\n *\n * const x = tf.tensor1d([2, 3]);\n * g(x).print();\n * ```\n *\n * ```js\n * // f(x) = x ^ 3\n * const f = x => x.pow(tf.scalar(3, 'int32'));\n * // f'(x) = 3x ^ 2\n * const g = tf.grad(f);\n * // f''(x) = 6x\n * const gg = tf.grad(g);\n *\n * const x = tf.tensor1d([2, 3]);\n * gg(x).print();\n * ```\n *\n * @param f The function f(x), to compute gradient for.\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction grad(f) {\n    util.assert(util.isFunction(f), function () { return 'The f passed in grad(f) must be a function'; });\n    return function (x, dy) {\n        // x can be of any dtype, thus null as the last argument.\n        var $x = tensor_util_env_1.convertToTensor(x, 'x', 'tf.grad', null);\n        var $dy = (dy != null) ? tensor_util_env_1.convertToTensor(dy, 'dy', 'tf.grad') : null;\n        return engine_1.ENGINE.tidy(function () {\n            var _a = engine_1.ENGINE.gradients(function () { return f($x); }, [$x], $dy), value = _a.value, grads = _a.grads;\n            if ($dy != null) {\n                util.assertShapesMatch(value.shape, $dy.shape, 'The shape of dy passed in grad(f)(x, dy) must match the shape ' +\n                    'returned by f(x)');\n            }\n            checkGrads(grads);\n            return grads[0];\n        });\n    };\n}\nexports.grad = grad;\n/**\n * Provided `f(x1, x2,...)`, returns another function `g([x1, x2,...], dy?)`,\n * which gives an array of gradients of `f()` with respect to each input\n * [`x1`,`x2`,...].\n *\n * If `dy` is passed when calling `g()`, the gradient of\n * `f(x1,...).mul(dy).sum()` with respect to each input is computed instead.\n * The provided `f` must take one or more tensors and return a single tensor\n * `y`. If `f()` takes a single input, we recommend using `tf.grad` instead.\n *\n * ```js\n * // f(a, b) = a * b\n * const f = (a, b) => a.mul(b);\n * // df / da = b, df / db = a\n * const g = tf.grads(f);\n *\n * const a = tf.tensor1d([2, 3]);\n * const b = tf.tensor1d([-2, -3]);\n * const [da, db] = g([a, b]);\n * console.log('da');\n * da.print();\n * console.log('db');\n * db.print();\n * ```\n *\n * @param f The function `f(x1, x2,...)` to compute gradients for.\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction grads(f) {\n    util.assert(util.isFunction(f), function () { return 'The f passed in grads(f) must be a function'; });\n    return function (args, dy) {\n        util.assert(Array.isArray(args), function () { return 'The args passed in grads(f)(args) must be an array ' +\n            'of `Tensor`s or `TensorLike`s'; });\n        // args can be of any dtype, thus null as the last argument.\n        var $args = tensor_util_env_1.convertToTensorArray(args, 'args', 'tf.grads', null);\n        var $dy = (dy != null) ? tensor_util_env_1.convertToTensor(dy, 'dy', 'tf.grads') : null;\n        return engine_1.ENGINE.tidy(function () {\n            var _a = engine_1.ENGINE.gradients(function () { return f.apply(void 0, $args); }, $args, $dy), value = _a.value, grads = _a.grads;\n            if ($dy != null) {\n                util.assertShapesMatch(value.shape, $dy.shape, 'The shape of dy passed in grads(f)([x1,...], dy) must ' +\n                    'match the shape returned by f([x1,...])');\n            }\n            checkGrads(grads);\n            return grads;\n        });\n    };\n}\nexports.grads = grads;\n/**\n * Like `tf.grad`, but also returns the value of `f()`. Useful when `f()`\n * returns a metric you want to show.\n *\n * The result is a rich object with the following properties:\n * - grad: The gradient of `f(x)` w.r.t `x` (result of `tf.grad`).\n * - value: The value returned by `f(x)`.\n *\n * ```js\n * // f(x) = x ^ 2\n * const f = x => x.square();\n * // f'(x) = 2x\n * const g = tf.valueAndGrad(f);\n *\n * const x = tf.tensor1d([2, 3]);\n * const {value, grad} = g(x);\n *\n * console.log('value');\n * value.print();\n * console.log('grad');\n * grad.print();\n * ```\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction valueAndGrad(f) {\n    util.assert(util.isFunction(f), function () { return 'The f passed in valueAndGrad(f) must be a function'; });\n    return function (x, dy) {\n        util.assert(x instanceof tensor_1.Tensor, function () { return 'The x passed in valueAndGrad(f)(x) must be a tensor'; });\n        util.assert(dy == null || dy instanceof tensor_1.Tensor, function () { return 'The dy passed in valueAndGrad(f)(x, dy) must be a tensor'; });\n        var _a = engine_1.ENGINE.gradients(function () { return f(x); }, [x], dy), grads = _a.grads, value = _a.value;\n        checkGrads(grads);\n        return { grad: grads[0], value: value };\n    };\n}\nexports.valueAndGrad = valueAndGrad;\n/**\n * Like `tf.grads`, but returns also the value of `f()`. Useful when `f()`\n * returns a metric you want to show.\n *\n * The result is a rich object with the following properties:\n * - grads: The gradients of `f()` w.r.t each input (result of `tf.grads`).\n * - value: The value returned by `f(x)`.\n *\n * ```js\n * // f(a, b) = a * b\n * const f = (a, b) => a.mul(b);\n * // df/da = b, df/db = a\n * const g = tf.valueAndGrads(f);\n *\n * const a = tf.tensor1d([2, 3]);\n * const b = tf.tensor1d([-2, -3]);\n * const {value, grads} = g([a, b]);\n *\n * const [da, db] = grads;\n *\n * console.log('value');\n * value.print();\n *\n * console.log('da');\n * da.print();\n * console.log('db');\n * db.print();\n * ```\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction valueAndGrads(f) {\n    util.assert(util.isFunction(f), function () { return 'The f passed in valueAndGrads(f) must be a function'; });\n    return function (args, dy) {\n        util.assert(Array.isArray(args) && args.every(function (arg) { return arg instanceof tensor_1.Tensor; }), function () { return 'The args passed in valueAndGrads(f)(args) must be array of ' +\n            'tensors'; });\n        util.assert(dy == null || dy instanceof tensor_1.Tensor, function () { return 'The dy passed in valueAndGrads(f)(args, dy) must be a tensor'; });\n        var res = engine_1.ENGINE.gradients(function () { return f.apply(void 0, args); }, args, dy);\n        if (dy != null) {\n            util.assertShapesMatch(res.value.shape, dy.shape, 'The shape of dy passed in valueAndGrads(f)([x1,...], dy) must ' +\n                'match the shape returned by f([x1,...])');\n        }\n        checkGrads(res.grads);\n        return res;\n    };\n}\nexports.valueAndGrads = valueAndGrads;\n/**\n * Computes and returns the gradient of f(x) with respect to the list of\n * trainable variables provided by `varList`. If no list is provided, it\n * defaults to all trainable variables.\n *\n * ```js\n * const a = tf.variable(tf.tensor1d([3, 4]));\n * const b = tf.variable(tf.tensor1d([5, 6]));\n * const x = tf.tensor1d([1, 2]);\n *\n * // f(a, b) = a * x ^ 2 + b * x\n * const f = () => a.mul(x.square()).add(b.mul(x)).sum();\n * // df/da = x ^ 2, df/db = x\n * const {value, grads} = tf.variableGrads(f);\n *\n * Object.keys(grads).forEach(varName => grads[varName].print());\n * ```\n *\n * @param f The function to execute. f() should return a scalar.\n * @param varList The list of variables to compute the gradients with respect\n *     to. Defaults to all trainable variables.\n * @returns An object with the following keys and values:\n *   - `value`: The value of the function `f`.\n *   - `grads`: A map from the names of the variables to the gradients.\n *     If the `varList` argument is provided explicitly and contains a subset of\n *     non-trainable variables, this map in the return value will contain keys\n *     that map the names of the non-trainable variables to `null`.\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction variableGrads(f, varList) {\n    util.assert(util.isFunction(f), function () { return 'The f passed in variableGrads(f) must be a function'; });\n    util.assert(varList == null ||\n        Array.isArray(varList) && varList.every(function (v) { return v instanceof tensor_1.Variable; }), function () {\n        return 'The varList passed in variableGrads(f, varList) must be an array ' +\n            'of variables';\n    });\n    var specifiedVarList = varList != null;\n    if (!specifiedVarList) {\n        // Get all of the trainable variables.\n        varList = [];\n        for (var varName in engine_1.ENGINE.registeredVariables) {\n            varList.push(engine_1.ENGINE.registeredVariables[varName]);\n        }\n    }\n    var specifiedNonTrainable = specifiedVarList ? varList.filter(function (variable) { return !variable.trainable; }) : null;\n    // Prune non-trainable variables.\n    var originalVarCount = varList.length;\n    varList = varList.filter(function (variable) { return variable.trainable; });\n    util.assert(varList.length > 0, function () { return \"variableGrads() expects at least one of the input variables to \" +\n        (\"be trainable, but none of the \" + originalVarCount + \" variables is \") +\n        \"trainable.\"; });\n    var allowNoGradients = true;\n    var _a = engine_1.ENGINE.gradients(f, varList, null, allowNoGradients), value = _a.value, grads = _a.grads;\n    util.assert(grads.some(function (g) { return g != null; }), function () { return 'Cannot find a connection between any variable and the result of ' +\n        'the loss function y=f(x). Please make sure the operations that ' +\n        'use variables are inside the function f passed to minimize().'; });\n    util.assert(value.rank === 0, function () { return \"The f passed in variableGrads(f) must return a scalar, but it \" +\n        (\"returned a rank-\" + value.rank + \" tensor\"); });\n    var namedGrads = {};\n    varList.forEach(function (v, i) {\n        if (grads[i] != null) {\n            namedGrads[v.name] = grads[i];\n        }\n    });\n    if (specifiedNonTrainable != null) {\n        // If varList is explicitly provided and contains non-trainable values,\n        // add them to the returned gradients with `null` values.\n        specifiedNonTrainable.forEach(function (v) { return namedGrads[v.name] = null; });\n    }\n    return { value: value, grads: namedGrads };\n}\nexports.variableGrads = variableGrads;\n/**\n * Overrides the gradient computation of a function `f`.\n *\n * Takes a function\n * `f(...inputs, save) => {value: Tensor, gradFunc: (dy, saved) => Tensor[]}`\n * and returns another function `g(...inputs)` which takes the same inputs as\n * `f`. When called, `g` returns `f().value`. In backward mode, custom gradients\n * with respect to each input of `f` are computed using `f().gradFunc`.\n *\n * The `save` function passsed to `f` should be used for saving tensors needed\n * in the gradient. And the `saved` passed to the `gradFunc` is a\n * `NamedTensorMap`, which contains those saved tensor.\n *\n * ```js\n * const customOp = tf.customGrad((x, save) => {\n *   // Save x to make sure it's available later for the gradient.\n *   save([x]);\n *   // Override gradient of our custom x ^ 2 op to be dy * abs(x);\n *   return {\n *     value: x.square(),\n *     // Note `saved.x` which points to the `x` we saved earlier.\n *     gradFunc: (dy, saved) => [dy.mul(saved[0].abs())]\n *   };\n * });\n *\n * const x = tf.tensor1d([-1, -2, 3]);\n * const dx = tf.grad(x => customOp(x));\n *\n * console.log(`f(x):`);\n * customOp(x).print();\n * console.log(`f'(x):`);\n * dx(x).print();\n * ```\n *\n * @param f The function to evaluate in forward mode, which should return\n *     `{value: Tensor, gradFunc: (dy, saved) => Tensor[]}`, where `gradFunc`\n *     returns the custom gradients of `f` with respect to its inputs.\n */\n/** @doc {heading: 'Training', subheading: 'Gradients'} */\nfunction customGrad(f) {\n    return engine_1.ENGINE.customGrad(f);\n}\nexports.customGrad = customGrad;\nfunction checkGrads(grads) {\n    var numNullGradients = grads.filter(function (g) { return g == null; }).length;\n    if (numNullGradients > 0) {\n        throw new Error(\"Cannot compute gradient of y=f(x) with respect to x. Make sure that\\n    the f you passed encloses all operations that lead from x to y.\");\n    }\n}\n//# sourceMappingURL=gradients.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/gradients.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/gradients/Square_grad.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/gradients/Square_grad.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar kernel_names_1 = __webpack_require__(/*! ../kernel_names */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js\");\nexports.squareGradConfig = {\n    kernelName: kernel_names_1.Square,\n    gradFunc: function (dy, saved) {\n        var x = saved[0];\n        return { x: function () { return dy.mul(x.toFloat().mul(2)); } };\n    }\n};\n//# sourceMappingURL=Square_grad.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/gradients/Square_grad.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/gradients/SquaredDifference_grad.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/gradients/SquaredDifference_grad.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar kernel_names_1 = __webpack_require__(/*! ../kernel_names */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js\");\nvar binary_ops_1 = __webpack_require__(/*! ../ops/binary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ../ops/tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\nexports.squaredDifferenceGradConfig = {\n    kernelName: kernel_names_1.SquaredDifference,\n    gradFunc: function (dy, saved) {\n        var a = saved[0], b = saved[1];\n        var two = tensor_ops_1.scalar(2);\n        var derA = function () { return binary_ops_1.mul(dy, binary_ops_1.mul(two, binary_ops_1.sub(a, b))); };\n        var derB = function () { return binary_ops_1.mul(dy, binary_ops_1.mul(two, binary_ops_1.sub(b, a))); };\n        return { a: derA, b: derB };\n    }\n};\n//# sourceMappingURL=SquaredDifference_grad.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/gradients/SquaredDifference_grad.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/index.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction __export(m) {\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n}\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @fileoverview\n * @suppress {partialAlias} Optimization disabled due to passing the module\n * object into a function below:\n *\n *   import * as ops from './ops/ops';\n *   setOpHandler(ops);\n */\n// Engine is the global singleton that needs to be initialized before the rest\n// of the app.\n__webpack_require__(/*! ./engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\n// Register backend-agnostic flags.\n__webpack_require__(/*! ./flags */ \"./node_modules/@tensorflow/tfjs-core/dist/flags.js\");\n// backend_cpu.ts and backend_webgl.ts are standalone files and should be\n// explicitly included here.\n__webpack_require__(/*! ./backends/webgl/backend_webgl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/backend_webgl.js\");\n__webpack_require__(/*! ./backends/cpu/backend_cpu */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/backend_cpu.js\");\n// Import all kernels from cpu.\n__webpack_require__(/*! ./backends/cpu/register_all_kernels */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/cpu/register_all_kernels.js\");\n// Import all kernels from webgl.\n__webpack_require__(/*! ./backends/webgl/register_all_kernels */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/register_all_kernels.js\");\n// Register all the gradients.\n__webpack_require__(/*! ./register_all_gradients */ \"./node_modules/@tensorflow/tfjs-core/dist/register_all_gradients.js\");\n__webpack_require__(/*! ./platforms/platform_browser */ \"./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js\");\n__webpack_require__(/*! ./platforms/platform_node */ \"./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js\");\nvar backend_util = __webpack_require__(/*! ./backends/backend_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js\");\nexports.backend_util = backend_util;\n// Serialization.\nvar io = __webpack_require__(/*! ./io/io */ \"./node_modules/@tensorflow/tfjs-core/dist/io/io.js\");\nexports.io = io;\nvar math = __webpack_require__(/*! ./math */ \"./node_modules/@tensorflow/tfjs-core/dist/math.js\");\nexports.math = math;\nvar browser = __webpack_require__(/*! ./ops/browser */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/browser.js\");\nexports.browser = browser;\nvar gather_util = __webpack_require__(/*! ./ops/gather_nd_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js\");\nexports.gather_util = gather_util;\nvar scatter_util = __webpack_require__(/*! ./ops/scatter_nd_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js\");\nexports.scatter_util = scatter_util;\nvar slice_util = __webpack_require__(/*! ./ops/slice_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js\");\nexports.slice_util = slice_util;\nvar serialization = __webpack_require__(/*! ./serialization */ \"./node_modules/@tensorflow/tfjs-core/dist/serialization.js\");\nexports.serialization = serialization;\nvar tensor_1 = __webpack_require__(/*! ./tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nvar tensor_util = __webpack_require__(/*! ./tensor_util */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js\");\nexports.tensor_util = tensor_util;\nvar test_util = __webpack_require__(/*! ./test_util */ \"./node_modules/@tensorflow/tfjs-core/dist/test_util.js\");\nexports.test_util = test_util;\nvar util = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nexports.util = util;\nvar version_1 = __webpack_require__(/*! ./version */ \"./node_modules/@tensorflow/tfjs-core/dist/version.js\");\nexports.version_core = version_1.version;\nvar webgl = __webpack_require__(/*! ./webgl */ \"./node_modules/@tensorflow/tfjs-core/dist/webgl.js\");\nexports.webgl = webgl;\n// Optimizers.\nvar adadelta_optimizer_1 = __webpack_require__(/*! ./optimizers/adadelta_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js\");\nexports.AdadeltaOptimizer = adadelta_optimizer_1.AdadeltaOptimizer;\nvar adagrad_optimizer_1 = __webpack_require__(/*! ./optimizers/adagrad_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js\");\nexports.AdagradOptimizer = adagrad_optimizer_1.AdagradOptimizer;\nvar adam_optimizer_1 = __webpack_require__(/*! ./optimizers/adam_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js\");\nexports.AdamOptimizer = adam_optimizer_1.AdamOptimizer;\nvar adamax_optimizer_1 = __webpack_require__(/*! ./optimizers/adamax_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js\");\nexports.AdamaxOptimizer = adamax_optimizer_1.AdamaxOptimizer;\nvar momentum_optimizer_1 = __webpack_require__(/*! ./optimizers/momentum_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js\");\nexports.MomentumOptimizer = momentum_optimizer_1.MomentumOptimizer;\nvar optimizer_1 = __webpack_require__(/*! ./optimizers/optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js\");\nexports.Optimizer = optimizer_1.Optimizer;\nvar rmsprop_optimizer_1 = __webpack_require__(/*! ./optimizers/rmsprop_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js\");\nexports.RMSPropOptimizer = rmsprop_optimizer_1.RMSPropOptimizer;\nvar sgd_optimizer_1 = __webpack_require__(/*! ./optimizers/sgd_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js\");\nexports.SGDOptimizer = sgd_optimizer_1.SGDOptimizer;\nvar tensor_2 = __webpack_require__(/*! ./tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nexports.Tensor = tensor_2.Tensor;\nexports.TensorBuffer = tensor_2.TensorBuffer;\nexports.Variable = tensor_2.Variable;\nvar types_1 = __webpack_require__(/*! ./types */ \"./node_modules/@tensorflow/tfjs-core/dist/types.js\");\nexports.Rank = types_1.Rank;\nexports.sumOutType = types_1.sumOutType;\n__export(__webpack_require__(/*! ./ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\"));\nvar loss_ops_1 = __webpack_require__(/*! ./ops/loss_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops.js\");\nexports.Reduction = loss_ops_1.Reduction;\n__export(__webpack_require__(/*! ./train */ \"./node_modules/@tensorflow/tfjs-core/dist/train.js\"));\n__export(__webpack_require__(/*! ./globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\"));\n__export(__webpack_require__(/*! ./kernel_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js\"));\nvar gradients_1 = __webpack_require__(/*! ./gradients */ \"./node_modules/@tensorflow/tfjs-core/dist/gradients.js\");\nexports.customGrad = gradients_1.customGrad;\nexports.grad = gradients_1.grad;\nexports.grads = gradients_1.grads;\nexports.valueAndGrad = gradients_1.valueAndGrad;\nexports.valueAndGrads = gradients_1.valueAndGrads;\nexports.variableGrads = gradients_1.variableGrads;\nvar environment_1 = __webpack_require__(/*! ./environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nexports.Environment = environment_1.Environment;\nexports.env = environment_1.env;\nexports.ENV = environment_1.ENV;\n// Top-level method exports.\nvar browser_util_1 = __webpack_require__(/*! ./browser_util */ \"./node_modules/@tensorflow/tfjs-core/dist/browser_util.js\");\nexports.nextFrame = browser_util_1.nextFrame;\n// Backend specific.\nvar backend_1 = __webpack_require__(/*! ./backends/backend */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/backend.js\");\nexports.KernelBackend = backend_1.KernelBackend;\nexports.DataStorage = backend_1.DataStorage;\nvar ops = __webpack_require__(/*! ./ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\ntensor_1.setOpHandler(ops);\n// Import all op chainers and add type info to Tensor.\n__webpack_require__(/*! ./public/chained_ops/register_all_chained_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/register_all_chained_ops.js\");\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/index.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * IOHandlers related to files, such as browser-triggered file downloads,\n * user-selected files in browser.\n */\nvar environment_1 = __webpack_require__(/*! ../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar io_utils_1 = __webpack_require__(/*! ./io_utils */ \"./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js\");\nvar router_registry_1 = __webpack_require__(/*! ./router_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js\");\nvar DEFAULT_FILE_NAME_PREFIX = 'model';\nvar DEFAULT_JSON_EXTENSION_NAME = '.json';\nvar DEFAULT_WEIGHT_DATA_EXTENSION_NAME = '.weights.bin';\nfunction defer(f) {\n    return new Promise(function (resolve) { return setTimeout(resolve); }).then(f);\n}\nvar BrowserDownloads = /** @class */ (function () {\n    function BrowserDownloads(fileNamePrefix) {\n        if (!environment_1.env().getBool('IS_BROWSER')) {\n            // TODO(cais): Provide info on what IOHandlers are available under the\n            //   current environment.\n            throw new Error('browserDownloads() cannot proceed because the current environment ' +\n                'is not a browser.');\n        }\n        if (fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)) {\n            fileNamePrefix = fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length);\n        }\n        if (fileNamePrefix == null || fileNamePrefix.length === 0) {\n            fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;\n        }\n        this.modelTopologyFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;\n        this.weightDataFileName =\n            fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;\n    }\n    BrowserDownloads.prototype.save = function (modelArtifacts) {\n        return __awaiter(this, void 0, void 0, function () {\n            var weightsURL, weightsManifest, modelTopologyAndWeightManifest, modelTopologyAndWeightManifestURL, jsonAnchor_1, weightDataAnchor_1;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (typeof (document) === 'undefined') {\n                            throw new Error('Browser downloads are not supported in ' +\n                                'this environment since `document` is not present');\n                        }\n                        weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: 'application/octet-stream' }));\n                        if (!(modelArtifacts.modelTopology instanceof ArrayBuffer)) return [3 /*break*/, 1];\n                        throw new Error('BrowserDownloads.save() does not support saving model topology ' +\n                            'in binary formats yet.');\n                    case 1:\n                        weightsManifest = [{\n                                paths: ['./' + this.weightDataFileName],\n                                weights: modelArtifacts.weightSpecs\n                            }];\n                        modelTopologyAndWeightManifest = {\n                            modelTopology: modelArtifacts.modelTopology,\n                            format: modelArtifacts.format,\n                            generatedBy: modelArtifacts.generatedBy,\n                            convertedBy: modelArtifacts.convertedBy,\n                            weightsManifest: weightsManifest\n                        };\n                        modelTopologyAndWeightManifestURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: 'application/json' }));\n                        jsonAnchor_1 = this.jsonAnchor == null ? document.createElement('a') :\n                            this.jsonAnchor;\n                        jsonAnchor_1.download = this.modelTopologyFileName;\n                        jsonAnchor_1.href = modelTopologyAndWeightManifestURL;\n                        // Trigger downloads by evoking a click event on the download anchors.\n                        // When multiple downloads are started synchronously, Firefox will only\n                        // save the last one.\n                        return [4 /*yield*/, defer(function () { return jsonAnchor_1.dispatchEvent(new MouseEvent('click')); })];\n                    case 2:\n                        // Trigger downloads by evoking a click event on the download anchors.\n                        // When multiple downloads are started synchronously, Firefox will only\n                        // save the last one.\n                        _a.sent();\n                        if (!(modelArtifacts.weightData != null)) return [3 /*break*/, 4];\n                        weightDataAnchor_1 = this.weightDataAnchor == null ?\n                            document.createElement('a') :\n                            this.weightDataAnchor;\n                        weightDataAnchor_1.download = this.weightDataFileName;\n                        weightDataAnchor_1.href = weightsURL;\n                        return [4 /*yield*/, defer(function () { return weightDataAnchor_1.dispatchEvent(new MouseEvent('click')); })];\n                    case 3:\n                        _a.sent();\n                        _a.label = 4;\n                    case 4: return [2 /*return*/, { modelArtifactsInfo: io_utils_1.getModelArtifactsInfoForJSON(modelArtifacts) }];\n                }\n            });\n        });\n    };\n    BrowserDownloads.URL_SCHEME = 'downloads://';\n    return BrowserDownloads;\n}());\nexports.BrowserDownloads = BrowserDownloads;\nvar BrowserFiles = /** @class */ (function () {\n    function BrowserFiles(files) {\n        if (files == null || files.length < 1) {\n            throw new Error(\"When calling browserFiles, at least 1 file is required, \" +\n                (\"but received \" + files));\n        }\n        this.files = files;\n    }\n    BrowserFiles.prototype.load = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var jsonFile, weightFiles;\n            var _this = this;\n            return __generator(this, function (_a) {\n                jsonFile = this.files[0];\n                weightFiles = this.files.slice(1);\n                return [2 /*return*/, new Promise(function (resolve, reject) {\n                        var jsonReader = new FileReader();\n                        jsonReader.onload = function (event) {\n                            // tslint:disable-next-line:no-any\n                            var modelJSON = JSON.parse(event.target.result);\n                            var modelTopology = modelJSON.modelTopology;\n                            if (modelTopology == null) {\n                                reject(new Error(\"modelTopology field is missing from file \" + jsonFile.name));\n                                return;\n                            }\n                            if (weightFiles.length === 0) {\n                                resolve({ modelTopology: modelTopology });\n                            }\n                            var weightsManifest = modelJSON.weightsManifest;\n                            if (weightsManifest == null) {\n                                reject(new Error(\"weightManifest field is missing from file \" + jsonFile.name));\n                                return;\n                            }\n                            var pathToFile;\n                            try {\n                                pathToFile =\n                                    _this.checkManifestAndWeightFiles(weightsManifest, weightFiles);\n                            }\n                            catch (err) {\n                                reject(err);\n                                return;\n                            }\n                            var weightSpecs = [];\n                            var paths = [];\n                            var perFileBuffers = [];\n                            weightsManifest.forEach(function (weightsGroup) {\n                                weightsGroup.paths.forEach(function (path) {\n                                    paths.push(path);\n                                    perFileBuffers.push(null);\n                                });\n                                weightSpecs.push.apply(weightSpecs, weightsGroup.weights);\n                            });\n                            weightsManifest.forEach(function (weightsGroup) {\n                                weightsGroup.paths.forEach(function (path) {\n                                    var weightFileReader = new FileReader();\n                                    weightFileReader.onload = function (event) {\n                                        // tslint:disable-next-line:no-any\n                                        var weightData = event.target.result;\n                                        var index = paths.indexOf(path);\n                                        perFileBuffers[index] = weightData;\n                                        if (perFileBuffers.indexOf(null) === -1) {\n                                            resolve({\n                                                modelTopology: modelTopology,\n                                                weightSpecs: weightSpecs,\n                                                weightData: io_utils_1.concatenateArrayBuffers(perFileBuffers),\n                                                format: modelJSON.format,\n                                                generatedBy: modelJSON.generatedBy,\n                                                convertedBy: modelJSON.convertedBy,\n                                                userDefinedMetadata: modelJSON.userDefinedMetadata\n                                            });\n                                        }\n                                    };\n                                    weightFileReader.onerror = function (error) {\n                                        return reject(\"Failed to weights data from file of path '\" + path + \"'.\");\n                                    };\n                                    weightFileReader.readAsArrayBuffer(pathToFile[path]);\n                                });\n                            });\n                        };\n                        jsonReader.onerror = function (error) { return reject(\"Failed to read model topology and weights manifest JSON \" +\n                            (\"from file '\" + jsonFile.name + \"'. BrowserFiles supports loading \") +\n                            \"Keras-style tf.Model artifacts only.\"); };\n                        jsonReader.readAsText(jsonFile);\n                    })];\n            });\n        });\n    };\n    /**\n     * Check the compatibility between weights manifest and weight files.\n     */\n    BrowserFiles.prototype.checkManifestAndWeightFiles = function (manifest, files) {\n        var basenames = [];\n        var fileNames = files.map(function (file) { return io_utils_1.basename(file.name); });\n        var pathToFile = {};\n        for (var _i = 0, manifest_1 = manifest; _i < manifest_1.length; _i++) {\n            var group = manifest_1[_i];\n            group.paths.forEach(function (path) {\n                var pathBasename = io_utils_1.basename(path);\n                if (basenames.indexOf(pathBasename) !== -1) {\n                    throw new Error(\"Duplicate file basename found in weights manifest: \" +\n                        (\"'\" + pathBasename + \"'\"));\n                }\n                basenames.push(pathBasename);\n                if (fileNames.indexOf(pathBasename) === -1) {\n                    throw new Error(\"Weight file with basename '\" + pathBasename + \"' is not provided.\");\n                }\n                else {\n                    pathToFile[path] = files[fileNames.indexOf(pathBasename)];\n                }\n            });\n        }\n        if (basenames.length !== files.length) {\n            throw new Error(\"Mismatch in the number of files in weights manifest \" +\n                (\"(\" + basenames.length + \") and the number of weight files provided \") +\n                (\"(\" + files.length + \").\"));\n        }\n        return pathToFile;\n    };\n    return BrowserFiles;\n}());\nexports.browserDownloadsRouter = function (url) {\n    if (!environment_1.env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {\n            return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nrouter_registry_1.IORouterRegistry.registerSaveRouter(exports.browserDownloadsRouter);\n/**\n * Creates an IOHandler that triggers file downloads from the browser.\n *\n * The returned `IOHandler` instance can be used as model exporting methods such\n * as `tf.Model.save` and supports only saving.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * const saveResult = await model.save('downloads://mymodel');\n * // This will trigger downloading of two files:\n * //   'mymodel.json' and 'mymodel.weights.bin'.\n * console.log(saveResult);\n * ```\n *\n * @param fileNamePrefix Prefix name of the files to be downloaded. For use with\n *   `tf.Model`, `fileNamePrefix` should follow either of the following two\n *   formats:\n *   1. `null` or `undefined`, in which case the default file\n *      names will be used:\n *      - 'model.json' for the JSON file containing the model topology and\n *        weights manifest.\n *      - 'model.weights.bin' for the binary file containing the binary weight\n *        values.\n *   2. A single string or an Array of a single string, as the file name prefix.\n *      For example, if `'foo'` is provided, the downloaded JSON\n *      file and binary weights file will be named 'foo.json' and\n *      'foo.weights.bin', respectively.\n * @param config Additional configuration for triggering downloads.\n * @returns An instance of `BrowserDownloads` `IOHandler`.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction browserDownloads(fileNamePrefix) {\n    if (fileNamePrefix === void 0) { fileNamePrefix = 'model'; }\n    return new BrowserDownloads(fileNamePrefix);\n}\nexports.browserDownloads = browserDownloads;\n/**\n * Creates an IOHandler that loads model artifacts from user-selected files.\n *\n * This method can be used for loading from files such as user-selected files\n * in the browser.\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * // Note: This code snippet won't run properly without the actual file input\n * //   elements in the HTML DOM.\n *\n * // Suppose there are two HTML file input (`<input type=\"file\" ...>`)\n * // elements.\n * const uploadJSONInput = document.getElementById('upload-json');\n * const uploadWeightsInput = document.getElementById('upload-weights');\n * const model = await tf.loadLayersModel(tf.io.browserFiles(\n *     [uploadJSONInput.files[0], uploadWeightsInput.files[0]]));\n * ```\n *\n * @param files `File`s to load from. Currently, this function supports only\n *   loading from files that contain Keras-style models (i.e., `tf.Model`s), for\n *   which an `Array` of `File`s is expected (in that order):\n *   - A JSON file containing the model topology and weight manifest.\n *   - Optionally, One or more binary files containing the binary weights.\n *     These files must have names that match the paths in the `weightsManifest`\n *     contained by the aforementioned JSON file, or errors will be thrown\n *     during loading. These weights files have the same format as the ones\n *     generated by `tensorflowjs_converter` that comes with the `tensorflowjs`\n *     Python PIP package. If no weights files are provided, only the model\n *     topology will be loaded from the JSON file above.\n * @returns An instance of `Files` `IOHandler`.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction browserFiles(files) {\n    return new BrowserFiles(files);\n}\nexports.browserFiles = browserFiles;\n//# sourceMappingURL=browser_files.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/http.js":
/*!************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/http.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * IOHandler implementations based on HTTP requests in the web browser.\n *\n * Uses [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n */\nvar environment_1 = __webpack_require__(/*! ../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar io_utils_1 = __webpack_require__(/*! ./io_utils */ \"./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js\");\nvar router_registry_1 = __webpack_require__(/*! ./router_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js\");\nvar weights_loader_1 = __webpack_require__(/*! ./weights_loader */ \"./node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js\");\nvar OCTET_STREAM_MIME_TYPE = 'application/octet-stream';\nvar JSON_TYPE = 'application/json';\nvar HTTPRequest = /** @class */ (function () {\n    function HTTPRequest(path, loadOptions) {\n        this.DEFAULT_METHOD = 'POST';\n        if (loadOptions == null) {\n            loadOptions = {};\n        }\n        this.weightPathPrefix = loadOptions.weightPathPrefix;\n        this.onProgress = loadOptions.onProgress;\n        if (loadOptions.fetchFunc != null) {\n            util_1.assert(typeof loadOptions.fetchFunc === 'function', function () { return 'Must pass a function that matches the signature of ' +\n                '`fetch` (see ' +\n                'https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)'; });\n            this.fetch = loadOptions.fetchFunc;\n        }\n        else {\n            this.fetch = environment_1.env().platform.fetch;\n        }\n        util_1.assert(path != null && path.length > 0, function () { return 'URL path for http must not be null, undefined or ' +\n            'empty.'; });\n        if (Array.isArray(path)) {\n            util_1.assert(path.length === 2, function () { return 'URL paths for http must have a length of 2, ' +\n                (\"(actual length is \" + path.length + \").\"); });\n        }\n        this.path = path;\n        if (loadOptions.requestInit != null &&\n            loadOptions.requestInit.body != null) {\n            throw new Error('requestInit is expected to have no pre-existing body, but has one.');\n        }\n        this.requestInit = loadOptions.requestInit || {};\n    }\n    HTTPRequest.prototype.save = function (modelArtifacts) {\n        return __awaiter(this, void 0, void 0, function () {\n            var init, weightsManifest, modelTopologyAndWeightManifest, response;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n                            throw new Error('BrowserHTTPRequest.save() does not support saving model topology ' +\n                                'in binary formats yet.');\n                        }\n                        init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);\n                        init.body = new FormData();\n                        weightsManifest = [{\n                                paths: ['./model.weights.bin'],\n                                weights: modelArtifacts.weightSpecs,\n                            }];\n                        modelTopologyAndWeightManifest = {\n                            modelTopology: modelArtifacts.modelTopology,\n                            format: modelArtifacts.format,\n                            generatedBy: modelArtifacts.generatedBy,\n                            convertedBy: modelArtifacts.convertedBy,\n                            userDefinedMetadata: modelArtifacts.userDefinedMetadata,\n                            weightsManifest: weightsManifest\n                        };\n                        init.body.append('model.json', new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), 'model.json');\n                        if (modelArtifacts.weightData != null) {\n                            init.body.append('model.weights.bin', new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), 'model.weights.bin');\n                        }\n                        return [4 /*yield*/, this.fetch(this.path, init)];\n                    case 1:\n                        response = _a.sent();\n                        if (response.ok) {\n                            return [2 /*return*/, {\n                                    modelArtifactsInfo: io_utils_1.getModelArtifactsInfoForJSON(modelArtifacts),\n                                    responses: [response],\n                                }];\n                        }\n                        else {\n                            throw new Error(\"BrowserHTTPRequest.save() failed due to HTTP response status \" +\n                                (response.status + \".\"));\n                        }\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    /**\n     * Load model artifacts via HTTP request(s).\n     *\n     * See the documentation to `tf.io.http` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model artifacts (if loading succeeds).\n     */\n    HTTPRequest.prototype.load = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var modelConfigRequest, modelConfig, e_1, message, modelTopology, weightsManifest, generatedBy, convertedBy, format, userDefinedMetadata, weightSpecs, weightData, results;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.fetch(this.path, this.requestInit)];\n                    case 1:\n                        modelConfigRequest = _a.sent();\n                        if (!modelConfigRequest.ok) {\n                            throw new Error(\"Request to \" + this.path + \" failed with status code \" +\n                                (modelConfigRequest.status + \". Please verify this URL points to \") +\n                                \"the model JSON of the model to load.\");\n                        }\n                        _a.label = 2;\n                    case 2:\n                        _a.trys.push([2, 4, , 5]);\n                        return [4 /*yield*/, modelConfigRequest.json()];\n                    case 3:\n                        modelConfig = _a.sent();\n                        return [3 /*break*/, 5];\n                    case 4:\n                        e_1 = _a.sent();\n                        message = \"Failed to parse model JSON of response from \" + this.path + \".\";\n                        // TODO(nsthorat): Remove this after some time when we're comfortable that\n                        // .pb files are mostly gone.\n                        if (this.path.endsWith('.pb')) {\n                            message += ' Your path contains a .pb file extension. ' +\n                                'Support for .pb models have been removed in TensorFlow.js 1.0 ' +\n                                'in favor of .json models. You can re-convert your Python ' +\n                                'TensorFlow model using the TensorFlow.js 1.0 conversion scripts ' +\n                                'or you can convert your.pb models with the \\'pb2json\\'' +\n                                'NPM script in the tensorflow/tfjs-converter repository.';\n                        }\n                        else {\n                            message += ' Please make sure the server is serving valid ' +\n                                'JSON for this request.';\n                        }\n                        throw new Error(message);\n                    case 5:\n                        modelTopology = modelConfig.modelTopology;\n                        weightsManifest = modelConfig.weightsManifest;\n                        generatedBy = modelConfig.generatedBy;\n                        convertedBy = modelConfig.convertedBy;\n                        format = modelConfig.format;\n                        userDefinedMetadata = modelConfig.userDefinedMetadata;\n                        // We do not allow both modelTopology and weightsManifest to be missing.\n                        if (modelTopology == null && weightsManifest == null) {\n                            throw new Error(\"The JSON from HTTP path \" + this.path + \" contains neither model \" +\n                                \"topology or manifest for weights.\");\n                        }\n                        if (!(weightsManifest != null)) return [3 /*break*/, 7];\n                        return [4 /*yield*/, this.loadWeights(weightsManifest)];\n                    case 6:\n                        results = _a.sent();\n                        weightSpecs = results[0], weightData = results[1];\n                        _a.label = 7;\n                    case 7: return [2 /*return*/, {\n                            modelTopology: modelTopology,\n                            weightSpecs: weightSpecs,\n                            weightData: weightData,\n                            userDefinedMetadata: userDefinedMetadata,\n                            generatedBy: generatedBy,\n                            convertedBy: convertedBy,\n                            format: format\n                        }];\n                }\n            });\n        });\n    };\n    HTTPRequest.prototype.loadWeights = function (weightsManifest) {\n        return __awaiter(this, void 0, void 0, function () {\n            var weightPath, _a, prefix, suffix, pathPrefix, weightSpecs, _i, weightsManifest_1, entry, fetchURLs, buffers;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        weightPath = Array.isArray(this.path) ? this.path[1] : this.path;\n                        _a = parseUrl(weightPath), prefix = _a[0], suffix = _a[1];\n                        pathPrefix = this.weightPathPrefix || prefix;\n                        weightSpecs = [];\n                        for (_i = 0, weightsManifest_1 = weightsManifest; _i < weightsManifest_1.length; _i++) {\n                            entry = weightsManifest_1[_i];\n                            weightSpecs.push.apply(weightSpecs, entry.weights);\n                        }\n                        fetchURLs = [];\n                        weightsManifest.forEach(function (weightsGroup) {\n                            weightsGroup.paths.forEach(function (path) {\n                                fetchURLs.push(pathPrefix + path + suffix);\n                            });\n                        });\n                        return [4 /*yield*/, weights_loader_1.loadWeightsAsArrayBuffer(fetchURLs, {\n                                requestInit: this.requestInit,\n                                fetchFunc: this.fetch,\n                                onProgress: this.onProgress\n                            })];\n                    case 1:\n                        buffers = _b.sent();\n                        return [2 /*return*/, [weightSpecs, io_utils_1.concatenateArrayBuffers(buffers)]];\n                }\n            });\n        });\n    };\n    HTTPRequest.URL_SCHEME_REGEX = /^https?:\\/\\//;\n    return HTTPRequest;\n}());\nexports.HTTPRequest = HTTPRequest;\n/**\n * Extract the prefix and suffix of the url, where the prefix is the path before\n * the last file, and suffix is the search params after the last file.\n * ```\n * const url = 'http://tfhub.dev/model/1/tensorflowjs_model.pb?tfjs-format=file'\n * [prefix, suffix] = parseUrl(url)\n * // prefix = 'http://tfhub.dev/model/1/'\n * // suffix = '?tfjs-format=file'\n * ```\n * @param url the model url to be parsed.\n */\nfunction parseUrl(url) {\n    var lastSlash = url.lastIndexOf('/');\n    var lastSearchParam = url.lastIndexOf('?');\n    var prefix = url.substring(0, lastSlash);\n    var suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : '';\n    return [prefix + '/', suffix];\n}\nexports.parseUrl = parseUrl;\nfunction isHTTPScheme(url) {\n    return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;\n}\nexports.isHTTPScheme = isHTTPScheme;\nexports.httpRouter = function (url, onProgress) {\n    if (typeof fetch === 'undefined') {\n        // `http` uses `fetch` or `node-fetch`, if one wants to use it in\n        // an environment that is not the browser or node they have to setup a\n        // global fetch polyfill.\n        return null;\n    }\n    else {\n        var isHTTP = true;\n        if (Array.isArray(url)) {\n            isHTTP = url.every(function (urlItem) { return isHTTPScheme(urlItem); });\n        }\n        else {\n            isHTTP = isHTTPScheme(url);\n        }\n        if (isHTTP) {\n            return http(url, { onProgress: onProgress });\n        }\n    }\n    return null;\n};\nrouter_registry_1.IORouterRegistry.registerSaveRouter(exports.httpRouter);\nrouter_registry_1.IORouterRegistry.registerLoadRouter(exports.httpRouter);\n/**\n * Creates an IOHandler subtype that sends model artifacts to HTTP server.\n *\n * An HTTP request of the `multipart/form-data` mime type will be sent to the\n * `path` URL. The form data includes artifacts that represent the topology\n * and/or weights of the model. In the case of Keras-style `tf.Model`, two\n * blobs (files) exist in form-data:\n *   - A JSON file consisting of `modelTopology` and `weightsManifest`.\n *   - A binary weights file consisting of the concatenated weight values.\n * These files are in the same format as the one generated by\n * [tfjs_converter](https://js.tensorflow.org/tutorials/import-keras.html).\n *\n * The following code snippet exemplifies the client-side code that uses this\n * function:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save(tf.io.http(\n *     'http://model-server:5000/upload', {requestInit: {method: 'PUT'}}));\n * console.log(saveResult);\n * ```\n *\n * If the default `POST` method is to be used, without any custom parameters\n * such as headers, you can simply pass an HTTP or HTTPS URL to `model.save`:\n *\n * ```js\n * const saveResult = await model.save('http://model-server:5000/upload');\n * ```\n *\n * The following GitHub Gist\n * https://gist.github.com/dsmilkov/1b6046fd6132d7408d5257b0976f7864\n * implements a server based on [flask](https://github.com/pallets/flask) that\n * can receive the request. Upon receiving the model artifacts via the requst,\n * this particular server reconsistutes instances of [Keras\n * Models](https://keras.io/models/model/) in memory.\n *\n *\n * @param path A URL path to the model.\n *   Can be an absolute HTTP path (e.g.,\n *   'http://localhost:8000/model-upload)') or a relative path (e.g.,\n *   './model-upload').\n * @param requestInit Request configurations to be used when sending\n *    HTTP request to server using `fetch`. It can contain fields such as\n *    `method`, `credentials`, `headers`, `mode`, etc. See\n *    https://developer.mozilla.org/en-US/docs/Web/API/Request/Request\n *    for more information. `requestInit` must not have a body, because the\n * body will be set by TensorFlow.js. File blobs representing the model\n * topology (filename: 'model.json') and the weights of the model (filename:\n * 'model.weights.bin') will be appended to the body. If `requestInit` has a\n * `body`, an Error will be thrown.\n * @param loadOptions Optional configuration for the loading. It includes the\n *   following fields:\n *   - weightPathPrefix Optional, this specifies the path prefix for weight\n *     files, by default this is calculated from the path param.\n *   - fetchFunc Optional, custom `fetch` function. E.g., in Node.js,\n *     the `fetch` from node-fetch can be used here.\n *   - onProgress Optional, progress callback function, fired periodically\n *     before the load is completed.\n * @returns An instance of `IOHandler`.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction http(path, loadOptions) {\n    return new HTTPRequest(path, loadOptions);\n}\nexports.http = http;\n/**\n * Deprecated. Use `tf.io.http`.\n * @param path\n * @param loadOptions\n */\nfunction browserHTTPRequest(path, loadOptions) {\n    return http(path, loadOptions);\n}\nexports.browserHTTPRequest = browserHTTPRequest;\n//# sourceMappingURL=http.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/http.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar io_utils_1 = __webpack_require__(/*! ./io_utils */ \"./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js\");\nvar model_management_1 = __webpack_require__(/*! ./model_management */ \"./node_modules/@tensorflow/tfjs-core/dist/io/model_management.js\");\nvar router_registry_1 = __webpack_require__(/*! ./router_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js\");\nvar DATABASE_NAME = 'tensorflowjs';\nvar DATABASE_VERSION = 1;\n// Model data and ModelArtifactsInfo (metadata) are stored in two separate\n// stores for efficient access of the list of stored models and their metadata.\n// 1. The object store for model data: topology, weights and weight manifests.\nvar MODEL_STORE_NAME = 'models_store';\n// 2. The object store for ModelArtifactsInfo, including meta-information such\n//    as the type of topology (JSON vs binary), byte size of the topology, byte\n//    size of the weights, etc.\nvar INFO_STORE_NAME = 'model_info_store';\n/**\n * Delete the entire database for tensorflow.js, including the models store.\n */\nfunction deleteDatabase() {\n    return __awaiter(this, void 0, void 0, function () {\n        var idbFactory;\n        return __generator(this, function (_a) {\n            idbFactory = getIndexedDBFactory();\n            return [2 /*return*/, new Promise(function (resolve, reject) {\n                    var deleteRequest = idbFactory.deleteDatabase(DATABASE_NAME);\n                    deleteRequest.onsuccess = function () { return resolve(); };\n                    deleteRequest.onerror = function (error) { return reject(error); };\n                })];\n        });\n    });\n}\nexports.deleteDatabase = deleteDatabase;\nfunction getIndexedDBFactory() {\n    if (!environment_1.env().getBool('IS_BROWSER')) {\n        // TODO(cais): Add more info about what IOHandler subtypes are available.\n        //   Maybe point to a doc page on the web and/or automatically determine\n        //   the available IOHandlers and print them in the error message.\n        throw new Error('Failed to obtain IndexedDB factory because the current environment' +\n            'is not a web browser.');\n    }\n    // tslint:disable-next-line:no-any\n    var theWindow = window || self;\n    var factory = theWindow.indexedDB || theWindow.mozIndexedDB ||\n        theWindow.webkitIndexedDB || theWindow.msIndexedDB ||\n        theWindow.shimIndexedDB;\n    if (factory == null) {\n        throw new Error('The current browser does not appear to support IndexedDB.');\n    }\n    return factory;\n}\nfunction setUpDatabase(openRequest) {\n    var db = openRequest.result;\n    db.createObjectStore(MODEL_STORE_NAME, { keyPath: 'modelPath' });\n    db.createObjectStore(INFO_STORE_NAME, { keyPath: 'modelPath' });\n}\n/**\n * IOHandler subclass: Browser IndexedDB.\n *\n * See the doc string of `browserIndexedDB` for more details.\n */\nvar BrowserIndexedDB = /** @class */ (function () {\n    function BrowserIndexedDB(modelPath) {\n        this.indexedDB = getIndexedDBFactory();\n        if (modelPath == null || !modelPath) {\n            throw new Error('For IndexedDB, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n    }\n    BrowserIndexedDB.prototype.save = function (modelArtifacts) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                // TODO(cais): Support saving GraphDef models.\n                if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n                    throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                        'in binary formats yet.');\n                }\n                return [2 /*return*/, this.databaseAction(this.modelPath, modelArtifacts)];\n            });\n        });\n    };\n    BrowserIndexedDB.prototype.load = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.databaseAction(this.modelPath)];\n            });\n        });\n    };\n    /**\n     * Perform database action to put model artifacts into or read model artifacts\n     * from IndexedDB object store.\n     *\n     * Whether the action is put or get depends on whether `modelArtifacts` is\n     * specified. If it is specified, the action will be put; otherwise the action\n     * will be get.\n     *\n     * @param modelPath A unique string path for the model.\n     * @param modelArtifacts If specified, it will be the model artifacts to be\n     *   stored in IndexedDB.\n     * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`\n     *   of `ModelArtifacts`, if the action is get.\n     */\n    BrowserIndexedDB.prototype.databaseAction = function (modelPath, modelArtifacts) {\n        var _this = this;\n        return new Promise(function (resolve, reject) {\n            var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = function () { return setUpDatabase(openRequest); };\n            openRequest.onsuccess = function () {\n                var db = openRequest.result;\n                if (modelArtifacts == null) {\n                    // Read model out from object store.\n                    var modelTx = db.transaction(MODEL_STORE_NAME, 'readonly');\n                    var modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                    var getRequest_1 = modelStore.get(_this.modelPath);\n                    getRequest_1.onsuccess = function () {\n                        if (getRequest_1.result == null) {\n                            db.close();\n                            return reject(new Error(\"Cannot find model with path '\" + _this.modelPath + \"' \" +\n                                \"in IndexedDB.\"));\n                        }\n                        else {\n                            resolve(getRequest_1.result.modelArtifacts);\n                        }\n                    };\n                    getRequest_1.onerror = function (error) {\n                        db.close();\n                        return reject(getRequest_1.error);\n                    };\n                    modelTx.oncomplete = function () { return db.close(); };\n                }\n                else {\n                    // Put model into object store.\n                    var modelArtifactsInfo_1 = io_utils_1.getModelArtifactsInfoForJSON(modelArtifacts);\n                    // First, put ModelArtifactsInfo into info store.\n                    var infoTx_1 = db.transaction(INFO_STORE_NAME, 'readwrite');\n                    var infoStore_1 = infoTx_1.objectStore(INFO_STORE_NAME);\n                    var putInfoRequest_1 = infoStore_1.put({ modelPath: _this.modelPath, modelArtifactsInfo: modelArtifactsInfo_1 });\n                    var modelTx_1;\n                    putInfoRequest_1.onsuccess = function () {\n                        // Second, put model data into model store.\n                        modelTx_1 = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                        var modelStore = modelTx_1.objectStore(MODEL_STORE_NAME);\n                        var putModelRequest = modelStore.put({\n                            modelPath: _this.modelPath,\n                            modelArtifacts: modelArtifacts,\n                            modelArtifactsInfo: modelArtifactsInfo_1\n                        });\n                        putModelRequest.onsuccess = function () { return resolve({ modelArtifactsInfo: modelArtifactsInfo_1 }); };\n                        putModelRequest.onerror = function (error) {\n                            // If the put-model request fails, roll back the info entry as\n                            // well.\n                            infoStore_1 = infoTx_1.objectStore(INFO_STORE_NAME);\n                            var deleteInfoRequest = infoStore_1.delete(_this.modelPath);\n                            deleteInfoRequest.onsuccess = function () {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                            deleteInfoRequest.onerror = function (error) {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                        };\n                    };\n                    putInfoRequest_1.onerror = function (error) {\n                        db.close();\n                        return reject(putInfoRequest_1.error);\n                    };\n                    infoTx_1.oncomplete = function () {\n                        if (modelTx_1 == null) {\n                            db.close();\n                        }\n                        else {\n                            modelTx_1.oncomplete = function () { return db.close(); };\n                        }\n                    };\n                }\n            };\n            openRequest.onerror = function (error) { return reject(openRequest.error); };\n        });\n    };\n    BrowserIndexedDB.URL_SCHEME = 'indexeddb://';\n    return BrowserIndexedDB;\n}());\nexports.BrowserIndexedDB = BrowserIndexedDB;\nexports.indexedDBRouter = function (url) {\n    if (!environment_1.env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {\n            return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nrouter_registry_1.IORouterRegistry.registerSaveRouter(exports.indexedDBRouter);\nrouter_registry_1.IORouterRegistry.registerLoadRouter(exports.indexedDBRouter);\n/**\n * Creates a browser IndexedDB IOHandler for saving and loading models.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save('indexeddb://MyModel'));\n * console.log(saveResult);\n * ```\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `BrowserIndexedDB` (sublcass of `IOHandler`),\n *   which can be used with, e.g., `tf.Model.save`.\n */\nfunction browserIndexedDB(modelPath) {\n    return new BrowserIndexedDB(modelPath);\n}\nexports.browserIndexedDB = browserIndexedDB;\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserIndexedDB.URL_SCHEME) ?\n        key.slice(BrowserIndexedDB.URL_SCHEME.length) :\n        key;\n}\nvar BrowserIndexedDBManager = /** @class */ (function () {\n    function BrowserIndexedDBManager() {\n        this.indexedDB = getIndexedDBFactory();\n    }\n    BrowserIndexedDBManager.prototype.listModels = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                return [2 /*return*/, new Promise(function (resolve, reject) {\n                        var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n                        openRequest.onupgradeneeded = function () { return setUpDatabase(openRequest); };\n                        openRequest.onsuccess = function () {\n                            var db = openRequest.result;\n                            var tx = db.transaction(INFO_STORE_NAME, 'readonly');\n                            var store = tx.objectStore(INFO_STORE_NAME);\n                            // tslint:disable:max-line-length\n                            // Need to cast `store` as `any` here because TypeScript's DOM\n                            // library does not have the `getAll()` method even though the\n                            // method is supported in the latest version of most mainstream\n                            // browsers:\n                            // https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/getAll\n                            // tslint:enable:max-line-length\n                            // tslint:disable-next-line:no-any\n                            var getAllInfoRequest = store.getAll();\n                            getAllInfoRequest.onsuccess = function () {\n                                var out = {};\n                                for (var _i = 0, _a = getAllInfoRequest.result; _i < _a.length; _i++) {\n                                    var item = _a[_i];\n                                    out[item.modelPath] = item.modelArtifactsInfo;\n                                }\n                                resolve(out);\n                            };\n                            getAllInfoRequest.onerror = function (error) {\n                                db.close();\n                                return reject(getAllInfoRequest.error);\n                            };\n                            tx.oncomplete = function () { return db.close(); };\n                        };\n                        openRequest.onerror = function (error) { return reject(openRequest.error); };\n                    })];\n            });\n        });\n    };\n    BrowserIndexedDBManager.prototype.removeModel = function (path) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _this = this;\n            return __generator(this, function (_a) {\n                path = maybeStripScheme(path);\n                return [2 /*return*/, new Promise(function (resolve, reject) {\n                        var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n                        openRequest.onupgradeneeded = function () { return setUpDatabase(openRequest); };\n                        openRequest.onsuccess = function () {\n                            var db = openRequest.result;\n                            var infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n                            var infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                            var getInfoRequest = infoStore.get(path);\n                            var modelTx;\n                            getInfoRequest.onsuccess = function () {\n                                if (getInfoRequest.result == null) {\n                                    db.close();\n                                    return reject(new Error(\"Cannot find model with path '\" + path + \"' \" +\n                                        \"in IndexedDB.\"));\n                                }\n                                else {\n                                    // First, delete the entry in the info store.\n                                    var deleteInfoRequest = infoStore.delete(path);\n                                    var deleteModelData_1 = function () {\n                                        // Second, delete the entry in the model store.\n                                        modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                                        var modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                                        var deleteModelRequest = modelStore.delete(path);\n                                        deleteModelRequest.onsuccess = function () {\n                                            return resolve(getInfoRequest.result.modelArtifactsInfo);\n                                        };\n                                        deleteModelRequest.onerror = function (error) {\n                                            return reject(getInfoRequest.error);\n                                        };\n                                    };\n                                    // Proceed with deleting model data regardless of whether deletion\n                                    // of info data succeeds or not.\n                                    deleteInfoRequest.onsuccess = deleteModelData_1;\n                                    deleteInfoRequest.onerror = function (error) {\n                                        deleteModelData_1();\n                                        db.close();\n                                        return reject(getInfoRequest.error);\n                                    };\n                                }\n                            };\n                            getInfoRequest.onerror = function (error) {\n                                db.close();\n                                return reject(getInfoRequest.error);\n                            };\n                            infoTx.oncomplete = function () {\n                                if (modelTx == null) {\n                                    db.close();\n                                }\n                                else {\n                                    modelTx.oncomplete = function () { return db.close(); };\n                                }\n                            };\n                        };\n                        openRequest.onerror = function (error) { return reject(openRequest.error); };\n                    })];\n            });\n        });\n    };\n    return BrowserIndexedDBManager;\n}());\nexports.BrowserIndexedDBManager = BrowserIndexedDBManager;\nif (environment_1.env().getBool('IS_BROWSER')) {\n    // Wrap the construction and registration, to guard against browsers that\n    // don't support Local Storage.\n    try {\n        model_management_1.ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());\n    }\n    catch (err) {\n    }\n}\n//# sourceMappingURL=indexed_db.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/io.js":
/*!**********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/io.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Importing local_storage and indexed_db is necessary for the routers to be\n// registered.\n__webpack_require__(/*! ./indexed_db */ \"./node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js\");\n__webpack_require__(/*! ./local_storage */ \"./node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js\");\nvar browser_files_1 = __webpack_require__(/*! ./browser_files */ \"./node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js\");\nexports.browserFiles = browser_files_1.browserFiles;\nvar http_1 = __webpack_require__(/*! ./http */ \"./node_modules/@tensorflow/tfjs-core/dist/io/http.js\");\nexports.browserHTTPRequest = http_1.browserHTTPRequest;\nexports.http = http_1.http;\nexports.isHTTPScheme = http_1.isHTTPScheme;\nvar io_utils_1 = __webpack_require__(/*! ./io_utils */ \"./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js\");\nexports.concatenateArrayBuffers = io_utils_1.concatenateArrayBuffers;\nexports.decodeWeights = io_utils_1.decodeWeights;\nexports.encodeWeights = io_utils_1.encodeWeights;\nexports.getModelArtifactsInfoForJSON = io_utils_1.getModelArtifactsInfoForJSON;\nvar passthrough_1 = __webpack_require__(/*! ./passthrough */ \"./node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js\");\nexports.fromMemory = passthrough_1.fromMemory;\nexports.withSaveHandler = passthrough_1.withSaveHandler;\nvar router_registry_1 = __webpack_require__(/*! ./router_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js\");\nexports.getLoadHandlers = router_registry_1.getLoadHandlers;\nexports.getSaveHandlers = router_registry_1.getSaveHandlers;\nexports.registerLoadRouter = router_registry_1.registerLoadRouter;\nexports.registerSaveRouter = router_registry_1.registerSaveRouter;\nvar weights_loader_1 = __webpack_require__(/*! ./weights_loader */ \"./node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js\");\nexports.loadWeights = weights_loader_1.loadWeights;\nexports.weightsLoaderFactory = weights_loader_1.weightsLoaderFactory;\nvar model_management_1 = __webpack_require__(/*! ./model_management */ \"./node_modules/@tensorflow/tfjs-core/dist/io/model_management.js\");\nexports.copyModel = model_management_1.copyModel;\nexports.listModels = model_management_1.listModels;\nexports.moveModel = model_management_1.moveModel;\nexports.removeModel = model_management_1.removeModel;\n//# sourceMappingURL=io.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/io.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(Buffer) {\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_ops_1 = __webpack_require__(/*! ../ops/tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar types_1 = __webpack_require__(/*! ./types */ \"./node_modules/@tensorflow/tfjs-core/dist/io/types.js\");\n/** Number of bytes reserved for the length of the string. (32bit integer). */\nvar NUM_BYTES_STRING_LENGTH = 4;\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @param group Group to which the weights belong (optional).\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\nfunction encodeWeights(tensors, group) {\n    return __awaiter(this, void 0, void 0, function () {\n        var specs, dataPromises, names, _loop_1, i, tensorValues;\n        var _this = this;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    specs = [];\n                    dataPromises = [];\n                    names = Array.isArray(tensors) ?\n                        tensors.map(function (tensor) { return tensor.name; }) :\n                        Object.keys(tensors);\n                    _loop_1 = function (i) {\n                        var name_1 = names[i];\n                        var t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name_1];\n                        if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool' &&\n                            t.dtype !== 'string') {\n                            throw new Error(\"Unsupported dtype in weight '\" + name_1 + \"': \" + t.dtype);\n                        }\n                        var spec = { name: name_1, shape: t.shape, dtype: t.dtype };\n                        if (t.dtype === 'string') {\n                            var utf8bytes = new Promise(function (resolve) { return __awaiter(_this, void 0, void 0, function () {\n                                var vals, totalNumBytes, bytes, offset, i_1, val, bytesOfLength;\n                                return __generator(this, function (_a) {\n                                    switch (_a.label) {\n                                        case 0: return [4 /*yield*/, t.bytes()];\n                                        case 1:\n                                            vals = _a.sent();\n                                            totalNumBytes = vals.reduce(function (p, c) { return p + c.length; }, 0) +\n                                                NUM_BYTES_STRING_LENGTH * vals.length;\n                                            bytes = new Uint8Array(totalNumBytes);\n                                            offset = 0;\n                                            for (i_1 = 0; i_1 < vals.length; i_1++) {\n                                                val = vals[i_1];\n                                                bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);\n                                                bytes.set(bytesOfLength, offset);\n                                                offset += NUM_BYTES_STRING_LENGTH;\n                                                bytes.set(val, offset);\n                                                offset += val.length;\n                                            }\n                                            resolve(bytes);\n                                            return [2 /*return*/];\n                                    }\n                                });\n                            }); });\n                            dataPromises.push(utf8bytes);\n                        }\n                        else {\n                            dataPromises.push(t.data());\n                        }\n                        if (group != null) {\n                            spec.group = group;\n                        }\n                        specs.push(spec);\n                    };\n                    for (i = 0; i < names.length; ++i) {\n                        _loop_1(i);\n                    }\n                    return [4 /*yield*/, Promise.all(dataPromises)];\n                case 1:\n                    tensorValues = _a.sent();\n                    return [2 /*return*/, { data: concatenateTypedArrays(tensorValues), specs: specs }];\n            }\n        });\n    });\n}\nexports.encodeWeights = encodeWeights;\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param buffer A flat ArrayBuffer carrying the binary values of the tensors\n *   concatenated in the order specified in `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\nfunction decodeWeights(buffer, specs) {\n    // TODO(adarob, cais): Support quantization.\n    var out = {};\n    var offset = 0;\n    var _loop_2 = function (spec) {\n        var name_2 = spec.name;\n        var dtype = spec.dtype;\n        var shape = spec.shape;\n        var size = util_1.sizeFromShape(shape);\n        var values = void 0;\n        if ('quantization' in spec) {\n            var quantization_1 = spec.quantization;\n            if (quantization_1.dtype !== 'uint8' && quantization_1.dtype !== 'uint16') {\n                throw new Error(\"Weight \" + spec.name + \" has unknown \" +\n                    (\"quantization dtype \" + quantization_1.dtype + \". \") +\n                    \"Supported quantization dtypes are: 'uint8' and 'uint16'.\");\n            }\n            var quantizationSizeFactor = types_1.DTYPE_VALUE_SIZE_MAP[quantization_1.dtype];\n            var byteBuffer = buffer.slice(offset, offset + size * quantizationSizeFactor);\n            var quantizedArray = (quantization_1.dtype === 'uint8') ?\n                new Uint8Array(byteBuffer) :\n                new Uint16Array(byteBuffer);\n            if (dtype === 'float32') {\n                values = Float32Array.from(quantizedArray, function (v) { return v * quantization_1.scale + quantization_1.min; });\n            }\n            else if (dtype === 'int32') {\n                values = Int32Array.from(quantizedArray, function (v) { return Math.round(v * quantization_1.scale + quantization_1.min); });\n            }\n            else {\n                throw new Error(\"Unsupported dtype in weight '\" + name_2 + \"': \" + dtype);\n            }\n            offset += size * quantizationSizeFactor;\n        }\n        else if (dtype === 'string') {\n            var size_1 = util_1.sizeFromShape(spec.shape);\n            values = [];\n            for (var i = 0; i < size_1; i++) {\n                var byteLength = new Uint32Array(buffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];\n                offset += NUM_BYTES_STRING_LENGTH;\n                var bytes = new Uint8Array(buffer.slice(offset, offset + byteLength));\n                values.push(bytes);\n                offset += byteLength;\n            }\n        }\n        else {\n            var dtypeFactor = types_1.DTYPE_VALUE_SIZE_MAP[dtype];\n            var byteBuffer = buffer.slice(offset, offset + size * dtypeFactor);\n            if (dtype === 'float32') {\n                values = new Float32Array(byteBuffer);\n            }\n            else if (dtype === 'int32') {\n                values = new Int32Array(byteBuffer);\n            }\n            else if (dtype === 'bool') {\n                values = new Uint8Array(byteBuffer);\n            }\n            else {\n                throw new Error(\"Unsupported dtype in weight '\" + name_2 + \"': \" + dtype);\n            }\n            offset += size * dtypeFactor;\n        }\n        out[name_2] = tensor_ops_1.tensor(values, shape, dtype);\n    };\n    for (var _i = 0, specs_1 = specs; _i < specs_1.length; _i++) {\n        var spec = specs_1[_i];\n        _loop_2(spec);\n    }\n    return out;\n}\nexports.decodeWeights = decodeWeights;\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\nfunction concatenateTypedArrays(xs) {\n    // TODO(adarob, cais): Support quantization.\n    if (xs === null) {\n        throw new Error(\"Invalid input value: \" + JSON.stringify(xs));\n    }\n    var totalByteLength = 0;\n    // `normalizedXs` is here for this reason: a `TypedArray`'s `buffer'\n    // can have a different byte length from that of the `TypedArray` itself,\n    // for example, when the `TypedArray` is created from an offset in an\n    // `ArrayBuffer`. `normliazedXs` holds `TypedArray`s whose `buffer`s match\n    // the `TypedArray` in byte length. If an element of `xs` does not show\n    // this property, a new `TypedArray` that satisfy this property will be\n    // constructed and pushed into `normalizedXs`.\n    var normalizedXs = [];\n    xs.forEach(function (x) {\n        totalByteLength += x.byteLength;\n        // tslint:disable:no-any\n        normalizedXs.push(x.byteLength === x.buffer.byteLength ? x :\n            new x.constructor(x));\n        if (!(x instanceof Float32Array || x instanceof Int32Array ||\n            x instanceof Uint8Array)) {\n            throw new Error(\"Unsupported TypedArray subtype: \" + x.constructor.name);\n        }\n        // tslint:enable:no-any\n    });\n    var y = new Uint8Array(totalByteLength);\n    var offset = 0;\n    normalizedXs.forEach(function (x) {\n        y.set(new Uint8Array(x.buffer), offset);\n        offset += x.byteLength;\n    });\n    return y.buffer;\n}\nexports.concatenateTypedArrays = concatenateTypedArrays;\n// Use Buffer on Node.js instead of Blob/atob/btoa\nvar useNodeBuffer = typeof Buffer !== 'undefined' &&\n    (typeof Blob === 'undefined' || typeof atob === 'undefined' ||\n        typeof btoa === 'undefined');\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\nfunction stringByteLength(str) {\n    if (useNodeBuffer) {\n        return Buffer.byteLength(str);\n    }\n    return new Blob([str]).size;\n}\nexports.stringByteLength = stringByteLength;\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\nfunction arrayBufferToBase64String(buffer) {\n    if (useNodeBuffer) {\n        return Buffer.from(buffer).toString('base64');\n    }\n    var buf = new Uint8Array(buffer);\n    var s = '';\n    for (var i = 0, l = buf.length; i < l; i++) {\n        s += String.fromCharCode(buf[i]);\n    }\n    return btoa(s);\n}\nexports.arrayBufferToBase64String = arrayBufferToBase64String;\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\nfunction base64StringToArrayBuffer(str) {\n    if (useNodeBuffer) {\n        var buf = Buffer.from(str, 'base64');\n        return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n    }\n    var s = atob(str);\n    var buffer = new Uint8Array(s.length);\n    for (var i = 0; i < s.length; ++i) {\n        buffer.set([s.charCodeAt(i)], i);\n    }\n    return buffer.buffer;\n}\nexports.base64StringToArrayBuffer = base64StringToArrayBuffer;\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\nfunction concatenateArrayBuffers(buffers) {\n    var totalByteLength = 0;\n    buffers.forEach(function (buffer) {\n        totalByteLength += buffer.byteLength;\n    });\n    var temp = new Uint8Array(totalByteLength);\n    var offset = 0;\n    buffers.forEach(function (buffer) {\n        temp.set(new Uint8Array(buffer), offset);\n        offset += buffer.byteLength;\n    });\n    return temp.buffer;\n}\nexports.concatenateArrayBuffers = concatenateArrayBuffers;\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\nfunction basename(path) {\n    var SEPARATOR = '/';\n    path = path.trim();\n    while (path.endsWith(SEPARATOR)) {\n        path = path.slice(0, path.length - 1);\n    }\n    var items = path.split(SEPARATOR);\n    return items[items.length - 1];\n}\nexports.basename = basename;\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\nfunction getModelArtifactsInfoForJSON(modelArtifacts) {\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n        throw new Error('Expected JSON model topology, received ArrayBuffer.');\n    }\n    return {\n        dateSaved: new Date(),\n        modelTopologyType: 'JSON',\n        modelTopologyBytes: modelArtifacts.modelTopology == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n        weightSpecsBytes: modelArtifacts.weightSpecs == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n        weightDataBytes: modelArtifacts.weightData == null ?\n            0 :\n            modelArtifacts.weightData.byteLength,\n    };\n}\nexports.getModelArtifactsInfoForJSON = getModelArtifactsInfoForJSON;\n//# sourceMappingURL=io_utils.js.map\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer))\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar io_utils_1 = __webpack_require__(/*! ./io_utils */ \"./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js\");\nvar model_management_1 = __webpack_require__(/*! ./model_management */ \"./node_modules/@tensorflow/tfjs-core/dist/io/model_management.js\");\nvar router_registry_1 = __webpack_require__(/*! ./router_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js\");\nvar PATH_SEPARATOR = '/';\nvar PATH_PREFIX = 'tensorflowjs_models';\nvar INFO_SUFFIX = 'info';\nvar MODEL_TOPOLOGY_SUFFIX = 'model_topology';\nvar WEIGHT_SPECS_SUFFIX = 'weight_specs';\nvar WEIGHT_DATA_SUFFIX = 'weight_data';\nvar MODEL_METADATA_SUFFIX = 'model_metadata';\n/**\n * Purge all tensorflow.js-saved model artifacts from local storage.\n *\n * @returns Paths of the models purged.\n */\nfunction purgeLocalStorageArtifacts() {\n    if (!environment_1.env().getBool('IS_BROWSER') ||\n        typeof window === 'undefined' ||\n        typeof window.localStorage === 'undefined') {\n        throw new Error('purgeLocalStorageModels() cannot proceed because local storage is ' +\n            'unavailable in the current environment.');\n    }\n    var LS = window.localStorage;\n    var purgedModelPaths = [];\n    for (var i = 0; i < LS.length; ++i) {\n        var key = LS.key(i);\n        var prefix = PATH_PREFIX + PATH_SEPARATOR;\n        if (key.startsWith(prefix) && key.length > prefix.length) {\n            LS.removeItem(key);\n            var modelName = getModelPathFromKey(key);\n            if (purgedModelPaths.indexOf(modelName) === -1) {\n                purgedModelPaths.push(modelName);\n            }\n        }\n    }\n    return purgedModelPaths;\n}\nexports.purgeLocalStorageArtifacts = purgeLocalStorageArtifacts;\nfunction getModelKeys(path) {\n    return {\n        info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),\n        topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),\n        weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),\n        weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),\n        modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)\n    };\n}\n/**\n * Get model path from a local-storage key.\n *\n * E.g., 'tensorflowjs_models/my/model/1/info' --> 'my/model/1'\n *\n * @param key\n */\nfunction getModelPathFromKey(key) {\n    var items = key.split(PATH_SEPARATOR);\n    if (items.length < 3) {\n        throw new Error(\"Invalid key format: \" + key);\n    }\n    return items.slice(1, items.length - 1).join(PATH_SEPARATOR);\n}\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserLocalStorage.URL_SCHEME) ?\n        key.slice(BrowserLocalStorage.URL_SCHEME.length) :\n        key;\n}\n/**\n * IOHandler subclass: Browser Local Storage.\n *\n * See the doc string to `browserLocalStorage` for more details.\n */\nvar BrowserLocalStorage = /** @class */ (function () {\n    function BrowserLocalStorage(modelPath) {\n        if (!environment_1.env().getBool('IS_BROWSER') ||\n            typeof window === 'undefined' ||\n            typeof window.localStorage === 'undefined') {\n            // TODO(cais): Add more info about what IOHandler subtypes are\n            // available.\n            //   Maybe point to a doc page on the web and/or automatically determine\n            //   the available IOHandlers and print them in the error message.\n            throw new Error('The current environment does not support local storage.');\n        }\n        this.LS = window.localStorage;\n        if (modelPath == null || !modelPath) {\n            throw new Error('For local storage, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n        this.keys = getModelKeys(this.modelPath);\n    }\n    /**\n     * Save model artifacts to browser local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @param modelArtifacts The model artifacts to be stored.\n     * @returns An instance of SaveResult.\n     */\n    BrowserLocalStorage.prototype.save = function (modelArtifacts) {\n        return __awaiter(this, void 0, void 0, function () {\n            var topology, weightSpecs, modelArtifactsInfo;\n            return __generator(this, function (_a) {\n                if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n                    throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                        'in binary formats yet.');\n                }\n                else {\n                    topology = JSON.stringify(modelArtifacts.modelTopology);\n                    weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);\n                    modelArtifactsInfo = io_utils_1.getModelArtifactsInfoForJSON(modelArtifacts);\n                    try {\n                        this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));\n                        this.LS.setItem(this.keys.topology, topology);\n                        this.LS.setItem(this.keys.weightSpecs, weightSpecs);\n                        this.LS.setItem(this.keys.weightData, io_utils_1.arrayBufferToBase64String(modelArtifacts.weightData));\n                        this.LS.setItem(this.keys.modelMetadata, JSON.stringify({\n                            format: modelArtifacts.format,\n                            generatedBy: modelArtifacts.generatedBy,\n                            convertedBy: modelArtifacts.convertedBy,\n                            userDefinedMetadata: modelArtifacts.userDefinedMetadata\n                        }));\n                        return [2 /*return*/, { modelArtifactsInfo: modelArtifactsInfo }];\n                    }\n                    catch (err) {\n                        // If saving failed, clean up all items saved so far.\n                        this.LS.removeItem(this.keys.info);\n                        this.LS.removeItem(this.keys.topology);\n                        this.LS.removeItem(this.keys.weightSpecs);\n                        this.LS.removeItem(this.keys.weightData);\n                        this.LS.removeItem(this.keys.modelMetadata);\n                        throw new Error(\"Failed to save model '\" + this.modelPath + \"' to local storage: \" +\n                            \"size quota being exceeded is a possible cause of this failure: \" +\n                            (\"modelTopologyBytes=\" + modelArtifactsInfo.modelTopologyBytes + \", \") +\n                            (\"weightSpecsBytes=\" + modelArtifactsInfo.weightSpecsBytes + \", \") +\n                            (\"weightDataBytes=\" + modelArtifactsInfo.weightDataBytes + \".\"));\n                    }\n                }\n                return [2 /*return*/];\n            });\n        });\n    };\n    /**\n     * Load a model from local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model (if loading succeeds).\n     */\n    BrowserLocalStorage.prototype.load = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var info, out, topology, weightSpecs, metadataString, metadata, weightDataBase64;\n            return __generator(this, function (_a) {\n                info = JSON.parse(this.LS.getItem(this.keys.info));\n                if (info == null) {\n                    throw new Error(\"In local storage, there is no model with name '\" + this.modelPath + \"'\");\n                }\n                if (info.modelTopologyType !== 'JSON') {\n                    throw new Error('BrowserLocalStorage does not support loading non-JSON model ' +\n                        'topology yet.');\n                }\n                out = {};\n                topology = JSON.parse(this.LS.getItem(this.keys.topology));\n                if (topology == null) {\n                    throw new Error(\"In local storage, the topology of model '\" + this.modelPath + \"' \" +\n                        \"is missing.\");\n                }\n                out.modelTopology = topology;\n                weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));\n                if (weightSpecs == null) {\n                    throw new Error(\"In local storage, the weight specs of model '\" + this.modelPath + \"' \" +\n                        \"are missing.\");\n                }\n                out.weightSpecs = weightSpecs;\n                metadataString = this.LS.getItem(this.keys.modelMetadata);\n                if (metadataString != null) {\n                    metadata = JSON.parse(metadataString);\n                    out.format = metadata['format'];\n                    out.generatedBy = metadata['generatedBy'];\n                    out.convertedBy = metadata['convertedBy'];\n                    out.userDefinedMetadata = metadata['userDefinedMetadata'];\n                }\n                weightDataBase64 = this.LS.getItem(this.keys.weightData);\n                if (weightDataBase64 == null) {\n                    throw new Error(\"In local storage, the binary weight values of model \" +\n                        (\"'\" + this.modelPath + \"' are missing.\"));\n                }\n                out.weightData = io_utils_1.base64StringToArrayBuffer(weightDataBase64);\n                return [2 /*return*/, out];\n            });\n        });\n    };\n    BrowserLocalStorage.URL_SCHEME = 'localstorage://';\n    return BrowserLocalStorage;\n}());\nexports.BrowserLocalStorage = BrowserLocalStorage;\nexports.localStorageRouter = function (url) {\n    if (!environment_1.env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {\n            return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nrouter_registry_1.IORouterRegistry.registerSaveRouter(exports.localStorageRouter);\nrouter_registry_1.IORouterRegistry.registerLoadRouter(exports.localStorageRouter);\n/**\n * Factory function for local storage IOHandler.\n *\n * This `IOHandler` supports both `save` and `load`.\n *\n * For each model's saved artifacts, four items are saved to local storage.\n *   - `${PATH_SEPARATOR}/${modelPath}/info`: Contains meta-info about the\n *     model, such as date saved, type of the topology, size in bytes, etc.\n *   - `${PATH_SEPARATOR}/${modelPath}/topology`: Model topology. For Keras-\n *     style models, this is a stringized JSON.\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_specs`: Weight specs of the\n *     model, can be used to decode the saved binary weight values (see\n *     item below).\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_data`: Concatenated binary\n *     weight values, stored as a base64-encoded string.\n *\n * Saving may throw an `Error` if the total size of the artifacts exceed the\n * browser-specific quota.\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `IOHandler`, which can be used with, e.g.,\n *   `tf.Model.save`.\n */\nfunction browserLocalStorage(modelPath) {\n    return new BrowserLocalStorage(modelPath);\n}\nexports.browserLocalStorage = browserLocalStorage;\nvar BrowserLocalStorageManager = /** @class */ (function () {\n    function BrowserLocalStorageManager() {\n        util_1.assert(environment_1.env().getBool('IS_BROWSER'), function () { return 'Current environment is not a web browser'; });\n        util_1.assert(typeof window === 'undefined' ||\n            typeof window.localStorage !== 'undefined', function () { return 'Current browser does not appear to support localStorage'; });\n        this.LS = window.localStorage;\n    }\n    BrowserLocalStorageManager.prototype.listModels = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var out, prefix, suffix, i, key, modelPath;\n            return __generator(this, function (_a) {\n                out = {};\n                prefix = PATH_PREFIX + PATH_SEPARATOR;\n                suffix = PATH_SEPARATOR + INFO_SUFFIX;\n                for (i = 0; i < this.LS.length; ++i) {\n                    key = this.LS.key(i);\n                    if (key.startsWith(prefix) && key.endsWith(suffix)) {\n                        modelPath = getModelPathFromKey(key);\n                        out[modelPath] = JSON.parse(this.LS.getItem(key));\n                    }\n                }\n                return [2 /*return*/, out];\n            });\n        });\n    };\n    BrowserLocalStorageManager.prototype.removeModel = function (path) {\n        return __awaiter(this, void 0, void 0, function () {\n            var keys, info;\n            return __generator(this, function (_a) {\n                path = maybeStripScheme(path);\n                keys = getModelKeys(path);\n                if (this.LS.getItem(keys.info) == null) {\n                    throw new Error(\"Cannot find model at path '\" + path + \"'\");\n                }\n                info = JSON.parse(this.LS.getItem(keys.info));\n                this.LS.removeItem(keys.info);\n                this.LS.removeItem(keys.topology);\n                this.LS.removeItem(keys.weightSpecs);\n                this.LS.removeItem(keys.weightData);\n                return [2 /*return*/, info];\n            });\n        });\n    };\n    return BrowserLocalStorageManager;\n}());\nexports.BrowserLocalStorageManager = BrowserLocalStorageManager;\nif (environment_1.env().getBool('IS_BROWSER')) {\n    // Wrap the construction and registration, to guard against browsers that\n    // don't support Local Storage.\n    try {\n        model_management_1.ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());\n    }\n    catch (err) {\n    }\n}\n//# sourceMappingURL=local_storage.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/model_management.js":
/*!************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/model_management.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Classes and functions for model management across multiple storage mediums.\n *\n * Supported client actions:\n * - Listing models on all registered storage mediums.\n * - Remove model by URL from any registered storage mediums, by using URL\n *   string.\n * - Moving or copying model from one path to another in the same medium or from\n *   one medium to another, by using URL strings.\n */\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar router_registry_1 = __webpack_require__(/*! ./router_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js\");\nvar URL_SCHEME_SUFFIX = '://';\nvar ModelStoreManagerRegistry = /** @class */ (function () {\n    function ModelStoreManagerRegistry() {\n        this.managers = {};\n    }\n    ModelStoreManagerRegistry.getInstance = function () {\n        if (ModelStoreManagerRegistry.instance == null) {\n            ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();\n        }\n        return ModelStoreManagerRegistry.instance;\n    };\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    ModelStoreManagerRegistry.registerManager = function (scheme, manager) {\n        util_1.assert(scheme != null, function () { return 'scheme must not be undefined or null.'; });\n        if (scheme.endsWith(URL_SCHEME_SUFFIX)) {\n            scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));\n        }\n        util_1.assert(scheme.length > 0, function () { return 'scheme must not be an empty string.'; });\n        var registry = ModelStoreManagerRegistry.getInstance();\n        util_1.assert(registry.managers[scheme] == null, function () { return \"A model store manager is already registered for scheme '\" + scheme + \"'.\"; });\n        registry.managers[scheme] = manager;\n    };\n    ModelStoreManagerRegistry.getManager = function (scheme) {\n        var manager = this.getInstance().managers[scheme];\n        if (manager == null) {\n            throw new Error(\"Cannot find model manager for scheme '\" + scheme + \"'\");\n        }\n        return manager;\n    };\n    ModelStoreManagerRegistry.getSchemes = function () {\n        return Object.keys(this.getInstance().managers);\n    };\n    return ModelStoreManagerRegistry;\n}());\nexports.ModelStoreManagerRegistry = ModelStoreManagerRegistry;\n/**\n * Helper method for parsing a URL string into a scheme and a path.\n *\n * @param url E.g., 'localstorage://my-model'\n * @returns A dictionary with two fields: scheme and path.\n *   Scheme: e.g., 'localstorage' in the example above.\n *   Path: e.g., 'my-model' in the example above.\n */\nfunction parseURL(url) {\n    if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {\n        throw new Error(\"The url string provided does not contain a scheme. \" +\n            \"Supported schemes are: \" +\n            (\"\" + ModelStoreManagerRegistry.getSchemes().join(',')));\n    }\n    return {\n        scheme: url.split(URL_SCHEME_SUFFIX)[0],\n        path: url.split(URL_SCHEME_SUFFIX)[1],\n    };\n}\nfunction cloneModelInternal(sourceURL, destURL, deleteSource) {\n    if (deleteSource === void 0) { deleteSource = false; }\n    return __awaiter(this, void 0, void 0, function () {\n        var loadHandlers, loadHandler, saveHandlers, saveHandler, sourceScheme, sourcePath, sameMedium, modelArtifacts, saveResult;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    util_1.assert(sourceURL !== destURL, function () { return \"Old path and new path are the same: '\" + sourceURL + \"'\"; });\n                    loadHandlers = router_registry_1.IORouterRegistry.getLoadHandlers(sourceURL);\n                    util_1.assert(loadHandlers.length > 0, function () { return \"Copying failed because no load handler is found for source URL \" + sourceURL + \".\"; });\n                    util_1.assert(loadHandlers.length < 2, function () { return \"Copying failed because more than one (\" + loadHandlers.length + \") \" +\n                        (\"load handlers for source URL \" + sourceURL + \".\"); });\n                    loadHandler = loadHandlers[0];\n                    saveHandlers = router_registry_1.IORouterRegistry.getSaveHandlers(destURL);\n                    util_1.assert(saveHandlers.length > 0, function () { return \"Copying failed because no save handler is found for destination \" +\n                        (\"URL \" + destURL + \".\"); });\n                    util_1.assert(saveHandlers.length < 2, function () { return \"Copying failed because more than one (\" + loadHandlers.length + \") \" +\n                        (\"save handlers for destination URL \" + destURL + \".\"); });\n                    saveHandler = saveHandlers[0];\n                    sourceScheme = parseURL(sourceURL).scheme;\n                    sourcePath = parseURL(sourceURL).path;\n                    sameMedium = sourceScheme === parseURL(sourceURL).scheme;\n                    return [4 /*yield*/, loadHandler.load()];\n                case 1:\n                    modelArtifacts = _a.sent();\n                    if (!(deleteSource && sameMedium)) return [3 /*break*/, 3];\n                    return [4 /*yield*/, ModelStoreManagerRegistry.getManager(sourceScheme)\n                            .removeModel(sourcePath)];\n                case 2:\n                    _a.sent();\n                    _a.label = 3;\n                case 3: return [4 /*yield*/, saveHandler.save(modelArtifacts)];\n                case 4:\n                    saveResult = _a.sent();\n                    if (!(deleteSource && !sameMedium)) return [3 /*break*/, 6];\n                    return [4 /*yield*/, ModelStoreManagerRegistry.getManager(sourceScheme)\n                            .removeModel(sourcePath)];\n                case 5:\n                    _a.sent();\n                    _a.label = 6;\n                case 6: return [2 /*return*/, saveResult.modelArtifactsInfo];\n            }\n        });\n    });\n}\n/**\n * List all models stored in registered storage mediums.\n *\n * For a web browser environment, the registered mediums are Local Storage and\n * IndexedDB.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @returns A `Promise` of a dictionary mapping URLs of existing models to\n * their model artifacts info. URLs include medium-specific schemes, e.g.,\n *   'indexeddb://my/model/1'. Model artifacts info include type of the\n * model's topology, byte sizes of the topology, weights, etc.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction listModels() {\n    return __awaiter(this, void 0, void 0, function () {\n        var schemes, out, _i, schemes_1, scheme, schemeOut, path, url;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    schemes = ModelStoreManagerRegistry.getSchemes();\n                    out = {};\n                    _i = 0, schemes_1 = schemes;\n                    _a.label = 1;\n                case 1:\n                    if (!(_i < schemes_1.length)) return [3 /*break*/, 4];\n                    scheme = schemes_1[_i];\n                    return [4 /*yield*/, ModelStoreManagerRegistry.getManager(scheme).listModels()];\n                case 2:\n                    schemeOut = _a.sent();\n                    for (path in schemeOut) {\n                        url = scheme + URL_SCHEME_SUFFIX + path;\n                        out[url] = schemeOut[path];\n                    }\n                    _a.label = 3;\n                case 3:\n                    _i++;\n                    return [3 /*break*/, 1];\n                case 4: return [2 /*return*/, out];\n            }\n        });\n    });\n}\nexports.listModels = listModels;\n/**\n * Remove a model specified by URL from a reigstered storage medium.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @param url A URL to a stored model, with a scheme prefix, e.g.,\n *   'localstorage://my-model-1', 'indexeddb://my/model/2'.\n * @returns ModelArtifactsInfo of the deleted model (if and only if deletion\n *   is successful).\n * @throws Error if deletion fails, e.g., if no model exists at `path`.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction removeModel(url) {\n    return __awaiter(this, void 0, void 0, function () {\n        var schemeAndPath, manager;\n        return __generator(this, function (_a) {\n            schemeAndPath = parseURL(url);\n            manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);\n            return [2 /*return*/, manager.removeModel(schemeAndPath.path)];\n        });\n    });\n}\nexports.removeModel = removeModel;\n/**\n * Copy a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Copying within a storage medium, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Copying between two storage mediums, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Copy the model, from Local Storage to IndexedDB.\n * await tf.io.copyModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove both models.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of copying.\n * @param destURL Destination URL of copying.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if copying fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction copyModel(sourceURL, destURL) {\n    return __awaiter(this, void 0, void 0, function () {\n        var deleteSource;\n        return __generator(this, function (_a) {\n            deleteSource = false;\n            return [2 /*return*/, cloneModelInternal(sourceURL, destURL, deleteSource)];\n        });\n    });\n}\nexports.copyModel = copyModel;\n/**\n * Move a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Moving within a storage medium, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Moving between two storage mediums, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Move the model, from Local Storage to IndexedDB.\n * await tf.io.moveModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove the moved model.\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of moving.\n * @param destURL Destination URL of moving.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if moving fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n */\n/**\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nfunction moveModel(sourceURL, destURL) {\n    return __awaiter(this, void 0, void 0, function () {\n        var deleteSource;\n        return __generator(this, function (_a) {\n            deleteSource = true;\n            return [2 /*return*/, cloneModelInternal(sourceURL, destURL, deleteSource)];\n        });\n    });\n}\nexports.moveModel = moveModel;\n//# sourceMappingURL=model_management.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/model_management.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar PassthroughLoader = /** @class */ (function () {\n    function PassthroughLoader(modelArtifacts) {\n        this.modelArtifacts = modelArtifacts;\n    }\n    PassthroughLoader.prototype.load = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.modelArtifacts];\n            });\n        });\n    };\n    return PassthroughLoader;\n}());\nvar PassthroughSaver = /** @class */ (function () {\n    function PassthroughSaver(saveHandler) {\n        this.saveHandler = saveHandler;\n    }\n    PassthroughSaver.prototype.save = function (modelArtifacts) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2 /*return*/, this.saveHandler(modelArtifacts)];\n            });\n        });\n    };\n    return PassthroughSaver;\n}());\n/**\n * Creates an IOHandler that loads model artifacts from memory.\n *\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * const model = await tf.loadLayersModel(tf.io.fromMemory(\n *     modelTopology, weightSpecs, weightData));\n * ```\n *\n * @param modelArtifacts a object containing model topology (i.e., parsed from\n *   the JSON format).\n * @param weightSpecs An array of `WeightsManifestEntry` objects describing the\n *   names, shapes, types, and quantization of the weight data.\n * @param weightData A single `ArrayBuffer` containing the weight data,\n *   concatenated in the order described by the weightSpecs.\n * @param trainingConfig Model training configuration. Optional.\n *\n * @returns A passthrough `IOHandler` that simply loads the provided data.\n */\nfunction fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {\n    if (arguments.length === 1) {\n        var isModelArtifacts = modelArtifacts.modelTopology != null ||\n            modelArtifacts.weightSpecs != null;\n        if (isModelArtifacts) {\n            return new PassthroughLoader(modelArtifacts);\n        }\n        else {\n            // Legacy support: with only modelTopology.\n            // TODO(cais): Remove this deprecated API.\n            console.warn('Please call tf.io.fromMemory() with only one argument. ' +\n                'The argument should be of type ModelArtifacts. ' +\n                'The multi-argument signature of tf.io.fromMemory() has been ' +\n                'deprecated and will be removed in a future release.');\n            return new PassthroughLoader({ modelTopology: modelArtifacts });\n        }\n    }\n    else {\n        // Legacy support.\n        // TODO(cais): Remove this deprecated API.\n        console.warn('Please call tf.io.fromMemory() with only one argument. ' +\n            'The argument should be of type ModelArtifacts. ' +\n            'The multi-argument signature of tf.io.fromMemory() has been ' +\n            'deprecated and will be removed in a future release.');\n        return new PassthroughLoader({\n            modelTopology: modelArtifacts,\n            weightSpecs: weightSpecs,\n            weightData: weightData,\n            trainingConfig: trainingConfig\n        });\n    }\n}\nexports.fromMemory = fromMemory;\n/**\n * Creates an IOHandler that passes saved model artifacts to a callback.\n *\n * ```js\n * function handleSave(artifacts) {\n *   // ... do something with the artifacts ...\n *   return {modelArtifactsInfo: {...}, ...};\n * }\n *\n * const saveResult = model.save(tf.io.withSaveHandler(handleSave));\n * ```\n *\n * @param saveHandler A function that accepts a `ModelArtifacts` and returns a\n *     `SaveResult`.\n */\nfunction withSaveHandler(saveHandler) {\n    return new PassthroughSaver(saveHandler);\n}\nexports.withSaveHandler = withSaveHandler;\n//# sourceMappingURL=passthrough.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/progress.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/progress.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n/**\n * Monitor Promise.all progress, fire onProgress callback function.\n *\n * @param promises Promise list going to be monitored\n * @param onProgress Callback function. Fired when a promise resolved.\n * @param startFraction Optional fraction start. Default to 0.\n * @param endFraction Optional fraction end. Default to 1.\n */\nfunction monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {\n    checkPromises(promises);\n    startFraction = startFraction == null ? 0 : startFraction;\n    endFraction = endFraction == null ? 1 : endFraction;\n    checkFraction(startFraction, endFraction);\n    var resolvedPromise = 0;\n    var registerMonitor = function (promise) {\n        promise.then(function (value) {\n            var fraction = startFraction +\n                ++resolvedPromise / promises.length * (endFraction - startFraction);\n            // pass fraction as parameter to callback function.\n            onProgress(fraction);\n            return value;\n        });\n        return promise;\n    };\n    function checkPromises(promises) {\n        util_1.assert(promises != null && Array.isArray(promises) && promises.length > 0, function () { return 'promises must be a none empty array'; });\n    }\n    function checkFraction(startFraction, endFraction) {\n        util_1.assert(startFraction >= 0 && startFraction <= 1, function () { return \"Progress fraction must be in range [0, 1], but \" +\n            (\"got startFraction \" + startFraction); });\n        util_1.assert(endFraction >= 0 && endFraction <= 1, function () { return \"Progress fraction must be in range [0, 1], but \" +\n            (\"got endFraction \" + endFraction); });\n        util_1.assert(endFraction >= startFraction, function () { return \"startFraction must be no more than endFraction, but \" +\n            (\"got startFraction \" + startFraction + \" and endFraction \") +\n            (\"\" + endFraction); });\n    }\n    return Promise.all(promises.map(registerMonitor));\n}\nexports.monitorPromisesProgress = monitorPromisesProgress;\n//# sourceMappingURL=progress.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/progress.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar IORouterRegistry = /** @class */ (function () {\n    function IORouterRegistry() {\n        this.saveRouters = [];\n        this.loadRouters = [];\n    }\n    IORouterRegistry.getInstance = function () {\n        if (IORouterRegistry.instance == null) {\n            IORouterRegistry.instance = new IORouterRegistry();\n        }\n        return IORouterRegistry.instance;\n    };\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    IORouterRegistry.registerSaveRouter = function (saveRouter) {\n        IORouterRegistry.getInstance().saveRouters.push(saveRouter);\n    };\n    /**\n     * Register a load-handler router.\n     *\n     * @param loadRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `load` method defined or `null`.\n     */\n    IORouterRegistry.registerLoadRouter = function (loadRouter) {\n        IORouterRegistry.getInstance().loadRouters.push(loadRouter);\n    };\n    /**\n     * Look up IOHandler for saving, given a URL-like string.\n     *\n     * @param url\n     * @returns If only one match is found, an instance of IOHandler with the\n     * `save` method defined. If no match is found, `null`.\n     * @throws Error, if more than one match is found.\n     */\n    IORouterRegistry.getSaveHandlers = function (url) {\n        return IORouterRegistry.getHandlers(url, 'save');\n    };\n    /**\n     * Look up IOHandler for loading, given a URL-like string.\n     *\n     * @param url\n     * @param onProgress Optional, progress callback function, fired periodically\n     *   before the load is completed.\n     * @returns All valid handlers for `url`, given the currently registered\n     *   handler routers.\n     */\n    IORouterRegistry.getLoadHandlers = function (url, onProgress) {\n        return IORouterRegistry.getHandlers(url, 'load', onProgress);\n    };\n    IORouterRegistry.getHandlers = function (url, handlerType, onProgress) {\n        var validHandlers = [];\n        var routers = handlerType === 'load' ?\n            IORouterRegistry.getInstance().loadRouters :\n            IORouterRegistry.getInstance().saveRouters;\n        routers.forEach(function (router) {\n            var handler = router(url, onProgress);\n            if (handler !== null) {\n                validHandlers.push(handler);\n            }\n        });\n        return validHandlers;\n    };\n    return IORouterRegistry;\n}());\nexports.IORouterRegistry = IORouterRegistry;\nexports.registerSaveRouter = function (loudRouter) {\n    return IORouterRegistry.registerSaveRouter(loudRouter);\n};\nexports.registerLoadRouter = function (loudRouter) {\n    return IORouterRegistry.registerLoadRouter(loudRouter);\n};\nexports.getSaveHandlers = function (url) {\n    return IORouterRegistry.getSaveHandlers(url);\n};\nexports.getLoadHandlers = function (url, onProgress) {\n    return IORouterRegistry.getLoadHandlers(url, onProgress);\n};\n//# sourceMappingURL=router_registry.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/types.js":
/*!*************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/types.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/* Type definitions for exporting and importing of models. */\n/**\n * A map from Tensor dtype to number of bytes per element of the Tensor.\n */\nexports.DTYPE_VALUE_SIZE_MAP = {\n    'float32': 4,\n    'int32': 4,\n    'uint16': 2,\n    'uint8': 1,\n    'bool': 1,\n};\n//# sourceMappingURL=types.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/types.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar io_utils_1 = __webpack_require__(/*! ./io_utils */ \"./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js\");\nvar progress_1 = __webpack_require__(/*! ./progress */ \"./node_modules/@tensorflow/tfjs-core/dist/io/progress.js\");\nvar types_1 = __webpack_require__(/*! ./types */ \"./node_modules/@tensorflow/tfjs-core/dist/io/types.js\");\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\nfunction loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {\n    return __awaiter(this, void 0, void 0, function () {\n        var fetchFunc, requests, fetchStartFraction, fetchEndFraction, responses, _a, bufferPromises, bufferStartFraction, bufferEndFraction, buffers, _b;\n        return __generator(this, function (_c) {\n            switch (_c.label) {\n                case 0:\n                    if (loadOptions == null) {\n                        loadOptions = {};\n                    }\n                    fetchFunc = loadOptions.fetchFunc == null ? environment_1.env().platform.fetch :\n                        loadOptions.fetchFunc;\n                    requests = fetchURLs.map(function (fetchURL) {\n                        return fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true });\n                    });\n                    fetchStartFraction = 0;\n                    fetchEndFraction = 0.5;\n                    if (!(loadOptions.onProgress == null)) return [3 /*break*/, 2];\n                    return [4 /*yield*/, Promise.all(requests)];\n                case 1:\n                    _a = _c.sent();\n                    return [3 /*break*/, 4];\n                case 2: return [4 /*yield*/, progress_1.monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction)];\n                case 3:\n                    _a = _c.sent();\n                    _c.label = 4;\n                case 4:\n                    responses = _a;\n                    bufferPromises = responses.map(function (response) { return response.arrayBuffer(); });\n                    bufferStartFraction = 0.5;\n                    bufferEndFraction = 1;\n                    if (!(loadOptions.onProgress == null)) return [3 /*break*/, 6];\n                    return [4 /*yield*/, Promise.all(bufferPromises)];\n                case 5:\n                    _b = _c.sent();\n                    return [3 /*break*/, 8];\n                case 6: return [4 /*yield*/, progress_1.monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction)];\n                case 7:\n                    _b = _c.sent();\n                    _c.label = 8;\n                case 8:\n                    buffers = _b;\n                    return [2 /*return*/, buffers];\n            }\n        });\n    });\n}\nexports.loadWeightsAsArrayBuffer = loadWeightsAsArrayBuffer;\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\nfunction loadWeights(manifest, filePathPrefix, weightNames, requestInit) {\n    if (filePathPrefix === void 0) { filePathPrefix = ''; }\n    return __awaiter(this, void 0, void 0, function () {\n        var fetchWeights, loadWeights;\n        return __generator(this, function (_a) {\n            fetchWeights = function (fetchUrls) {\n                return loadWeightsAsArrayBuffer(fetchUrls, { requestInit: requestInit });\n            };\n            loadWeights = weightsLoaderFactory(fetchWeights);\n            return [2 /*return*/, loadWeights(manifest, filePathPrefix, weightNames)];\n        });\n    });\n}\nexports.loadWeights = loadWeights;\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\nfunction weightsLoaderFactory(fetchWeightsFunction) {\n    var _this = this;\n    return function (manifest, filePathPrefix, weightNames) {\n        if (filePathPrefix === void 0) { filePathPrefix = ''; }\n        return __awaiter(_this, void 0, void 0, function () {\n            var groupIndicesToFetchMap, groupWeightsToFetch, weightsFound, allManifestWeightNames, weightsNotFound, groupIndicesToFetch, fetchUrls, buffers, weightsTensorMap, bufferIndexOffset;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        groupIndicesToFetchMap = manifest.map(function () { return false; });\n                        groupWeightsToFetch = {};\n                        weightsFound = weightNames != null ? weightNames.map(function () { return false; }) : [];\n                        allManifestWeightNames = [];\n                        manifest.forEach(function (manifestGroupConfig, groupIndex) {\n                            var groupOffset = 0;\n                            manifestGroupConfig.weights.forEach(function (weightsEntry) {\n                                var rawDtype = ('quantization' in weightsEntry) ?\n                                    weightsEntry.quantization.dtype :\n                                    weightsEntry.dtype;\n                                var weightsBytes = types_1.DTYPE_VALUE_SIZE_MAP[rawDtype] *\n                                    util.sizeFromShape(weightsEntry.shape);\n                                var enqueueWeightsForFetchingFn = function () {\n                                    groupIndicesToFetchMap[groupIndex] = true;\n                                    if (groupWeightsToFetch[groupIndex] == null) {\n                                        groupWeightsToFetch[groupIndex] = [];\n                                    }\n                                    groupWeightsToFetch[groupIndex].push({\n                                        manifestEntry: weightsEntry,\n                                        groupOffset: groupOffset,\n                                        sizeBytes: weightsBytes\n                                    });\n                                };\n                                if (weightNames != null) {\n                                    weightNames.forEach(function (weightName, weightIndex) {\n                                        if (weightName === weightsEntry.name) {\n                                            enqueueWeightsForFetchingFn();\n                                            weightsFound[weightIndex] = true;\n                                        }\n                                    });\n                                }\n                                else {\n                                    enqueueWeightsForFetchingFn();\n                                }\n                                allManifestWeightNames.push(weightsEntry.name);\n                                groupOffset += weightsBytes;\n                            });\n                        });\n                        if (!weightsFound.every(function (found) { return found; })) {\n                            weightsNotFound = weightNames.filter(function (_, i) { return !weightsFound[i]; });\n                            throw new Error(\"Could not find weights in manifest with names: \" +\n                                (weightsNotFound.join(', ') + \". \\n\") +\n                                \"Manifest JSON has weights with names: \" +\n                                (allManifestWeightNames.join(', ') + \".\"));\n                        }\n                        groupIndicesToFetch = groupIndicesToFetchMap.reduce(function (accumulator, shouldFetch, i) {\n                            if (shouldFetch) {\n                                accumulator.push(i);\n                            }\n                            return accumulator;\n                        }, []);\n                        fetchUrls = [];\n                        groupIndicesToFetch.forEach(function (i) {\n                            manifest[i].paths.forEach(function (filepath) {\n                                var fetchUrl = filePathPrefix +\n                                    (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n                                fetchUrls.push(fetchUrl);\n                            });\n                        });\n                        return [4 /*yield*/, fetchWeightsFunction(fetchUrls)];\n                    case 1:\n                        buffers = _a.sent();\n                        weightsTensorMap = {};\n                        bufferIndexOffset = 0;\n                        groupIndicesToFetch.forEach(function (i) {\n                            var numBuffers = manifest[i].paths.length;\n                            var groupBytes = 0;\n                            for (var i_1 = 0; i_1 < numBuffers; i_1++) {\n                                groupBytes += buffers[bufferIndexOffset + i_1].byteLength;\n                            }\n                            // Create a buffer for the whole group.\n                            var groupBuffer = new ArrayBuffer(groupBytes);\n                            var groupByteBuffer = new Uint8Array(groupBuffer);\n                            var groupBufferOffset = 0;\n                            for (var i_2 = 0; i_2 < numBuffers; i_2++) {\n                                var buffer = new Uint8Array(buffers[bufferIndexOffset + i_2]);\n                                groupByteBuffer.set(buffer, groupBufferOffset);\n                                groupBufferOffset += buffer.byteLength;\n                            }\n                            var weightsEntries = groupWeightsToFetch[i];\n                            weightsEntries.forEach(function (weightsEntry) {\n                                var byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);\n                                var nameToTensorMap = io_utils_1.decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n                                for (var name_1 in nameToTensorMap) {\n                                    weightsTensorMap[name_1] = nameToTensorMap[name_1];\n                                }\n                            });\n                            bufferIndexOffset += numBuffers;\n                        });\n                        return [2 /*return*/, weightsTensorMap];\n                }\n            });\n        });\n    };\n}\nexports.weightsLoaderFactory = weightsLoaderFactory;\n//# sourceMappingURL=weights_loader.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.SquaredDifference = 'SquaredDifference';\nexports.Square = 'Square';\nexports.NonMaxSuppressionV5 = 'NonMaxSuppressionV5';\n/**\n * TensorFlow.js-only kernels\n */\nexports.FromPixels = 'FromPixels';\n//# sourceMappingURL=kernel_names.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js":
/*!********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar kernelRegistry = new Map();\nvar gradRegistry = new Map();\n/**\n * Returns the kernel function (code) associated with the provided names.\n *\n * @param kernelName The official name of the kernel.\n * @param backendName The official name of the backend.\n */\nfunction getKernel(kernelName, backendName) {\n    var key = makeKey(kernelName, backendName);\n    return kernelRegistry.get(key);\n}\nexports.getKernel = getKernel;\n/**\n * Returns the registered gradient info associated with the provided kernel.\n * @param kernelName The official TF kernel name.\n */\nfunction getGradient(kernelName) {\n    return gradRegistry.get(kernelName);\n}\nexports.getGradient = getGradient;\nfunction getKernelsForBackend(backendName) {\n    var it = kernelRegistry.entries();\n    var result = [];\n    while (true) {\n        var _a = it.next(), done = _a.done, value = _a.value;\n        if (done) {\n            break;\n        }\n        var key = value[0], config = value[1];\n        var backend = key.split('_')[0];\n        if (backend === backendName) {\n            result.push(config);\n        }\n    }\n    return result;\n}\nexports.getKernelsForBackend = getKernelsForBackend;\n/**\n * Registers the function (forward pass) for the kernel in a global registry.\n *\n * @param config A config object with the following properties:\n * - `kernelName` The official name of the kernel.\n * - `backendName` The official name of the backend.\n * - `kernelFunc` The function to run during the forward pass of the kernel.\n * - `setupFunc` Optional. Gets called once, after the backend initializes.\n * - `disposeFunc` Optional. Gets called once, right before the backend is\n * disposed.\n */\nfunction registerKernel(config) {\n    var kernelName = config.kernelName, backendName = config.backendName;\n    var key = makeKey(kernelName, backendName);\n    if (kernelRegistry.has(key)) {\n        throw new Error(\"The kernel '\" + kernelName + \"' for backend \" +\n            (\"'\" + backendName + \"' is already registered\"));\n    }\n    kernelRegistry.set(key, config);\n}\nexports.registerKernel = registerKernel;\n/**\n * Registers a gradient function for a given kernel in the global registry,\n * to be used during the back-propagation of that kernel.\n *\n * @param config An object with the following properties:\n * - `kernelName` The name of the kernel that the gradient function is for.\n * - `gradFunc` The function to run during back-propagation.\n */\nfunction registerGradient(config) {\n    var kernelName = config.kernelName;\n    if (gradRegistry.has(kernelName)) {\n        console.warn(\"Overriding the gradient for '\" + kernelName + \"'\");\n    }\n    gradRegistry.set(kernelName, config);\n}\nexports.registerGradient = registerGradient;\n/**\n * Removes the kernel function from the registry.\n *\n * @param kernelName The official name of the kernel.\n * @param backendName The official name of the backend.\n *\n */\nfunction unregisterKernel(kernelName, backendName) {\n    var key = makeKey(kernelName, backendName);\n    if (!kernelRegistry.has(key)) {\n        throw new Error(\"The kernel '\" + kernelName + \"' for backend \" +\n            (\"'\" + backendName + \"' is not registered\"));\n    }\n    kernelRegistry.delete(key);\n}\nexports.unregisterKernel = unregisterKernel;\n/** Removes the registered gradient from the global registry. */\nfunction unregisterGradient(kernelName) {\n    if (!gradRegistry.has(kernelName)) {\n        throw new Error(\"The gradient '\" + kernelName + \"' for backend is not registered\");\n    }\n    gradRegistry.delete(kernelName);\n}\nexports.unregisterGradient = unregisterGradient;\nfunction makeKey(kernelName, backendName) {\n    return backendName + \"_\" + kernelName;\n}\n//# sourceMappingURL=kernel_registry.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/log.js":
/*!********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/log.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ./environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nfunction warn() {\n    var msg = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        msg[_i] = arguments[_i];\n    }\n    if (!environment_1.env().getBool('IS_TEST')) {\n        console.warn.apply(console, msg);\n    }\n}\nexports.warn = warn;\nfunction log() {\n    var msg = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        msg[_i] = arguments[_i];\n    }\n    if (!environment_1.env().getBool('IS_TEST')) {\n        console.log.apply(console, msg);\n    }\n}\nexports.log = log;\n//# sourceMappingURL=log.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/log.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/math.js":
/*!*********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/math.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Exports under the tf.math.* namespace.\n */\nvar confusion_matrix_1 = __webpack_require__(/*! ./ops/confusion_matrix */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/confusion_matrix.js\");\nexports.confusionMatrix = confusion_matrix_1.confusionMatrix;\n//# sourceMappingURL=math.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/math.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_1 = __webpack_require__(/*! ../tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar axis_util_1 = __webpack_require__(/*! ./axis_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js\");\nvar concat_split_1 = __webpack_require__(/*! ./concat_split */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/concat_split.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar rand_1 = __webpack_require__(/*! ./rand */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/rand.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until is has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction broadcastTo_(x, shape) {\n    var input = tensor_util_env_1.convertToTensor(x, 'broadcastTo', 'x');\n    var xShape = input.shape;\n    if (shape.some(function (d) { return !(d > 0) || d % 1 !== 0; })) {\n        throw new Error(\"broadcastTo(): Invalid broadcast shape [\" + shape + \"].\");\n    }\n    if (shape.length < input.rank) {\n        throw new Error(\"broadcastTo(): shape.length=\" + shape.length + \" < input.rank=\" + input.rank + \".\");\n    }\n    if (shape.length > input.rank) {\n        var newShape = input.shape.slice();\n        while (newShape.length < shape.length) {\n            newShape.unshift(1);\n        }\n        input = input.reshape(newShape);\n    }\n    var reps = Array.from(shape);\n    for (var i = shape.length - 1; i >= 0; i--) {\n        if (input.shape[i] === shape[i]) {\n            reps[i] = 1;\n        }\n        else if (input.shape[i] !== 1) {\n            throw new Error(\"broadcastTo(): [\" + xShape + \"] cannot be broadcast to [\" + shape + \"].\");\n        }\n    }\n    var axes = reps.map(function (n, i) { return n > 1 ? i : -1; }).filter(function (i) { return i >= 0; });\n    if (axes.length === 0) {\n        return input.clone();\n    }\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.tile(input, reps); }, { input: input }, function (dy) {\n        return ({ input: function () { return dy.sum(axes, /*keepDims=*/ true); } });\n    });\n}\n/**\n * Creates a new tensor with the same values and shape as the specified\n * tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n *\n * x.clone().print();\n * ```\n *\n * @param x The tensor to clone.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction clone_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'clone', null);\n    var der = function (dy) {\n        return { $x: function () { return dy.toFloat(); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function () { return engine_1.ENGINE.makeTensorFromDataId($x.dataId, $x.shape, $x.dtype); }, { $x: $x }, der);\n}\n/**\n * Create an identity matrix.\n *\n * @param numRows Number of rows.\n * @param numColumns Number of columns. Defaults to `numRows`.\n * @param batchShape If provided, will add the batch shape to the beginning\n *   of the shape of the returned `tf.Tensor` by repeating the identity\n *   matrix.\n * @param dtype Data type.\n * @returns Identity matrix of the specified size and data type, possibly\n *   with batch repetition if `batchShape` is specified.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction eye_(numRows, numColumns, batchShape, dtype) {\n    if (dtype === void 0) { dtype = 'float32'; }\n    if (numColumns == null) {\n        numColumns = numRows;\n    }\n    var buff = buffer([numRows, numColumns], dtype);\n    var n = numRows <= numColumns ? numRows : numColumns;\n    for (var i = 0; i < n; ++i) {\n        buff.set(1, i, i);\n    }\n    var out = buff.toTensor().as2D(numRows, numColumns);\n    if (batchShape == null) {\n        return out;\n    }\n    else {\n        if (batchShape.length === 1) {\n            return exports.tile(exports.expandDims(out, 0), [batchShape[0], 1, 1]);\n        }\n        else if (batchShape.length === 2) {\n            return exports.tile(exports.expandDims(exports.expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);\n        }\n        else if (batchShape.length === 3) {\n            return exports.tile(exports.expandDims(exports.expandDims(exports.expandDims(out, 0), 0), 0), [batchShape[0], batchShape[1], batchShape[2], 1, 1]);\n        }\n        else {\n            throw new Error(\"eye() currently supports only 1D and 2D \" +\n                (\n                // tslint:disable-next-line:no-any\n                \"batchShapes, but received \" + batchShape.length + \"D.\"));\n        }\n    }\n}\n/**\n * Creates a `tf.Tensor` with values sampled from a normal distribution.\n *\n * ```js\n * tf.randomNormal([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param mean The mean of the normal distribution.\n * @param stdDev The standard deviation of the normal distribution.\n * @param dtype The data type of the output.\n * @param seed The seed for the random number generator.\n */\n/** @doc {heading: 'Tensors', subheading: 'Random'} */\nfunction randomNormal_(shape, mean, stdDev, dtype, seed) {\n    if (mean === void 0) { mean = 0; }\n    if (stdDev === void 0) { stdDev = 1; }\n    if (dtype != null && dtype === 'bool') {\n        throw new Error(\"Unsupported data type \" + dtype);\n    }\n    var randGauss = new rand_1.MPRandGauss(mean, stdDev, dtype, false /* truncated */, seed);\n    var res = buffer(shape, dtype);\n    for (var i = 0; i < res.values.length; i++) {\n        res.values[i] = randGauss.nextValue();\n    }\n    return res.toTensor();\n}\n/**\n * Creates a `tf.Tensor` with values sampled from a truncated normal\n * distribution.\n *\n * ```js\n * tf.truncatedNormal([2, 2]).print();\n * ```\n *\n * The generated values follow a normal distribution with specified mean and\n * standard deviation, except that values whose magnitude is more than 2\n * standard deviations from the mean are dropped and re-picked.\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param mean The mean of the normal distribution.\n * @param stdDev The standard deviation of the normal distribution.\n * @param dtype The data type of the output tensor.\n * @param seed The seed for the random number generator.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction truncatedNormal_(shape, mean, stdDev, dtype, seed) {\n    if (mean === void 0) { mean = 0; }\n    if (stdDev === void 0) { stdDev = 1; }\n    if (dtype != null && dtype === 'bool') {\n        throw new Error(\"Unsupported data type \" + dtype);\n    }\n    var randGauss = new rand_1.MPRandGauss(mean, stdDev, dtype, true /* truncated */, seed);\n    var res = buffer(shape, dtype);\n    for (var i = 0; i < res.values.length; i++) {\n        res.values[i] = randGauss.nextValue();\n    }\n    return res.toTensor();\n}\n/**\n * Creates a `tf.Tensor` with values sampled from a gamma distribution.\n *\n * ```js\n * tf.randomGamma([2, 2], 1).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param alpha The shape parameter of the gamma distribution.\n * @param beta The inverse scale parameter of the gamma distribution. Defaults\n *     to 1.\n * @param dtype The data type of the output. Defaults to float32.\n * @param seed The seed for the random number generator.\n */\n/** @doc {heading: 'Tensors', subheading: 'Random'} */\nfunction randomGamma_(shape, alpha, beta, dtype, seed) {\n    if (beta === void 0) { beta = 1; }\n    if (dtype === void 0) { dtype = 'float32'; }\n    if (beta == null) {\n        beta = 1;\n    }\n    if (dtype == null) {\n        dtype = 'float32';\n    }\n    if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new Error(\"Unsupported data type \" + dtype);\n    }\n    var rgamma = new rand_1.RandGamma(alpha, beta, dtype, seed);\n    var res = buffer(shape, dtype);\n    for (var i = 0; i < res.values.length; i++) {\n        res.values[i] = rgamma.nextValue();\n    }\n    return res.toTensor();\n}\n/**\n * Creates a `tf.Tensor` with values sampled from a uniform distribution.\n *\n * The generated values follow a uniform distribution in the range [minval,\n * maxval). The lower bound minval is included in the range, while the upper\n * bound maxval is excluded.\n *\n * ```js\n * tf.randomUniform([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param minval The lower bound on the range of random values to generate.\n *   Defaults to 0.\n * @param maxval The upper bound on the range of random values to generate.\n *   Defaults to 1.\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n */\n/** @doc {heading: 'Tensors', subheading: 'Random'} */\nfunction randomUniform_(shape, minval, maxval, dtype, seed) {\n    if (minval === void 0) { minval = 0; }\n    if (maxval === void 0) { maxval = 1; }\n    if (dtype === void 0) { dtype = 'float32'; }\n    var res = buffer(shape, dtype);\n    var random = new rand_1.UniformRandom(minval, maxval, null, seed);\n    for (var i = 0; i < res.values.length; i++) {\n        res.values[i] = random.nextValue();\n    }\n    return res.toTensor();\n}\n/**\n * Creates a `tf.Tensor` with values sampled from a random number generator\n * function defined by the user.\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param randFunction A random number generator function which is called\n * for each element in the output tensor.\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n */\nfunction rand_(shape, randFunction, dtype) {\n    var size = util.sizeFromShape(shape);\n    var values = null;\n    if (dtype == null || dtype === 'float32') {\n        values = new Float32Array(size);\n    }\n    else if (dtype === 'int32') {\n        values = new Int32Array(size);\n    }\n    else if (dtype === 'bool') {\n        values = new Uint8Array(size);\n    }\n    else {\n        throw new Error(\"Unknown data type \" + dtype);\n    }\n    for (var i = 0; i < size; i++) {\n        values[i] = randFunction();\n    }\n    return engine_1.ENGINE.makeTensor(values, shape, dtype);\n}\n/**\n * Creates a `tf.Tensor` with values drawn from a multinomial distribution.\n *\n * ```js\n * const probs = tf.tensor([.75, .25]);\n * tf.multinomial(probs, 3).print();\n * ```\n *\n * @param logits 1D array with unnormalized log-probabilities, or\n *     2D array of shape `[batchSize, numOutcomes]`. See the `normalized`\n *     parameter.\n * @param numSamples Number of samples to draw for each row slice.\n * @param seed The seed number.\n * @param normalized Whether the provided `logits` are normalized true\n *     probabilities (sum to 1). Defaults to false.\n * @return 1D array of shape `[numSamples]`, or 2D array of shape\n *     `[batchSize, numSamples]`, depending on the rank of the input.\n */\n/** @doc {heading: 'Tensors', subheading: 'Random'} */\nfunction multinomial_(logits, numSamples, seed, normalized) {\n    if (normalized === void 0) { normalized = false; }\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'multinomial');\n    var numOutcomes = $logits.size;\n    var origRank = $logits.rank;\n    if (numOutcomes < 2) {\n        throw new Error(\"Error in multinomial: you need at least 2 outcomes, but got \" +\n            (numOutcomes + \".\"));\n    }\n    if (origRank > 2) {\n        throw new Error(\"Rank of probabilities must be 1 or 2, but is \" + origRank);\n    }\n    seed = seed || Math.random();\n    var logits2D = origRank === 1 ? $logits.as2D(1, -1) : $logits;\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.multinomial(logits2D, normalized, numSamples, seed); }, { logits2D: logits2D });\n    return origRank === 1 ? res.as1D() : res;\n}\n/**\n * Creates a one-hot `tf.Tensor`. The locations represented by `indices` take\n * value `onValue` (defaults to 1), while all other locations take value\n * `offValue` (defaults to 0). If `indices` is rank `R`, the output has rank\n * `R+1` with the last axis of size `depth`.\n *\n * ```js\n * tf.oneHot(tf.tensor1d([0, 1], 'int32'), 3).print();\n * ```\n *\n * @param indices `tf.Tensor` of indices with dtype `int32`.\n * @param depth The depth of the one hot dimension.\n * @param onValue A number used to fill in the output when the index matches\n * the location.\n * @param offValue A number used to fill in the output when the index does\n *     not match the location.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction oneHot_(indices, depth, onValue, offValue) {\n    if (onValue === void 0) { onValue = 1; }\n    if (offValue === void 0) { offValue = 0; }\n    if (depth < 2) {\n        throw new Error(\"Error in oneHot: depth must be >=2, but it is \" + depth);\n    }\n    var $indices = tensor_util_env_1.convertToTensor(indices, 'indices', 'oneHot', 'int32');\n    var outShape = $indices.shape.concat([depth]);\n    $indices = $indices.flatten();\n    var grad = function (dy) {\n        return { $indices: function () { return tensor_ops_1.zeros($indices.shape, 'float32'); } };\n    };\n    var result = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.oneHot($indices, depth, onValue, offValue); }, { $indices: $indices }, grad);\n    return result.reshape(outShape);\n}\n/**\n * Reshapes a `tf.Tensor` to a given shape.\n *\n * Given an input tensor, returns a new tensor with the same values as the\n * input tensor with shape `shape`.\n *\n * If one component of shape is the special value -1, the size of that\n * dimension is computed so that the total size remains constant. In\n * particular, a shape of [-1] flattens into 1-D. At most one component of\n * shape can be -1.\n *\n * If shape is 1-D or higher, then the operation returns a tensor with shape\n * shape filled with the values of tensor. In this case, the number of\n * elements implied by shape must be the same as the number of elements in\n * tensor.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.reshape([2, 2]).print();\n * ```\n *\n * @param x The input tensor to be reshaped.\n * @param shape An array of integers defining the output tensor shape.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction reshape_(x, shape) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reshape', null);\n    shape = util.inferFromImplicitShape(shape, $x.size);\n    util.assert($x.size === util.sizeFromShape(shape), function () { return 'new shape and old shape must have the same number of elements.'; });\n    var grad = function (dy) {\n        return { x: function () { return dy.reshape($x.shape); } };\n    };\n    var attrs = { shape: shape };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.reshape($x, shape); }, { x: $x }, grad, 'Reshape', attrs);\n}\n/**\n * Removes dimensions of size 1 from the shape of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4], [1, 1, 4]);\n * x.squeeze().print();\n * ```\n *\n * @param x The input tensor to be squeezed.\n * @param axis An optional list of numbers. If specified, only\n *     squeezes the dimensions listed. The dimension index starts at 0. It\n * is an error to squeeze a dimension that is not 1.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction squeeze_(x, axis) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'squeeze');\n    return exports.reshape($x, util.squeezeShape($x.shape, axis).newShape);\n}\n/**\n * Casts a `tf.Tensor` to a new dtype.\n *\n * ```js\n * const x = tf.tensor1d([1.5, 2.5, 3]);\n * tf.cast(x, 'int32').print();\n * ```\n * @param x The input tensor to be casted.\n * @param dtype The dtype to cast the input tensor to.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction cast_(x, dtype) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'cast');\n    // Sanity checks.\n    if (!util.isValidDtype(dtype)) {\n        throw new Error(\"Failed to cast to unknown dtype \" + dtype);\n    }\n    if (dtype === 'string' && $x.dtype !== 'string' ||\n        dtype !== 'string' && $x.dtype === 'string') {\n        throw new Error('Only strings can be casted to strings');\n    }\n    var grad = function (dy) {\n        return { x: function () { return dy.clone(); } };\n    };\n    var attrs = { dtype: dtype };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.cast($x, dtype); }, { x: $x }, grad, 'Cast', attrs);\n}\n/**\n * Construct a tensor by repeating it the number of times given by reps.\n *\n * This operation creates a new tensor by replicating `input` `reps`\n * times. The output tensor's i'th dimension has `input.shape[i] *\n * reps[i]` elements, and the values of `input` are replicated\n * `reps[i]` times along the i'th dimension. For example, tiling\n * `[a, b, c, d]` by `[2]` produces `[a, b, c, d, a, b, c, d]`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n *\n * a.tile([2]).print();    // or a.tile([2])\n * ```\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.tile([1, 2]).print();  // or a.tile([1, 2])\n * ```\n * @param x The tensor to tile.\n * @param reps Determines the number of replications per dimension.\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction tile_(x, reps) {\n    var parseAs = null;\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'tile', parseAs);\n    util.assert($x.rank === reps.length, function () { return \"Error in transpose: rank of input \" + $x.rank + \" \" +\n        (\"must match length of reps \" + reps + \".\"); });\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        var derX = function () {\n            var xGrad = tensor_ops_1.zerosLike($x);\n            // TODO(cais): Maybe reduce memory footprint by avoiding repeated\n            // slicing.\n            if ($x.rank === 1) {\n                for (var i = 0; i < reps[0]; ++i) {\n                    xGrad = xGrad.add(dy.slice([i * $x.shape[0]], [$x.shape[0]]));\n                }\n            }\n            else if ($x.rank === 2) {\n                for (var i = 0; i < reps[0]; ++i) {\n                    for (var j = 0; j < reps[1]; ++j) {\n                        xGrad = xGrad.add(dy.slice([i * $x.shape[0], j * $x.shape[1]], [$x.shape[0], $x.shape[1]]));\n                    }\n                }\n            }\n            else if ($x.rank === 3) {\n                for (var i = 0; i < reps[0]; ++i) {\n                    for (var j = 0; j < reps[1]; ++j) {\n                        for (var k = 0; k < reps[2]; ++k) {\n                            xGrad = xGrad.add(dy.slice([i * $x.shape[0], j * $x.shape[1], k * $x.shape[2]], [$x.shape[0], $x.shape[1], $x.shape[2]]));\n                        }\n                    }\n                }\n            }\n            else if ($x.rank === 4) {\n                for (var i = 0; i < reps[0]; ++i) {\n                    for (var j = 0; j < reps[1]; ++j) {\n                        for (var k = 0; k < reps[2]; ++k) {\n                            for (var l = 0; l < reps[3]; ++l) {\n                                xGrad = xGrad.add(dy.slice([\n                                    i * $x.shape[0], j * $x.shape[1], k * $x.shape[2],\n                                    l * $x.shape[3]\n                                ], [$x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]));\n                            }\n                        }\n                    }\n                }\n            }\n            else {\n                throw new Error(\"Gradient for tile operation is not implemented for rank-\" +\n                    ($x.rank + \" tensors yet.\"));\n            }\n            return xGrad;\n        };\n        return { x: derX };\n    };\n    var inputsToSave = [$x];\n    var attrs = { reps: reps };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.tile($x, reps);\n        save([$x]);\n        return res;\n    }, { x: $x }, grad, 'Tile', attrs, inputsToSave);\n}\n/**\n * Pads a `tf.Tensor1D` with a given value and paddings. See `pad` for details.\n */\nfunction pad1d_(x, paddings, constantValue) {\n    if (constantValue === void 0) { constantValue = 0; }\n    util.assert(paddings.length === 2, function () { return 'Invalid number of paddings. Must be length of 2.'; });\n    return exports.pad(x, [paddings], constantValue);\n}\n/**\n * Pads a `tf.Tensor2D` with a given value and paddings. See `pad` for details.\n */\nfunction pad2d_(x, paddings, constantValue) {\n    if (constantValue === void 0) { constantValue = 0; }\n    util.assert(paddings.length === 2 && paddings[0].length === 2 &&\n        paddings[1].length === 2, function () { return 'Invalid number of paddings. Must be length of 2 each.'; });\n    return exports.pad(x, paddings, constantValue);\n}\n/**\n * Pads a `tf.Tensor3D` with a given value and paddings. See `pad` for details.\n */\nfunction pad3d_(x, paddings, constantValue) {\n    if (constantValue === void 0) { constantValue = 0; }\n    util.assert(paddings.length === 3 && paddings[0].length === 2 &&\n        paddings[1].length === 2 && paddings[2].length === 2, function () { return 'Invalid number of paddings. Must be length of 2 each.'; });\n    return exports.pad(x, paddings, constantValue);\n}\n/**\n * Pads a `tf.Tensor4D` with a given value and paddings. See `pad` for details.\n */\nfunction pad4d_(x, paddings, constantValue) {\n    if (constantValue === void 0) { constantValue = 0; }\n    util.assert(paddings.length === 4 && paddings[0].length === 2 &&\n        paddings[1].length === 2 && paddings[2].length === 2 &&\n        paddings[3].length === 2, function () { return 'Invalid number of paddings. Must be length of 2 each.'; });\n    return exports.pad(x, paddings, constantValue);\n}\n/**\n * Pads a `tf.Tensor` with a given value and paddings.\n *\n * This operation currently only implements the `CONSTANT` mode.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `paddings` is of given length.\n *   - `tf.pad1d`\n *   - `tf.pad2d`\n *   - `tf.pad3d`\n *   - `tf.pad4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.pad([[1, 2]]).print();\n * ```\n * @param x The tensor to pad.\n * @param paddings An array of length `R` (the rank of the tensor), where\n * each element is a length-2 tuple of ints `[padBefore, padAfter]`,\n * specifying how much to pad along each dimension of the tensor.\n * @param constantValue The pad value to use. Defaults to 0.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction pad_(x, paddings, constantValue) {\n    if (constantValue === void 0) { constantValue = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'pad');\n    if ($x.rank === 0) {\n        throw new Error('pad(scalar) is not defined. Pass non-scalar to pad');\n    }\n    var grad = function (dy) {\n        // Pad introduces values around the original tensor, so the gradient\n        // slices the original shape out of the gradient.\n        var begin = paddings.map(function (p) { return p[0]; });\n        return { x: function () { return dy.slice(begin, $x.shape); } };\n    };\n    var attrs = { paddings: paddings, constantValue: constantValue };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.pad($x, paddings, constantValue); }, { x: $x }, grad, 'PadV2', attrs);\n}\n/**\n * Stacks a list of rank-`R` `tf.Tensor`s into one rank-`(R+1)` `tf.Tensor`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.stack([a, b, c]).print();\n * ```\n *\n * @param tensors A list of tensor objects with the same shape and dtype.\n * @param axis The axis to stack along. Defaults to 0 (the first dim).\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction stack_(tensors, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $tensors = tensor_util_env_1.convertToTensorArray(tensors, 'tensors', 'stack');\n    util.assert($tensors.length >= 1, function () { return 'Pass at least one tensor to tf.stack'; });\n    if ($tensors.length === 1) {\n        return $tensors[0].expandDims(axis);\n    }\n    var rank = $tensors[0].rank;\n    var shape = $tensors[0].shape;\n    var dtype = $tensors[0].dtype;\n    util.assert(axis <= rank, function () { return 'Axis must be <= rank of the tensor'; });\n    $tensors.forEach(function (t) {\n        util.assertShapesMatch(shape, t.shape, 'All tensors passed to stack must have matching shapes');\n    });\n    $tensors.forEach(function (t) {\n        util.assert(dtype === t.dtype, function () { return 'All tensors passed to stack must have matching dtypes'; });\n    });\n    var expandedTensors = $tensors.map(function (t) { return t.expandDims(axis); });\n    return concat_split_1.concat(expandedTensors, axis);\n}\n/**\n * This operation reshapes the \"batch\" dimension 0 into `M + 1` dimensions of\n * shape `blockShape + [batch]`, interleaves these blocks back into the grid\n * defined by the spatial dimensions `[1, ..., M]`, to obtain a result with\n * the same rank as the input. The spatial dimensions of this intermediate\n * result are then optionally cropped according to `crops` to produce the\n * output. This is the reverse of `tf.spaceToBatchND`. See below for a precise\n * description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [4, 1, 1, 1]);\n * const blockShape = [2, 2];\n * const crops = [[0, 0], [0, 0]];\n *\n * x.batchToSpaceND(blockShape, crops).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param crops A 2-D array.  Must have shape `[M, 2]`, all values must be >= 0.\n * `crops[i] = [cropStart, cropEnd]` specifies the amount to crop from input\n * dimension `i + 1`, which corresponds to spatial dimension `i`. It is required\n * that `cropStart[i] + cropEnd[i] <= blockShape[i] * inputShape[i + 1]`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Reshape `x` to `reshaped` of shape: `[blockShape[0], ...,\n * blockShape[M-1], batch / prod(blockShape), x.shape[1], ...,\n * x.shape[N-1]]`\n *\n * 2. Permute dimensions of `reshaped`to produce `permuted` of shape `[batch /\n * prod(blockShape),x.shape[1], blockShape[0], ..., x.shape[M],\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 3. Reshape `permuted` to produce `reshapedPermuted` of shape `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0], ..., x.shape[M] *\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 4. Crop the start and end of dimensions `[1, ..., M]` of `reshapedPermuted`\n * according to `crops` to produce the output of shape: `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0] - crops[0,0] - crops[0,1],\n * ..., x.shape[M] * blockShape[M-1] - crops[M-1,0] -\n * crops[M-1,1],x.shape[M+1], ..., x.shape[N-1]]`\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction batchToSpaceND_(x, blockShape, crops) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'batchToSpaceND');\n    var prod = blockShape.reduce(function (a, b) { return a * b; });\n    util.assert($x.rank >= 1 + blockShape.length, function () { return \"input rank is \" + $x.rank + \" but should be > than blockShape.length \" + blockShape.length; });\n    util.assert(crops.length === blockShape.length, function () { return \"crops.length is \" + crops.length + \" but should be equal to blockShape.length  \" + blockShape.length; });\n    util.assert($x.shape[0] % prod === 0, function () { return \"input tensor batch is \" + $x.shape[0] + \" but is not divisible by the product of \" +\n        (\"the elements of blockShape \" + blockShape.join(' * ') + \" === \" + prod); });\n    var grad = function (dy) {\n        return { $x: function () { return dy.spaceToBatchND(blockShape, crops); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.batchToSpaceND($x, blockShape, crops); }, { $x: $x }, grad);\n}\n/**\n * This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into\n * a grid of blocks of shape `blockShape`, and interleaves these blocks with\n * the \"batch\" dimension (0) such that in the output, the spatial\n * dimensions `[1, ..., M]` correspond to the position within the grid,\n * and the batch dimension combines both the position within a spatial block\n * and the original batch position. Prior to division into blocks,\n * the spatial dimensions of the input are optionally zero padded\n * according to `paddings`. See below for a precise description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 2, 2, 1]);\n * const blockShape = [2, 2];\n * const paddings = [[0, 0], [0, 0]];\n *\n * x.spaceToBatchND(blockShape, paddings).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param paddings A 2-D array. Must have shape `[M, 2]`, all values must be >=\n *     0. `paddings[i] = [padStart, padEnd]` specifies the amount to zero-pad\n * from input dimension `i + 1`, which corresponds to spatial dimension `i`. It\n * is required that\n * `(inputShape[i + 1] + padStart + padEnd) % blockShape[i] === 0`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the input\n * according to `paddings` to produce `padded` of shape paddedShape.\n *\n * 2. Reshape `padded` to `reshapedPadded` of shape:\n * `[batch] + [paddedShape[1] / blockShape[0], blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1], blockShape[M-1]] + remainingShape`\n *\n * 3. Permute dimensions of `reshapedPadded` to produce `permutedReshapedPadded`\n * of shape: `blockShape + [batch] + [paddedShape[1] / blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1]] + remainingShape`\n *\n * 4. Reshape `permutedReshapedPadded` to flatten `blockShape` into the\n * batch dimension, producing an output tensor of shape:\n * `[batch * prod(blockShape)] + [paddedShape[1] / blockShape[0], ...,\n * paddedShape[M] / blockShape[M-1]] + remainingShape`\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction spaceToBatchND_(x, blockShape, paddings) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'spaceToBatchND');\n    util.assert($x.rank >= 1 + blockShape.length, function () { return \"input rank \" + $x.rank + \" should be > than [blockShape] \" + blockShape.length; });\n    util.assert(paddings.length === blockShape.length, function () { return \"paddings.shape[0] \" + paddings.length + \" must be equal to [blockShape] \" + blockShape.length; });\n    util.assert($x.shape.reduce(function (a, b, i) {\n        if (i > 0 && i <= blockShape.length) {\n            return a &&\n                ((b + paddings[i - 1][0] + paddings[i - 1][1]) %\n                    blockShape[i - 1] ===\n                    0);\n        }\n        return a;\n    }, true), function () { return \"input spatial dimensions \" + $x.shape.slice(1) + \" with paddings \" + paddings.toString() + \" must be divisible by blockShapes \" + blockShape.toString(); });\n    var grad = function (dy) {\n        return { $x: function () { return dy.batchToSpaceND(blockShape, paddings); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.spaceToBatchND($x, blockShape, paddings); }, { $x: $x }, grad);\n}\n/**\n * Unstacks a `tf.Tensor` of rank-`R` into a list of rank-`(R-1)` `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * tf.unstack(a).forEach(tensor => tensor.print());\n * ```\n *\n * @param x A tensor object.\n * @param axis The axis to unstack along. Defaults to 0 (the first dim).\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction unstack_(x, axis) {\n    if (axis === void 0) { axis = 0; }\n    axis = axis || 0;\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'unstack');\n    util.assert(axis >= -$x.shape.length && axis < $x.shape.length, function () {\n        return \"Axis = \" + axis + \" is not in [-\" + $x.shape.length + \", \" + $x.shape.length + \")\";\n    });\n    if (axis < 0) {\n        axis += $x.shape.length;\n    }\n    var grad = function (dy) {\n        return { x: function () { return exports.stack(dy, axis); } };\n    };\n    var attrs = { axis: axis };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.unstack($x, axis); }, { x: $x }, grad, 'Unpack', attrs);\n}\n/**\n * Computes the cumulative sum of a `tf.Tensor` along `axis`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4]);\n * x.cumsum().print();\n * ```\n * ```js\n * const x = tf.tensor([[1, 2], [3, 4]]);\n * x.cumsum().print();\n * ```\n *\n * @param x The input tensor to be summed.\n * @param axis The axis along which to sum. Optional. Defaults to 0.\n * @param exclusive Whether to perform exclusive cumulative sum. Optional.\n *     Defaults to false. If set to true then the sum of each tensor entry\n *     does not include its own value, but only the values previous to it\n *     along the specified axis.\n * @param reverse Whether to sum in the opposite direction. Optional.\n *     Defaults to false.\n */\n/** @doc {heading: 'Operations', subheading: 'Scan'} */\nfunction cumsum_(x, axis, exclusive, reverse) {\n    if (axis === void 0) { axis = 0; }\n    if (exclusive === void 0) { exclusive = false; }\n    if (reverse === void 0) { reverse = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'cumsum');\n    axis = axis | 0;\n    var permutation = axis_util_1.getAxesPermutation([axis], $x.rank);\n    var permutedX = $x;\n    if (permutation != null) {\n        permutedX = $x.transpose(permutation);\n    }\n    var permutedAxis = axis_util_1.getInnerMostAxes(1, $x.rank)[0];\n    var grad = function (dy) {\n        return { permutedX: function () { return dy.cumsum(axis, exclusive, !reverse); } };\n    };\n    var value = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.cumsum(permutedX, permutedAxis, exclusive, reverse); }, { permutedX: permutedX }, grad);\n    if (permutation != null) {\n        value = value.transpose(permutation);\n    }\n    return value;\n}\n/**\n * Returns a `tf.Tensor` that has expanded rank, by inserting a dimension\n * into the tensor's shape.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const axis = 1;\n * x.expandDims(axis).print();\n * ```\n *\n * @param x The input tensor whose dimensions to be expanded.\n * @param axis The dimension index at which to insert shape of `1`. Defaults\n *     to 0 (the first dimension).\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction expandDims_(x, axis) {\n    if (axis === void 0) { axis = 0; }\n    var parseAs = null;\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'expandDims', parseAs);\n    util.assert(axis <= $x.rank, function () { return 'Axis must be <= rank of the tensor'; });\n    var newShape = $x.shape.slice();\n    if (axis < 0) {\n        // Negative value is counted from the tail of rank.\n        util.assert(-($x.rank + 1) <= axis, function () { return \"Axis must be in the interval [\" + -($x.rank + 1) + \", \" + $x.rank + \"]\"; });\n        axis = $x.rank + axis + 1;\n    }\n    newShape.splice(axis, 0, 1);\n    return exports.reshape($x, newShape);\n}\n/**\n * Rearranges data from depth into blocks of spatial data. More specifically,\n * this op outputs a copy of the input tensor where values from the `depth`\n * dimension are moved in spatial blocks to the `height` and `width` dimensions.\n * The attr `blockSize` indicates the input block size and how the data is\n * moved.\n *\n *  - Chunks of data of size `blockSize * blockSize` from depth are rearranged\n * into non-overlapping blocks of size `blockSize x blockSize`\n *\n *  - The width the output tensor is `inputWidth * blockSize`, whereas the\n * height is `inputHeight * blockSize`\n *\n *  - The Y, X coordinates within each block of the output image are determined\n * by the high order component of the input channel index\n *\n *  - The depth of the input tensor must be divisible by `blockSize *\n * blockSize`\n *\n * The `dataFormat` attr specifies the layout of the input and output tensors\n * with the following options: \"NHWC\": [ `batch, height, width, channels` ]\n * \"NCHW\": [ `batch, channels, height, width` ]\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 1, 1, 4]);\n * const blockSize = 2;\n * const dataFormat = \"NHWC\";\n *\n * tf.depthToSpace(x, blockSize, dataFormat).print();\n * ```\n *\n * @param x The input tensor of rank 4\n * @param blockSIze  An `int` that is `>= 2`. The size of the spatial block\n * @param dataFormat An optional string from: \"NHWC\", \"NCHW\". Defaults to \"NHWC\"\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction depthToSpace_(x, blockSize, dataFormat) {\n    if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'depthToSpace');\n    var inputHeight = (dataFormat === 'NHWC') ? $x.shape[1] : $x.shape[2];\n    var inputWidth = (dataFormat === 'NHWC') ? $x.shape[2] : $x.shape[3];\n    var inputDepth = (dataFormat === 'NHWC') ? $x.shape[3] : $x.shape[1];\n    util.assert(inputHeight * blockSize >= 0, function () { return \"Negative dimension size caused by overflow when multiplying\\n      \" + inputHeight + \" and \" + blockSize + \"  for depthToSpace with input shape\\n      \" + $x.shape; });\n    util.assert(inputWidth * blockSize >= 0, function () { return \"Negative dimension size caused by overflow when multiplying\\n      \" + inputWidth + \" and \" + blockSize + \" for depthToSpace with input shape\\n          \" + $x.shape; });\n    util.assert((inputDepth % (blockSize * blockSize) === 0), function () { return \"Dimension size must be evenly divisible by \" + blockSize * blockSize + \" but is \" + inputDepth + \" for depthToSpace with input shape \" + $x.shape; });\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.depthToSpace($x, blockSize, dataFormat); }, { $x: $x });\n}\n/**\n * Computes the difference between two lists of numbers.\n *\n * Given a Tensor `x` and a Tensor `y`, this operation returns a Tensor `out`\n * that represents all values that are in `x` but not in `y`. The returned\n * Tensor `out` is sorted in the same order that the numbers appear in `x`\n * (duplicates are preserved). This operation also returns a Tensor indices that\n * represents the position of each out element in `x`. In other words:\n *\n * `out[i] = x[idx[i]] for i in [0, 1, ..., out.length - 1]`\n *\n * ```js\n * const x = [1, 2, 3, 4, 5, 6];\n * const y = [1, 3, 5];\n *\n * const [out, indices] = await tf.setdiff1dAsync(x, y);\n * out.print(); // [2, 4, 6]\n * indices.print(); // [1, 3, 5]\n * ```\n *\n * @param x 1-D Tensor. Values to keep.\n * @param y 1-D Tensor. Must have the same type as x. Values to exclude in the\n *     output.\n * @returns Promise of Tensor tuple [out, indices].\n *  out: Tensor with the same type as x.\n *  indices: A Tensor of type int32.\n */\n/** @doc {heading: 'Tensors', subheading: 'Transformations'} */\nfunction setdiff1dAsync_(x, y) {\n    return __awaiter(this, void 0, void 0, function () {\n        var $x, $y, xVals, yVals, ySet, outputSize, i, buffer, indices, i, p;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    $x = tensor_util_env_1.convertToTensor(x, 'x', 'setdiff1d');\n                    $y = tensor_util_env_1.convertToTensor(y, 'y', 'setdiff1d');\n                    util.assert($x.dtype === $y.dtype, function () { return \"x and y should have the same dtype, but got x (\" + $x.dtype + \") and y (\" + $y.dtype + \").\"; });\n                    util.assert($x.rank === 1, function () { return \"x should be 1D tensor, but got x (\" + $x.shape + \").\"; });\n                    util.assert($y.rank === 1, function () { return \"y should be 1D tensor, but got y (\" + $y.shape + \").\"; });\n                    return [4 /*yield*/, $x.data()];\n                case 1:\n                    xVals = _a.sent();\n                    return [4 /*yield*/, $y.data()];\n                case 2:\n                    yVals = _a.sent();\n                    ySet = new Set(yVals);\n                    outputSize = 0;\n                    for (i = 0; i < xVals.length; i++) {\n                        if (!ySet.has(xVals[i])) {\n                            outputSize++;\n                        }\n                    }\n                    buffer = new tensor_1.TensorBuffer([outputSize], $x.dtype);\n                    indices = new tensor_1.TensorBuffer([outputSize], 'int32');\n                    for (i = 0, p = 0; i < xVals.length; i++) {\n                        if (!ySet.has(xVals[i])) {\n                            buffer.values[p] = xVals[i];\n                            indices.values[p] = i;\n                            p++;\n                        }\n                    }\n                    return [2 /*return*/, [buffer.toTensor(), indices.toTensor()]];\n            }\n        });\n    });\n}\n/**\n * Creates an empty `tf.TensorBuffer` with the specified `shape` and `dtype`.\n *\n * The values are stored in CPU as `TypedArray`. Fill the buffer using\n * `buffer.set()`, or by modifying directly `buffer.values`.\n *\n * When done, call `buffer.toTensor()` to get an immutable `tf.Tensor` with\n * those values.\n *\n * ```js\n * // Create a buffer and set values at particular indices.\n * const buffer = tf.buffer([2, 2]);\n * buffer.set(3, 0, 0);\n * buffer.set(5, 1, 0);\n *\n * // Convert the buffer back to a tensor.\n * buffer.toTensor().print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The dtype of the buffer. Defaults to 'float32'.\n * @param values The values of the buffer as `TypedArray`. Defaults to\n * zeros.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction buffer(shape, dtype, values) {\n    if (dtype === void 0) { dtype = 'float32'; }\n    dtype = dtype || 'float32';\n    util.assertNonNegativeIntegerDimensions(shape);\n    return new tensor_1.TensorBuffer(shape, dtype, values);\n}\nexports.buffer = buffer;\n/**\n * Prints information about the `tf.Tensor` including its data.\n *\n * ```js\n * const verbose = true;\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print(verbose);\n * ```\n * @param x The tensor to be printed.\n * @param verbose Whether to print verbose information about the ` Tensor`,\n * including dtype and size.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction print(x, verbose) {\n    if (verbose === void 0) { verbose = false; }\n    console.log(x.toString(verbose));\n}\nexports.print = print;\nexports.batchToSpaceND = operation_1.op({ batchToSpaceND_: batchToSpaceND_ });\nexports.broadcastTo = operation_1.op({ broadcastTo_: broadcastTo_ });\nexports.cast = operation_1.op({ cast_: cast_ });\nexports.clone = operation_1.op({ clone_: clone_ });\nexports.cumsum = operation_1.op({ cumsum_: cumsum_ });\nexports.depthToSpace = operation_1.op({ depthToSpace_: depthToSpace_ });\nexports.expandDims = operation_1.op({ expandDims_: expandDims_ });\nexports.eye = operation_1.op({ eye_: eye_ });\nexports.multinomial = operation_1.op({ multinomial_: multinomial_ });\nexports.oneHot = operation_1.op({ oneHot_: oneHot_ });\nexports.pad = operation_1.op({ pad_: pad_ });\nexports.pad1d = operation_1.op({ pad1d_: pad1d_ });\nexports.pad2d = operation_1.op({ pad2d_: pad2d_ });\nexports.pad3d = operation_1.op({ pad3d_: pad3d_ });\nexports.pad4d = operation_1.op({ pad4d_: pad4d_ });\nexports.rand = operation_1.op({ rand_: rand_ });\nexports.randomNormal = operation_1.op({ randomNormal_: randomNormal_ });\nexports.randomGamma = operation_1.op({ randomGamma_: randomGamma_ });\nexports.randomUniform = operation_1.op({ randomUniform_: randomUniform_ });\nexports.reshape = operation_1.op({ reshape_: reshape_ });\nexports.spaceToBatchND = operation_1.op({ spaceToBatchND_: spaceToBatchND_ });\nexports.squeeze = operation_1.op({ squeeze_: squeeze_ });\nexports.stack = operation_1.op({ stack_: stack_ });\nexports.tile = operation_1.op({ tile_: tile_ });\nexports.truncatedNormal = operation_1.op({ truncatedNormal_: truncatedNormal_ });\nexports.unstack = operation_1.op({ unstack_: unstack_ });\nexports.setdiff1dAsync = setdiff1dAsync_;\n//# sourceMappingURL=array_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Gets the new shape of the input Tensor after it's been reshaped\n * to:\n * [blockShape[0], ..., blockShape[M-1], batch / prod(blockShape),\n * inputShape[1], ..., inputShape[N-1]]\n *\n * See step 1: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nfunction getReshaped(inputShape, blockShape, prod, batchToSpace) {\n    if (batchToSpace === void 0) { batchToSpace = true; }\n    var reshaped = [];\n    if (batchToSpace) {\n        reshaped = reshaped.concat(blockShape.slice(0));\n        reshaped.push(inputShape[0] / prod);\n        reshaped = reshaped.concat(inputShape.slice(1));\n    }\n    else {\n        reshaped = reshaped.concat(inputShape[0]);\n        var spatialLength = blockShape.length;\n        for (var i = 0; i < spatialLength; ++i) {\n            reshaped =\n                reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);\n        }\n        reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));\n    }\n    return reshaped;\n}\nexports.getReshaped = getReshaped;\n/**\n * Gets the permutation that will transpose the dimensions of the\n * reshaped tensor to shape:\n *\n * [batch / prod(block_shape),inputShape[1], blockShape[0], ...,\n * inputShape[M], blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * see step 2: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nfunction getPermuted(reshapedRank, blockShapeRank, batchToSpace) {\n    if (batchToSpace === void 0) { batchToSpace = true; }\n    var permuted = [];\n    if (batchToSpace) {\n        permuted.push(blockShapeRank);\n        for (var i = blockShapeRank + 1; i < reshapedRank; ++i) {\n            if (i <= 2 * blockShapeRank) {\n                permuted.push(i);\n                permuted.push(i - (blockShapeRank + 1));\n            }\n            else {\n                permuted.push(i);\n            }\n        }\n    }\n    else {\n        var permutedBeforeBatch = [];\n        var permutedAfterBatch = [];\n        for (var i = 1; i < reshapedRank; ++i) {\n            if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {\n                permutedAfterBatch.push(i);\n            }\n            else {\n                permutedBeforeBatch.push(i);\n            }\n        }\n        permuted.push.apply(permuted, permutedBeforeBatch);\n        permuted.push(0);\n        permuted.push.apply(permuted, permutedAfterBatch);\n    }\n    return permuted;\n}\nexports.getPermuted = getPermuted;\n/**\n * Gets the shape of the reshaped and permuted input Tensor before any cropping\n * is applied.  The new shape will be:\n *\n * [batch / prod(blockShape),inputShape[1] * blockShape[0], ...,\n * inputShape[M] * blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 3: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nfunction getReshapedPermuted(inputShape, blockShape, prod, batchToSpace) {\n    if (batchToSpace === void 0) { batchToSpace = true; }\n    var reshapedPermuted = [];\n    if (batchToSpace) {\n        reshapedPermuted.push(inputShape[0] / prod);\n    }\n    else {\n        reshapedPermuted.push(inputShape[0] * prod);\n    }\n    for (var i = 1; i < inputShape.length; ++i) {\n        if (i <= blockShape.length) {\n            if (batchToSpace) {\n                reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);\n            }\n            else {\n                reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);\n            }\n        }\n        else {\n            reshapedPermuted.push(inputShape[i]);\n        }\n    }\n    return reshapedPermuted;\n}\nexports.getReshapedPermuted = getReshapedPermuted;\n/**\n * Converts the crops argument into the beginning coordinates of a slice\n * operation.\n */\nfunction getSliceBeginCoords(crops, blockShape) {\n    var sliceBeginCoords = [0];\n    for (var i = 0; i < blockShape; ++i) {\n        sliceBeginCoords.push(crops[i][0]);\n    }\n    return sliceBeginCoords;\n}\nexports.getSliceBeginCoords = getSliceBeginCoords;\n/**\n * Converts the crops argument into the size of a slice operation.  When\n * combined with getSliceBeginCoords this function allows the reshaped and\n * permuted Tensor to be cropped to its final output shape of:\n *\n * inputShape[1] * blockShape[0] - crops[0,0] - crops[0,1], ...,\n * inputShape[M] * blockShape[M-1] -crops[M-1,0] -\n * crops[M-1,1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 4: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nfunction getSliceSize(uncroppedShape, crops, blockShape) {\n    var sliceSize = uncroppedShape.slice(0, 1);\n    for (var i = 0; i < blockShape; ++i) {\n        sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);\n    }\n    return sliceSize;\n}\nexports.getSliceSize = getSliceSize;\n//# sourceMappingURL=array_ops_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n/**\n * Returns true if the axis specifies the inner most dimensions of the\n * array.\n */\nfunction axesAreInnerMostDims(axes, rank) {\n    for (var i = 0; i < axes.length; ++i) {\n        if (axes[axes.length - i - 1] !== rank - 1 - i) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.axesAreInnerMostDims = axesAreInnerMostDims;\nfunction combineLocations(outputLoc, reduceLoc, axes) {\n    var rank = outputLoc.length + reduceLoc.length;\n    var loc = [];\n    var outIdx = 0;\n    var reduceIdx = 0;\n    for (var dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            loc.push(outputLoc[outIdx++]);\n        }\n        else {\n            loc.push(reduceLoc[reduceIdx++]);\n        }\n    }\n    return loc;\n}\nexports.combineLocations = combineLocations;\nfunction computeOutAndReduceShapes(aShape, axes) {\n    var outShape = [];\n    var rank = aShape.length;\n    for (var dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            outShape.push(aShape[dim]);\n        }\n    }\n    var reduceShape = axes.map(function (dim) { return aShape[dim]; });\n    return [outShape, reduceShape];\n}\nexports.computeOutAndReduceShapes = computeOutAndReduceShapes;\nfunction expandShapeToKeepDim(shape, axes) {\n    var reduceSubShape = axes.map(function (x) { return 1; });\n    return combineLocations(shape, reduceSubShape, axes);\n}\nexports.expandShapeToKeepDim = expandShapeToKeepDim;\nfunction assertAxesAreInnerMostDims(msg, axes, rank) {\n    util.assert(axesAreInnerMostDims(axes, rank), function () { return msg + \" supports only inner-most axes for now. \" +\n        (\"Got axes \" + axes + \" and rank-\" + rank + \" input.\"); });\n}\nexports.assertAxesAreInnerMostDims = assertAxesAreInnerMostDims;\n/**\n * Returns the axes permutation to be used with `tf.transpose`, if such\n * permutation is necessary. Otherwise it returns null. This method is used by\n * operations that operate only on inner-most axes.\n */\nfunction getAxesPermutation(axes, rank) {\n    if (axesAreInnerMostDims(axes, rank)) {\n        return null;\n    }\n    var result = [];\n    for (var i = 0; i < rank; ++i) {\n        if (axes.indexOf(i) === -1) {\n            result.push(i);\n        }\n    }\n    axes.forEach(function (axis) { return result.push(axis); });\n    return result;\n}\nexports.getAxesPermutation = getAxesPermutation;\n/** Returns the axes permutation that undoes the original permutation. */\nfunction getUndoAxesPermutation(axes) {\n    return axes.map(function (axis, i) { return [i, axis]; })\n        .sort(function (a, b) { return a[1] - b[1]; })\n        .map(function (x) { return x[0]; });\n}\nexports.getUndoAxesPermutation = getUndoAxesPermutation;\nfunction getInnerMostAxes(numAxes, rank) {\n    var res = [];\n    for (var i = rank - numAxes; i < rank; ++i) {\n        res.push(i);\n    }\n    return res;\n}\nexports.getInnerMostAxes = getInnerMostAxes;\n//# sourceMappingURL=axis_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar globals_1 = __webpack_require__(/*! ../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar array_ops_1 = __webpack_require__(/*! ./array_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js\");\nvar broadcast_util_1 = __webpack_require__(/*! ./broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\nvar unary_ops_1 = __webpack_require__(/*! ./unary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/unary_ops.js\");\n/**\n * Batch normalization, strictly for 2D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm2d_(x, mean, variance, offset, scale, varianceEpsilon) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'batchNorm');\n    var $mean = tensor_util_env_1.convertToTensor(mean, 'mean', 'batchNorm');\n    var $variance = tensor_util_env_1.convertToTensor(variance, 'variance', 'batchNorm');\n    var $scale;\n    if (scale != null) {\n        $scale = tensor_util_env_1.convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    var $offset;\n    if (offset != null) {\n        $offset = tensor_util_env_1.convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($x.rank === 2, function () { return \"Error in batchNorm3D: x must be rank 3 but got rank \" +\n        ($x.rank + \".\"); });\n    util.assert($mean.rank === 2 || $mean.rank === 1, function () { return \"Error in batchNorm2D: mean must be rank 2 or rank 1 but \" +\n        (\"got rank \" + $mean.rank + \".\"); });\n    util.assert($variance.rank === 2 || $variance.rank === 1, function () { return \"Error in batchNorm2D: variance must be rank 2 or rank 1 \" +\n        (\"but got rank \" + $variance.rank + \".\"); });\n    if ($scale != null) {\n        util.assert($scale.rank === 2 || $scale.rank === 1, function () { return \"Error in batchNorm2D: scale must be rank 2 or rank 1 \" +\n            (\"but got rank \" + $scale.rank + \".\"); });\n    }\n    if ($offset != null) {\n        util.assert($offset.rank === 2 || $offset.rank === 1, function () { return \"Error in batchNorm2D: offset must be rank 2 or rank 1 \" +\n            (\"but got rank \" + $offset.rank + \".\"); });\n    }\n    return batchNorm_($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\n/**\n * Batch normalization, strictly for 3D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm3d_(x, mean, variance, offset, scale, varianceEpsilon) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'batchNorm');\n    var $mean = tensor_util_env_1.convertToTensor(mean, 'mean', 'batchNorm');\n    var $variance = tensor_util_env_1.convertToTensor(variance, 'variance', 'batchNorm');\n    var $scale;\n    if (scale != null) {\n        $scale = tensor_util_env_1.convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    var $offset;\n    if (offset != null) {\n        $offset = tensor_util_env_1.convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($x.rank === 3, function () { return \"Error in batchNorm3D: x must be rank 3 but got rank \" +\n        ($x.rank + \".\"); });\n    util.assert($mean.rank === 3 || $mean.rank === 1, function () { return \"Error in batchNorm3D: mean must be rank 3 or rank 1 but \" +\n        (\"got rank \" + $mean.rank + \".\"); });\n    util.assert($variance.rank === 3 || $variance.rank === 1, function () { return \"Error in batchNorm3D: variance must be rank 3 or rank 1 \" +\n        (\"but got rank \" + $variance.rank + \".\"); });\n    if ($scale != null) {\n        util.assert($scale.rank === 3 || $scale.rank === 1, function () { return \"Error in batchNorm3D: scale must be rank 3 or rank 1 \" +\n            (\"but got rank \" + $scale.rank + \".\"); });\n    }\n    if ($offset != null) {\n        util.assert($offset.rank === 3 || $offset.rank === 1, function () { return \"Error in batchNorm3D: offset must be rank 3 or rank 1 \" +\n            (\"but got rank \" + $offset.rank + \".\"); });\n    }\n    return batchNorm_($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\n/**\n * Batch normalization, strictly for 4D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm4d_(x, mean, variance, offset, scale, varianceEpsilon) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'batchNorm');\n    var $mean = tensor_util_env_1.convertToTensor(mean, 'mean', 'batchNorm');\n    var $variance = tensor_util_env_1.convertToTensor(variance, 'variance', 'batchNorm');\n    var $scale;\n    if (scale != null) {\n        $scale = tensor_util_env_1.convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    var $offset;\n    if (offset != null) {\n        $offset = tensor_util_env_1.convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($x.rank === 4, function () { return \"Error in batchNorm4D: x must be rank 4 but got rank \" +\n        ($x.rank + \".\"); });\n    util.assert($mean.rank === 4 || $mean.rank === 1, function () { return \"Error in batchNorm4D: mean must be rank 4 or rank 1 but \" +\n        (\"got rank \" + $mean.rank + \".\"); });\n    util.assert($variance.rank === 4 || $variance.rank === 1, function () { return \"Error in batchNorm4D: variance must be rank 4 or rank 1 \" +\n        (\"but got rank \" + $variance.rank + \".\"); });\n    if ($scale != null) {\n        util.assert($scale.rank === 4 || $scale.rank === 1, function () { return \"Error in batchNorm4D: scale must be rank 4 or rank 1 \" +\n            (\"but got rank \" + $scale.rank + \".\"); });\n    }\n    if ($offset != null) {\n        util.assert($offset.rank === 4 || $offset.rank === 1, function () { return \"Error in batchNorm4D: offset must be rank 4 or rank 1 \" +\n            (\"but got rank \" + $offset.rank + \".\"); });\n    }\n    return batchNorm_($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\n/**\n * @deprecated Please use `tf.batchNorm` instead and note the positional\n *     argument change of scale, offset, and varianceEpsilon.\n */\nfunction batchNormalization_(x, mean, variance, varianceEpsilon, scale, offset) {\n    if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n    warnDeprecation();\n    return batchNorm_(x, mean, variance, offset, scale, varianceEpsilon);\n}\n/**\n * Batch normalization.\n *\n * As described in\n * [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167).\n *\n * Mean, variance, scale, and offset can be of two shapes:\n *   - The same shape as the input.\n *   - In the common case, the depth dimension is the last dimension of x, so\n *     the values would be an `tf.Tensor1D` of shape [depth].\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that parameters passed are of given rank\n *   - `tf.batchNorm2d`\n *   - `tf.batchNorm3d`\n *   - `tf.batchNorm4d`\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction batchNorm_(x, mean, variance, offset, scale, varianceEpsilon) {\n    if (varianceEpsilon == null) {\n        varianceEpsilon = 0.001;\n    }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'batchNorm');\n    var $mean = tensor_util_env_1.convertToTensor(mean, 'mean', 'batchNorm');\n    var $variance = tensor_util_env_1.convertToTensor(variance, 'variance', 'batchNorm');\n    var $scale;\n    if (scale != null) {\n        $scale = tensor_util_env_1.convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    var $offset;\n    if (offset != null) {\n        $offset = tensor_util_env_1.convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($mean.rank === $variance.rank, function () { return 'Batch normalization gradient requires mean and variance to have ' +\n        'equal ranks.'; });\n    util.assert($offset == null || $mean.rank === $offset.rank, function () { return 'Batch normalization gradient requires mean and offset to have ' +\n        'equal ranks.'; });\n    util.assert($scale == null || $mean.rank === $scale.rank, function () { return 'Batch normalization gradient requires mean and scale to have ' +\n        'equal ranks.'; });\n    var x4D;\n    if ($x.rank === 0 || $x.rank === 1) {\n        x4D = $x.as4D(1, 1, 1, $x.size);\n    }\n    else if ($x.rank === 2) {\n        x4D = $x.as4D(1, 1, $x.shape[0], $x.shape[1]);\n    }\n    else if ($x.rank === 3) {\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    else {\n        x4D = $x;\n    }\n    var der = function (dy, saved) {\n        var _a = saved, $x = _a[0], $mean = _a[1], $variance = _a[2], $scale = _a[3];\n        var scaleValue = $scale == null ? tensor_ops_1.scalar(1) : $scale;\n        var reductionAxes = broadcast_util_1.getReductionAxes($mean.shape, x4D.shape);\n        var tileShape = [];\n        if ($mean.rank === 1) {\n            for (var i = 0; i < x4D.shape.length - 1; ++i) {\n                tileShape.push(x4D.shape[i]);\n            }\n            tileShape.push(1);\n        }\n        var xMinusMean = $x.sub($mean);\n        var dyTimesScaleValue = dy.mul(scaleValue);\n        var oneOverSqrtVariance = unary_ops_1.rsqrt($variance.add(tensor_ops_1.scalar(varianceEpsilon)));\n        var minusHalfRCube = oneOverSqrtVariance.mul(oneOverSqrtVariance)\n            .mul(oneOverSqrtVariance)\n            .mul(tensor_ops_1.scalar(-0.5));\n        var derX = function () {\n            if ($mean.rank === 1) {\n                return dy\n                    .mul(array_ops_1.tile(oneOverSqrtVariance.as4D(1, 1, 1, $mean.shape[0]), tileShape))\n                    .mul(scaleValue)\n                    .reshape($x.shape);\n            }\n            else {\n                return dy.mul(oneOverSqrtVariance).mul(scaleValue).reshape($x.shape);\n            }\n        };\n        var derMean = function () {\n            var meanDer = oneOverSqrtVariance.mul(tensor_ops_1.scalar(-1)).mul(dyTimesScaleValue);\n            if ($mean.rank === 1) {\n                meanDer = meanDer.sum(reductionAxes);\n            }\n            return meanDer.reshape($mean.shape);\n        };\n        var derVariance = function () {\n            var varianceDer = minusHalfRCube.mul(xMinusMean).mul(dyTimesScaleValue);\n            if ($mean.rank === 1) {\n                varianceDer = varianceDer.sum(reductionAxes);\n            }\n            return varianceDer.reshape($mean.shape);\n        };\n        var derScale = function () {\n            var xMinusMean2TimesRsqrt = xMinusMean.mul(oneOverSqrtVariance);\n            var scaleDer = dy.mul(xMinusMean2TimesRsqrt);\n            if ($mean.rank === 1) {\n                scaleDer = scaleDer.sum(reductionAxes);\n            }\n            return scaleDer.reshape($mean.shape);\n        };\n        var derOffset = function () {\n            var offsetDer = dy;\n            if ($mean.rank === 1) {\n                offsetDer = offsetDer.sum(reductionAxes);\n            }\n            return offsetDer.reshape($mean.shape);\n        };\n        return {\n            x: derX,\n            mean: derMean,\n            variance: derVariance,\n            scale: derScale,\n            offset: derOffset\n        };\n    };\n    var inputsToSave = [$x, $mean, $variance, $scale];\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.batchNormalization(x4D, batchnormReshape4D($mean), batchnormReshape4D($variance), varianceEpsilon, batchnormReshape4D($scale), batchnormReshape4D($offset));\n        save([$x, $mean, $variance, $scale]);\n        return res;\n    }, { x: $x, mean: $mean, variance: $variance, scale: $scale, offset: $offset }, der, 'BatchNormalization', { varianceEpsilon: varianceEpsilon }, inputsToSave);\n    return res.reshape($x.shape);\n}\nfunction batchnormReshape4D(x) {\n    if (x == null) {\n        return null;\n    }\n    if (x.rank === 0) {\n        return x.as1D();\n    }\n    else if (x.rank === 1) {\n        return x;\n    }\n    else if (x.rank === 2) {\n        return x.as4D(1, 1, x.shape[0], x.shape[1]);\n    }\n    else if (x.rank === 3) {\n        return x.as4D(1, x.shape[0], x.shape[1], x.shape[2]);\n    }\n    return x;\n}\n/**\n * @deprecated Please use `tf.batchNorm2d` instead and note the positional\n *     argument change of scale, offset, and varianceEpsilon.\n */\nfunction batchNormalization2d_(x, mean, variance, varianceEpsilon, scale, offset) {\n    if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n    warnDeprecation();\n    return batchNorm2d_(x, mean, variance, offset, scale, varianceEpsilon);\n}\n/**\n * @deprecated Please use `tf.batchNorm3d` instead and note the positional\n *     argument change of scale, offset, and varianceEpsilon.\n */\nfunction batchNormalization3d_(x, mean, variance, varianceEpsilon, scale, offset) {\n    if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n    warnDeprecation();\n    return batchNorm3d_(x, mean, variance, offset, scale, varianceEpsilon);\n}\n/**\n * @deprecated Please use `tf.batchNorm4d` instead and note the positional\n *     argument change of scale, offset, and varianceEpsilon.\n */\nfunction batchNormalization4d_(x, mean, variance, varianceEpsilon, scale, offset) {\n    if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n    warnDeprecation();\n    return batchNorm4d_(x, mean, variance, offset, scale, varianceEpsilon);\n}\nfunction warnDeprecation() {\n    globals_1.deprecationWarn('tf.batchNormalization() is going away. ' +\n        'Use tf.batchNorm() instead, and note the positional argument change ' +\n        'of scale, offset, and varianceEpsilon');\n}\nexports.batchNormalization2d = operation_1.op({ batchNormalization2d_: batchNormalization2d_ });\nexports.batchNormalization3d = operation_1.op({ batchNormalization3d_: batchNormalization3d_ });\nexports.batchNormalization4d = operation_1.op({ batchNormalization4d_: batchNormalization4d_ });\nexports.batchNormalization = operation_1.op({ batchNormalization_: batchNormalization_ });\nexports.batchNorm = operation_1.op({ batchNorm_: batchNorm_ });\nexports.batchNorm2d = operation_1.op({ batchNorm2d_: batchNorm2d_ });\nexports.batchNorm3d = operation_1.op({ batchNorm3d_: batchNorm3d_ });\nexports.batchNorm4d = operation_1.op({ batchNorm4d_: batchNorm4d_ });\n//# sourceMappingURL=batchnorm.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_1 = __webpack_require__(/*! ../tensor_util */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar broadcast_util = __webpack_require__(/*! ./broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar logical_ops_1 = __webpack_require__(/*! ./logical_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/logical_ops.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\nvar unary_ops_1 = __webpack_require__(/*! ./unary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/unary_ops.js\");\n/**\n * Adds two `tf.Tensor`s element-wise, A + B. Supports broadcasting.\n *\n * We also expose `tf.addStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n *\n * ```js\n * // Broadcast add a with b.\n * const a = tf.scalar(5);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n * @param a The first `tf.Tensor` to add.\n * @param b The second `tf.Tensor` to add. Must have the same type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction add_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'add');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'add');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy) {\n        var derA = function () {\n            var res = dy;\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($a.shape);\n        };\n        var derB = function () {\n            var res = dy;\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($b.shape);\n        };\n        return { a: derA, b: derB };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.add($a, $b); }, { a: $a, b: $b }, der, 'Add');\n}\n/**\n * Adds a list of `tf.Tensor`s element-wise, each with the same shape and dtype.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n *\n * tf.addN([a, b, c]).print();\n * ```\n * @param tensors A list of tensors with the same shape and dtype.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction addN_(tensors) {\n    util.assert(Array.isArray(tensors), function () { return 'The argument passed to tf.addN() must be a list of tensors'; });\n    util.assert(tensors.length >= 1, function () { return \"Must pass at least one tensor to tf.addN(), but got \" +\n        (\"\" + tensors.length); });\n    var $tensors = tensors.map(function (t, i) { return tensor_util_env_1.convertToTensor(t, \"tensors\" + i, 'addN'); });\n    var firstTensor = $tensors[0];\n    $tensors.forEach(function (t) {\n        if (t.dtype !== firstTensor.dtype) {\n            throw new Error('All tensors passed to tf.addN() must have the same dtype');\n        }\n    });\n    $tensors.forEach(function (t) {\n        if (!util.arraysEqual(t.shape, firstTensor.shape)) {\n            throw new Error('All tensors passed to tf.addN() must have the same shape');\n        }\n    });\n    var der = function (dy) {\n        var ders = {};\n        $tensors.forEach(function (t, i) {\n            ders[i] = function () { return dy.clone(); };\n        });\n        return ders;\n    };\n    var inputs = $tensors;\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.addN($tensors); }, inputs, der, 'AddN');\n}\n/**\n * Adds two `tf.Tensor`s element-wise, A + B.\n *\n * Inputs must be the same shape. For broadcasting support, use add() instead.\n *\n * @param a The first Tensor to add element-wise.\n * @param b The second Tensor to add element-wise.\n */\nfunction addStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'addStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'addStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in addStrict: ');\n    return $a.add($b);\n}\n/**\n * Subtracts two `tf.Tensor`s element-wise, A - B. Supports broadcasting.\n *\n * We also expose `tf.subStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n *\n * ```js\n * // Broadcast subtract a with b.\n * const a = tf.tensor1d([10, 20, 30, 40]);\n * const b = tf.scalar(5);\n *\n * a.sub(b).print();  // or tf.sub(a, b)\n * ```\n * @param a The first `tf.Tensor` to subtract from.\n * @param b The second `tf.Tensor` to be subtracted. Must have the same dtype as\n * `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction sub_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'sub');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'sub');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy) {\n        var derA = function () {\n            var res = dy;\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($a.shape);\n        };\n        var derB = function () {\n            var res = dy;\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.neg().reshape($b.shape);\n        };\n        return { a: derA, b: derB };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.subtract($a, $b); }, { a: $a, b: $b }, der, 'Sub');\n}\n/**\n * Subtracts two `tf.Tensor`s element-wise, A - B. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.sub` instead.\n *\n * @param a The first Tensor to subtract element-wise.\n * @param b The second Tensor to subtract element-wise.\n */\nfunction subStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'subStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'subStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in subStrict: ');\n    return $a.sub($b);\n}\n/**\n * Computes the power of one `tf.Tensor` to another. Supports broadcasting.\n *\n * Given a `tf.Tensor` x and a `tf.Tensor` y, this operation computes x^y for\n * corresponding elements in x and y. The result's dtype will be the upcasted\n * type of the `base` and `exp` dtypes.\n *\n * ```js\n * const a = tf.tensor([[2, 3], [4, 5]])\n * const b = tf.tensor([[1, 2], [3, 0]]).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n *\n * ```js\n * const a = tf.tensor([[1, 2], [3, 4]])\n * const b = tf.tensor(2).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n * We also expose `powStrict` which has the same signature as this op and\n * asserts that `base` and `exp` are the same shape (does not broadcast).\n *\n * @param base The base `tf.Tensor` to pow element-wise.\n * @param exp The exponent `tf.Tensor` to pow element-wise.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction pow_(base, exp) {\n    var _a;\n    var $base = tensor_util_env_1.convertToTensor(base, 'base', 'pow');\n    var $exp = tensor_util_env_1.convertToTensor(exp, 'exp', 'pow');\n    _a = tensor_util_1.makeTypesMatch($base, $exp), $base = _a[0], $exp = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($base.shape, $exp.shape);\n    var grad = function (dy, saved) {\n        var $base = saved[0], $exp = saved[1], y = saved[2];\n        var derBase = function () {\n            var expFloat = $exp.toFloat();\n            var res = dy.mul(expFloat.mul($base.pow(expFloat.sub(tensor_ops_1.scalar(1)))));\n            var reduceAxes = broadcast_util.getReductionAxes($base.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($base.shape);\n        };\n        var derExp = function () {\n            var condition = $base.greater(0);\n            var logBase = $base.log().where(condition, tensor_ops_1.zerosLike($base));\n            var res = dy.mul(y.mul(logBase));\n            var reduceAxes = broadcast_util.getReductionAxes($exp.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($exp.shape);\n        };\n        return { a: derBase, b: derExp };\n    };\n    var attrs = {};\n    var inputsToSave = [$base, $exp];\n    var outputsToSave = [true];\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.pow($base, $exp);\n        save([$base, $exp, y]);\n        return y;\n    }, { a: $base, b: $exp }, grad, 'Pow', attrs, inputsToSave, outputsToSave);\n}\n/**\n * Computes the power of one `tf.Tensor` to another. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.pow` instead.\n *\n * @param base The base tensor to pow element-wise.\n * @param exp The exponent tensor to pow element-wise.\n */\nfunction powStrict_(base, exp) {\n    util.assertShapesMatch(base.shape, exp.shape, 'Error in powStrict: ');\n    return base.pow(exp);\n}\n/**\n * Multiplies two `tf.Tensor`s element-wise, A * B. Supports broadcasting.\n *\n * We also expose `tf.mulStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([2, 3, 4, 5]);\n *\n * a.mul(b).print();  // or tf.mul(a, b)\n * ```\n *\n * ```js\n * // Broadcast mul a with b.\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.scalar(5);\n *\n * a.mul(b).print();  // or tf.mul(a, b)\n * ```\n * @param a The first tensor to multiply.\n * @param b The second tensor to multiply. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction mul_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'mul');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'mul');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () {\n            var res = dy.mul($b.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return res.sum(reduceAxes).reshape($a.shape);\n            }\n            return res;\n        };\n        var derB = function () {\n            var res = dy.mul($a.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return res.sum(reduceAxes).reshape($b.shape);\n            }\n            return res;\n        };\n        return { a: derA, b: derB };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.multiply($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { a: $a, b: $b }, der, 'Mul');\n}\n/**\n * Multiplies two `tf.Tensor`s element-wise, A * B.\n *\n * Inputs must be the same shape. For broadcasting support, use `tf.mul`.\n *\n * @param a The first tensor to multiply.\n * @param b The first tensor to multiply. Must have the same\n *    dtype as `a`.\n */\nfunction mulStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'mul');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'mul');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in multiplyStrict: ');\n    return $a.mul($b);\n}\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n *\n * We also expose `tf.divStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction div_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'div');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'div');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    if ($a.dtype === 'int32' && $b.dtype === 'int32') {\n        return exports.floorDiv($a, $b);\n    }\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () {\n            var res = dy.div($b.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return res.sum(reduceAxes).reshape($a.shape);\n            }\n            return res;\n        };\n        var derB = function () {\n            var res = dy.mul($a.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes).reshape($b.shape);\n            }\n            var tmp = $b.square();\n            return res.div(tmp.toFloat()).neg();\n        };\n        return { a: derA, b: derB };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.realDivide($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { a: $a, b: $b }, der, 'Div');\n}\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting. Return 0\n * if denominator is 0.\n *\n * We also expose `tf.divStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n * const c = tf.tensor1d([0, 0, 0, 0]);\n *\n * a.divNoNan(b).print();  // or tf.divNoNan(a, b)\n * a.divNoNan(c).print();  // or tf.divNoNan(a, c)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n * const c = tf.scalar(0);\n *\n * a.divNoNan(b).print();  // or tf.divNoNan(a, b)\n * a.divNoNan(c).print();  // or tf.divNoNan(a, c)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction divNoNan_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'div');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'div');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var divResult = exports.div($a, $b);\n    var zeros = tensor_ops_1.zerosLike(divResult);\n    var bEqualsZero = $b.equal(zeros);\n    return logical_ops_1.where(bEqualsZero, zeros, divResult);\n}\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n * The result is rounded with floor function.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.floorDiv(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.floorDiv(b).print();  // or tf.floorDiv(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction floorDiv_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'floorDiv');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'floorDiv');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () {\n            var res = dy.div($b.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return res.sum(reduceAxes).reshape($a.shape);\n            }\n            return res;\n        };\n        var derB = function () {\n            var res = dy.mul($a.toFloat());\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes).reshape($b.shape);\n            }\n            var tmp = $b.square();\n            return res.div(tmp.toFloat()).neg();\n        };\n        return { a: derA, b: derB };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.floorDiv($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { a: $a, b: $b }, der, 'FloorDiv');\n}\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Inputs must\n * be the same shape.\n *\n * @param a The first tensor as the numerator for element-wise division.\n * @param b The second tensor as the denominator for element-wise division.\n */\nfunction divStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'div');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'div');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in divideStrict: ');\n    return $a.div($b);\n}\n/**\n * Returns the mod of a and b element-wise.\n * `floor(x / y) * y + mod(x, y) = x`\n * Supports broadcasting.\n *\n * We also expose `tf.modStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.mod(b).print();  // or tf.mod(a, b)\n * ```\n *\n * ```js\n * // Broadcast a mod b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.mod(b).print();  // or tf.mod(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction mod_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'mod');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'mod');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () {\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return dy.sum(reduceAxes).reshape($a.shape);\n            }\n            return dy;\n        };\n        var derB = function () {\n            var res = dy.mul($a.div($b).floor().neg());\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                return res.sum(reduceAxes).reshape($b.shape);\n            }\n            return res;\n        };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.mod($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, der);\n}\n/**\n * Returns the mod of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use mod().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction modStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'modStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'modStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in modStrict: ');\n    return $a.mod($b);\n}\n/**\n * Returns the min of a and b (`a < b ? a : b`) element-wise.\n * Supports broadcasting.\n *\n * We also expose `minimumStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.minimum(b).print();  // or tf.minimum(a, b)\n * ```\n *\n * ```js\n * // Broadcast minimum a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.minimum(b).print();  // or tf.minimum(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction minimum_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'minimum');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'minimum');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    if ($a.dtype === 'bool') {\n        $a = $a.toInt();\n        $b = $b.toInt();\n    }\n    broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () { return dy.mul($a.lessEqual($b).toFloat()); };\n        var derB = function () { return dy.mul($a.greater($b).toFloat()); };\n        return { a: derA, b: derB };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.minimum($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { a: $a, b: $b }, der, 'Minimum');\n}\n/**\n * Returns the min of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use minimum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction minimumStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'minimumStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'minimumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in minimumStrict: ');\n    return $a.minimum($b);\n}\n/**\n * Returns the max of a and b (`a > b ? a : b`) element-wise.\n * Supports broadcasting.\n *\n * We also expose `tf.maximumStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.maximum(b).print();  // or tf.maximum(a, b)\n * ```\n *\n * ```js\n * // Broadcast maximum a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.maximum(b).print();  // or tf.maximum(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction maximum_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'maximum');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'maximum');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    if ($a.dtype === 'bool') {\n        $a = $a.toInt();\n        $b = $b.toInt();\n    }\n    broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () { return dy.mul($a.greaterEqual($b).toFloat()); };\n        var derB = function () { return dy.mul($a.less($b).toFloat()); };\n        return { a: derA, b: derB };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.maximum($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { a: $a, b: $b }, der, 'Maximum');\n}\n/**\n * Returns the max of a and b (`a > b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use maximum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction maximumStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'maximumStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'maximumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in maximumStrict: ');\n    return $a.maximum($b);\n}\n/**\n * Returns (a - b) * (a - b) element-wise.\n *\n * Inputs must be the same shape. For broadcasting support, use\n * `tf.squaredDifference` instead.\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\nfunction squaredDifferenceStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'squaredDifferenceStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'squaredDifferenceStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in squaredDifferenceStrict: ');\n    return $a.squaredDifference($b);\n}\n/**\n * Computes arctangent of `tf.Tensor`s a / b element-wise: `atan2(a, b)`.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1.0, 1.0, -1.0, .7]);\n * const b = tf.tensor1d([2.0, 13.0, 3.5, .21]);\n *\n * tf.atan2(a, b).print()\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n *\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction atan2_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'atan2');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'atan2');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var outShape = broadcast_util.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var derA = function () {\n            var d = exports.add($a.square(), $b.square());\n            var res = dy.mul($b.div(d));\n            var reduceAxes = broadcast_util.getReductionAxes($a.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($a.shape);\n        };\n        var derB = function () {\n            var d = exports.add($a.square(), $b.square());\n            var res = unary_ops_1.neg(dy.mul($a.div(d)));\n            var reduceAxes = broadcast_util.getReductionAxes($b.shape, outShape);\n            if (reduceAxes.length > 0) {\n                res = res.sum(reduceAxes);\n            }\n            return res.reshape($b.shape);\n        };\n        return { $a: derA, $b: derB };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.atan2($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { $a: $a, $b: $b }, der);\n}\nexports.add = operation_1.op({ add_: add_ });\nexports.addN = operation_1.op({ addN_: addN_ });\nexports.addStrict = operation_1.op({ addStrict_: addStrict_ });\nexports.atan2 = operation_1.op({ atan2_: atan2_ });\nexports.div = operation_1.op({ div_: div_ });\nexports.divNoNan = operation_1.op({ divNoNan_: divNoNan_ });\nexports.divStrict = operation_1.op({ divStrict_: divStrict_ });\nexports.floorDiv = operation_1.op({ floorDiv_: floorDiv_ });\nexports.maximum = operation_1.op({ maximum_: maximum_ });\nexports.maximumStrict = operation_1.op({ maximumStrict_: maximumStrict_ });\nexports.minimum = operation_1.op({ minimum_: minimum_ });\nexports.minimumStrict = operation_1.op({ minimumStrict_: minimumStrict_ });\nexports.mod = operation_1.op({ mod_: mod_ });\nexports.modStrict = operation_1.op({ modStrict_: modStrict_ });\nexports.mul = operation_1.op({ mul_: mul_ });\nexports.mulStrict = operation_1.op({ mulStrict_: mulStrict_ });\nexports.pow = operation_1.op({ pow_: pow_ });\nexports.powStrict = operation_1.op({ powStrict_: powStrict_ });\nexports.squaredDifferenceStrict = operation_1.op({ squaredDifferenceStrict_: squaredDifferenceStrict_ });\nexports.sub = operation_1.op({ sub_: sub_ });\nexports.subStrict = operation_1.op({ subStrict_: subStrict_ });\n//# sourceMappingURL=binary_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/boolean_mask.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/boolean_mask.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar logical_ops_1 = __webpack_require__(/*! ./logical_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/logical_ops.js\");\nvar segment_ops_1 = __webpack_require__(/*! ./segment_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/segment_ops.js\");\n/**\n * Apply boolean mask to tensor.\n *\n * ```js\n * const tensor = tf.tensor2d([1, 2, 3, 4, 5, 6], [3, 2]);\n * const mask = tf.tensor1d([1, 0, 1], 'bool');\n * const result = await tf.booleanMaskAsync(tensor, mask);\n * result.print();\n * ```\n *\n * @param tensor N-D tensor.\n * @param mask K-D boolean tensor, K <= N and K must be known statically.\n * @param axis A 0-D int Tensor representing the axis in tensor to mask from.\n *     By default, axis is 0 which will mask from the first dimension.\n *     Otherwise K + axis <= N.\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction booleanMaskAsync_(tensor, mask, axis) {\n    return __awaiter(this, void 0, void 0, function () {\n        var $tensor, $mask, axisFrom, maskDim, tensorShape, leadingSize, i, targetTensorShape, reshapedTensor, reshapedMask, positivePositions, indices, res;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    $tensor = tensor_util_env_1.convertToTensor(tensor, 'tensor', 'boolMask');\n                    $mask = tensor_util_env_1.convertToTensor(mask, 'mask', 'boolMask', 'bool');\n                    axisFrom = axis == null ? 0 : axis;\n                    maskDim = $mask.rank;\n                    tensorShape = $tensor.shape;\n                    util.assert(maskDim > 0, function () { return 'mask cannot be scalar'; });\n                    util.assertShapesMatch(tensorShape.slice(axisFrom, axisFrom + maskDim), $mask.shape, \"mask's shape must match the first K dimensions of tensor's shape,\");\n                    leadingSize = 1;\n                    for (i = axisFrom; i < axisFrom + maskDim; i++) {\n                        leadingSize *= tensorShape[i];\n                    }\n                    targetTensorShape = tensorShape.slice(0, axisFrom)\n                        .concat([leadingSize], tensorShape.slice(axisFrom + maskDim));\n                    reshapedTensor = $tensor.reshape(targetTensorShape);\n                    reshapedMask = $mask.reshape([-1]);\n                    return [4 /*yield*/, logical_ops_1.whereAsync(reshapedMask)];\n                case 1:\n                    positivePositions = _a.sent();\n                    indices = positivePositions.squeeze([1]);\n                    res = segment_ops_1.gather(reshapedTensor, indices, axisFrom);\n                    // Ensure no memory leak.\n                    if (tensor !== $tensor) {\n                        $tensor.dispose();\n                    }\n                    if (mask !== $mask) {\n                        $mask.dispose();\n                    }\n                    indices.dispose();\n                    reshapedTensor.dispose();\n                    reshapedMask.dispose();\n                    positivePositions.dispose();\n                    return [2 /*return*/, res];\n            }\n        });\n    });\n}\nexports.booleanMaskAsync = booleanMaskAsync_;\n//# sourceMappingURL=boolean_mask.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/boolean_mask.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nfunction getBroadcastDims(inShape, outShape) {\n    var inRank = inShape.length;\n    var dims = [];\n    for (var i = 0; i < inRank; i++) {\n        var dim = inRank - 1 - i;\n        var a = inShape[dim] || 1;\n        var b = outShape[outShape.length - 1 - i] || 1;\n        if (b > 1 && a === 1) {\n            dims.unshift(dim);\n        }\n    }\n    return dims;\n}\nexports.getBroadcastDims = getBroadcastDims;\n/**\n * Returns the axes in the output space that should be reduced to produce\n * the input space.\n */\nfunction getReductionAxes(inShape, outShape) {\n    var result = [];\n    for (var i = 0; i < outShape.length; i++) {\n        var inDim = inShape[inShape.length - i - 1];\n        var outAxis = outShape.length - i - 1;\n        var outDim = outShape[outAxis];\n        if (inDim == null || (inDim === 1 && outDim > 1)) {\n            result.unshift(outAxis);\n        }\n    }\n    return result;\n}\nexports.getReductionAxes = getReductionAxes;\nfunction assertAndGetBroadcastShape(shapeA, shapeB) {\n    var result = [];\n    var l = Math.max(shapeA.length, shapeB.length);\n    for (var i = 0; i < l; i++) {\n        var a = shapeA[shapeA.length - i - 1];\n        if (a == null) {\n            a = 1;\n        }\n        var b = shapeB[shapeB.length - i - 1];\n        if (b == null) {\n            b = 1;\n        }\n        if (a === 1) {\n            result.unshift(b);\n        }\n        else if (b === 1) {\n            result.unshift(a);\n        }\n        else if (a !== b) {\n            var errMsg = \"Operands could not be broadcast together with shapes \" +\n                (shapeA + \" and \" + shapeB + \".\");\n            throw Error(errMsg);\n        }\n        else {\n            result.unshift(a);\n        }\n    }\n    return result;\n}\nexports.assertAndGetBroadcastShape = assertAndGetBroadcastShape;\n//# sourceMappingURL=broadcast_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/browser.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/browser.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar kernel_registry_1 = __webpack_require__(/*! ../kernel_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js\");\nvar tensor_1 = __webpack_require__(/*! ../tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\nvar fromPixels2DContext;\n/**\n * Creates a `tf.Tensor` from an image.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * tf.browser.fromPixels(image).print();\n * ```\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n */\n/** @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true} */\nfunction fromPixels_(pixels, numChannels) {\n    if (numChannels === void 0) { numChannels = 3; }\n    // Sanity checks.\n    if (numChannels > 4) {\n        throw new Error('Cannot construct Tensor with more than 4 channels from pixels.');\n    }\n    if (pixels == null) {\n        throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n    }\n    var isPixelData = false;\n    var isImageData = false;\n    var isVideo = false;\n    var isImage = false;\n    var isCanvasLike = false;\n    if (pixels.data instanceof Uint8Array) {\n        isPixelData = true;\n    }\n    else if (typeof (ImageData) !== 'undefined' && pixels instanceof ImageData) {\n        isImageData = true;\n    }\n    else if (typeof (HTMLVideoElement) !== 'undefined' &&\n        pixels instanceof HTMLVideoElement) {\n        isVideo = true;\n    }\n    else if (typeof (HTMLImageElement) !== 'undefined' &&\n        pixels instanceof HTMLImageElement) {\n        isImage = true;\n        // tslint:disable-next-line: no-any\n    }\n    else if (pixels.getContext != null) {\n        isCanvasLike = true;\n    }\n    else {\n        throw new Error('pixels passed to tf.browser.fromPixels() must be either an ' +\n            \"HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData \" +\n            \"in browser, or OffscreenCanvas, ImageData in webworker\" +\n            \" or {data: Uint32Array, width: number, height: number}, \" +\n            (\"but was \" + pixels.constructor.name));\n    }\n    if (isVideo) {\n        var HAVE_CURRENT_DATA_READY_STATE = 2;\n        if (isVideo &&\n            pixels.readyState <\n                HAVE_CURRENT_DATA_READY_STATE) {\n            throw new Error('The video element has not loaded data yet. Please wait for ' +\n                '`loadeddata` event on the <video> element.');\n        }\n    }\n    // If the current backend has 'FromPixels' registered, it has a more\n    // efficient way of handling pixel uploads, so we call that.\n    var kernel = kernel_registry_1.getKernel('FromPixels', engine_1.ENGINE.backendName);\n    if (kernel != null) {\n        return engine_1.ENGINE.runKernel('FromPixels', { pixels: pixels }, { numChannels: numChannels });\n    }\n    var _a = isVideo ?\n        [\n            pixels.videoWidth,\n            pixels.videoHeight\n        ] :\n        [pixels.width, pixels.height], width = _a[0], height = _a[1];\n    var vals;\n    if (isCanvasLike) {\n        vals =\n            // tslint:disable-next-line:no-any\n            pixels.getContext('2d').getImageData(0, 0, width, height).data;\n    }\n    else if (isImageData || isPixelData) {\n        vals = pixels.data;\n    }\n    else if (isImage || isVideo) {\n        if (fromPixels2DContext == null) {\n            fromPixels2DContext = document.createElement('canvas').getContext('2d');\n        }\n        fromPixels2DContext.canvas.width = width;\n        fromPixels2DContext.canvas.height = height;\n        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);\n        vals = fromPixels2DContext.getImageData(0, 0, width, height).data;\n    }\n    var values;\n    if (numChannels === 4) {\n        values = new Int32Array(vals);\n    }\n    else {\n        var numPixels = width * height;\n        values = new Int32Array(numPixels * numChannels);\n        for (var i = 0; i < numPixels; i++) {\n            for (var channel = 0; channel < numChannels; ++channel) {\n                values[i * numChannels + channel] = vals[i * 4 + channel];\n            }\n        }\n    }\n    var outShape = [height, width, numChannels];\n    return tensor_ops_1.tensor3d(values, outShape, 'int32');\n}\n/**\n * Draws a `tf.Tensor` of pixel values to a byte array or optionally a\n * canvas.\n *\n * When the dtype of the input is 'float32', we assume values in the range\n * [0-1]. Otherwise, when input is 'int32', we assume values in the range\n * [0-255].\n *\n * Returns a promise that resolves when the canvas has been drawn to.\n *\n * @param img A rank-2 or rank-3 tensor. If rank-2, draws grayscale. If\n *     rank-3, must have depth of 1, 3 or 4. When depth of 1, draws\n * grayscale. When depth of 3, we draw with the first three components of\n * the depth dimension corresponding to r, g, b and alpha = 1. When depth of\n * 4, all four components of the depth dimension correspond to r, g, b, a.\n * @param canvas The canvas to draw to.\n */\n/** @doc {heading: 'Browser', namespace: 'browser'} */\nfunction toPixels(img, canvas) {\n    return __awaiter(this, void 0, void 0, function () {\n        var $img, _a, height, width, depth, data, minTensor, maxTensor, vals, minVals, maxVals, min, max, multiplier, bytes, i, r, g, b, a, j, ctx, imageData;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    $img = tensor_util_env_1.convertToTensor(img, 'img', 'toPixels');\n                    if (!(img instanceof tensor_1.Tensor)) {\n                        // Assume int32 if user passed a native array.\n                        $img = $img.toInt();\n                    }\n                    if ($img.rank !== 2 && $img.rank !== 3) {\n                        throw new Error(\"toPixels only supports rank 2 or 3 tensors, got rank \" + $img.rank + \".\");\n                    }\n                    _a = $img.shape.slice(0, 2), height = _a[0], width = _a[1];\n                    depth = $img.rank === 2 ? 1 : $img.shape[2];\n                    if (depth > 4 || depth === 2) {\n                        throw new Error(\"toPixels only supports depth of size \" +\n                            (\"1, 3 or 4 but got \" + depth));\n                    }\n                    return [4 /*yield*/, $img.data()];\n                case 1:\n                    data = _b.sent();\n                    minTensor = $img.min();\n                    maxTensor = $img.max();\n                    return [4 /*yield*/, Promise.all([minTensor.data(), maxTensor.data()])];\n                case 2:\n                    vals = _b.sent();\n                    minVals = vals[0];\n                    maxVals = vals[1];\n                    min = minVals[0];\n                    max = maxVals[0];\n                    minTensor.dispose();\n                    maxTensor.dispose();\n                    if ($img.dtype === 'float32') {\n                        if (min < 0 || max > 1) {\n                            throw new Error(\"Tensor values for a float32 Tensor must be in the \" +\n                                (\"range [0 - 1] but got range [\" + min + \" - \" + max + \"].\"));\n                        }\n                    }\n                    else if ($img.dtype === 'int32') {\n                        if (min < 0 || max > 255) {\n                            throw new Error(\"Tensor values for a int32 Tensor must be in the \" +\n                                (\"range [0 - 255] but got range [\" + min + \" - \" + max + \"].\"));\n                        }\n                    }\n                    else {\n                        throw new Error(\"Unsupported type for toPixels: \" + $img.dtype + \".\" +\n                            \" Please use float32 or int32 tensors.\");\n                    }\n                    multiplier = $img.dtype === 'float32' ? 255 : 1;\n                    bytes = new Uint8ClampedArray(width * height * 4);\n                    for (i = 0; i < height * width; ++i) {\n                        r = void 0, g = void 0, b = void 0, a = void 0;\n                        if (depth === 1) {\n                            r = data[i] * multiplier;\n                            g = data[i] * multiplier;\n                            b = data[i] * multiplier;\n                            a = 255;\n                        }\n                        else if (depth === 3) {\n                            r = data[i * 3] * multiplier;\n                            g = data[i * 3 + 1] * multiplier;\n                            b = data[i * 3 + 2] * multiplier;\n                            a = 255;\n                        }\n                        else if (depth === 4) {\n                            r = data[i * 4] * multiplier;\n                            g = data[i * 4 + 1] * multiplier;\n                            b = data[i * 4 + 2] * multiplier;\n                            a = data[i * 4 + 3] * multiplier;\n                        }\n                        j = i * 4;\n                        bytes[j + 0] = Math.round(r);\n                        bytes[j + 1] = Math.round(g);\n                        bytes[j + 2] = Math.round(b);\n                        bytes[j + 3] = Math.round(a);\n                    }\n                    if (canvas != null) {\n                        canvas.width = width;\n                        canvas.height = height;\n                        ctx = canvas.getContext('2d');\n                        imageData = new ImageData(bytes, width, height);\n                        ctx.putImageData(imageData, 0, 0);\n                    }\n                    if ($img !== img) {\n                        $img.dispose();\n                    }\n                    return [2 /*return*/, bytes];\n            }\n        });\n    });\n}\nexports.toPixels = toPixels;\nexports.fromPixels = operation_1.op({ fromPixels_: fromPixels_ });\n//# sourceMappingURL=browser.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/browser.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/compare.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/compare.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_1 = __webpack_require__(/*! ../tensor_util */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar broadcast_util_1 = __webpack_require__(/*! ./broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Returns the truth value of (a != b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.notEqualStrict` which has the same signature as this op\n * and asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([0, 2, 3]);\n *\n * a.notEqual(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction notEqual_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'notEqual');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'notEqual');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.notEqual($a, $b); }, { a: $a, b: $b }, null /* grad */, 'NotEqual');\n}\n/**\n * Strict version of `tf.notEqual` that forces `a` and `b` to be of the same\n * shape.\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same shape and dtype as\n *     `a`.\n */\nfunction notEqualStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'notEqualStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'notEqualStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in notEqualStrict: ');\n    return $a.notEqual($b);\n}\n/**\n * Returns the truth value of (a < b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.lessStrict` which has the same signature as this op and\n * asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.less(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction less_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'less');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'less');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.less($a, $b); }, { a: $a, b: $b }, null /* grad */, 'Less');\n}\n/**\n * Strict version of `tf.less` that forces `a` and `b` to be of the same\n * shape.\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same shape and dtype as\n *     `a`.\n */\nfunction lessStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'lessStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'lessStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in lessStrict: ');\n    return $a.less($b);\n}\n/**\n * Returns the truth value of (a == b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.equalStrict` which has the same signature as this op\n * and asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.equal(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction equal_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'equal');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'equal');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.equal($a, $b); }, { $a: $a, $b: $b });\n}\nfunction equalStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'equalStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'equalStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in equalStrict: ');\n    return $a.equal($b);\n}\n/**\n * Returns the truth value of (a <= b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.lessEqualStrict` which has the same signature as this op\n * and asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.lessEqual(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction lessEqual_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'lessEqual');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'lessEqual');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.lessEqual($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { a: $a, b: $b }, null /* grad */, 'LessEqual');\n}\nfunction lessEqualStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'lessEqualStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'lessEqualStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in lessEqualStrict: ');\n    return $a.lessEqual($b);\n}\n/**\n * Returns the truth value of (a > b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.greaterStrict` which has the same signature as this\n * op and asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.greater(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction greater_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'greater');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'greater');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.greater($a, $b); }, { a: $a, b: $b }, null /* grad */, 'Greater');\n}\nfunction greaterStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'greaterStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'greaterStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in greaterStrict: ');\n    return $a.greater($b);\n}\n/**\n * Returns the truth value of (a >= b) element-wise. Supports broadcasting.\n *\n * We also expose `tf.greaterEqualStrict` which has the same signature as this\n * op and asserts that `a` and `b` are the same shape (does not broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.greaterEqual(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction greaterEqual_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'greaterEqual');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'greaterEqual');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var grad = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        return { a: function () { return tensor_ops_1.zerosLike($a); }, b: function () { return tensor_ops_1.zerosLike($b); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.greaterEqual($a, $b);\n        save([$a, $b]);\n        return res;\n    }, { a: $a, b: $b }, grad, 'GreaterEqual');\n}\nfunction greaterEqualStrict_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'greaterEqualStrict');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'greaterEqualStrict');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in greaterEqualStrict: ');\n    return $a.greaterEqual($b);\n}\nexports.equal = operation_1.op({ equal_: equal_ });\nexports.equalStrict = operation_1.op({ equalStrict_: equalStrict_ });\nexports.greater = operation_1.op({ greater_: greater_ });\nexports.greaterEqual = operation_1.op({ greaterEqual_: greaterEqual_ });\nexports.greaterEqualStrict = operation_1.op({ greaterEqualStrict_: greaterEqualStrict_ });\nexports.greaterStrict = operation_1.op({ greaterStrict_: greaterStrict_ });\nexports.less = operation_1.op({ less_: less_ });\nexports.lessEqual = operation_1.op({ lessEqual_: lessEqual_ });\nexports.lessEqualStrict = operation_1.op({ lessEqualStrict_: lessEqualStrict_ });\nexports.lessStrict = operation_1.op({ lessStrict_: lessStrict_ });\nexports.notEqual = operation_1.op({ notEqual_: notEqual_ });\nexports.notEqualStrict = operation_1.op({ notEqualStrict_: notEqualStrict_ });\n//# sourceMappingURL=compare.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/compare.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/complex_ops.js":
/*!********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/complex_ops.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Converts two real numbers to a complex number.\n *\n * Given a tensor `real` representing the real part of a complex number, and a\n * tensor `imag` representing the imaginary part of a complex number, this\n * operation returns complex numbers elementwise of the form [r0, i0, r1, i1],\n * where r represents the real part and i represents the imag part.\n *\n * The input tensors real and imag must have the same shape.\n *\n * ```js\n * const real = tf.tensor1d([2.25, 3.25]);\n * const imag = tf.tensor1d([4.75, 5.75]);\n * const complex = tf.complex(real, imag);\n *\n * complex.print();\n * ```\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction complex_(real, imag) {\n    var $real = tensor_util_env_1.convertToTensor(real, 'real', 'complex');\n    var $imag = tensor_util_env_1.convertToTensor(imag, 'imag', 'complex');\n    util.assertShapesMatch($real.shape, $imag.shape, \"real and imag shapes, \" + $real.shape + \" and \" + $imag.shape + \", \" +\n        \"must match in call to tf.complex().\");\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.complex($real, $imag); }, { $real: $real, $imag: $imag });\n}\n/**\n * Returns the real part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the real part of each element in input considered as a complex number.\n *\n * If the input is real, it simply makes a clone.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.real(x).print();\n * ```\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction real_(input) {\n    var $input = tensor_util_env_1.convertToTensor(input, 'input', 'real');\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.real($input); }, { $input: $input });\n}\n/**\n * Returns the imaginary part of a complex (or real) tensor.\n *\n * Given a tensor input, this operation returns a tensor of type float that is\n * the imaginary part of each element in input considered as a complex number.\n * If input is real, a tensor of all zeros is returned.\n *\n * ```js\n * const x = tf.complex([-2.25, 3.25], [4.75, 5.75]);\n * tf.imag(x).print();\n * ```\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction imag_(input) {\n    var $input = tensor_util_env_1.convertToTensor(input, 'input', 'imag');\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.imag($input); }, { $input: $input });\n}\nexports.complex = operation_1.op({ complex_: complex_ });\nexports.real = operation_1.op({ real_: real_ });\nexports.imag = operation_1.op({ imag_: imag_ });\n//# sourceMappingURL=complex_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/complex_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/concat_split.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/concat_split.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar util_2 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar concat_util_1 = __webpack_require__(/*! ./concat_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Concatenates a list of`tf.Tensor1D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(3) = |r1, g1, b1|\n * B: shape(2) = |r2, g2|\n * C = tf.concat1d([A, B]) == |r1, g1, b1, r2, g2|\n *\n * @param tensors A list of`tf.Tensor`s to concatenate.\n * @return The concatenated array.\n */\nfunction concat1d_(tensors) {\n    return exports.concat(tensors, 0 /* axis */);\n}\n/**\n * Concatenates a list of`tf.Tensor2D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *\n * B: shape(2, 3) = | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * C = tf.concat2d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *                  | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * if axis = 1:\n * C = shape(2, 6) = | r1, g1, b1, r3, g3, b3 |\n *                   | r2, g2, b2, r4, g4, b4 |\n *\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concatenate along.\n * @return The concatenated array.\n */\nfunction concat2d_(tensors, axis) {\n    return exports.concat(tensors, axis);\n}\n/**\n * Concatenates a list of `tf.Tensor3D`s along an axis.\n * See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 1, 3) = | r1, g1, b1 |\n *                     | r2, g2, b2 |\n *\n * B: shape(2, 1, 3) = | r3, g3, b3 |\n *                     | r4, g4, b4 |\n *\n * C = tf.concat3d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 1, 3) = | r1, g1, b1 |\n *                     | r2, g2, b2 |\n *                     | r3, g3, b3 |\n *                     | r4, g4, b4 |\n *\n * if axis = 1:\n * C: shape(2, 2, 3) = | r1, g1, b1, r3, g3, b3 |\n *                     | r2, g2, b2, r4, g4, b4 |\n *\n * if axis = 2:\n * C = shape(2, 1, 6) = | r1, g1, b1, r3, g3, b3 |\n *                      | r2, g2, b2, r4, g4, b4 |\n *\n * @param tensors A list of`tf.Tensor`s to concatenate.\n * @param axis The axis to concate along.\n * @return The concatenated array.\n */\nfunction concat3d_(tensors, axis) {\n    return exports.concat(tensors, axis);\n}\n/**\n * Concatenates a list of `tf.Tensor4D`s along an axis.\n * See `concat` for details.\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concate along.\n * @return The concatenated array.\n */\nfunction concat4d_(tensors, axis) {\n    return exports.concat(tensors, axis);\n}\n/**\n * Concatenates a list of `tf.Tensor`s along a given axis.\n *\n * The tensors ranks and types must match, and their sizes must match in all\n * dimensions except `axis`.\n *\n * Also available are stricter rank-specific methods that assert that\n * `tensors` are of the given rank:\n *   - `tf.concat1d`\n *   - `tf.concat2d`\n *   - `tf.concat3d`\n *   - `tf.concat4d`\n *\n * Except `tf.concat1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * a.concat(b).print();  // or a.concat(b)\n * ```\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.concat([a, b, c]).print();\n * ```\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [10, 20]]);\n * const b = tf.tensor2d([[3, 4], [30, 40]]);\n * const axis = 1;\n * tf.concat([a, b], axis).print();\n * ```\n * @param tensors A list of tensors to concatenate.\n * @param axis The axis to concate along. Defaults to 0 (the first dim).\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction concat_(tensors, axis) {\n    if (axis === void 0) { axis = 0; }\n    util_1.assert(tensors.length >= 1, function () { return 'Pass at least one tensor to concat'; });\n    var $tensors = tensor_util_env_1.convertToTensorArray(tensors, 'tensors', 'concat');\n    if ($tensors[0].dtype === 'complex64') {\n        $tensors.forEach(function (tensor) {\n            if (tensor.dtype !== 'complex64') {\n                throw new Error(\"Cannot concatenate complex64 tensors with a tensor\\n          with dtype \" + tensor.dtype + \". \");\n            }\n        });\n    }\n    axis = util_2.parseAxisParam(axis, $tensors[0].shape)[0];\n    var outShape = concat_util_1.computeOutShape($tensors.map(function (t) { return t.shape; }), axis);\n    if (util_1.sizeFromShape(outShape) === 0) {\n        return tensor_ops_1.tensor([], outShape);\n    }\n    // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n    $tensors = $tensors.filter(function (t) { return t.size > 0; });\n    if ($tensors.length === 1) {\n        return $tensors[0];\n    }\n    var shapes = $tensors.map(function (t) { return t.shape; });\n    concat_util_1.assertParamsConsistent(shapes, axis);\n    var der = function (dy) {\n        var sizeSplits = shapes.map(function (s) { return s[axis]; });\n        var derTensors = exports.split(dy, sizeSplits, axis);\n        return derTensors.map(function (t) { return function () { return t; }; });\n    };\n    var inputs = $tensors;\n    var attr = { axis: axis };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.concat($tensors, axis); }, inputs, der, 'Concat', attr);\n}\n/**\n * Splits a `tf.Tensor` into sub tensors.\n *\n * If `numOrSizeSplits` is a number, splits `x` along dimension `axis`\n * into `numOrSizeSplits` smaller tensors.\n * Requires that `numOrSizeSplits` evenly divides `x.shape[axis]`.\n *\n * If `numOrSizeSplits` is a number array, splits `x` into\n * `numOrSizeSplits.length` pieces. The shape of the `i`-th piece has the\n * same size as `x` except along dimension `axis` where the size is\n * `numOrSizeSplits[i]`.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4, 5, 6, 7, 8], [2, 4]);\n * const [a, b] = tf.split(x, 2, 1);\n * a.print();\n * b.print();\n *\n * const [c, d, e] = tf.split(x, [1, 2, 1], 1);\n * c.print();\n * d.print();\n * e.print();\n * ```\n *\n * @param x The input tensor to split.\n * @param numOrSizeSplits Either an integer indicating the number of\n * splits along the axis or an array of integers containing the sizes of\n * each output tensor along the axis. If a number then it must evenly divide\n * `x.shape[axis]`; otherwise the sum of sizes must match `x.shape[axis]`.\n * @param axis The dimension along which to split. Defaults to 0 (the first\n * dim).\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction split_(x, numOrSizeSplits, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'split');\n    axis = util_2.parseAxisParam(axis, $x.shape)[0];\n    var splitSizes;\n    if (typeof (numOrSizeSplits) === 'number') {\n        util_1.assert($x.shape[axis] % numOrSizeSplits === 0, function () { return 'Number of splits must evenly divide the axis.'; });\n        splitSizes =\n            new Array(numOrSizeSplits).fill($x.shape[axis] / numOrSizeSplits);\n    }\n    else {\n        util_1.assert($x.shape[axis] === numOrSizeSplits.reduce(function (a, b) { return a + b; }), function () { return 'The sum of sizes must match the size of the axis dimension.'; });\n        splitSizes = numOrSizeSplits;\n    }\n    var der = function (dy) { return ({ $x: function () { return exports.concat(dy, axis); } }); };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.split($x, splitSizes, axis); }, { $x: $x }, der);\n}\nexports.concat = operation_1.op({ concat_: concat_ });\nexports.concat1d = operation_1.op({ concat1d_: concat1d_ });\nexports.concat2d = operation_1.op({ concat2d_: concat2d_ });\nexports.concat3d = operation_1.op({ concat3d_: concat3d_ });\nexports.concat4d = operation_1.op({ concat4d_: concat4d_ });\nexports.split = operation_1.op({ split_: split_ });\n//# sourceMappingURL=concat_split.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat_split.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js":
/*!********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nfunction assertParamsConsistent(shapes, axis) {\n    var rank = shapes[0].length;\n    shapes.forEach(function (shape, i) {\n        util.assert(shape.length === rank, function () {\n            return \"Error in concat\" + rank + \"D: rank of tensors[\" + i + \"] must be the same \" +\n                (\"as the rank of the rest (\" + rank + \")\");\n        });\n    });\n    util.assert(axis >= 0 && axis < rank, function () { return \"Error in concat\" + rank + \"D: axis must be between 0 and \" + (rank - 1) + \".\"; });\n    var firstShape = shapes[0];\n    shapes.forEach(function (shape, i) {\n        for (var r = 0; r < rank; r++) {\n            util.assert((r === axis) || (shape[r] === firstShape[r]), function () { return \"Error in concat\" + rank + \"D: Shape of tensors[\" + i + \"] (\" + shape + \") \" +\n                (\"does not match the shape of the rest (\" + firstShape + \") \") +\n                (\"along the non-concatenated axis \" + i + \".\"); });\n        }\n    });\n}\nexports.assertParamsConsistent = assertParamsConsistent;\nfunction computeOutShape(shapes, axis) {\n    var outputShape = shapes[0].slice();\n    for (var i = 1; i < shapes.length; i++) {\n        outputShape[axis] += shapes[i][axis];\n    }\n    return outputShape;\n}\nexports.computeOutShape = computeOutShape;\n//# sourceMappingURL=concat_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/confusion_matrix.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/confusion_matrix.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar array_ops_1 = __webpack_require__(/*! ./array_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Computes the confusion matrix from true labels and predicted labels.\n *\n * ```js\n * const labels = tf.tensor1d([0, 1, 2, 1, 0], 'int32');\n * const predictions = tf.tensor1d([0, 2, 2, 1, 0], 'int32');\n * const numClasses = 3;\n * const out = tf.math.confusionMatrix(labels, predictions, numClasses);\n * out.print();\n * // Expected output matrix:\n * // [[2, 0, 0],\n * //  [0, 1, 1],\n * //  [0, 0, 1]]\n * ```\n *\n * @param labels The target labels, assumed to be 0-based integers\n *   for the classes. The shape is `[numExamples]`, where\n *   `numExamples` is the number of examples included.\n * @param predictions The predicted classes, assumed to be\n *   0-based integers for the classes. Must have the same shape as `labels`.\n * @param numClasses Number of all classes, as an integer.\n *   Its value must be larger than the largest element in `labels` and\n *   `predictions`.\n * @returns The confusion matrix as a int32-type 2D tensor. The value at\n *   row `r` and column `c` is the number of times examples of actual class\n *   `r` were predicted as class `c`.\n */\n/** @doc {heading: 'Operations', subheading: 'Evaluation'} */\nfunction confusionMatrix_(labels, predictions, numClasses) {\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'confusionMatrix');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'confusionMatrix');\n    util.assert(numClasses == null || numClasses > 0 && Number.isInteger(numClasses), function () { return \"If provided, numClasses must be a positive integer, \" +\n        (\"but got \" + numClasses); });\n    util.assert($labels.rank === 1, function () { return \"Expected the rank of labels to be 1, but got \" + $labels.rank; });\n    util.assert($predictions.rank === 1, function () { return \"Expected the rank of predictions to be 1, \" +\n        (\"but got \" + $predictions.rank); });\n    util.assert($labels.shape[0] === $predictions.shape[0], function () { return \"Mismatch in the number of examples: \" +\n        ($labels.shape[0] + \" vs. \" + $predictions.shape[0] + \". \") +\n        \"Labels and predictions should have the same number of elements.\"; });\n    util.assert(numClasses > 0 && Number.isInteger(numClasses), function () { return \"numClasses is required to be a positive integer, but got \" +\n        (\"\" + numClasses); });\n    // TODO(cais): In the future, if oneHot supports tensors inputs for\n    //   `numClasses`, `confusionMatrix` can make `numClasses` optional.\n    var oneHotLabels = array_ops_1.oneHot($labels.asType('int32'), numClasses);\n    var oneHotPredictions = array_ops_1.oneHot($predictions.asType('int32'), numClasses);\n    return oneHotLabels.transpose().matMul(oneHotPredictions).asType('int32');\n}\nexports.confusionMatrix_ = confusionMatrix_;\nexports.confusionMatrix = operation_1.op({ confusionMatrix_: confusionMatrix_ });\n//# sourceMappingURL=confusion_matrix.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/confusion_matrix.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/conv.js":
/*!*************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/conv.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar conv_util = __webpack_require__(/*! ./conv_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Computes a 1D convolution over the input x.\n *\n * @param x The input tensor, of rank 3 or rank 2, of shape\n *     `[batch, width, inChannels]`. If rank 2, batch of 1 is assumed.\n * @param filter The filter, rank 3, of shape\n *     `[filterWidth, inDepth, outDepth]`.\n * @param stride The number of entries by which the filter is moved right at\n *     each step.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat An optional string from \"NWC\", \"NCW\". Defaults to \"NWC\",\n *     the data is stored in the order of [batch, in_width, in_channels]. Only\n *     \"NWC\" is currently supported.\n * @param dilation The dilation rate in which we sample input values in\n *     atrous convolution. Defaults to `1`. If it is greater than 1, then\n *     stride must be `1`.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction conv1d_(x, filter, stride, pad, dataFormat, dilation, dimRoundingMode) {\n    if (dataFormat === void 0) { dataFormat = 'NWC'; }\n    if (dilation === void 0) { dilation = 1; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'conv1d');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'conv1d');\n    var x3D = $x;\n    var reshapedTo3D = false;\n    if ($x.rank === 2) {\n        reshapedTo3D = true;\n        x3D = $x.as3D(1, $x.shape[0], $x.shape[1]);\n    }\n    util.assert(x3D.rank === 3, function () { return \"Error in conv1d: input must be rank 3, but got rank \" + x3D.rank + \".\"; });\n    util.assert($filter.rank === 3, function () { return \"Error in conv1d: filter must be rank 3, but got rank \" +\n        ($filter.rank + \".\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in conv1d: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    util.assert(x3D.shape[2] === $filter.shape[1], function () { return \"Error in conv1d: depth of input (\" + x3D.shape[2] + \") must match \" +\n        (\"input depth for filter \" + $filter.shape[1] + \".\"); });\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(stride, dilation), function () { return 'Error in conv1D: Either stride or dilation must be 1. ' +\n        (\"Got stride \" + stride + \" and dilation '\" + dilation + \"'\"); });\n    util.assert(dataFormat === 'NWC', function () { return \"Error in conv1d: got dataFormat of \" + dataFormat + \" but only NWC is currently supported.\"; });\n    var filter4D = $filter.as4D(1, $filter.shape[0], $filter.shape[1], $filter.shape[2]);\n    var input4D = x3D.as4D(x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]);\n    var strides = [1, stride];\n    var dilations = [1, dilation];\n    var conv2dDataFormat = 'NHWC';\n    var res = exports.conv2d(input4D, filter4D, strides, pad, conv2dDataFormat, dilations, dimRoundingMode);\n    if (reshapedTo3D) {\n        return res.as2D(res.shape[2], res.shape[3]);\n    }\n    return res.as3D(res.shape[0], res.shape[2], res.shape[3]);\n}\n/**\n * Computes a 2D convolution over the input x.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction conv2d_(x, filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n    if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n    if (dilations === void 0) { dilations = [1, 1]; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'conv2d');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'conv2d');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in conv2d: input must be rank 4, but got rank \" + x4D.rank + \".\"; });\n    util.assert($filter.rank === 4, function () { return \"Error in conv2d: filter must be rank 4, but got rank \" +\n        ($filter.rank + \".\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in conv2d: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n    util.assert(inDepth === $filter.shape[2], function () { return \"Error in conv2d: depth of input (\" + inDepth + \") must match \" +\n        (\"input depth for filter \" + $filter.shape[2] + \".\"); });\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in conv2D: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    var $dataFormat = conv_util.convertConv2DDataFormat(dataFormat);\n    var convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode, false, $dataFormat);\n    var grad = function (dy, saved) {\n        var _a = saved, $filter = _a[0], x4D = _a[1];\n        util.assert(conv_util.tupleValuesAreOne(dilations), function () { return 'Error in gradient of conv2D: dilation rates greater than 1 ' +\n            (\"are not yet supported in gradients. Got dilations '\" + dilations + \"'\"); });\n        return {\n            x: function () { return exports.conv2dDerInput(x4D.shape, dy, $filter, strides, pad, dataFormat); },\n            filter: function () {\n                return exports.conv2dDerFilter(x4D, dy, $filter.shape, strides, pad, dataFormat);\n            }\n        };\n    };\n    var inputsToSave = [$filter, x4D];\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.conv2d(x4D, $filter, convInfo);\n        save([$filter, x4D]);\n        return res;\n    }, { x: x4D, filter: $filter }, grad, 'Conv2D', convInfo, inputsToSave);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes the derivative of the input of a 2D convolution.\n *\n * @param xShape The shape of the input: [batch, height, width, inDepth].\n * If length of 3, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 4 or rank 3 of shape\n *   `[batch, outHeight, outWidth, outDepth]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\nfunction conv2dDerInput_(xShape, dy, filter, strides, pad, dataFormat, dimRoundingMode) {\n    if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n    util.assert(xShape.length === dy.rank, function () { return \"Length of inShape \" +\n        (\"(\" + xShape.length + \") and rank of dy (\" + dy.rank + \") must match\"); });\n    var xShape4D = xShape;\n    var dy4D = dy;\n    var reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = dy.as4D(1, dy.shape[0], dy.shape[1], dy.shape[2]);\n        xShape4D = [1, xShape[0], xShape[1], xShape[2]];\n    }\n    util.assert(xShape4D.length === 4, function () {\n        return \"Error in conv2dDerInput: inShape must be length 4, but got length \" +\n            (xShape4D.length + \".\");\n    });\n    util.assert(dy4D.rank === 4, function () { return \"Error in conv2dDerInput: dy must be rank 4, but got \" +\n        (\"rank \" + dy4D.rank); });\n    util.assert(filter.rank === 4, function () { return \"Error in conv2dDerInput: filter must be rank 4, but got \" +\n        (\"rank \" + filter.rank); });\n    var inDepth = dataFormat === 'NHWC' ? xShape4D[3] : xShape4D[1];\n    var outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n    util.assert(inDepth === filter.shape[2], function () { return \"Error in conv2dDerInput: depth of input (\" + inDepth + \") must \" +\n        (\"match input depth for filter \" + filter.shape[2] + \".\"); });\n    util.assert(outDepth === filter.shape[3], function () { return \"Error in conv2dDerInput: depth of output (\" + outDepth + \") must \" +\n        (\"match output depth for filter \" + filter.shape[3] + \".\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in conv2dDerInput: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var dilations = 1;\n    var grad = function (ddx, saved) {\n        var filter = saved[0], dy4D = saved[1];\n        return {\n            dy4D: function () { return exports.conv2d(ddx, filter, strides, pad, dataFormat, dilations, dimRoundingMode); },\n            filter: function () { return exports.conv2dDerFilter(ddx, dy4D, filter.shape, strides, pad, dataFormat, dimRoundingMode); }\n        };\n    };\n    var $dataFormat = conv_util.convertConv2DDataFormat(dataFormat);\n    var convInfo = conv_util.computeConv2DInfo(xShape4D, filter.shape, strides, dilations, pad, dimRoundingMode, false, $dataFormat);\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.conv2dDerInput(dy4D, filter, convInfo);\n        save([filter, dy4D]);\n        return res;\n    }, { dy4D: dy4D, filter: filter }, grad);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes the derivative of the filter of a 2D convolution.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     [batch, height, width, inChannels]. If rank 3, batch of 1 is assumed.\n * @param dy The dy image, of rank 4 or rank 3, of shape\n *     [batch, height, width, outDepth]. If rank 3, batch of 1 is assumed.\n * @param filterShape The shape of the filter, length 4,\n *     [filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. The\n *     rounding mode used when computing output dimensions if pad is a\n *     number. If none is provided, it will not round and error if the output\n *     is of fractional size.\n */\nfunction conv2dDerFilter_(x, dy, filterShape, strides, pad, dataFormat, dimRoundingMode) {\n    if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n    var x4D = x;\n    if (x.rank === 3) {\n        x4D = x.as4D(1, x.shape[0], x.shape[1], x.shape[2]);\n    }\n    var dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = dy.as4D(1, dy.shape[0], dy.shape[1], dy.shape[2]);\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in conv2dDerFilter: input must be rank 4, but got shape \" +\n        (x4D.shape + \".\"); });\n    util.assert(dy4D.rank === 4, function () { return \"Error in conv2dDerFilter: dy must be rank 4, but got shape \" +\n        (dy4D.shape + \".\"); });\n    util.assert(filterShape.length === 4, function () { return \"Error in conv2dDerFilter: filterShape must be length 4, but got \" +\n        (filterShape + \".\"); });\n    var inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n    var outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n    util.assert(inDepth === filterShape[2], function () { return \"Error in conv2dDerFilter: depth of input \" + inDepth + \") must \" +\n        (\"match input depth in filter (\" + filterShape[2] + \".\"); });\n    util.assert(outDepth === filterShape[3], function () { return \"Error in conv2dDerFilter: depth of dy (\" + outDepth + \") must \" +\n        (\"match output depth for filter (\" + filterShape[3] + \").\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in conv2dDerFilter: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var dilations = 1;\n    var $dataFormat = conv_util.convertConv2DDataFormat(dataFormat);\n    var convInfo = conv_util.computeConv2DInfo(x4D.shape, filterShape, strides, dilations, pad, dimRoundingMode, false, $dataFormat);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.conv2dDerFilter(x4D, dy4D, convInfo); }, { x4D: x4D, dy4D: dy4D });\n}\n/**\n * Computes the transposed 2D convolution of an image, also known as a\n * deconvolution.\n *\n * @param x The input image, of rank 4 or rank 3, of shape\n *   `[batch, height, width, inDepth]`. If rank 3, batch of 1 is assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, outDepth, inDepth]`.\n *     `inDepth` must match `inDepth` in `x`.\n * @param outputShape Output shape, of rank 4 or rank 3:\n *     `[batch, height, width, outDepth]`. If rank 3, batch of 1 is assumed.\n * @param strides The strides of the original convolution:\n *     `[strideHeight, strideWidth]`.\n * @param pad  The type of padding algorithm used in the non-transpose version\n *    of the op.\n * @param dimRoundingMode The rounding mode used when computing output\n *    dimensions if pad is a number. If none is provided, it will not round\n *    and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction conv2dTranspose_(x, filter, outputShape, strides, pad, dimRoundingMode) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'conv2dTranspose');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'conv2dTranspose');\n    return conv2dDerInput_(outputShape, $x, $filter, strides, pad, 'NHWC', dimRoundingMode);\n}\n/**\n * Depthwise 2D convolution.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction depthwiseConv2d_(x, filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n    if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n    if (dilations === void 0) { dilations = [1, 1]; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'depthwiseConv2d');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'depthwiseConv2d');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in depthwiseConv2d: input must be rank 4, but got \" +\n        (\"rank \" + x4D.rank + \".\"); });\n    util.assert($filter.rank === 4, function () { return \"Error in depthwiseConv2d: filter must be rank 4, but got rank \" +\n        ($filter.rank + \".\"); });\n    util.assert(x4D.shape[3] === $filter.shape[2], function () { return \"Error in depthwiseConv2d: number of input channels \" +\n        (\"(\" + x4D.shape[3] + \") must match the inChannels dimension in \") +\n        (\"filter \" + $filter.shape[2] + \".\"); });\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () {\n        return 'Error in depthwiseConv2d: Either strides or dilations must be 1. ' +\n            (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\");\n    });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in depthwiseConv2d: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode, true /* depthwise */);\n    var grad = function (dy, saved) {\n        util.assert(conv_util.tupleValuesAreOne(dilations), function () { return 'Error in gradient of depthwiseConv2d: dilation rates ' +\n            \"greater than 1 are not yet supported. Got dilations \" +\n            (\"'\" + dilations + \"'\"); });\n        var x4D = saved[0], $filter = saved[1];\n        return {\n            x: function () { return exports.depthwiseConv2dDerInput(x4D.shape, dy, $filter, convInfo); },\n            filter: function () { return exports.depthwiseConv2dDerFilter(x4D, dy, $filter.shape, convInfo); },\n        };\n    };\n    var inputsToSave = [x4D, $filter];\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.depthwiseConv2D(x4D, $filter, convInfo);\n        save([x4D, $filter]);\n        return res;\n    }, { x: x4D, filter: $filter }, grad, 'DepthwiseConv2dNative', convInfo, inputsToSave);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * 2-D convolution with separable filters.\n *\n * Performs a depthwise convolution that acts separately on channels followed\n * by a pointwise convolution that mixes channels. Note that this is\n * separability between dimensions [1, 2] and 3, not spatial separability\n * between dimensions 1 and 2.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/separable_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param depthwiseFilter The depthwise filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`. This is\n *     the filter used in the first step.\n * @param pointwiseFilter The pointwise filter tensor, rank 4, of shape\n *     `[1, 1, inChannels * channelMultiplier, outChannels]`. This is\n *     the filter used in the second step.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad, dilation, dataFormat) {\n    if (dilation === void 0) { dilation = [1, 1]; }\n    if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'separableConv2d');\n    var $depthwiseFilter = tensor_util_env_1.convertToTensor(depthwiseFilter, 'depthwiseFilter', 'separableConv2d');\n    var $pointwiseFilter = tensor_util_env_1.convertToTensor(pointwiseFilter, 'pointwiseFilter', 'separableConv2d');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    if (dataFormat === 'NCHW') {\n        throw new Error('separableConv2d currently does not support dataFormat NCHW; only ' +\n            'NHWC is supported');\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in separableConv2d: input must be rank 4, but got \" +\n        (\"rank \" + x4D.rank + \".\"); });\n    util.assert($depthwiseFilter.rank === 4, function () { return \"Error in separableConv2d: depthwise filter must be rank 4, but \" +\n        (\"got rank \" + $depthwiseFilter.rank + \".\"); });\n    util.assert($pointwiseFilter.rank === 4, function () { return \"Error in separableConv2d: pointwise filter must be rank 4, but \" +\n        (\"got rank \" + $depthwiseFilter.rank + \".\"); });\n    util.assert($pointwiseFilter.shape[0] === 1, function () {\n        return \"Error in separableConv2d: the first dimension of pointwise filter \" +\n            (\" must be 1, but got \" + $pointwiseFilter.shape[0] + \".\");\n    });\n    util.assert($pointwiseFilter.shape[1] === 1, function () { return \"Error in separableConv2d: the second dimension of pointwise \" +\n        (\"filter must be 1, but got \" + $pointwiseFilter.shape[1] + \".\"); });\n    var inChannels = $depthwiseFilter.shape[2];\n    var channelMultiplier = $depthwiseFilter.shape[3];\n    util.assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, function () {\n        return \"Error in separableConv2d: the third dimension of pointwise filter \" +\n            (\"must be \" + inChannels * channelMultiplier + \", \") +\n            (\"but got \" + $pointwiseFilter.shape[2] + \".\");\n    });\n    var depthwise = exports.depthwiseConv2d(x4D, $depthwiseFilter, strides, pad, dataFormat, dilation);\n    var pointwiseStride = 1;\n    var res = exports.conv2d(depthwise, $pointwiseFilter, pointwiseStride, 'valid', dataFormat);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\nfunction parseTupleParam(param) {\n    if (typeof param === 'number') {\n        return [param, param, param];\n    }\n    if (param.length === 2) {\n        return [param[0], param[1], 1];\n    }\n    return param;\n}\nfunction tupleValuesAreOne(param) {\n    var _a = parseTupleParam(param), dimA = _a[0], dimB = _a[1], dimC = _a[2];\n    return dimA === 1 && dimB === 1 && dimC === 1;\n}\nfunction eitherStridesOrDilationsAreOne(strides, dilations) {\n    return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);\n}\nfunction depthwiseConv2dDerInput_(xShape, dy, filter, convInfo) {\n    var dy4D = dy;\n    var reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = dy.as4D(1, dy.shape[0], dy.shape[1], dy.shape[2]);\n    }\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.depthwiseConv2DDerInput(dy4D, filter, convInfo); }, { dy4D: dy4D });\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\nfunction depthwiseConv2dDerFilter_(x, dy, filterShape, convInfo) {\n    var x4D = x;\n    if (x.rank === 3) {\n        x4D = x.as4D(1, x.shape[0], x.shape[1], x.shape[2]);\n    }\n    var dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = dy.as4D(1, dy.shape[0], dy.shape[1], dy.shape[2]);\n    }\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.depthwiseConv2DDerFilter(x4D, dy4D, convInfo); }, { x4D: x4D, dy4D: dy4D });\n}\n/**\n * Computes a 3D convolution over the input x.\n *\n * @param x The input tensor, of rank 5 or rank 4, of shape\n *     `[batch, depth, height, width, channels]`. If rank 4,\n * batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inChannels, outChannels]`.\n *      inChannels must match between input and filter.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to\n *     \"NDHWC\". Specify the data format of the input and output data. With the\n *     default format \"NDHWC\", the data is stored in the order of: [batch,\n *     depth, height, width, channels]. Only \"NDHWC\" is currently supported.\n * @param dilations The dilation rates: `[dilationDepth, dilationHeight,\n *     dilationWidth]` in which we sample input values across the height\n *     and width dimensions in atrous convolution. Defaults to `[1, 1, 1]`.\n *     If `dilations` is a single number, then\n *     `dilationDepth == dilationHeight == dilationWidth`. If it is greater\n *     than 1, then all values of `strides` must be 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction conv3d_(x, filter, strides, pad, dataFormat, dilations) {\n    if (dataFormat === void 0) { dataFormat = 'NDHWC'; }\n    if (dilations === void 0) { dilations = [1, 1, 1]; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'conv3d');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'conv3d');\n    var x5D = $x;\n    var reshapedTo5D = false;\n    if ($x.rank === 4) {\n        reshapedTo5D = true;\n        x5D = $x.as5D(1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]);\n    }\n    util.assert(x5D.rank === 5, function () { return \"Error in conv3d: input must be rank 5, but got rank \" + x5D.rank + \".\"; });\n    util.assert($filter.rank === 5, function () { return \"Error in conv3d: filter must be rank 5, but got rank \" +\n        ($filter.rank + \".\"); });\n    util.assert(x5D.shape[4] === $filter.shape[3], function () { return \"Error in conv3d: depth of input (\" + x5D.shape[4] + \") must match \" +\n        (\"input depth for filter \" + $filter.shape[3] + \".\"); });\n    util.assert(eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in conv3D: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    util.assert(dataFormat === 'NDHWC', function () { return \"Error in conv3d: got dataFormat of \" + dataFormat + \" but only NDHWC is currently supported.\"; });\n    var convInfo = conv_util.computeConv3DInfo(x5D.shape, $filter.shape, strides, dilations, pad);\n    var grad = function (dy, saved) {\n        util.assert(tupleValuesAreOne(dilations), function () {\n            return 'Error in gradient of conv3D: dilation rates greater than 1 are ' +\n                (\"not yet supported in gradients. Got dilations '\" + dilations + \"'\");\n        });\n        var x5D = saved[0], $filter = saved[1];\n        return {\n            x: function () { return conv3dDerInput_(x5D.shape, dy, $filter, strides, pad); },\n            $filter: function () { return conv3dDerFilter_(x5D, dy, $filter.shape, strides, pad); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.conv3d(x5D, $filter, convInfo);\n        save([x5D, $filter]);\n        return res;\n    }, { x: x5D, $filter: $filter }, grad);\n    if (reshapedTo5D) {\n        return res.as4D(res.shape[1], res.shape[2], res.shape[3], res.shape[4]);\n    }\n    return res;\n}\n/**\n * Computes the derivative of the input of a 3D convolution.\n *\n * @param xShape The shape of the input: [batch, depth, height, width,\n * in_channels]. If length of 4, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 5 or rank 4 of shape\n *   `[batch, outDepth, outHeight, outWidth, in_channels]`.\n * If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n */\nfunction conv3dDerInput_(xShape, dy, filter, strides, pad) {\n    util.assert(xShape.length === dy.rank, function () { return \"Length of inShape \" +\n        (\"(\" + xShape.length + \") and rank of dy (\" + dy.rank + \") must match\"); });\n    var xShape5D = xShape;\n    var dy5D = dy;\n    var reshapedTo5D = false;\n    if (dy.rank === 4) {\n        reshapedTo5D = true;\n        dy5D = dy.as5D(1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]);\n        xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];\n    }\n    var inDepth = xShape5D[4];\n    var outDepth = dy5D.shape[4];\n    util.assert(xShape5D.length === 5, function () {\n        return \"Error in conv3dDerInput: inShape must be length 5, but got length \" +\n            (xShape5D.length + \".\");\n    });\n    util.assert(dy5D.rank === 5, function () { return \"Error in conv3dDerInput: dy must be rank 5, but got \" +\n        (\"rank \" + dy5D.rank); });\n    util.assert(filter.rank === 5, function () { return \"Error in conv3dDerInput: filter must be rank 5, but got \" +\n        (\"rank \" + filter.rank); });\n    util.assert(inDepth === filter.shape[3], function () { return \"Error in conv3dDerInput: depth of input (\" + inDepth + \") must \" +\n        (\"match input depth for filter \" + filter.shape[3] + \".\"); });\n    util.assert(outDepth === filter.shape[4], function () { return \"Error in conv3dDerInput: depth of output (\" + outDepth + \") must \" +\n        (\"match output depth for filter \" + filter.shape[4] + \".\"); });\n    var dilations = 1;\n    var convInfo = conv_util.computeConv3DInfo(xShape5D, filter.shape, strides, dilations, pad);\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.conv3dDerInput(dy5D, filter, convInfo); }, { dy5D: dy5D });\n    if (reshapedTo5D) {\n        return res.as4D(res.shape[1], res.shape[2], res.shape[3], res.shape[4]);\n    }\n    return res;\n}\n/**\n * Computes the derivative of the filter of a 3D convolution.\n *\n * @param x The input tensor, of rank 5 or rank 4 of shape\n *     [batch, depth, height, width, inChannels]. If rank 4, batch of 1 is\n *     assumed.\n * @param dy The dy image, of rank 5 or rank 4, of shape\n *     [batch, depth, height, width, outDepth]. If rank 4, batch of 1 is\n *     assumed.\n * @param filterShape The shape of the filter, length 5,\n *     [filterDepth, filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideDepth, strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n */\nfunction conv3dDerFilter_(x, dy, filterShape, strides, pad) {\n    var x5D = x;\n    if (x.rank === 4) {\n        x5D = x.as5D(1, x.shape[0], x.shape[1], x.shape[2], x.shape[3]);\n    }\n    var dy5D = dy;\n    if (dy5D.rank === 4) {\n        dy5D = dy.as5D(1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]);\n    }\n    util.assert(x5D.rank === 5, function () { return \"Error in conv3dDerFilter: input must be rank 5, but got shape \" +\n        (x5D.shape + \".\"); });\n    util.assert(dy5D.rank === 5, function () { return \"Error in conv3dDerFilter: dy must be rank 5, but got shape \" +\n        (dy5D.shape + \".\"); });\n    util.assert(filterShape.length === 5, function () { return \"Error in conv3dDerFilter: filterShape must be length 5, but got \" +\n        (filterShape + \".\"); });\n    util.assert(x5D.shape[4] === filterShape[3], function () { return \"Error in conv3dDerFilter: depth of input \" + x5D.shape[4] + \") must \" +\n        (\"match input depth in filter (\" + filterShape[3] + \".\"); });\n    util.assert(dy5D.shape[4] === filterShape[4], function () { return \"Error in conv3dDerFilter: depth of dy (\" + dy5D.shape[4] + \") must \" +\n        (\"match output depth for filter (\" + filterShape[4] + \").\"); });\n    var dilations = 1;\n    var convInfo = conv_util.computeConv3DInfo(x5D.shape, filterShape, strides, dilations, pad);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.conv3dDerFilter(x5D, dy5D, convInfo); }, { x5D: x5D, dy5D: dy5D });\n}\n/**\n * Computes the transposed 3D convolution of a volume, also known as a\n * deconvolution.\n *\n * @param x The input image, of rank 5 or rank 4, of shape\n *   `[batch, depth, height, width, inDepth]`. If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 4, of shape\n *     `[depth, filterHeight, filterWidth, outDepth, inDepth]`.\n *     `inDepth` must match `inDepth` in `x`.\n * @param outputShape Output shape, of rank 5 or rank 4:\n *     `[batch, depth, height, width, outDepth]`. If rank 3, batch of 1 is\n *    assumed.\n * @param strides The strides of the original convolution:\n *     `[strideDepth, strideHeight, strideWidth]`.\n * @param pad  The type of padding algorithm used in the non-transpose version\n *    of the op.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction conv3dTranspose_(x, filter, outputShape, strides, pad) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'conv3dTranspose');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'conv3dTranspose');\n    return conv3dDerInput_(outputShape, $x, $filter, strides, pad);\n}\nexports.conv1d = operation_1.op({ conv1d_: conv1d_ });\nexports.conv2d = operation_1.op({ conv2d_: conv2d_ });\nexports.conv3d = operation_1.op({ conv3d_: conv3d_ });\nexports.conv2dDerFilter = operation_1.op({ conv2dDerFilter_: conv2dDerFilter_ });\nexports.conv2dDerInput = operation_1.op({ conv2dDerInput_: conv2dDerInput_ });\nexports.depthwiseConv2d = operation_1.op({ depthwiseConv2d_: depthwiseConv2d_ });\nexports.depthwiseConv2dDerInput = operation_1.op({ depthwiseConv2dDerInput_: depthwiseConv2dDerInput_ });\nexports.depthwiseConv2dDerFilter = operation_1.op({ depthwiseConv2dDerFilter_: depthwiseConv2dDerFilter_ });\nexports.separableConv2d = operation_1.op({ separableConv2d_: separableConv2d_ });\nexports.conv2dTranspose = operation_1.op({ conv2dTranspose_: conv2dTranspose_ });\nexports.conv3dTranspose = operation_1.op({ conv3dTranspose_: conv3dTranspose_ });\n//# sourceMappingURL=conv.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nfunction computePool2DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat) {\n    if (dataFormat === void 0) { dataFormat = 'channelsLast'; }\n    var _a = parseTupleParam(filterSize), filterHeight = _a[0], filterWidth = _a[1];\n    var filterShape;\n    if (dataFormat === 'channelsLast') {\n        filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];\n    }\n    else if (dataFormat === 'channelsFirst') {\n        filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(\"Unknown dataFormat \" + dataFormat);\n    }\n    return computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, false, dataFormat);\n}\nexports.computePool2DInfo = computePool2DInfo;\n/**\n * Computes the information for a forward pass of a pooling3D operation.\n */\nfunction computePool3DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat) {\n    if (dataFormat === void 0) { dataFormat = 'NDHWC'; }\n    var _a = parse3TupleParam(filterSize), filterDepth = _a[0], filterHeight = _a[1], filterWidth = _a[2];\n    var filterShape;\n    var $dataFormat;\n    if (dataFormat === 'NDHWC') {\n        $dataFormat = 'channelsLast';\n        filterShape =\n            [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];\n    }\n    else if (dataFormat === 'NCDHW') {\n        $dataFormat = 'channelsFirst';\n        filterShape =\n            [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(\"Unknown dataFormat \" + dataFormat);\n    }\n    return computeConv3DInfo(inShape, filterShape, strides, dilations, pad, false, $dataFormat, roundingMode);\n}\nexports.computePool3DInfo = computePool3DInfo;\n/**\n * Computes the information for a forward pass of a convolution/pooling\n * operation.\n */\nfunction computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, depthwise, dataFormat) {\n    if (depthwise === void 0) { depthwise = false; }\n    if (dataFormat === void 0) { dataFormat = 'channelsLast'; }\n    var _a = [-1, -1, -1, -1], batchSize = _a[0], inHeight = _a[1], inWidth = _a[2], inChannels = _a[3];\n    if (dataFormat === 'channelsLast') {\n        batchSize = inShape[0], inHeight = inShape[1], inWidth = inShape[2], inChannels = inShape[3];\n    }\n    else if (dataFormat === 'channelsFirst') {\n        batchSize = inShape[0], inChannels = inShape[1], inHeight = inShape[2], inWidth = inShape[3];\n    }\n    else {\n        throw new Error(\"Unknown dataFormat \" + dataFormat);\n    }\n    var filterHeight = filterShape[0], filterWidth = filterShape[1], filterChannels = filterShape[3];\n    var _b = parseTupleParam(strides), strideHeight = _b[0], strideWidth = _b[1];\n    var _c = parseTupleParam(dilations), dilationHeight = _c[0], dilationWidth = _c[1];\n    var effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    var effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    var _d = getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode), padInfo = _d.padInfo, outHeight = _d.outHeight, outWidth = _d.outWidth;\n    var outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    var outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize: batchSize,\n        dataFormat: dataFormat,\n        inHeight: inHeight,\n        inWidth: inWidth,\n        inChannels: inChannels,\n        outHeight: outHeight,\n        outWidth: outWidth,\n        outChannels: outChannels,\n        padInfo: padInfo,\n        strideHeight: strideHeight,\n        strideWidth: strideWidth,\n        filterHeight: filterHeight,\n        filterWidth: filterWidth,\n        effectiveFilterHeight: effectiveFilterHeight,\n        effectiveFilterWidth: effectiveFilterWidth,\n        dilationHeight: dilationHeight,\n        dilationWidth: dilationWidth,\n        inShape: inShape,\n        outShape: outShape,\n        filterShape: filterShape\n    };\n}\nexports.computeConv2DInfo = computeConv2DInfo;\n/**\n * Computes the information for a forward pass of a 3D convolution/pooling\n * operation.\n */\nfunction computeConv3DInfo(inShape, filterShape, strides, dilations, pad, depthwise, dataFormat, roundingMode) {\n    if (depthwise === void 0) { depthwise = false; }\n    if (dataFormat === void 0) { dataFormat = 'channelsLast'; }\n    var _a = [-1, -1, -1, -1, -1], batchSize = _a[0], inDepth = _a[1], inHeight = _a[2], inWidth = _a[3], inChannels = _a[4];\n    if (dataFormat === 'channelsLast') {\n        batchSize = inShape[0], inDepth = inShape[1], inHeight = inShape[2], inWidth = inShape[3], inChannels = inShape[4];\n    }\n    else if (dataFormat === 'channelsFirst') {\n        batchSize = inShape[0], inChannels = inShape[1], inDepth = inShape[2], inHeight = inShape[3], inWidth = inShape[4];\n    }\n    else {\n        throw new Error(\"Unknown dataFormat \" + dataFormat);\n    }\n    var filterDepth = filterShape[0], filterHeight = filterShape[1], filterWidth = filterShape[2], filterChannels = filterShape[4];\n    var _b = parse3TupleParam(strides), strideDepth = _b[0], strideHeight = _b[1], strideWidth = _b[2];\n    var _c = parse3TupleParam(dilations), dilationDepth = _c[0], dilationHeight = _c[1], dilationWidth = _c[2];\n    var effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);\n    var effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    var effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    var _d = get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode), padInfo = _d.padInfo, outDepth = _d.outDepth, outHeight = _d.outHeight, outWidth = _d.outWidth;\n    var outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    var outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize: batchSize,\n        dataFormat: dataFormat,\n        inDepth: inDepth,\n        inHeight: inHeight,\n        inWidth: inWidth,\n        inChannels: inChannels,\n        outDepth: outDepth,\n        outHeight: outHeight,\n        outWidth: outWidth,\n        outChannels: outChannels,\n        padInfo: padInfo,\n        strideDepth: strideDepth,\n        strideHeight: strideHeight,\n        strideWidth: strideWidth,\n        filterDepth: filterDepth,\n        filterHeight: filterHeight,\n        filterWidth: filterWidth,\n        effectiveFilterDepth: effectiveFilterDepth,\n        effectiveFilterHeight: effectiveFilterHeight,\n        effectiveFilterWidth: effectiveFilterWidth,\n        dilationDepth: dilationDepth,\n        dilationHeight: dilationHeight,\n        dilationWidth: dilationWidth,\n        inShape: inShape,\n        outShape: outShape,\n        filterShape: filterShape\n    };\n}\nexports.computeConv3DInfo = computeConv3DInfo;\nfunction computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    var inputRows = inShape[0];\n    var inputCols = inShape[1];\n    var outputRows = conditionalRound((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputRows), function () { return \"The output # of rows (\" + outputRows + \") must be an integer. \" +\n        \"Change the stride and/or zero pad parameters\"; });\n    var outputCols = conditionalRound((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputCols), function () { return \"The output # of columns (\" + outputCols + \") must be an integer. \" +\n        \"Change the stride and/or zero pad parameters\"; });\n    return [outputRows, outputCols];\n}\nfunction computeOutputShape4D(inShape, fieldSize, outChannels, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    var inputDepth = inShape[0];\n    var inputRows = inShape[1];\n    var inputCols = inShape[2];\n    var outputDepths = conditionalRound((inputDepth - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputDepths), function () { return \"The output # of depths (\" + outputDepths + \") must be an integer. \" +\n        \"Change the stride and/or zero pad parameters\"; });\n    var outputRows = conditionalRound((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputRows), function () { return \"The output # of rows (\" + outputRows + \") must be an integer. \" +\n        \"Change the stride and/or zero pad parameters\"; });\n    var outputCols = conditionalRound((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    util.assert(util.isInt(outputCols), function () { return \"The output # of columns (\" + outputCols + \") must be an integer. \" +\n        \"Change the stride and/or zero pad parameters\"; });\n    return [outputDepths, outputRows, outputCols, outChannels];\n}\nfunction computeDefaultPad(inputShape, fieldSize, stride, dilation) {\n    if (dilation === void 0) { dilation = 1; }\n    var effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);\n    return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);\n}\nexports.computeDefaultPad = computeDefaultPad;\nfunction parseTupleParam(param) {\n    if (typeof param === 'number') {\n        return [param, param, param];\n    }\n    if (param.length === 2) {\n        return [param[0], param[1], 1];\n    }\n    return param;\n}\nfunction parse3TupleParam(param) {\n    return typeof param === 'number' ? [param, param, param] : param;\n}\n/* See https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d\n * Atrous convolution is equivalent to standard convolution with upsampled\n * filters with effective_filter_height =\n * filter_height + (filter_height - 1) * (dilation - 1)\n * and effective_filter_width =\n * filter_width + (filter_width - 1) * (dilation - 1),\n * produced by inserting dilation - 1 zeros along consecutive elements across\n * the filters' spatial dimensions.\n * When there is a dilation, this converts a filter dimension to the\n * effective filter dimension, so it can be used in a standard convolution.\n */\nfunction getEffectiveFilterSize(filterSize, dilation) {\n    if (dilation <= 1) {\n        return filterSize;\n    }\n    return filterSize + (filterSize - 1) * (dilation - 1);\n}\nfunction getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode) {\n    var padInfo;\n    var outHeight;\n    var outWidth;\n    if (typeof pad === 'number') {\n        var padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = { top: pad, bottom: pad, left: pad, right: pad, type: padType };\n        var outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad, roundingMode);\n        outHeight = outShape[0];\n        outWidth = outShape[1];\n    }\n    else if (pad === 'same') {\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        var padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);\n        var padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);\n        var top_1 = Math.floor(padAlongHeight / 2);\n        var bottom = padAlongHeight - top_1;\n        var left = Math.floor(padAlongWidth / 2);\n        var right = padAlongWidth - left;\n        padInfo = { top: top_1, bottom: bottom, left: left, right: right, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: 'VALID' };\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else {\n        throw Error(\"Unknown padding parameter: \" + pad);\n    }\n    return { padInfo: padInfo, outHeight: outHeight, outWidth: outWidth };\n}\nfunction get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {\n    var padInfo;\n    var outDepth;\n    var outHeight;\n    var outWidth;\n    if (typeof pad === 'number') {\n        var padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = {\n            top: pad,\n            bottom: pad,\n            left: pad,\n            right: pad,\n            front: pad,\n            back: pad,\n            type: padType\n        };\n        var outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], filterDepth, 1, strideDepth, pad, roundingMode);\n        outDepth = outShape[0];\n        outHeight = outShape[1];\n        outWidth = outShape[2];\n    }\n    else if (pad === 'same') {\n        outDepth = Math.ceil(inDepth / strideDepth);\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        var padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;\n        var padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;\n        var padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;\n        var front = Math.floor(padAlongDepth / 2);\n        var back = padAlongDepth - front;\n        var top_2 = Math.floor(padAlongHeight / 2);\n        var bottom = padAlongHeight - top_2;\n        var left = Math.floor(padAlongWidth / 2);\n        var right = padAlongWidth - left;\n        padInfo = { top: top_2, bottom: bottom, left: left, right: right, front: front, back: back, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = {\n            top: 0,\n            bottom: 0,\n            left: 0,\n            right: 0,\n            front: 0,\n            back: 0,\n            type: 'VALID'\n        };\n        outDepth = Math.ceil((inDepth - filterDepth + 1) / strideDepth);\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else {\n        throw Error(\"Unknown padding parameter: \" + pad);\n    }\n    return { padInfo: padInfo, outDepth: outDepth, outHeight: outHeight, outWidth: outWidth };\n}\n/**\n * Rounds a value depending on the rounding mode\n * @param value\n * @param roundingMode\n */\nfunction conditionalRound(value, roundingMode) {\n    if (!roundingMode) {\n        return value;\n    }\n    switch (roundingMode) {\n        case 'round':\n            // used for Caffe Conv\n            return Math.round(value);\n        case 'ceil':\n            // used for Caffe Pool\n            return Math.ceil(value);\n        case 'floor':\n            return Math.floor(value);\n        default:\n            throw new Error(\"Unknown roundingMode \" + roundingMode);\n    }\n}\nfunction tupleValuesAreOne(param) {\n    var _a = parseTupleParam(param), dimA = _a[0], dimB = _a[1], dimC = _a[2];\n    return dimA === 1 && dimB === 1 && dimC === 1;\n}\nexports.tupleValuesAreOne = tupleValuesAreOne;\nfunction eitherStridesOrDilationsAreOne(strides, dilations) {\n    return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);\n}\nexports.eitherStridesOrDilationsAreOne = eitherStridesOrDilationsAreOne;\n/**\n * Convert Conv2D dataFormat from 'NHWC'|'NCHW' to\n *    'channelsLast'|'channelsFirst'\n * @param dataFormat in 'NHWC'|'NCHW' mode\n * @return dataFormat in 'channelsLast'|'channelsFirst' mode\n * @throws unknown dataFormat\n */\nfunction convertConv2DDataFormat(dataFormat) {\n    if (dataFormat === 'NHWC') {\n        return 'channelsLast';\n    }\n    else if (dataFormat === 'NCHW') {\n        return 'channelsFirst';\n    }\n    else {\n        throw new Error(\"Unknown dataFormat \" + dataFormat);\n    }\n}\nexports.convertConv2DDataFormat = convertConv2DDataFormat;\n//# sourceMappingURL=conv_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/diag.js":
/*!*************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/diag.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Returns a diagonal tensor with a given diagonal values.\n *\n * Given a diagonal, this operation returns a tensor with the diagonal and\n * everything else padded with zeros.\n *\n * Assume the input has dimensions `[D1,..., Dk]`, then the output is a tensor\n * of rank 2k with dimensions `[D1,..., Dk, D1,..., Dk]`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * tf.diag(x).print()\n * ```\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4, 5, 6, 6, 8], [4, 2])\n *\n * tf.diag(x).print()\n * ```\n * @param x The input tensor.\n */\nfunction diag_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'diag').flatten();\n    var outShape = x.shape.concat(x.shape);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.diag($x); }, { $x: $x })\n        .reshape(outShape);\n}\nexports.diag = operation_1.op({ diag_: diag_ });\n//# sourceMappingURL=diag.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/diag.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_1 = __webpack_require__(/*! ../tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar array_ops_1 = __webpack_require__(/*! ./array_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js\");\nvar dropout_util_1 = __webpack_require__(/*! ./dropout_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Computes dropout.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 2, 1]);\n * const rate = 0.75;\n * const output = tf.dropout(x, rate);\n * output.print();\n * ```\n *\n * @param x A floating point Tensor or TensorLike.\n * @param rate A float in the range [0, 1). The probability that each element\n *   of x is discarded.\n * @param noiseShape An array of numbers of type int32, representing the\n * shape for randomly generated keep/drop flags. If the noiseShape has null\n * value, it will be automatically replaced with the x's relative dimension\n * size. Optional.\n * @param seed Used to create random seeds. Optional.\n * @returns A Tensor of the same shape of x.\n */\n/** @doc {heading: 'Operations', subheading: 'Dropout'} */\nfunction dropout_(x, rate, noiseShape, seed) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'dropout');\n    util.assert($x.dtype === 'float32', function () { return \"x has to be a floating point tensor since it's going to be \" +\n        (\"scaled, but got a \" + $x.dtype + \" tensor instead.\"); });\n    util.assert(rate >= 0 && rate < 1, function () { return \"rate must be a float in the range [0, 1), but got \" + rate + \".\"; });\n    if (rate === 0) {\n        return x instanceof tensor_1.Tensor ? $x.clone() : $x;\n    }\n    var $noiseShape = dropout_util_1.getNoiseShape($x, noiseShape);\n    var keepProb = 1 - rate;\n    var multiplier = array_ops_1.randomUniform($noiseShape, 0, 1, 'float32', seed)\n        .add(keepProb)\n        .floor()\n        .div(keepProb);\n    return $x.mul(multiplier);\n}\nexports.dropout = operation_1.op({ dropout_: dropout_ });\n//# sourceMappingURL=dropout.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n/**\n * Normalize noise shape based on provided tensor and noise shape.\n *\n * @param x Tensor.\n * @param noiseShape The shape for the randomly generated keep/drop flags, as\n *   an array of numbers. Optional.\n * @returns Normalized noise shape.\n */\nfunction getNoiseShape(x, noiseShape) {\n    if (noiseShape == null) {\n        return x.shape.slice();\n    }\n    if (util.arraysEqual(x.shape, noiseShape)) {\n        return noiseShape;\n    }\n    if (x.shape.length === noiseShape.length) {\n        var newDimension = [];\n        for (var i = 0; i < x.shape.length; i++) {\n            if (noiseShape[i] == null && x.shape[i] != null) {\n                newDimension.push(x.shape[i]);\n            }\n            else {\n                newDimension.push(noiseShape[i]);\n            }\n        }\n        return newDimension;\n    }\n    return noiseShape;\n}\nexports.getNoiseShape = getNoiseShape;\n//# sourceMappingURL=dropout_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ERF_P = 0.3275911;\nexports.ERF_A1 = 0.254829592;\nexports.ERF_A2 = -0.284496736;\nexports.ERF_A3 = 1.421413741;\nexports.ERF_A4 = -1.453152027;\nexports.ERF_A5 = 1.061405429;\n//# sourceMappingURL=erf_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar conv_1 = __webpack_require__(/*! ../ops/conv */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/conv.js\");\nvar conv_util = __webpack_require__(/*! ../ops/conv_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js\");\nvar operation_1 = __webpack_require__(/*! ../ops/operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_util_1 = __webpack_require__(/*! ../tensor_util */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar binary_ops_1 = __webpack_require__(/*! ./binary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js\");\nvar broadcast_util = __webpack_require__(/*! ./broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar conv_2 = __webpack_require__(/*! ./conv */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/conv.js\");\nvar fused_util_1 = __webpack_require__(/*! ./fused_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js\");\nvar matmul_1 = __webpack_require__(/*! ./matmul */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/matmul.js\");\nvar relu_ops_1 = __webpack_require__(/*! ./relu_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/relu_ops.js\");\n// Returns gradient for fused activation.\nvar getFusedDyActivation = function (dy, y, activation) {\n    if (activation == null || activation === 'linear') {\n        return dy;\n    }\n    if (activation === 'relu') {\n        return dy.mul(y.step());\n    }\n    throw new Error(\"Gradient for activation \" + activation + \" has not been \" +\n        \"implemented yet.\");\n};\n// Returns gradient for fused bias.\nvar getFusedBiasGradient = function (bias, dyActivation) {\n    var res = dyActivation;\n    var reduceAxes = broadcast_util.getReductionAxes(bias.shape, dyActivation.shape);\n    if (reduceAxes.length > 0) {\n        res = res.sum(reduceAxes);\n    }\n    return res.reshape(bias.shape);\n};\nvar applyActivation = function (x, activation, preluActivationWeights) {\n    if (activation === 'linear') {\n        return x;\n    }\n    else if (activation === 'relu') {\n        return relu_ops_1.relu(x);\n    }\n    else if (activation === 'elu') {\n        return relu_ops_1.elu(x);\n    }\n    else if (activation === 'relu6') {\n        return relu_ops_1.relu6(x);\n    }\n    else if (activation === 'prelu') {\n        return relu_ops_1.prelu(x, preluActivationWeights);\n    }\n    throw new Error(\"Unknown fused activation \" + activation + \".\");\n};\n/**\n * Computes the dot product of two matrices with optional activation and bias.\n *\n * ```js\n * const a = tf.tensor2d([-1, -2], [1, 2]);\n * const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const bias = tf.tensor2d([1, 2], [1, 2]);\n *\n * tf.fused.matMul({a, b, bias, activation: 'relu'}).print();\n * ```\n *\n * @param obj An object with the following properties:\n * - `a` First matrix in dot product operation.\n * - `b` Second matrix in dot product operation.\n * - `transposeA` If true, `a` is transposed before multiplication.\n * - `transposeB` If true, `b` is transposed before multiplication.\n * - `bias` Matrix to be added to the result.\n * - `activation` Name of activation kernel (defaults to `linear`).\n * - `preluActivationWeights` Tensor of prelu weights.\n */\nfunction fusedMatMul_(_a) {\n    var _b;\n    var a = _a.a, b = _a.b, _c = _a.transposeA, transposeA = _c === void 0 ? false : _c, _d = _a.transposeB, transposeB = _d === void 0 ? false : _d, bias = _a.bias, _e = _a.activation, activation = _e === void 0 ? 'linear' : _e, preluActivationWeights = _a.preluActivationWeights;\n    if (fused_util_1.shouldFuse(engine_1.ENGINE.state.gradientDepth, activation) === false) {\n        var result = matmul_1.matMul(a, b, transposeA, transposeB);\n        if (bias != null) {\n            result = binary_ops_1.add(result, bias);\n        }\n        return applyActivation(result, activation, preluActivationWeights);\n    }\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'fused matMul');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'fused matMul');\n    _b = tensor_util_1.makeTypesMatch($a, $b), $a = _b[0], $b = _b[1];\n    var innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];\n    var innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];\n    var outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];\n    var outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];\n    var outerDimsA = $a.shape.slice(0, -2);\n    var outerDimsB = $b.shape.slice(0, -2);\n    var batchDimA = util.sizeFromShape(outerDimsA);\n    var batchDimB = util.sizeFromShape(outerDimsB);\n    util.assert($a.rank >= 2 && $b.rank >= 2 && $a.rank === $b.rank, function () {\n        return \"Error in fused matMul: inputs must have the same rank of at least \" +\n            (\"2, got ranks \" + $a.rank + \" and \" + $b.rank + \".\");\n    });\n    util.assert(util.arraysEqual(outerDimsA, outerDimsB), function () { return \"Error in fused matMul: outer dimensions (\" + outerDimsA + \") and (\" +\n        (outerDimsB + \") of Tensors with shapes \" + $a.shape + \" and \") +\n        ($b.shape + \" must match.\"); });\n    util.assert(innerShapeA === innerShapeB, function () { return \"Error in fused matMul: inner shapes (\" + innerShapeA + \") and (\" +\n        (innerShapeB + \") of Tensors with shapes \" + $a.shape + \" and \") +\n        ($b.shape + \" and transposeA=\" + transposeA) +\n        (\" and transposeB=\" + transposeB + \" must match.\"); });\n    var outShape = $a.shape.slice(0, -2).concat([outerShapeA, outerShapeB]);\n    var a3D = transposeA ? $a.as3D(batchDimA, innerShapeA, outerShapeA) :\n        $a.as3D(batchDimA, outerShapeA, innerShapeA);\n    var b3D = transposeB ? $b.as3D(batchDimB, outerShapeB, innerShapeB) :\n        $b.as3D(batchDimB, innerShapeB, outerShapeB);\n    var $bias;\n    if (bias != null) {\n        $bias = tensor_util_env_1.convertToTensor(bias, 'bias', 'fused matMul');\n        $bias = tensor_util_1.makeTypesMatch($bias, $a)[0];\n        broadcast_util.assertAndGetBroadcastShape(outShape, $bias.shape);\n    }\n    var $preluActivationWeights;\n    if (preluActivationWeights != null) {\n        $preluActivationWeights = tensor_util_env_1.convertToTensor(preluActivationWeights, 'prelu weights', 'fused matMul');\n    }\n    var grad = function (dy, saved) {\n        var a3D = saved[0], b3D = saved[1], y = saved[2];\n        var dyActivation = getFusedDyActivation(dy, y, activation);\n        var biasGradient = {};\n        if (bias != null) {\n            biasGradient = { bias: function () { return getFusedBiasGradient($bias, dyActivation); } };\n        }\n        if (!transposeA && !transposeB) {\n            return Object.assign({\n                a: function () { return dyActivation.matMul(b3D, false, true); },\n                b: function () { return a3D.matMul(dyActivation, true, false); }\n            }, biasGradient);\n        }\n        else if (!transposeA && transposeB) {\n            return Object.assign({\n                a: function () { return dyActivation.matMul(b3D, false, false); },\n                b: function () { return dyActivation.matMul(a3D, true, false); }\n            }, biasGradient);\n        }\n        else if (transposeA && !transposeB) {\n            return Object.assign({\n                a: function () { return b3D.matMul(dyActivation, false, true); },\n                b: function () { return a3D.matMul(dyActivation, false, false); }\n            }, biasGradient);\n        }\n        else {\n            return Object.assign({\n                a: function () { return b3D.matMul(dyActivation, true, true); },\n                b: function () { return dyActivation.matMul(a3D, true, true); }\n            }, biasGradient);\n        }\n    };\n    var inputs = { a: a3D, b: b3D };\n    if (bias != null) {\n        inputs.bias = $bias;\n    }\n    if (preluActivationWeights != null) {\n        inputs.preluActivationWeights = $preluActivationWeights;\n    }\n    var inputsToSave = [a3D, b3D];\n    var outputsToSave = [true];\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.fusedBatchMatMul({\n            a: a3D,\n            b: b3D,\n            transposeA: transposeA,\n            transposeB: transposeB,\n            bias: $bias,\n            activation: activation,\n            preluActivationWeights: $preluActivationWeights\n        });\n        save([a3D, b3D, y]);\n        return y;\n    }, inputs, grad, '_FusedMatMul', { transposeA: transposeA, transposeB: transposeB, activation: activation }, inputsToSave, outputsToSave);\n    return res.reshape(outShape);\n}\n/**\n * Computes a 2D convolution over the input x, optionally fused with adding a\n * bias and applying an activation.\n *\n * ```js\n * const inputDepth = 2;\n * const inShape = [2, 2, 2, inputDepth];\n * const outputDepth = 2;\n * const fSize = 1;\n * const pad = 0;\n * const strides = 1;\n *\n * const x = tf.tensor4d( [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n * 16], inShape);\n * const w = tf.tensor4d([-1, 1, -2, 0.5], [fSize, fSize, inputDepth,\n * outputDepth]);\n *\n * tf.fused.conv2d({ x, filter: w, strides, pad, dataFormat: 'NHWC',\n * dilations: [1, 1], bias: tf.scalar(5), activation: 'relu' }).print();\n * ```\n *\n * @param obj An object with the following properties:\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid` output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n * @param bias Tensor to be added to the result.\n * @param activation Name of activation kernel (defaults to `linear`) to be\n *     applied\n *      after biasAdd.\n * @param preluActivationWeights Tensor of prelu weights to be applied as part\n *     of a `prelu` activation, typically the same shape as `x`.\n */\nfunction fusedConv2d_(_a) {\n    var x = _a.x, filter = _a.filter, strides = _a.strides, pad = _a.pad, _b = _a.dataFormat, dataFormat = _b === void 0 ? 'NHWC' : _b, _c = _a.dilations, dilations = _c === void 0 ? [1, 1] : _c, dimRoundingMode = _a.dimRoundingMode, bias = _a.bias, _d = _a.activation, activation = _d === void 0 ? 'linear' : _d, preluActivationWeights = _a.preluActivationWeights;\n    activation = activation || 'linear';\n    if (fused_util_1.shouldFuse(engine_1.ENGINE.state.gradientDepth, activation) === false) {\n        var result = conv_2.conv2d(x, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n        if (bias != null) {\n            result = binary_ops_1.add(result, bias);\n        }\n        return applyActivation(result, activation, preluActivationWeights);\n    }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'conv2d');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'conv2d');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in fused conv2d: input must be rank 4, but got rank \" +\n        (x4D.rank + \".\"); });\n    util.assert($filter.rank === 4, function () { return \"Error in fused conv2d: filter must be rank 4, but got rank \" +\n        ($filter.rank + \".\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in fused conv2d: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    util.assert(x4D.shape[3] === $filter.shape[2], function () { return \"Error in conv2d: depth of input (\" + x4D.shape[3] + \") must match \" +\n        (\"input depth for filter \" + $filter.shape[2] + \".\"); });\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in conv2D: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    util.assert(dataFormat === 'NHWC', function () { return \"Error in conv2d: got dataFormat of \" + dataFormat + \" but only NHWC is currently supported.\"; });\n    var convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode);\n    var $bias;\n    if (bias != null) {\n        $bias = tensor_util_env_1.convertToTensor(bias, 'bias', 'fused conv2d');\n        $bias = tensor_util_1.makeTypesMatch($bias, $x)[0];\n        broadcast_util.assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);\n    }\n    var $preluActivationWeights;\n    if (preluActivationWeights != null) {\n        $preluActivationWeights = tensor_util_env_1.convertToTensor(preluActivationWeights, 'prelu weights', 'fused conv2d');\n    }\n    var grad = function (dy, saved) {\n        var _a = saved, $filter = _a[0], x4D = _a[1], y = _a[2];\n        var dyActivation = getFusedDyActivation(dy, y, activation);\n        util.assert(conv_util.tupleValuesAreOne(dilations), function () { return 'Error in gradient of fused conv2D: ' +\n            \"dilation rates greater than 1 \" +\n            (\"are not yet supported in gradients. Got dilations '\" + dilations + \"'\"); });\n        var biasGradient = {};\n        if (bias != null) {\n            biasGradient = { bias: function () { return getFusedBiasGradient($bias, dyActivation); } };\n        }\n        return Object.assign({\n            x: function () {\n                return conv_1.conv2dDerInput(x4D.shape, dyActivation, $filter, strides, pad);\n            },\n            filter: function () {\n                return conv_1.conv2dDerFilter(x4D, dyActivation, $filter.shape, strides, pad);\n            }\n        }, biasGradient);\n    };\n    var inputs = { x: x4D, filter: $filter };\n    if (bias != null) {\n        inputs.bias = $bias;\n    }\n    if (preluActivationWeights != null) {\n        inputs.preluActivationWeights = $preluActivationWeights;\n    }\n    var inputsToSave = [$filter, x4D];\n    var outputsToSave = [true]; // Save the only output.\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.fusedConv2d({\n            input: x4D,\n            filter: $filter,\n            convInfo: convInfo,\n            bias: $bias,\n            activation: activation,\n            preluActivationWeights: $preluActivationWeights\n        });\n        save([$filter, x4D, res]);\n        return res;\n    }, inputs, grad, 'FusedConv2D', { convInfo: convInfo, activation: activation }, inputsToSave, outputsToSave);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes depthwise 2D convolution, optionally fused with adding a\n * bias and applying an activation.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param obj An object with the following properties:\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n * @param bias Tensor to be added to the result.\n * @param activation Name of activation kernel (defaults to `linear`).\n * @param preluActivationWeights Tensor of prelu weights to be applied as part\n *     of a `prelu` activation, typically the same shape as `x`.\n */\nfunction fusedDepthwiseConv2d_(_a) {\n    var x = _a.x, filter = _a.filter, strides = _a.strides, pad = _a.pad, _b = _a.dataFormat, dataFormat = _b === void 0 ? 'NHWC' : _b, _c = _a.dilations, dilations = _c === void 0 ? [1, 1] : _c, dimRoundingMode = _a.dimRoundingMode, bias = _a.bias, _d = _a.activation, activation = _d === void 0 ? 'linear' : _d, preluActivationWeights = _a.preluActivationWeights;\n    if (fused_util_1.shouldFuse(engine_1.ENGINE.state.gradientDepth, activation) === false) {\n        var result = conv_2.depthwiseConv2d(x, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n        if (bias != null) {\n            result = binary_ops_1.add(result, bias);\n        }\n        return applyActivation(result, activation, preluActivationWeights);\n    }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'depthwiseConv2d');\n    var $filter = tensor_util_env_1.convertToTensor(filter, 'filter', 'depthwiseConv2d');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in fused depthwiseConv2d: input must be rank 4, but got \" +\n        (\"rank \" + x4D.rank + \".\"); });\n    util.assert($filter.rank === 4, function () { return \"Error in fused depthwiseConv2d: filter must be rank 4, \" +\n        (\"but got rank \" + $filter.rank + \".\"); });\n    util.assert(x4D.shape[3] === $filter.shape[2], function () { return \"Error in fused depthwiseConv2d: number of input channels \" +\n        (\"(\" + x4D.shape[3] + \") must match the inChannels dimension in \") +\n        (\"filter \" + $filter.shape[2] + \".\"); });\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () {\n        return 'Error in fused depthwiseConv2d: Either strides or dilations must ' +\n            (\"be 1. Got strides \" + strides + \" and dilations '\" + dilations + \"'\");\n    });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in fused depthwiseConv2d: pad must be an integer when \" +\n            (\"using dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode, true /* depthwise */);\n    var $bias;\n    if (bias != null) {\n        $bias = tensor_util_env_1.convertToTensor(bias, 'bias', 'fused conv2d');\n        $bias = tensor_util_1.makeTypesMatch($bias, $x)[0];\n        broadcast_util.assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);\n    }\n    var $preluActivationWeights;\n    if (preluActivationWeights != null) {\n        $preluActivationWeights = tensor_util_env_1.convertToTensor(preluActivationWeights, 'prelu weights', 'fused depthwiseConv2d');\n    }\n    var grad = function (dy, saved) {\n        util.assert(conv_util.tupleValuesAreOne(dilations), function () { return 'Error in gradient of fused depthwiseConv2d: dilation rates ' +\n            \"greater than 1 are not yet supported. Got dilations \" +\n            (\"'\" + dilations + \"'\"); });\n        var $filter = saved[0], x4D = saved[1], y = saved[2];\n        var dyActivation = getFusedDyActivation(dy, y, activation);\n        var biasGradient = {};\n        if (bias != null) {\n            biasGradient = { bias: function () { return getFusedBiasGradient($bias, dyActivation); } };\n        }\n        return Object.assign({\n            x: function () { return conv_1.depthwiseConv2dDerInput(x4D.shape, dyActivation, $filter, convInfo); },\n            filter: function () { return conv_1.depthwiseConv2dDerFilter(x4D, dyActivation, $filter.shape, convInfo); },\n        }, biasGradient);\n    };\n    var inputs = { x: x4D, filter: $filter };\n    if (bias != null) {\n        inputs.bias = $bias;\n    }\n    if (preluActivationWeights != null) {\n        inputs.preluActivationWeights = $preluActivationWeights;\n    }\n    var inputsToSave = [$filter, x4D];\n    var outputsToSave = [true];\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.fusedDepthwiseConv2D({\n            input: x4D,\n            filter: $filter,\n            convInfo: convInfo,\n            bias: $bias,\n            activation: activation,\n            preluActivationWeights: $preluActivationWeights\n        });\n        save([$filter, x4D, res]);\n        return res;\n    }, inputs, grad, 'FusedDepthwiseConv2D', { convInfo: convInfo, activation: activation }, inputsToSave, outputsToSave);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\nexports.matMul = operation_1.op({ fusedMatMul_: fusedMatMul_ });\nexports.conv2d = operation_1.op({ fusedConv2d_: fusedConv2d_ });\nexports.depthwiseConv2d = operation_1.op({ fusedDepthwiseConv2d_: fusedDepthwiseConv2d_ });\n//# sourceMappingURL=fused_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Whether we should call fused ops.\nexports.shouldFuse = function (gradientDepth, activation) {\n    var gradientMode = gradientDepth > 0;\n    return !gradientMode || activation === 'linear';\n};\n//# sourceMappingURL=fused_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Gather slices from input tensor into a Tensor with shape specified by\n * `indices`.\n *\n * `indices` is an K-dimensional integer tensor, best thought of as a\n * (K-1)-dimensional tensor of indices into input, where each element defines a\n * slice of input:\n * output[\\\\(i_0, ..., i_{K-2}\\\\)] = input[indices[\\\\(i_0, ..., i_{K-2}\\\\)]]\n *\n * Whereas in `tf.gather`, `indices` defines slices into the first dimension of\n * input, in `tf.gatherND`, `indices` defines slices into the first N dimensions\n * of input, where N = indices.shape[-1].\n *\n * The last dimension of indices can be at most the rank of input:\n * indices.shape[-1] <= input.rank\n *\n * The last dimension of `indices` corresponds to elements\n * (if indices.shape[-1] == input.rank) or slices\n * (if indices.shape[-1] < input.rank) along dimension indices.shape[-1] of\n * input.\n * The output tensor has shape\n * indices.shape[:-1] + input.shape[indices.shape[-1]:]\n *\n * Note that on CPU, if an out of bound index is found, an error is returned. On\n * GPU, if an out of bound index is found, a 0 is stored in the corresponding\n * output value.\n *\n * ```js\n * const indices = tf.tensor2d([0, 1, 1, 0], [2,2], 'int32');\n * const input = tf.tensor2d([9, 10, 11, 12], [2, 2]);\n * tf.gatherND(input, indices).print() // [10, 11]\n * ```\n *\n * @param x The tensor from which to gather values.\n * @param indices Index tensor, must be of type int32.\n */\n/** @doc {heading: 'Operations', subheading: 'Slicing and Joining'} */\nfunction gatherND_(x, indices) {\n    var $indices = tensor_util_env_1.convertToTensor(indices, 'indices', 'gatherND', 'int32');\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'gatherND');\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.gatherND($x, $indices); }, { x: $x, indices: $indices }, null /* backward */, 'GatherNd');\n}\nexports.gatherND = operation_1.op({ gatherND_: gatherND_ });\n//# sourceMappingURL=gather_nd.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n/**\n * Validate gather nd inputs.\n *\n * @param tensor The tensor contains the source values.\n * @param indices The tensor contains the indices to slice the source.\n *\n * @returns [resultShape, numUpdates, sliceSize, strides]\n */\nfunction prepareAndValidate(tensor, indices) {\n    if (tensor.rank < 1) {\n        throw new Error('tf.gatherND() expects the input to be rank 1 or higher,' +\n            (\" but the rank was \" + tensor.rank + \".\"));\n    }\n    if (indices.rank < 1) {\n        throw new Error('tf.gatherND() expects the indices to be rank 1 or higher,' +\n            (\" but the rank was \" + indices.rank + \".\"));\n    }\n    if (indices.dtype !== 'int32') {\n        throw new Error('tf.gatherND() expects the indices to be int32 type,' +\n            (\" but the dtype was \" + indices.dtype + \".\"));\n    }\n    if (indices.shape[indices.rank - 1] > tensor.rank) {\n        throw new Error('index innermost dimension length must be <= tensor rank; saw: ' +\n            (indices.shape[indices.rank - 1] + \" vs. \" + tensor.rank));\n    }\n    if (tensor.size === 0) {\n        throw new Error('Requested more than 0 entries, but input is empty.' +\n            (\" Input shape: \" + tensor.shape + \".\"));\n    }\n    var indicesShape = indices.shape;\n    var sliceRank = indicesShape[indicesShape.length - 1];\n    // The result shape is\n    //   indices.shape[:-1] + params.shape[indices.shape[-1]:]\n    var nResult = 1;\n    for (var i = 0; i < indicesShape.length - 1; ++i) {\n        nResult *= indicesShape[i];\n    }\n    var inputShape = tensor.shape;\n    var resultShape = indicesShape.slice();\n    resultShape.pop();\n    var sliceSize = 1;\n    for (var i = sliceRank; i < tensor.rank; ++i) {\n        sliceSize *= inputShape[i];\n        resultShape.push(inputShape[i]);\n    }\n    var strides = util_1.computeStrides(tensor.shape).map(function (stride) { return stride / sliceSize; }).concat([1]).slice(0, sliceRank);\n    return [resultShape, nResult, sliceSize, strides];\n}\nexports.prepareAndValidate = prepareAndValidate;\n//# sourceMappingURL=gather_nd_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/image_ops.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/image_ops.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar non_max_suppression_impl_1 = __webpack_require__(/*! ../backends/non_max_suppression_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js\");\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Bilinear resize a batch of 3D images to a new shape.\n *\n * @param images The images, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param size The new shape `[newHeight, newWidth]` to resize the\n *     images to. Each channel is resized individually.\n * @param alignCorners Defaults to False. If true, rescale\n *     input by `(new_height - 1) / (height - 1)`, which exactly aligns the 4\n *     corners of images and resized images. If false, rescale by\n *     `new_height / height`. Treat similarly the width dimension.\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction resizeBilinear_(images, size, alignCorners) {\n    if (alignCorners === void 0) { alignCorners = false; }\n    var $images = tensor_util_env_1.convertToTensor(images, 'images', 'resizeBilinear');\n    util.assert($images.rank === 3 || $images.rank === 4, function () { return \"Error in resizeBilinear: x must be rank 3 or 4, but got \" +\n        (\"rank \" + $images.rank + \".\"); });\n    util.assert(size.length === 2, function () { return \"Error in resizeBilinear: new shape must 2D, but got shape \" +\n        (size + \".\"); });\n    var batchImages = $images;\n    var reshapedTo4D = false;\n    if ($images.rank === 3) {\n        reshapedTo4D = true;\n        batchImages =\n            $images.as4D(1, $images.shape[0], $images.shape[1], $images.shape[2]);\n    }\n    var newHeight = size[0], newWidth = size[1];\n    var forward = function (backend, save) {\n        save([batchImages]);\n        return backend.resizeBilinear(batchImages, newHeight, newWidth, alignCorners);\n    };\n    var backward = function (dy, saved) {\n        return {\n            x: function () { return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.resizeBilinearBackprop(dy, saved[0], alignCorners); }, {}); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernelFunc(forward, { x: batchImages }, backward, 'ResizeBilinear', { alignCorners: alignCorners, newHeight: newHeight, newWidth: newWidth });\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * NearestNeighbor resize a batch of 3D images to a new shape.\n *\n * @param images The images, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param size The new shape `[newHeight, newWidth]` to resize the\n *     images to. Each channel is resized individually.\n * @param alignCorners Defaults to False. If true, rescale\n *     input by `(new_height - 1) / (height - 1)`, which exactly aligns the 4\n *     corners of images and resized images. If false, rescale by\n *     `new_height / height`. Treat similarly the width dimension.\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction resizeNearestNeighbor_(images, size, alignCorners) {\n    if (alignCorners === void 0) { alignCorners = false; }\n    var $images = tensor_util_env_1.convertToTensor(images, 'images', 'resizeNearestNeighbor');\n    util.assert($images.rank === 3 || $images.rank === 4, function () { return \"Error in resizeNearestNeighbor: x must be rank 3 or 4, but got \" +\n        (\"rank \" + $images.rank + \".\"); });\n    util.assert(size.length === 2, function () {\n        return \"Error in resizeNearestNeighbor: new shape must 2D, but got shape \" +\n            (size + \".\");\n    });\n    util.assert($images.dtype === 'float32' || $images.dtype === 'int32', function () { return '`images` must have `int32` or `float32` as dtype'; });\n    var batchImages = $images;\n    var reshapedTo4D = false;\n    if ($images.rank === 3) {\n        reshapedTo4D = true;\n        batchImages =\n            $images.as4D(1, $images.shape[0], $images.shape[1], $images.shape[2]);\n    }\n    var newHeight = size[0], newWidth = size[1];\n    var forward = function (backend, save) {\n        save([batchImages]);\n        return backend.resizeNearestNeighbor(batchImages, newHeight, newWidth, alignCorners);\n    };\n    var backward = function (dy, saved) {\n        return {\n            batchImages: function () { return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.resizeNearestNeighborBackprop(dy, saved[0], alignCorners); }, {}); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernelFunc(forward, { batchImages: batchImages }, backward);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Performs non maximum suppression of bounding boxes based on\n * iou (intersection over union).\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @return A 1D tensor with the selected box indices.\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    if (iouThreshold === void 0) { iouThreshold = 0.5; }\n    if (scoreThreshold === void 0) { scoreThreshold = Number.NEGATIVE_INFINITY; }\n    var $boxes = tensor_util_env_1.convertToTensor(boxes, 'boxes', 'nonMaxSuppression');\n    var $scores = tensor_util_env_1.convertToTensor(scores, 'scores', 'nonMaxSuppression');\n    var inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);\n    maxOutputSize = inputs.maxOutputSize;\n    iouThreshold = inputs.iouThreshold;\n    scoreThreshold = inputs.scoreThreshold;\n    var attrs = { maxOutputSize: maxOutputSize, iouThreshold: iouThreshold, scoreThreshold: scoreThreshold };\n    return engine_1.ENGINE.runKernelFunc(function (b) { return b.nonMaxSuppression($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold); }, { boxes: $boxes, scores: $scores }, null /* grad */, 'NonMaxSuppressionV3', attrs);\n}\n/** This is the async version of `nonMaxSuppression` */\nfunction nonMaxSuppressionAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\n    if (iouThreshold === void 0) { iouThreshold = 0.5; }\n    if (scoreThreshold === void 0) { scoreThreshold = Number.NEGATIVE_INFINITY; }\n    return __awaiter(this, void 0, void 0, function () {\n        var $boxes, $scores, inputs, boxesAndScores, boxesVals, scoresVals, res;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    $boxes = tensor_util_env_1.convertToTensor(boxes, 'boxes', 'nonMaxSuppressionAsync');\n                    $scores = tensor_util_env_1.convertToTensor(scores, 'scores', 'nonMaxSuppressionAsync');\n                    inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);\n                    maxOutputSize = inputs.maxOutputSize;\n                    iouThreshold = inputs.iouThreshold;\n                    scoreThreshold = inputs.scoreThreshold;\n                    return [4 /*yield*/, Promise.all([$boxes.data(), $scores.data()])];\n                case 1:\n                    boxesAndScores = _a.sent();\n                    boxesVals = boxesAndScores[0];\n                    scoresVals = boxesAndScores[1];\n                    res = non_max_suppression_impl_1.nonMaxSuppressionV3(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n                    if ($boxes !== boxes) {\n                        $boxes.dispose();\n                    }\n                    if ($scores !== scores) {\n                        $scores.dispose();\n                    }\n                    return [2 /*return*/, res];\n            }\n        });\n    });\n}\n/**\n * Performs non maximum suppression of bounding boxes based on\n * iou (intersection over union).\n *\n * This op also supports a Soft-NMS mode (c.f.\n * Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score\n * of other overlapping boxes, therefore favoring different regions of the image\n * with high scores. To enable this Soft-NMS mode, set the `softNmsSigma`\n * parameter to be larger than 0.\n *\n * @param boxes a 2d tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the corners of\n *     the bounding box.\n * @param scores a 1d tensor providing the box scores of shape `[numBoxes]`.\n * @param maxOutputSize The maximum number of boxes to be selected.\n * @param iouThreshold A float representing the threshold for deciding whether\n *     boxes overlap too much with respect to IOU. Must be between [0, 1].\n *     Defaults to 0.5 (50% box overlap).\n * @param scoreThreshold A threshold for deciding when to remove boxes based\n *     on score. Defaults to -inf, which means any score is accepted.\n * @param softNmsSigma A float representing the sigma parameter for Soft NMS.\n *     When sigma is 0, it falls back to nonMaxSuppression.\n * @return A map with the following properties:\n *     - selectedIndices: A 1D tensor with the selected box indices.\n *     - selectedScores: A 1D tensor with the corresponding scores for each\n *       selected box.\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    if (iouThreshold === void 0) { iouThreshold = 0.5; }\n    if (scoreThreshold === void 0) { scoreThreshold = Number.NEGATIVE_INFINITY; }\n    if (softNmsSigma === void 0) { softNmsSigma = 0.0; }\n    var $boxes = tensor_util_env_1.convertToTensor(boxes, 'boxes', 'nonMaxSuppression');\n    var $scores = tensor_util_env_1.convertToTensor(scores, 'scores', 'nonMaxSuppression');\n    var inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);\n    maxOutputSize = inputs.maxOutputSize;\n    iouThreshold = inputs.iouThreshold;\n    scoreThreshold = inputs.scoreThreshold;\n    softNmsSigma = inputs.softNmsSigma;\n    var attrs = { maxOutputSize: maxOutputSize, iouThreshold: iouThreshold, scoreThreshold: scoreThreshold, softNmsSigma: softNmsSigma };\n    var result = engine_1.ENGINE.runKernel('NonMaxSuppressionV5', { boxes: $boxes, scores: $scores }, attrs);\n    return { selectedIndices: result[0], selectedScores: result[1] };\n}\n/** This is the async version of `nonMaxSuppressionWithScore` */\nfunction nonMaxSuppressionWithScoreAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    if (iouThreshold === void 0) { iouThreshold = 0.5; }\n    if (scoreThreshold === void 0) { scoreThreshold = Number.NEGATIVE_INFINITY; }\n    if (softNmsSigma === void 0) { softNmsSigma = 0.0; }\n    return __awaiter(this, void 0, void 0, function () {\n        var $boxes, $scores, inputs, boxesAndScores, boxesVals, scoresVals, res;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    $boxes = tensor_util_env_1.convertToTensor(boxes, 'boxes', 'nonMaxSuppressionAsync');\n                    $scores = tensor_util_env_1.convertToTensor(scores, 'scores', 'nonMaxSuppressionAsync');\n                    inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);\n                    maxOutputSize = inputs.maxOutputSize;\n                    iouThreshold = inputs.iouThreshold;\n                    scoreThreshold = inputs.scoreThreshold;\n                    softNmsSigma = inputs.softNmsSigma;\n                    return [4 /*yield*/, Promise.all([$boxes.data(), $scores.data()])];\n                case 1:\n                    boxesAndScores = _a.sent();\n                    boxesVals = boxesAndScores[0];\n                    scoresVals = boxesAndScores[1];\n                    res = non_max_suppression_impl_1.nonMaxSuppressionV5(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);\n                    if ($boxes !== boxes) {\n                        $boxes.dispose();\n                    }\n                    if ($scores !== scores) {\n                        $scores.dispose();\n                    }\n                    return [2 /*return*/, res];\n            }\n        });\n    });\n}\nfunction nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    if (iouThreshold == null) {\n        iouThreshold = 0.5;\n    }\n    if (scoreThreshold == null) {\n        scoreThreshold = Number.NEGATIVE_INFINITY;\n    }\n    if (softNmsSigma == null) {\n        softNmsSigma = 0.0;\n    }\n    var numBoxes = boxes.shape[0];\n    maxOutputSize = Math.min(maxOutputSize, numBoxes);\n    util.assert(0 <= iouThreshold && iouThreshold <= 1, function () { return \"iouThreshold must be in [0, 1], but was '\" + iouThreshold + \"'\"; });\n    util.assert(boxes.rank === 2, function () { return \"boxes must be a 2D tensor, but was of rank '\" + boxes.rank + \"'\"; });\n    util.assert(boxes.shape[1] === 4, function () {\n        return \"boxes must have 4 columns, but 2nd dimension was \" + boxes.shape[1];\n    });\n    util.assert(scores.rank === 1, function () { return 'scores must be a 1D tensor'; });\n    util.assert(scores.shape[0] === numBoxes, function () { return \"scores has incompatible shape with boxes. Expected \" + numBoxes + \", \" +\n        (\"but was \" + scores.shape[0]); });\n    util.assert(0 <= softNmsSigma && softNmsSigma <= 1, function () { return \"softNmsSigma must be in [0, 1], but was '\" + softNmsSigma + \"'\"; });\n    return { maxOutputSize: maxOutputSize, iouThreshold: iouThreshold, scoreThreshold: scoreThreshold, softNmsSigma: softNmsSigma };\n}\n/**\n * Extracts crops from the input image tensor and resizes them using bilinear\n * sampling or nearest neighbor sampling (possibly with aspect ratio change)\n * to a common output size specified by crop_size.\n *\n * @param image 4d tensor of shape `[batch,imageHeight,imageWidth, depth]`,\n *     where imageHeight and imageWidth must be positive, specifying the\n *     batch of images from which to take crops\n * @param boxes 2d float32 tensor of shape `[numBoxes, 4]`. Each entry is\n *     `[y1, x1, y2, x2]`, where `(y1, x1)` and `(y2, x2)` are the normalized\n *     coordinates of the box in the boxInd[i]'th image in the batch\n * @param boxInd 1d int32 tensor of shape `[numBoxes]` with values in range\n *     `[0, batch)` that specifies the image that the `i`-th box refers to.\n * @param cropSize 1d int32 tensor of 2 elements `[cropHeigh, cropWidth]`\n *     specifying the size to which all crops are resized to.\n * @param method Optional string from `'bilinear' | 'nearest'`,\n *     defaults to bilinear, which specifies the sampling method for resizing\n * @param extrapolationValue A threshold for deciding when to remove boxes based\n *     on score. Defaults to 0.\n * @return A 4D tensor of the shape `[numBoxes,cropHeight,cropWidth,depth]`\n */\n/** @doc {heading: 'Operations', subheading: 'Images', namespace: 'image'} */\nfunction cropAndResize_(image, boxes, boxInd, cropSize, method, extrapolationValue) {\n    var $image = tensor_util_env_1.convertToTensor(image, 'image', 'cropAndResize');\n    var $boxes = tensor_util_env_1.convertToTensor(boxes, 'boxes', 'cropAndResize', 'float32');\n    var $boxInd = tensor_util_env_1.convertToTensor(boxInd, 'boxInd', 'cropAndResize', 'int32');\n    method = method || 'bilinear';\n    extrapolationValue = extrapolationValue || 0;\n    var numBoxes = $boxes.shape[0];\n    util.assert($image.rank === 4, function () { return 'Error in cropAndResize: image must be rank 4,' +\n        (\"but got rank \" + $image.rank + \".\"); });\n    util.assert($boxes.rank === 2 && $boxes.shape[1] === 4, function () { return \"Error in cropAndResize: boxes must be have size [\" + numBoxes + \",4] \" +\n        (\"but had shape \" + $boxes.shape + \".\"); });\n    util.assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, function () { return \"Error in cropAndResize: boxInd must be have size [\" + numBoxes + \"] \" +\n        (\"but had shape \" + $boxes.shape + \".\"); });\n    util.assert(cropSize.length === 2, function () { return \"Error in cropAndResize: cropSize must be of length 2, but got \" +\n        (\"length \" + cropSize.length + \".\"); });\n    util.assert(cropSize[0] >= 1 && cropSize[1] >= 1, function () { return \"cropSize must be atleast [1,1], but was \" + cropSize; });\n    util.assert(method === 'bilinear' || method === 'nearest', function () { return \"method must be bilinear or nearest, but was \" + method; });\n    var forward = function (backend, save) {\n        return backend.cropAndResize($image, $boxes, $boxInd, cropSize, method, extrapolationValue);\n    };\n    var res = engine_1.ENGINE.runKernelFunc(forward, { images: $image, boxes: $boxes, boxInd: $boxInd }, null /* der */, 'CropAndResize', { method: method, extrapolationValue: extrapolationValue, cropSize: cropSize });\n    return res;\n}\nexports.resizeBilinear = operation_1.op({ resizeBilinear_: resizeBilinear_ });\nexports.resizeNearestNeighbor = operation_1.op({ resizeNearestNeighbor_: resizeNearestNeighbor_ });\nexports.nonMaxSuppression = operation_1.op({ nonMaxSuppression_: nonMaxSuppression_ });\nexports.nonMaxSuppressionAsync = nonMaxSuppressionAsync_;\nexports.nonMaxSuppressionWithScore = operation_1.op({ nonMaxSuppressionWithScore_: nonMaxSuppressionWithScore_ });\nexports.nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;\nexports.cropAndResize = operation_1.op({ cropAndResize_: cropAndResize_ });\n//# sourceMappingURL=image_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/image_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/in_top_k.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/in_top_k.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Returns whether the targets are in the top K predictions.\n *\n * ```js\n * const predictions = tf.tensor2d([[20, 10, 40, 30], [30, 50, -20, 10]]);\n * const targets = tf.tensor1d([2, 0]);\n * const precision = await tf.inTopKAsync(predictions, targets);\n * precision.print();\n * ```\n * @param predictions 2-D or higher `tf.Tensor` with last dimension being\n *     at least `k`.\n * @param targets 1-D or higher `tf.Tensor`.\n * @param k Optional Number of top elements to look at for computing precision,\n *     default to 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Evaluation'} */\nfunction inTopKAsync_(predictions, targets, k) {\n    if (k === void 0) { k = 1; }\n    return __awaiter(this, void 0, void 0, function () {\n        var $predictions, $targets, lastDim, predictionsVals, targetsVals, _a, batch, size, precision, b, offset, vals, valAndInd, i, i;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'inTopK');\n                    $targets = tensor_util_env_1.convertToTensor(targets, 'targets', 'inTopK');\n                    util_1.assert($predictions.rank > 1, function () { return 'inTopK() expects the predictions to be of rank 2 or higher, ' +\n                        (\"but got \" + $predictions.rank); });\n                    util_1.assert($predictions.rank - 1 === $targets.rank, function () { return \"predictions rank should be 1 larger than \" +\n                        \"targets rank, but got predictions rank \" +\n                        ($predictions.rank + \" and targets rank \" + $targets.rank); });\n                    util_1.assertShapesMatch($predictions.shape.slice(0, $predictions.shape.length - 1), $targets.shape, \"predictions's shape should be align with the targets' shape, \" +\n                        'except the last dimension.');\n                    lastDim = $predictions.shape[$predictions.shape.length - 1];\n                    util_1.assert(k > 0 && k <= lastDim, function () { return \"'k' passed to inTopK() must be > 0 && <= the predictions last \" +\n                        (\"dimension (\" + lastDim + \"), but got \" + k); });\n                    return [4 /*yield*/, $predictions.data()];\n                case 1:\n                    predictionsVals = _b.sent();\n                    return [4 /*yield*/, $targets.data()];\n                case 2:\n                    targetsVals = _b.sent();\n                    _a = [predictionsVals.length / lastDim, lastDim], batch = _a[0], size = _a[1];\n                    precision = util_1.getTypedArrayFromDType('bool', batch);\n                    for (b = 0; b < batch; b++) {\n                        offset = b * size;\n                        vals = predictionsVals.subarray(offset, offset + size);\n                        valAndInd = [];\n                        for (i = 0; i < vals.length; i++) {\n                            valAndInd.push({ value: vals[i], index: i });\n                        }\n                        valAndInd.sort(function (a, b) { return b.value - a.value; });\n                        precision[b] = 0;\n                        for (i = 0; i < k; i++) {\n                            if (valAndInd[i].index === targetsVals[b]) {\n                                precision[b] = 1;\n                                break;\n                            }\n                        }\n                    }\n                    if (predictions !== $predictions) {\n                        $predictions.dispose();\n                    }\n                    if (targets !== $targets) {\n                        $targets.dispose();\n                    }\n                    // Output precision has the same shape as targets.\n                    return [2 /*return*/, tensor_ops_1.tensor(precision, $targets.shape, 'bool')];\n            }\n        });\n    });\n}\nexports.inTopKAsync = inTopKAsync_;\n//# sourceMappingURL=in_top_k.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/in_top_k.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/linalg_ops.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/linalg_ops.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Linear algebra ops.\n */\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar globals_1 = __webpack_require__(/*! ../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar array_ops_1 = __webpack_require__(/*! ./array_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js\");\nvar binary_ops_1 = __webpack_require__(/*! ./binary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js\");\nvar concat_split_1 = __webpack_require__(/*! ./concat_split */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/concat_split.js\");\nvar logical_ops_1 = __webpack_require__(/*! ./logical_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/logical_ops.js\");\nvar norm_1 = __webpack_require__(/*! ./norm */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar reduction_ops_1 = __webpack_require__(/*! ./reduction_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/reduction_ops.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Copy a tensor setting everything outside a central band in each innermost\n * matrix to zero.\n *\n * The band part is computed as follows: Assume input has `k` dimensions\n * `[I, J, K, ..., M, N]`, then the output is a tensor with the same shape where\n * `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.\n * The indicator function\n * `in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower))`\n * `&& (num_upper < 0 || (n-m) <= num_upper)`\n *\n * ```js\n * const x = tf.tensor2d([[ 0,  1,  2, 3],\n *                        [-1,  0,  1, 2],\n *                        [-2, -1,  0, 1],\n *                        [-3, -2, -1, 0]]);\n * let y = tf.linalg.bandPart(x, 1, -1);\n * y.print(); // [[ 0,  1,  2, 3],\n *            //  [-1,  0,  1, 2],\n *            //  [ 0, -1,  0, 1],\n *            //  [ 0, 0 , -1, 0]]\n * let z = tf.linalg.bandPart(x, 2, 1);\n * z.print(); // [[ 0,  1,  0, 0],\n *            //  [-1,  0,  1, 0],\n *            //  [-2, -1,  0, 1],\n *            //  [ 0, -2, -1, 0]]\n * ```\n *\n * @param x Rank `k` tensor\n * @param numLower Number of subdiagonals to keep.\n *   If negative, keep entire lower triangle.\n * @param numUpper Number of subdiagonals to keep.\n *   If negative, keep entire upper triangle.\n * @returns Rank `k` tensor of the same shape as input.\n *   The extracted banded tensor.\n */\n/**\n * @doc {heading:'Operations',\n *       subheading:'Linear Algebra',\n *       namespace:'linalg'}\n */\nfunction bandPart_(a, numLower, numUpper) {\n    if (numLower % 1 !== 0) {\n        throw new Error(\"bandPart(): numLower must be an integer, got \" + numLower + \".\");\n    }\n    if (numUpper % 1 !== 0) {\n        throw new Error(\"bandPart(): numUpper must be an integer, got \" + numUpper + \".\");\n    }\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'bandPart');\n    if ($a.rank < 2) {\n        throw new Error(\"bandPart(): Rank must be at least 2, got \" + $a.rank + \".\");\n    }\n    var shape = $a.shape, _a = $a.shape.slice(-2), M = _a[0], N = _a[1];\n    if (!(numLower <= M)) {\n        throw new Error(\"bandPart(): numLower (\" + numLower + \")\" +\n            (\" must not be greater than the number of rows (\" + M + \").\"));\n    }\n    if (!(numUpper <= N)) {\n        throw new Error(\"bandPart(): numUpper (\" + numUpper + \")\" +\n            (\" must not be greater than the number of columns (\" + N + \").\"));\n    }\n    if (numLower < 0) {\n        numLower = M;\n    }\n    if (numUpper < 0) {\n        numUpper = N;\n    }\n    var i = tensor_ops_1.range(0, M, 1, 'int32').reshape([-1, 1]), j = tensor_ops_1.range(0, N, 1, 'int32'), ij = binary_ops_1.sub(i, j);\n    var inBand = logical_ops_1.logicalAnd(ij.lessEqual(tensor_ops_1.scalar(+numLower, 'int32')), ij.greaterEqual(tensor_ops_1.scalar(-numUpper, 'int32')));\n    var zero = tensor_ops_1.zeros([M, N], $a.dtype);\n    return array_ops_1.stack(array_ops_1.unstack($a.reshape([-1, M, N])).map(function (mat) { return logical_ops_1.where(inBand, mat, zero); })).reshape(shape);\n}\n/**\n * Gram-Schmidt orthogonalization.\n *\n * ```js\n * const x = tf.tensor2d([[1, 2], [3, 4]]);\n * let y = tf.linalg.gramSchmidt(x);\n * y.print();\n * console.log('Othogonalized:');\n * y.dot(y.transpose()).print();  // should be nearly the identity matrix.\n * console.log('First row direction maintained:');\n * const data = await y.array();\n * console.log(data[0][1] / data[0][0]);  // should be nearly 2.\n * ```\n *\n * @param xs The vectors to be orthogonalized, in one of the two following\n *   formats:\n *   - An Array of `tf.Tensor1D`.\n *   - A `tf.Tensor2D`, i.e., a matrix, in which case the vectors are the rows\n *     of `xs`.\n *   In each case, all the vectors must have the same length and the length\n *   must be greater than or equal to the number of vectors.\n * @returns The orthogonalized and normalized vectors or matrix.\n *   Orthogonalization means that the vectors or the rows of the matrix\n *   are orthogonal (zero inner products). Normalization means that each\n *   vector or each row of the matrix has an L2 norm that equals `1`.\n */\n/**\n * @doc {heading:'Operations',\n *       subheading:'Linear Algebra',\n *       namespace:'linalg'}\n */\nfunction gramSchmidt_(xs) {\n    var inputIsTensor2D;\n    if (Array.isArray(xs)) {\n        inputIsTensor2D = false;\n        util_1.assert(xs != null && xs.length > 0, function () { return 'Gram-Schmidt process: input must not be null, undefined, or ' +\n            'empty'; });\n        var dim_1 = xs[0].shape[0];\n        var _loop_1 = function (i) {\n            util_1.assert(xs[i].shape[0] === dim_1, function () {\n                return 'Gram-Schmidt: Non-unique lengths found in the input vectors: ' +\n                    (\"(\" + xs[i].shape[0] + \" vs. \" + dim_1 + \")\");\n            });\n        };\n        for (var i = 1; i < xs.length; ++i) {\n            _loop_1(i);\n        }\n    }\n    else {\n        inputIsTensor2D = true;\n        xs = concat_split_1.split(xs, xs.shape[0], 0).map(function (x) { return array_ops_1.squeeze(x, [0]); });\n    }\n    util_1.assert(xs.length <= xs[0].shape[0], function () { return \"Gram-Schmidt: Number of vectors (\" + xs.length + \") exceeds \" +\n        (\"number of dimensions (\" + xs[0].shape[0] + \").\"); });\n    var ys = [];\n    var xs1d = xs;\n    var _loop_2 = function (i) {\n        ys.push(engine_1.ENGINE.tidy(function () {\n            var x = xs1d[i];\n            if (i > 0) {\n                for (var j = 0; j < i; ++j) {\n                    var proj = reduction_ops_1.sum(ys[j].mulStrict(x)).mul(ys[j]);\n                    x = x.sub(proj);\n                }\n            }\n            return x.div(norm_1.norm(x, 'euclidean'));\n        }));\n    };\n    for (var i = 0; i < xs.length; ++i) {\n        _loop_2(i);\n    }\n    if (inputIsTensor2D) {\n        return array_ops_1.stack(ys, 0);\n    }\n    else {\n        return ys;\n    }\n}\n/**\n * Compute QR decomposition of m-by-n matrix using Householder transformation.\n *\n * Implementation based on\n *   [http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf]\n * (http://www.cs.cornell.edu/~bindel/class/cs6210-f09/lec18.pdf)\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [3, 4]]);\n * let [q, r] = tf.linalg.qr(a);\n * console.log('Q');\n * q.print();\n * console.log('R');\n * r.print();\n * console.log('Orthogonalized');\n * q.dot(q.transpose()).print()  // should be nearly the identity matrix.\n * console.log('Reconstructed');\n * q.dot(r).print(); // should be nearly [[1, 2], [3, 4]];\n * ```\n *\n * @param x The `tf.Tensor` to be QR-decomposed. Must have rank >= 2. Suppose\n *   it has the shape `[..., M, N]`.\n * @param fullMatrices An optional boolean parameter. Defaults to `false`.\n *   If `true`, compute full-sized `Q`. If `false` (the default),\n *   compute only the leading N columns of `Q` and `R`.\n * @returns An `Array` of two `tf.Tensor`s: `[Q, R]`. `Q` is a unitary matrix,\n *   i.e., its columns all have unit norm and are mutually orthogonal.\n *   If `M >= N`,\n *     If `fullMatrices` is `false` (default),\n *       - `Q` has a shape of `[..., M, N]`,\n *       - `R` has a shape of `[..., N, N]`.\n *     If `fullMatrices` is `true` (default),\n *       - `Q` has a shape of `[..., M, M]`,\n *       - `R` has a shape of `[..., M, N]`.\n *   If `M < N`,\n *     - `Q` has a shape of `[..., M, M]`,\n *     - `R` has a shape of `[..., M, N]`.\n * @throws If the rank of `x` is less than 2.\n */\n/**\n * @doc {heading:'Operations',\n *       subheading:'Linear Algebra',\n *       namespace:'linalg'}\n */\nfunction qr_(x, fullMatrices) {\n    if (fullMatrices === void 0) { fullMatrices = false; }\n    if (x.rank < 2) {\n        throw new Error(\"qr() requires input tensor to have a rank >= 2, but got rank \" + x.rank);\n    }\n    else if (x.rank === 2) {\n        return qr2d(x, fullMatrices);\n    }\n    else {\n        // Rank > 2.\n        // TODO(cais): Below we split the input into individual 2D tensors,\n        //   perform QR decomposition on them and then stack the results back\n        //   together. We should explore whether this can be parallelized.\n        var outerDimsProd = x.shape.slice(0, x.shape.length - 2)\n            .reduce(function (value, prev) { return value * prev; });\n        var x2ds = array_ops_1.unstack(x.reshape([\n            outerDimsProd, x.shape[x.shape.length - 2],\n            x.shape[x.shape.length - 1]\n        ]), 0);\n        var q2ds_1 = [];\n        var r2ds_1 = [];\n        x2ds.forEach(function (x2d) {\n            var _a = qr2d(x2d, fullMatrices), q2d = _a[0], r2d = _a[1];\n            q2ds_1.push(q2d);\n            r2ds_1.push(r2d);\n        });\n        var q = array_ops_1.stack(q2ds_1, 0).reshape(x.shape);\n        var r = array_ops_1.stack(r2ds_1, 0).reshape(x.shape);\n        return [q, r];\n    }\n}\nfunction qr2d(x, fullMatrices) {\n    if (fullMatrices === void 0) { fullMatrices = false; }\n    return engine_1.ENGINE.tidy(function () {\n        if (x.shape.length !== 2) {\n            throw new Error(\"qr2d() requires a 2D Tensor, but got a \" + x.shape.length + \"D Tensor.\");\n        }\n        var m = x.shape[0];\n        var n = x.shape[1];\n        var q = array_ops_1.eye(m); // Orthogonal transform so far.\n        var r = x.clone(); // Transformed matrix so far.\n        var one2D = tensor_ops_1.tensor2d([[1]], [1, 1]);\n        var w = one2D.clone();\n        var iters = m >= n ? n : m;\n        var _loop_3 = function (j) {\n            var _a;\n            // This tidy within the for-loop ensures we clean up temporary\n            // tensors as soon as they are no longer needed.\n            var rTemp = r;\n            var wTemp = w;\n            var qTemp = q;\n            _a = engine_1.ENGINE.tidy(function () {\n                // Find H = I - tau * w * w', to put zeros below R(j, j).\n                var rjEnd1 = r.slice([j, j], [m - j, 1]);\n                var normX = rjEnd1.norm();\n                var rjj = r.slice([j, j], [1, 1]);\n                // The sign() function returns 0 on 0, which causes division by zero.\n                var s = tensor_ops_1.tensor2d([[-1]]).where(rjj.greater(0), tensor_ops_1.tensor2d([[1]]));\n                var u1 = rjj.sub(s.mul(normX));\n                var wPre = rjEnd1.div(u1);\n                if (wPre.shape[0] === 1) {\n                    w = one2D.clone();\n                }\n                else {\n                    w = one2D.concat(wPre.slice([1, 0], [wPre.shape[0] - 1, wPre.shape[1]]), 0);\n                }\n                var tau = s.matMul(u1).div(normX).neg();\n                // -- R := HR, Q := QH.\n                var rjEndAll = r.slice([j, 0], [m - j, n]);\n                var tauTimesW = tau.mul(w);\n                if (j === 0) {\n                    r = rjEndAll.sub(tauTimesW.matMul(w.transpose().matMul(rjEndAll)));\n                }\n                else {\n                    var rTimesTau = rjEndAll.sub(tauTimesW.matMul(w.transpose().matMul(rjEndAll)));\n                    r = r.slice([0, 0], [j, n]).concat(rTimesTau, 0);\n                }\n                var qAllJEnd = q.slice([0, j], [m, q.shape[1] - j]);\n                if (j === 0) {\n                    q = qAllJEnd.sub(qAllJEnd.matMul(w).matMul(tauTimesW.transpose()));\n                }\n                else {\n                    var qTimesTau = qAllJEnd.sub(qAllJEnd.matMul(w).matMul(tauTimesW.transpose()));\n                    q = q.slice([0, 0], [m, j]).concat(qTimesTau, 1);\n                }\n                return [w, r, q];\n            }), w = _a[0], r = _a[1], q = _a[2];\n            globals_1.dispose([rTemp, wTemp, qTemp]);\n        };\n        for (var j = 0; j < iters; ++j) {\n            _loop_3(j);\n        }\n        if (!fullMatrices && m > n) {\n            q = q.slice([0, 0], [m, n]);\n            r = r.slice([0, 0], [n, n]);\n        }\n        return [q, r];\n    });\n}\nexports.bandPart = operation_1.op({ bandPart_: bandPart_ });\nexports.gramSchmidt = operation_1.op({ gramSchmidt_: gramSchmidt_ });\nexports.qr = operation_1.op({ qr_: qr_ });\n//# sourceMappingURL=linalg_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/linalg_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/logical_ops.js":
/*!********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/logical_ops.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar where_impl_1 = __webpack_require__(/*! ../backends/where_impl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js\");\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar broadcast_util_1 = __webpack_require__(/*! ./broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Returns the truth value of `NOT x` element-wise.\n *\n * ```js\n * const a = tf.tensor1d([false, true], 'bool');\n *\n * a.logicalNot().print();\n * ```\n *\n * @param x The input tensor. Must be of dtype 'bool'.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalNot_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'logicalNot', 'bool');\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.logicalNot($x); }, { $x: $x });\n}\n/**\n * Returns the truth value of `a AND b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalAnd(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalAnd_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'logicalAnd', 'bool');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'logicalAnd', 'bool');\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.logicalAnd($a, $b); }, { a: $a, b: $b }, null /* grad */, 'LogicalAnd');\n}\n/**\n * Returns the truth value of `a OR b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalOr(b).print();\n * ```\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalOr_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'logicalOr', 'bool');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'logicalOr', 'bool');\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.logicalOr($a, $b); }, { $a: $a, $b: $b });\n}\n/**\n * Returns the truth value of `a XOR b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalXor(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalXor_(a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'logicalXor', 'bool');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'logicalXor', 'bool');\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    // x ^ y = (x | y) & ~(x & y)\n    return exports.logicalOr(a, b).logicalAnd(exports.logicalAnd(a, b).logicalNot());\n}\n/**\n * Returns the elements, either `a` or `b` depending on the `condition`.\n *\n * If the condition is true, select from `a`, otherwise select from `b`.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const a = tf.tensor1d([1 , 2, 3]);\n * const b = tf.tensor1d([-1, -2, -3]);\n *\n * a.where(cond, b).print();\n * ```\n *\n * @param condition The input condition. Must be of dtype bool.\n * @param a If `condition` is rank 1, `a` may have a higher rank but\n *     its first dimension must match the size of `condition`.\n * @param b A tensor with the same shape and type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction where_(condition, a, b) {\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'where');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'where');\n    var $condition = tensor_util_env_1.convertToTensor(condition, 'condition', 'where', 'bool');\n    util_1.assertShapesMatch($a.shape, $b.shape, 'Error in where: ');\n    if ($condition.rank === 1) {\n        // If condition rank is 1, then the first dimension must match the size of\n        // condition.\n        util_1.assert($condition.shape[0] === $a.shape[0], function () { return 'The first dimension of `a` must match the size of `condition`.'; });\n    }\n    else {\n        // A must have the same shape as condition.\n        util_1.assertShapesMatch($condition.shape, $b.shape, 'Error in where: ');\n    }\n    // TODO(julianoks): Return null for condition gradient\n    // when backprop supports it.\n    var grad = function (dy, saved) {\n        var $condition = saved[0];\n        return {\n            $condition: function () { return tensor_ops_1.zerosLike($condition).toFloat(); },\n            $a: function () { return dy.mul($condition.cast(dy.dtype)); },\n            $b: function () { return dy.mul($condition.logicalNot().cast(dy.dtype)); }\n        };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.select($condition, $a, $b);\n        save([$condition]);\n        return res;\n    }, { $condition: $condition, $a: $a, $b: $b }, grad);\n}\n/**\n * Returns the coordinates of true elements of condition.\n *\n * The coordinates are returned in a 2-D tensor where the first dimension (rows)\n * represents the number of true elements, and the second dimension (columns)\n * represents the coordinates of the true elements. Keep in mind, the shape of\n * the output tensor can vary depending on how many true values there are in\n * input. Indices are output in row-major order. The resulting tensor has the\n * shape `[numTrueElems, condition.rank]`.\n *\n * This is analogous to calling the python `tf.where(cond)` without an x or y.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const result = await tf.whereAsync(cond);\n * result.print();\n * ```\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction whereAsync_(condition) {\n    return __awaiter(this, void 0, void 0, function () {\n        var $condition, vals, res;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    $condition = tensor_util_env_1.convertToTensor(condition, 'condition', 'whereAsync', 'bool');\n                    return [4 /*yield*/, $condition.data()];\n                case 1:\n                    vals = _a.sent();\n                    res = where_impl_1.whereImpl($condition.shape, vals);\n                    if (condition !== $condition) {\n                        $condition.dispose();\n                    }\n                    return [2 /*return*/, res];\n            }\n        });\n    });\n}\nexports.logicalAnd = operation_1.op({ logicalAnd_: logicalAnd_ });\nexports.logicalNot = operation_1.op({ logicalNot_: logicalNot_ });\nexports.logicalOr = operation_1.op({ logicalOr_: logicalOr_ });\nexports.logicalXor = operation_1.op({ logicalXor_: logicalXor_ });\nexports.where = operation_1.op({ where_: where_ });\nexports.whereAsync = whereAsync_;\n//# sourceMappingURL=logical_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/logical_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar gradients_1 = __webpack_require__(/*! ../gradients */ \"./node_modules/@tensorflow/tfjs-core/dist/gradients.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar axis_util_1 = __webpack_require__(/*! ./axis_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js\");\nvar binary_ops_1 = __webpack_require__(/*! ./binary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\nvar Reduction;\n(function (Reduction) {\n    Reduction[Reduction[\"NONE\"] = 0] = \"NONE\";\n    Reduction[Reduction[\"MEAN\"] = 1] = \"MEAN\";\n    Reduction[Reduction[\"SUM\"] = 2] = \"SUM\";\n    Reduction[Reduction[\"SUM_BY_NONZERO_WEIGHTS\"] = 3] = \"SUM_BY_NONZERO_WEIGHTS\";\n})(Reduction = exports.Reduction || (exports.Reduction = {}));\n/**\n * Computes the weighted loss between two tensors.\n *\n * @param losses Tensor of shape `[batch_size, d1, ... dN]`.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `losses`, and must be broadcastable to `losses` (i.e., all\n *    dimensions must be either `1`, or the same as the corresponding\n *    `losses` dimension).\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction computeWeightedLoss_(losses, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $losses = tensor_util_env_1.convertToTensor(losses, 'losses', 'computeWeightedLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'computeWeightedLoss');\n    }\n    var weightedLoss = ($weights == null) ? $losses : $losses.mul($weights);\n    if (reduction === Reduction.NONE) {\n        return weightedLoss;\n    }\n    if (reduction === Reduction.SUM) {\n        return weightedLoss.sum();\n    }\n    if (reduction === Reduction.MEAN) {\n        if ($weights == null) {\n            return weightedLoss.mean();\n        }\n        else {\n            var broadcastFactor = $losses.size / $weights.size;\n            var result = weightedLoss.sum().div($weights.sum());\n            return broadcastFactor > 1 ? result.div(tensor_ops_1.scalar(broadcastFactor)) :\n                result;\n        }\n    }\n    if (reduction === Reduction.SUM_BY_NONZERO_WEIGHTS) {\n        if ($weights == null) {\n            return weightedLoss.sum().div(tensor_ops_1.scalar($losses.size));\n        }\n        else {\n            var broadcastedWeights = $weights.mul(tensor_ops_1.ones($losses.shape));\n            var numNonZeros = broadcastedWeights.notEqual(tensor_ops_1.scalar(0)).sum().toFloat();\n            return weightedLoss.sum().div(numNonZeros);\n        }\n    }\n    throw Error(\"Unknown reduction: \" + reduction);\n}\n/**\n * Computes the absolute difference loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction absoluteDifference_(labels, predictions, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'absoluteDifference');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'absoluteDifference');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'absoluteDifference');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in absoluteDifference: ');\n    var losses = $labels.sub($predictions).abs();\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes the mean squared error between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction meanSquaredError_(labels, predictions, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'meanSquaredError');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'meanSquaredError');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'meanSquaredError');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in meanSquaredError: ');\n    var losses = $labels.squaredDifference($predictions);\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes the cosine distance loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param axis The dimension along which the cosine distance is computed.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction cosineDistance_(labels, predictions, axis, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'cosineDistance');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'cosineDistance');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'cosineDistance');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in cosineDistance: ');\n    var one = tensor_ops_1.scalar(1);\n    var losses = one.sub($labels.mul($predictions).sum(axis, true));\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes the Hinge loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction hingeLoss_(labels, predictions, weights, reduction) {\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'hingeLoss');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'hingeLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'hingeLoss');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in hingeLoss: ');\n    var one = tensor_ops_1.scalar(1);\n    // Convert binary labels to (-1, 1)\n    $labels = tensor_ops_1.scalar(2).mul($labels).sub(one);\n    var losses = one.sub($labels.mul($predictions)).relu();\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes the log loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param epsilon A small increment to avoid taking log of zero\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction logLoss_(labels, predictions, weights, epsilon, reduction) {\n    if (epsilon === void 0) { epsilon = 1e-7; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'logLoss');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'logLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'logLoss');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in logLoss: ');\n    var one = tensor_ops_1.scalar(1);\n    var epsilonScalar = tensor_ops_1.scalar(epsilon);\n    var losses = $labels.mul($predictions.add(epsilonScalar).log())\n        .neg()\n        .sub(one.sub($labels).mul(one.sub($predictions).add(epsilonScalar).log()));\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nfunction sigmoidCrossEntropyWithLogits_(labels, logits) {\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'sigmoidCrossEntropyWithLogits');\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'sigmoidCrossEntropyWithLogits');\n    util_1.assertShapesMatch($labels.shape, $logits.shape, 'Error in sigmoidCrossEntropyWithLogits: ');\n    /**\n     * Implementation Details:\n     *\n     * For brevity, let `x = logits`, `z = labels`.  The logistic loss is\n     *     z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n     *   = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n     *   = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n     *   = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n     *   = (1 - z) * x + log(1 + exp(-x))\n     *   = x - x * z + log(1 + exp(-x))\n     *\n     *   For x < 0, to avoid overflow in exp(-x), we reformulate the above\n     *     x - x * z + log(1 + exp(-x))\n     *   = log(exp(x)) - x * z + log(1 + exp(-x))\n     *   = - x * z + log(1 + exp(x))\n     *\n     * Hence, to ensure stability and avoid overflow, the implementation uses\n     * this equivalent formulation:\n     *     max(x, 0) - x * z + log(1 + exp(-abs(x)))\n     */\n    var maxOutput = $logits.relu();\n    var outputXTarget = $logits.mul($labels);\n    var sigmoidOutput = $logits.abs().neg().exp().log1p();\n    return maxOutput.sub(outputXTarget).add(sigmoidOutput);\n}\n/**\n * Computes the sigmoid cross entropy loss between two tensors.\n *\n * If labelSmoothing is nonzero, smooth the labels towards 1/2:\n *\n *   newMulticlassLabels = multiclassLabels * (1 - labelSmoothing)\n *                         + 0.5 * labelSmoothing\n *\n * @param multiClassLabels The ground truth output tensor of shape\n * [batch_size, num_classes], same dimensions as 'predictions'.\n * @param logits The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param labelSmoothing If greater than 0, then smooth the labels.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc { heading: 'Training', subheading: 'Losses', namespace: 'losses' } */\nfunction sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing, reduction) {\n    if (labelSmoothing === void 0) { labelSmoothing = 0; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $multiClassLabels = tensor_util_env_1.convertToTensor(multiClassLabels, 'multiClassLabels', 'sigmoidCrossEntropy');\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'sigmoidCrossEntropy');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'sigmoidCrossEntropy');\n    }\n    util_1.assertShapesMatch($multiClassLabels.shape, $logits.shape, 'Error in sigmoidCrossEntropy: ');\n    if (labelSmoothing > 0) {\n        var labelSmoothingScalar = tensor_ops_1.scalar(labelSmoothing);\n        var one = tensor_ops_1.scalar(1);\n        var half = tensor_ops_1.scalar(0.5);\n        $multiClassLabels = $multiClassLabels.mul(one.sub(labelSmoothingScalar))\n            .add(half.mul(labelSmoothingScalar));\n    }\n    var losses = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes the huber loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param delta Point where huber loss changes from quadratic to linear.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`.\n */\n/** @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'} */\nfunction huberLoss_(labels, predictions, weights, delta, reduction) {\n    if (delta === void 0) { delta = 1.0; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $labels = tensor_util_env_1.convertToTensor(labels, 'labels', 'huberLoss');\n    var $predictions = tensor_util_env_1.convertToTensor(predictions, 'predictions', 'huberLoss');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'huberLoss');\n    }\n    util_1.assertShapesMatch($labels.shape, $predictions.shape, 'Error in huberLoss: ');\n    var deltaScalar = tensor_ops_1.scalar(delta);\n    var error = $predictions.sub($labels).abs();\n    var quadratic = binary_ops_1.minimum(error, deltaScalar);\n    var linear = error.sub(quadratic);\n    var losses = tensor_ops_1.scalar(0.5).mul(quadratic.square()).add(deltaScalar.mul(linear));\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\n/**\n * Computes softmax cross entropy between logits and labels.\n *\n * Measures the probability error in discrete classification tasks in which\n * the classes are mutually exclusive (each entry is in exactly one class).\n * For example, each CIFAR-10 image is labeled with one and only one label: an\n * image can be a dog or a truck, but not both.\n *\n * `NOTE`: While the classes are mutually exclusive, their probabilities need\n * not be. All that is required is that each row of labels is a valid\n * probability distribution. If they are not, the computation of the gradient\n * will be incorrect.\n *\n * `WARNING`: This op expects unscaled logits, since it performs a softmax on\n * logits internally for efficiency. Do not call this op with the output of\n * softmax, as it will produce incorrect results.\n *\n * logits and labels must have the same shape, e.g. [batch_size, num_classes]\n * and the same dtype.\n * @param labels The labels array.\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n */\nfunction softmaxCrossEntropyWithLogits_(labels, logits, dim) {\n    if (dim === void 0) { dim = -1; }\n    if (dim === -1) {\n        dim = logits.rank - 1;\n    }\n    if (dim !== logits.rank - 1) {\n        throw Error(\"Softmax cross entropy along a non-last dimension is not yet \" +\n            (\"supported. Labels / logits was rank \" + logits.rank + \" \") +\n            (\"and dim was \" + dim));\n    }\n    // Use a custom gradient for numerical stability.\n    var customOp = gradients_1.customGrad(function (labels, logits, save) {\n        // Reference:\n        //   1. http://cs231n.github.io/linear-classify/#softmax\n        //   2. https://blog.feedly.com/tricks-of-the-trade-logsumexp/\n        var keepDims = true;\n        var lse = logits.logSumExp([dim], keepDims);\n        var logResult = logits.toFloat().sub(lse);\n        save([labels, logResult]);\n        var costVector = logResult.mul(labels).neg();\n        var value = costVector.sum([dim]);\n        var gradFunc = function (dy, saved) {\n            var labels = saved[0], logResult = saved[1];\n            var dyShape = axis_util_1.expandShapeToKeepDim(dy.shape, [dim]);\n            return [\n                dy.reshape(dyShape).mul(labels.toFloat().sub(logResult.exp())),\n                dy.reshape(dyShape).mul(logResult.exp().sub(labels.toFloat())),\n            ];\n        };\n        return { value: value, gradFunc: gradFunc };\n    });\n    return customOp(labels, logits);\n}\n/**\n * Computes the softmax cross entropy loss between two tensors.\n *\n * If labelSmoothing is nonzero, smooth the labels towards 1/2:\n *\n *   newOnehotLabels = onehotLabels * (1 - labelSmoothing)\n *                         + labelSmoothing / numClasses\n *\n * @param onehotLabels One hot encoded labels\n *    [batch_size, num_classes], same dimensions as 'predictions'.\n * @param logits The predicted outputs.\n * @param weights Tensor whose rank is either 0, or 1, and must be\n *    broadcastable to `loss`  of shape [batch_size]\n * @param labelSmoothing If greater than 0, then smooth the labels.\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n */\n/** @doc { heading: 'Training', subheading: 'Losses', namespace: 'losses' } */\nfunction softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing, reduction) {\n    if (labelSmoothing === void 0) { labelSmoothing = 0; }\n    if (reduction === void 0) { reduction = Reduction.SUM_BY_NONZERO_WEIGHTS; }\n    var $onehotLabels = tensor_util_env_1.convertToTensor(onehotLabels, 'onehotLabels', 'softmaxCrossEntropy');\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'softmaxCrossEntropy');\n    var $weights = null;\n    if (weights != null) {\n        $weights = tensor_util_env_1.convertToTensor(weights, 'weights', 'softmaxCrossEntropy');\n    }\n    util_1.assertShapesMatch($onehotLabels.shape, $logits.shape, 'Error in softmaxCrossEntropy: ');\n    if (labelSmoothing > 0) {\n        var labelSmoothingScalar = tensor_ops_1.scalar(labelSmoothing);\n        var one = tensor_ops_1.scalar(1);\n        var numClasses = tensor_ops_1.scalar($onehotLabels.shape[1]);\n        $onehotLabels = $onehotLabels.mul(one.sub(labelSmoothingScalar))\n            .add(labelSmoothingScalar.div(numClasses));\n    }\n    var losses = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);\n    return exports.computeWeightedLoss(losses, $weights, reduction);\n}\nexports.absoluteDifference = operation_1.op({ absoluteDifference_: absoluteDifference_ });\nexports.computeWeightedLoss = operation_1.op({ computeWeightedLoss_: computeWeightedLoss_ });\nexports.cosineDistance = operation_1.op({ cosineDistance_: cosineDistance_ });\nexports.hingeLoss = operation_1.op({ hingeLoss_: hingeLoss_ });\nexports.huberLoss = operation_1.op({ huberLoss_: huberLoss_ });\nexports.logLoss = operation_1.op({ logLoss_: logLoss_ });\nexports.meanSquaredError = operation_1.op({ meanSquaredError_: meanSquaredError_ });\nexports.sigmoidCrossEntropy = operation_1.op({ sigmoidCrossEntropy_: sigmoidCrossEntropy_ });\nexports.softmaxCrossEntropy = operation_1.op({ softmaxCrossEntropy_: softmaxCrossEntropy_ });\n//# sourceMappingURL=loss_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/lrn.js":
/*!************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/lrn.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Normalizes the activation of a local neighborhood across or within\n * channels.\n *\n * @param x The input tensor. The 4-D input tensor is treated as a 3-D array\n *     of 1D vectors (along the last dimension), and each vector is\n *     normalized independently.\n * @param depthRadius The number of adjacent channels in the 1D normalization\n *     window.\n * @param bias A constant bias term for the basis.\n * @param alpha A scale factor, usually positive.\n * @param beta An exponent.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction localResponseNormalization_(x, depthRadius, bias, alpha, beta) {\n    if (depthRadius === void 0) { depthRadius = 5; }\n    if (bias === void 0) { bias = 1; }\n    if (alpha === void 0) { alpha = 1; }\n    if (beta === void 0) { beta = 0.5; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'localResponseNormalization');\n    util.assert($x.rank === 4 || $x.rank === 3, function () { return \"Error in localResponseNormalization: x must be rank 3 or 4 but got\\n               rank \" + $x.rank + \".\"; });\n    util.assert(util.isInt(depthRadius), function () { return \"Error in localResponseNormalization: depthRadius must be an \" +\n        (\"integer but got depthRadius \" + depthRadius + \".\"); });\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    var backward = function (dy, saved) {\n        var x4D = saved[0], y = saved[1];\n        return {\n            x4D: function () { return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.LRNGrad(dy, x4D, y, depthRadius, bias, alpha, beta); }, {}); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.localResponseNormalization4D(x4D, depthRadius, bias, alpha, beta);\n        save([x4D, y]);\n        return y;\n    }, { x4D: x4D }, backward);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    else {\n        return res;\n    }\n}\nexports.localResponseNormalization = operation_1.op({ localResponseNormalization_: localResponseNormalization_ });\n//# sourceMappingURL=lrn.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/lrn.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/lstm.js":
/*!*************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/lstm.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Computes the next states and outputs of a stack of LSTMCells.\n *\n * Each cell output is used as input to the next cell.\n *\n * Returns `[cellState, cellOutput]`.\n *\n * Derived from tf.contrib.rn.MultiRNNCell.\n *\n * @param lstmCells Array of LSTMCell functions.\n * @param data The input to the cell.\n * @param c Array of previous cell states.\n * @param h Array of previous cell outputs.\n */\n/** @doc {heading: 'Operations', subheading: 'RNN'} */\nfunction multiRNNCell_(lstmCells, data, c, h) {\n    var $data = tensor_util_env_1.convertToTensor(data, 'data', 'multiRNNCell');\n    var $c = tensor_util_env_1.convertToTensorArray(c, 'c', 'multiRNNCell');\n    var $h = tensor_util_env_1.convertToTensorArray(h, 'h', 'multiRNNCell');\n    var input = $data;\n    var newStates = [];\n    for (var i = 0; i < lstmCells.length; i++) {\n        var output = lstmCells[i](input, $c[i], $h[i]);\n        newStates.push(output[0]);\n        newStates.push(output[1]);\n        input = output[1];\n    }\n    var newC = [];\n    var newH = [];\n    for (var i = 0; i < newStates.length; i += 2) {\n        newC.push(newStates[i]);\n        newH.push(newStates[i + 1]);\n    }\n    return [newC, newH];\n}\n/**\n * Computes the next state and output of a BasicLSTMCell.\n *\n * Returns `[newC, newH]`.\n *\n * Derived from tf.contrib.rnn.BasicLSTMCell.\n *\n * @param forgetBias Forget bias for the cell.\n * @param lstmKernel The weights for the cell.\n * @param lstmBias The bias for the cell.\n * @param data The input to the cell.\n * @param c Previous cell state.\n * @param h Previous cell output.\n */\n/** @doc {heading: 'Operations', subheading: 'RNN'} */\nfunction basicLSTMCell_(forgetBias, lstmKernel, lstmBias, data, c, h) {\n    var $forgetBias = tensor_util_env_1.convertToTensor(forgetBias, 'forgetBias', 'basicLSTMCell');\n    var $lstmKernel = tensor_util_env_1.convertToTensor(lstmKernel, 'lstmKernel', 'basicLSTMCell');\n    var $lstmBias = tensor_util_env_1.convertToTensor(lstmBias, 'lstmBias', 'basicLSTMCell');\n    var $data = tensor_util_env_1.convertToTensor(data, 'data', 'basicLSTMCell');\n    var $c = tensor_util_env_1.convertToTensor(c, 'c', 'basicLSTMCell');\n    var $h = tensor_util_env_1.convertToTensor(h, 'h', 'basicLSTMCell');\n    var combined = $data.concat($h, 1);\n    var weighted = combined.matMul($lstmKernel);\n    var res = weighted.add($lstmBias);\n    // i = input_gate, j = new_input, f = forget_gate, o = output_gate\n    var batchSize = res.shape[0];\n    var sliceCols = res.shape[1] / 4;\n    var sliceSize = [batchSize, sliceCols];\n    var i = res.slice([0, 0], sliceSize);\n    var j = res.slice([0, sliceCols], sliceSize);\n    var f = res.slice([0, sliceCols * 2], sliceSize);\n    var o = res.slice([0, sliceCols * 3], sliceSize);\n    var newC = i.sigmoid().mulStrict(j.tanh()).addStrict($c.mulStrict($forgetBias.add(f).sigmoid()));\n    var newH = newC.tanh().mulStrict(o.sigmoid());\n    return [newC, newH];\n}\nexports.basicLSTMCell = operation_1.op({ basicLSTMCell_: basicLSTMCell_ });\nexports.multiRNNCell = operation_1.op({ multiRNNCell_: multiRNNCell_ });\n//# sourceMappingURL=lstm.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/lstm.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/matmul.js":
/*!***************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/matmul.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_1 = __webpack_require__(/*! ../tensor_util */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Computes the dot product of two matrices, A * B. These must be matrices.\n *\n * ```js\n * const a = tf.tensor2d([1, 2], [1, 2]);\n * const b = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * a.matMul(b).print();  // or tf.matMul(a, b)\n * ```\n * @param a First matrix in dot product operation.\n * @param b Second matrix in dot product operation.\n * @param transposeA If true, `a` is transposed before multiplication.\n * @param transposeB If true, `b` is transposed before multiplication.\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices'} */\nfunction matMul_(a, b, transposeA, transposeB) {\n    var _a;\n    if (transposeA === void 0) { transposeA = false; }\n    if (transposeB === void 0) { transposeB = false; }\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'matMul');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'matMul');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    var innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];\n    var innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];\n    var outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];\n    var outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];\n    var outerDimsA = $a.shape.slice(0, -2);\n    var outerDimsB = $b.shape.slice(0, -2);\n    var batchDimA = util.sizeFromShape(outerDimsA);\n    var batchDimB = util.sizeFromShape(outerDimsB);\n    util.assert($a.rank >= 2 && $b.rank >= 2 && $a.rank === $b.rank, function () { return \"Error in matMul: inputs must have the same rank of at least 2, \" +\n        (\"got ranks \" + $a.rank + \" and \" + $b.rank + \".\"); });\n    util.assert(util.arraysEqual(outerDimsA, outerDimsB), function () { return \"Error in matMul: outer dimensions (\" + outerDimsA + \") and (\" +\n        (outerDimsB + \") of Tensors with shapes \" + $a.shape + \" and \") +\n        ($b.shape + \" must match.\"); });\n    util.assert(innerShapeA === innerShapeB, function () { return \"Error in matMul: inner shapes (\" + innerShapeA + \") and (\" +\n        (innerShapeB + \") of Tensors with shapes \" + $a.shape + \" and \") +\n        ($b.shape + \" and transposeA=\" + transposeA) +\n        (\" and transposeB=\" + transposeB + \" must match.\"); });\n    var outShape = $a.shape.slice(0, -2).concat([outerShapeA, outerShapeB]);\n    var a3D = transposeA ? $a.as3D(batchDimA, innerShapeA, outerShapeA) :\n        $a.as3D(batchDimA, outerShapeA, innerShapeA);\n    var b3D = transposeB ? $b.as3D(batchDimB, outerShapeB, innerShapeB) :\n        $b.as3D(batchDimB, innerShapeB, outerShapeB);\n    var grad = function (dy, saved) {\n        var _a = saved, a3D = _a[0], b3D = _a[1];\n        if (!transposeA && !transposeB) {\n            return {\n                a: function () { return dy.matMul(b3D, false, true); },\n                b: function () { return a3D.matMul(dy, true, false); }\n            };\n        }\n        else if (!transposeA && transposeB) {\n            return {\n                a: function () { return dy.matMul(b3D, false, false); },\n                b: function () { return dy.matMul(a3D, true, false); }\n            };\n        }\n        else if (transposeA && !transposeB) {\n            return {\n                a: function () { return b3D.matMul(dy, false, true); },\n                b: function () { return a3D.matMul(dy, false, false); }\n            };\n        }\n        else {\n            return {\n                a: function () { return b3D.matMul(dy, true, true); },\n                b: function () { return dy.matMul(a3D, true, true); }\n            };\n        }\n    };\n    var attrs = { transposeA: transposeA, transposeB: transposeB };\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.batchMatMul(a3D, b3D, transposeA, transposeB);\n        save([a3D, b3D]);\n        return res;\n    }, { a: a3D, b: b3D }, grad, 'BatchMatMul', attrs);\n    return res.reshape(outShape);\n}\n/**\n * Computes the outer product of two vectors, `v1` and `v2`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([3, 4, 5]);\n *\n * tf.outerProduct(a, b).print();\n * ```\n * @param v1 The first vector in the outer product operation.\n * @param v2 The second vector in the outer product operation.\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices'} */\nfunction outerProduct_(v1, v2) {\n    var $v1 = tensor_util_env_1.convertToTensor(v1, 'v1', 'outerProduct');\n    var $v2 = tensor_util_env_1.convertToTensor(v2, 'v2', 'outerProduct');\n    util.assert($v1.rank === 1 && $v2.rank === 1, function () { return \"Error in outerProduct: inputs must be rank 1, but got ranks \" +\n        ($v1.rank + \" and \" + $v2.rank + \".\"); });\n    return $v1.as2D(-1, 1).matMul($v2.as2D(1, -1));\n}\n/**\n * Computes the dot product of two matrices and/or vectors, `t1` and `t2`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor2d([[1, 2], [3, 4]]);\n * const c = tf.tensor2d([[1, 2, 3], [4, 5, 6]]);\n *\n * a.dot(b).print();  // or tf.dot(a, b)\n * b.dot(a).print();\n * b.dot(c).print();\n * ```\n * @param t1 The first tensor in the dot operation.\n * @param t2 The second tensor in the dot operation.\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices'} */\nfunction dot_(t1, t2) {\n    var $t1 = tensor_util_env_1.convertToTensor(t1, 't1', 'dot');\n    var $t2 = tensor_util_env_1.convertToTensor(t2, 't2', 'dot');\n    util.assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), function () { return \"Error in dot: inputs must all be rank 1 or 2, but got ranks \" +\n        ($t1.rank + \" and \" + $t2.rank + \".\"); });\n    var t1Inner = ($t1.rank === 1 ? $t1.size : $t1.shape[1]);\n    var t2Inner = ($t2.rank === 1 ? $t2.size : $t2.shape[0]);\n    util.assert(t1Inner === t2Inner, function () { return \"Error in dot: inner dimensions of inputs must match, but got \" +\n        (t1Inner + \" and \" + t2Inner + \".\"); });\n    if ($t1.rank === 1 && $t2.rank === 1) {\n        return $t1.as2D(1, -1).matMul($t2.as2D(-1, 1)).asScalar();\n    }\n    else if ($t1.rank === 1 && $t2.rank === 2) {\n        return $t1.as2D(1, -1).matMul($t2.as2D($t2.shape[0], $t2.shape[1])).as1D();\n    }\n    else if ($t1.rank === 2 && $t2.rank === 1) {\n        return $t1.matMul($t2.as2D(-1, 1)).as1D();\n    }\n    else {\n        return $t1.matMul($t2.as2D($t2.shape[0], $t2.shape[1]));\n    }\n}\nexports.matMul = operation_1.op({ matMul_: matMul_ });\nexports.dot = operation_1.op({ dot_: dot_ });\nexports.outerProduct = operation_1.op({ outerProduct_: outerProduct_ });\n//# sourceMappingURL=matmul.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/matmul.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/moving_average.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/moving_average.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_util_1 = __webpack_require__(/*! ../tensor_util */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar binary_ops_1 = __webpack_require__(/*! ./binary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Compute the moving average of a variable.\n *\n * Without zeroDebias, the moving average operation is defined by:\n *   `v += delta`\n * where\n *   `delta = (1 - decay) * (x - v)`\n *\n * With zeroDebias (default), the `delta` term is scaled to debias the\n * effect of the (assumed) zero-initialization of `v`.\n *   `delta /= (1 - decay ^ step)`\n *\n * For more details on the zero-debiasing algorithm, see:\n *   https://arxiv.org/abs/1412.6980\n *\n * Note that this function is completely stateless and does not keep track of\n * step count. The step count needs to be maintained by the caller and passed\n * in as `step`.\n *\n * @param v The current moving average value.\n * @param x New input value, must have the same shape and dtype as `v`.\n * @param decay The decay factor. Typical values are 0.95 and 0.99.\n * @param step Step count.\n * @param zeroDebias: Whether zeroDebias is to be performed (default: `true`).\n * @returns The new moving average value.\n */\n/** @doc {heading: 'Operations', subheading: 'Moving Average'} */\nfunction movingAverage_(v, x, decay, step, zeroDebias) {\n    if (zeroDebias === void 0) { zeroDebias = true; }\n    var $v = tensor_util_env_1.convertToTensor(v, 'v', 'movingAverage');\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'movingAverage');\n    var $decay = tensor_util_env_1.convertToTensor(decay, 'decay', 'movingAverage');\n    tensor_util_1.assertTypesMatch($v, $x);\n    util.assert(util.arraysEqual($v.shape, $x.shape), function () { return 'Shape mismatch in v and x'; });\n    var one = tensor_ops_1.scalar(1);\n    var oneMinusDecay = one.sub($decay);\n    var update = $x.sub($v).mul(oneMinusDecay);\n    if (zeroDebias) {\n        util.assert(step != null, function () { return 'When using zeroDebias: true, step is required.'; });\n        var $step = tensor_util_env_1.convertToTensor(step, 'step', 'movingAverage');\n        update = update.div(one.sub(binary_ops_1.pow($decay, $step)));\n    }\n    return $v.add(update);\n}\nexports.movingAverage = operation_1.op({ movingAverage_: movingAverage_ });\n//# sourceMappingURL=moving_average.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/moving_average.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js":
/*!*************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar axis_util = __webpack_require__(/*! ./axis_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Computes the norm of scalar, vectors, and matrices.\n * This function can compute several different vector norms (the 1-norm, the\n * Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0)\n * and matrix norms (Frobenius, 1-norm, and inf-norm).\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.norm().print();  // or tf.norm(x)\n * ```\n *\n * @param x The input array.\n * @param ord Optional. Order of the norm. Supported norm types are\n * following:\n *\n *  | ord        | norm for matrices         | norm for vectors\n *  |------------|---------------------------|---------------------\n *  |'euclidean' |Frobenius norm             |2-norm\n *  |'fro'       |Frobenius norm\t           |\n *  |Infinity    |max(sum(abs(x), axis=1))   |max(abs(x))\n *  |-Infinity   |min(sum(abs(x), axis=1))   |min(abs(x))\n *  |1           |max(sum(abs(x), axis=0))   |sum(abs(x))\n *  |2           |                           |sum(abs(x)^2)^1/2*\n *\n * @param axis Optional. If axis is null (the default), the input is\n * considered a vector and a single vector norm is computed over the entire\n * set of values in the Tensor, i.e. norm(x, ord) is equivalent\n * to norm(x.reshape([-1]), ord). If axis is a integer, the input\n * is considered a batch of vectors, and axis determines the axis in x\n * over which to compute vector norms. If axis is a 2-tuple of integer it is\n * considered a batch of matrices and axis determines the axes in NDArray\n * over which to compute a matrix norm.\n * @param keepDims Optional. If true, the norm have the same dimensionality\n * as the input.\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices'} */\nfunction norm_(x, ord, axis, keepDims) {\n    if (ord === void 0) { ord = 'euclidean'; }\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    x = tensor_util_env_1.convertToTensor(x, 'x', 'norm');\n    var norm = normImpl(x, ord, axis);\n    var keepDimsShape = norm.shape;\n    if (keepDims) {\n        var axes = util_1.parseAxisParam(axis, x.shape);\n        keepDimsShape = axis_util.expandShapeToKeepDim(norm.shape, axes);\n    }\n    return norm.reshape(keepDimsShape);\n}\nfunction normImpl(x, p, axis) {\n    if (axis === void 0) { axis = null; }\n    if (x.rank === 0) {\n        return x.abs();\n    }\n    // consider vector when no axis is specified\n    if (x.rank !== 1 && axis === null) {\n        return normImpl(x.reshape([-1]), p, axis);\n    }\n    // vector\n    if (x.rank === 1 || typeof axis === 'number' ||\n        Array.isArray(axis) && axis.length === 1) {\n        if (p === 1) {\n            return x.abs().sum(axis);\n        }\n        if (p === Infinity) {\n            return x.abs().max(axis);\n        }\n        if (p === -Infinity) {\n            return x.abs().min(axis);\n        }\n        if (p === 'euclidean' || p === 2) {\n            // norm(x, 2) = sum(abs(xi) ^ 2) ^ 1/2\n            return x.abs().pow(tensor_ops_1.scalar(2, 'int32')).sum(axis).sqrt();\n        }\n        throw new Error(\"Error in norm: invalid ord value: \" + p);\n    }\n    // matrix (assumption axis[0] < axis[1])\n    if (Array.isArray(axis) && axis.length === 2) {\n        if (p === 1) {\n            return x.abs().sum(axis[0]).max(axis[1] - 1);\n        }\n        if (p === Infinity) {\n            return x.abs().sum(axis[1]).max(axis[0]);\n        }\n        if (p === -Infinity) {\n            return x.abs().sum(axis[1]).min(axis[0]);\n        }\n        if (p === 'fro' || p === 'euclidean') {\n            // norm(x) = sqrt(sum(pow(x, 2)))\n            return x.square().sum(axis).sqrt();\n        }\n        throw new Error(\"Error in norm: invalid ord value: \" + p);\n    }\n    throw new Error(\"Error in norm: invalid axis: \" + axis);\n}\nexports.norm = operation_1.op({ norm_: norm_ });\n//# sourceMappingURL=norm.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\n/**\n * Used for wrapping functions that perform math operations on\n * Tensors. The function will be wrapped in a named scope that cleans all\n * memory usage after the function is done.\n */\nfunction op(f) {\n    var keys = Object.keys(f);\n    if (keys.length !== 1) {\n        throw new Error(\"Please provide an object with a single key \" +\n            \"(operation name) mapping to a function. Got an object with \" +\n            (keys.length + \" keys.\"));\n    }\n    var opName = keys[0];\n    var fn = f[opName];\n    // Strip the underscore from the end of the function name.\n    if (opName.endsWith('_')) {\n        opName = opName.substring(0, opName.length - 1);\n    }\n    // tslint:disable-next-line:no-any\n    var f2 = function () {\n        var args = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            args[_i] = arguments[_i];\n        }\n        engine_1.ENGINE.startScope(opName);\n        try {\n            var result = fn.apply(void 0, args);\n            if (result instanceof Promise) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            engine_1.ENGINE.endScope(result);\n            return result;\n        }\n        catch (ex) {\n            engine_1.ENGINE.endScope(null);\n            throw ex;\n        }\n    };\n    Object.defineProperty(f2, 'name', { value: opName, configurable: true });\n    // tslint:disable-next-line:no-any\n    return f2;\n}\nexports.op = op;\n//# sourceMappingURL=operation.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js":
/*!************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction __export(m) {\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\n}\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// Modularized ops.\nvar square_1 = __webpack_require__(/*! ./square */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/square.js\");\nexports.square = square_1.square;\nvar squared_difference_1 = __webpack_require__(/*! ./squared_difference */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js\");\nexports.squaredDifference = squared_difference_1.squaredDifference;\n__export(__webpack_require__(/*! ./batchnorm */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js\"));\n__export(__webpack_require__(/*! ./boolean_mask */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/boolean_mask.js\"));\n__export(__webpack_require__(/*! ./complex_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/complex_ops.js\"));\n__export(__webpack_require__(/*! ./concat_split */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/concat_split.js\"));\n// Selectively exporting to avoid exposing gradient ops.\nvar conv_1 = __webpack_require__(/*! ./conv */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/conv.js\");\nexports.conv1d = conv_1.conv1d;\nexports.conv2d = conv_1.conv2d;\nexports.conv3d = conv_1.conv3d;\nexports.depthwiseConv2d = conv_1.depthwiseConv2d;\nexports.separableConv2d = conv_1.separableConv2d;\nexports.conv2dTranspose = conv_1.conv2dTranspose;\nexports.conv3dTranspose = conv_1.conv3dTranspose;\n__export(__webpack_require__(/*! ./matmul */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/matmul.js\"));\n__export(__webpack_require__(/*! ./reverse */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js\"));\n__export(__webpack_require__(/*! ./pool */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/pool.js\"));\n__export(__webpack_require__(/*! ./slice */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js\"));\n__export(__webpack_require__(/*! ./unary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/unary_ops.js\"));\n__export(__webpack_require__(/*! ./reduction_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/reduction_ops.js\"));\n__export(__webpack_require__(/*! ./compare */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/compare.js\"));\n__export(__webpack_require__(/*! ./binary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js\"));\n__export(__webpack_require__(/*! ./relu_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/relu_ops.js\"));\n__export(__webpack_require__(/*! ./logical_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/logical_ops.js\"));\n__export(__webpack_require__(/*! ./array_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js\"));\n__export(__webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\"));\n__export(__webpack_require__(/*! ./transpose */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js\"));\n__export(__webpack_require__(/*! ./softmax */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js\"));\n__export(__webpack_require__(/*! ./lrn */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/lrn.js\"));\n__export(__webpack_require__(/*! ./norm */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js\"));\n__export(__webpack_require__(/*! ./segment_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/segment_ops.js\"));\n__export(__webpack_require__(/*! ./lstm */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/lstm.js\"));\n__export(__webpack_require__(/*! ./moving_average */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/moving_average.js\"));\n__export(__webpack_require__(/*! ./strided_slice */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js\"));\n__export(__webpack_require__(/*! ./topk */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/topk.js\"));\n__export(__webpack_require__(/*! ./scatter_nd */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd.js\"));\n__export(__webpack_require__(/*! ./spectral_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/spectral_ops.js\"));\n__export(__webpack_require__(/*! ./sparse_to_dense */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js\"));\n__export(__webpack_require__(/*! ./gather_nd */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd.js\"));\n__export(__webpack_require__(/*! ./diag */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/diag.js\"));\n__export(__webpack_require__(/*! ./dropout */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js\"));\n__export(__webpack_require__(/*! ./signal_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops.js\"));\n__export(__webpack_require__(/*! ./in_top_k */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/in_top_k.js\"));\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nexports.op = operation_1.op;\n// Second level exports.\nvar losses = __webpack_require__(/*! ./loss_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/loss_ops.js\");\nexports.losses = losses;\nvar linalg = __webpack_require__(/*! ./linalg_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/linalg_ops.js\");\nexports.linalg = linalg;\nvar image = __webpack_require__(/*! ./image_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/image_ops.js\");\nexports.image = image;\nvar spectral = __webpack_require__(/*! ./spectral_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/spectral_ops.js\");\nexports.spectral = spectral;\nvar fused = __webpack_require__(/*! ./fused_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js\");\nexports.fused = fused;\nvar signal = __webpack_require__(/*! ./signal_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops.js\");\nexports.signal = signal;\n//# sourceMappingURL=ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/pool.js":
/*!*************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/pool.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar array_ops_1 = __webpack_require__(/*! ./array_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js\");\nvar conv_util = __webpack_require__(/*! ./conv_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Computes the 2D max pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\nfunction maxPoolImpl_(x, filterSize, strides, dilations, pad, dimRoundingMode) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'maxPool');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in maxPool: input must be rank 4 but got rank \" + x4D.rank + \".\"; });\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in maxPool: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in maxPool: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computePool2DInfo(x4D.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n        util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n        return $x.clone();\n    }\n    var grad = function (dy, saved) {\n        var x4D = saved[0], y = saved[1];\n        return {\n            x: function () { return maxPoolBackprop(dy, x4D, y, filterSize, strides, dilations, pad); }\n        };\n    };\n    var inputsToSave = [x4D];\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.maxPool(x4D, convInfo);\n        save([x4D, y]);\n        return y;\n    }, { x: x4D }, grad, 'MaxPool', convInfo, inputsToSave);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes the 2D max pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction maxPool_(x, filterSize, strides, pad, dimRoundingMode) {\n    return maxPoolImpl_(x, filterSize, strides, 1, pad, dimRoundingMode);\n}\n/**\n * Computes the 2D average pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\nfunction avgPoolImpl_(x, filterSize, strides, dilations, pad, dimRoundingMode) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'avgPool', 'float32');\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in avgPool: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    util.assert(x4D.rank === 4, function () { return \"Error in avgPool: x must be rank 4 but got rank \" + x4D.rank + \".\"; });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in avgPool: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computePool2DInfo(x4D.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n        util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n        return $x.clone();\n    }\n    var grad = function (dy) {\n        return {\n            x: function () { return avgPoolBackprop(dy, x4D, filterSize, strides, dilations, pad); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.avgPool(x4D, convInfo); }, { x: x4D }, grad, 'AvgPool', convInfo);\n    res = res.cast($x.dtype);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes the 2D average pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction avgPool_(x, filterSize, strides, pad, dimRoundingMode) {\n    return avgPoolImpl_(x, filterSize, strides, 1, pad, dimRoundingMode);\n}\n/**\n * Performs an N-D pooling operation\n *\n * @param input The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param windowShape The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param poolingType The type of pooling, either 'max' or 'avg'.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilationRate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction pool_(input, windowShape, poolingType, pad, dilations, strides) {\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    if (strides == null) {\n        strides = 1;\n    }\n    if (pad === 0) {\n        pad = 'valid';\n    }\n    var $x = tensor_util_env_1.convertToTensor(input, 'x', 'maxPool');\n    var x4D = $x;\n    var reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = $x.as4D(1, $x.shape[0], $x.shape[1], $x.shape[2]);\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in pool: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    var convInfo = conv_util.computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad);\n    var dilation = [convInfo.dilationHeight, convInfo.dilationWidth];\n    // The following implementation does batchToSpace(pool(spaceToBatch(x)))\n    // whenever dilation > 1 since the TF kernels do not support dilation > 1.\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L1037\n    var basePadding;\n    if (pad === 'same') {\n        basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);\n    }\n    else {\n        basePadding = [[0, 0], [0, 0]];\n    }\n    var isDilationOne = dilation[0] === 1 && dilation[1] === 1;\n    var _a = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding), adjustedPadding = _a[0], adjustedCrops = _a[1];\n    var convertedPad = isDilationOne ? pad : 'valid';\n    var convertedX = isDilationOne ? x4D : array_ops_1.spaceToBatchND(x4D, dilation, adjustedPadding);\n    var forwardOp = poolingType === 'avg' ?\n        function () { return avgPoolImpl_(convertedX, windowShape, strides, 1 /* dilation */, convertedPad); } :\n        function () { return maxPoolImpl_(convertedX, windowShape, strides, 1 /* dilation */, convertedPad); };\n    var y = forwardOp();\n    var res = isDilationOne ? y : array_ops_1.batchToSpaceND(y, dilation, adjustedCrops);\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n/**\n * Computes the backprop of a 2D max pool.\n *\n * @param dy The dy error, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param input The original input image, of rank 4, of shape\n *     [batchSize, height, width, channels].\n * @param output The original output image, of rank 4, of shape\n *     [batchSize, outHeight, outWidth, channels].\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. The\n *     rounding mode used when computing output dimensions if pad is a\n *     number. If none is provided, it will not round and error if the output\n *     is of fractional size.\n */\nfunction maxPoolBackprop(dy, input, output, filterSize, strides, dilations, pad, dimRoundingMode) {\n    var $dy = tensor_util_env_1.convertToTensor(dy, 'dy', 'maxPoolBackprop');\n    var $input = tensor_util_env_1.convertToTensor(input, 'input', 'maxPoolBackprop');\n    var $output = tensor_util_env_1.convertToTensor(output, 'output', 'maxPoolBackprop');\n    util.assert($input.rank === $dy.rank, function () { return \"Rank of input (\" + $input.rank + \") does not match rank of dy \" +\n        (\"(\" + $dy.rank + \")\"); });\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () {\n        return 'Error in maxPoolBackProp: Either strides or dilations must be 1. ' +\n            (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\");\n    });\n    util.assert($dy.rank === 4, function () { return \"Error in maxPoolBackprop: dy must be rank 4 but got rank \" +\n        ($dy.rank + \".\"); });\n    util.assert($input.rank === 4, function () { return \"Error in maxPoolBackprop: input must be rank 4 but got rank \" +\n        ($input.rank + \".\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in maxPoolBackprop: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computePool2DInfo($input.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.maxPoolBackprop($dy, $input, $output, convInfo); }, { $dy: $dy, $input: $input });\n    return res;\n}\n/**\n * Computes the backprop of an 2D avg pool.\n *\n * @param dy The dy error, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param input The input image, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n */\nfunction avgPoolBackprop(dy, input, filterSize, strides, dilations, pad) {\n    var $dy = tensor_util_env_1.convertToTensor(dy, 'dy', 'avgPoolBackprop');\n    var $input = tensor_util_env_1.convertToTensor(input, 'input', 'avgPoolBackprop');\n    util.assert($input.rank === $dy.rank, function () { return \"Rank of input (\" + $input.rank + \") does not match rank of dy (\" + $dy.rank + \")\"; });\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () {\n        return 'Error in avgPoolBackprop: Either strides or dilations must be 1. ' +\n            (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\");\n    });\n    var input4D = $input;\n    var dy4D = $dy;\n    var reshapedTo4D = false;\n    if ($input.rank === 3) {\n        reshapedTo4D = true;\n        input4D = $input.as4D(1, $input.shape[0], $input.shape[1], $input.shape[2]);\n        dy4D = $dy.as4D(1, $dy.shape[0], $dy.shape[1], $dy.shape[2]);\n    }\n    util.assert(dy4D.rank === 4, function () { return \"Error in avgPoolBackprop: dy must be rank 4 but got rank \" +\n        (dy4D.rank + \".\"); });\n    util.assert(input4D.rank === 4, function () { return \"Error in avgPoolBackprop: input must be rank 4 but got rank \" +\n        (input4D.rank + \".\"); });\n    var convInfo = conv_util.computePool2DInfo(input4D.shape, filterSize, strides, dilations, pad);\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.avgPoolBackprop(dy4D, input4D, convInfo); }, { dy4D: dy4D, input4D: input4D });\n    if (reshapedTo4D) {\n        return res.as3D(res.shape[1], res.shape[2], res.shape[3]);\n    }\n    return res;\n}\n// Helper function to compute crops and paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/array_ops.py#L2184\nfunction requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {\n    var padStart = basePadding.map(function (b) { return b[0]; });\n    var origPadEnd = basePadding.map(function (b) { return b[1]; });\n    var fullInputShape = inputShape.concat(padStart, origPadEnd);\n    var padEndExtra = blockShape.map(function (b, i) { return (b - fullInputShape[i] % b) % b; });\n    var padEnd = origPadEnd.map(function (s, i) { return s + padEndExtra[i]; });\n    var paddings = blockShape.map(function (_, i) { return [padStart[i], padEnd[i]]; });\n    var crops = blockShape.map(function (_, i) { return [0, padEndExtra[i]]; });\n    return [paddings, crops];\n}\n// Helper function to compute base paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L524\nfunction withSpaceToBatchBasePaddings(filterShape, dilation) {\n    // Spatial dimensions of the filters and the upsampled filters in which we\n    // introduce (rate - 1) zeros between consecutive filter values.\n    var dilatedFilterShape = filterShape.map(function (s, i) {\n        return s + (s - 1) * (dilation[i] - 1);\n    });\n    var padExtraShape = dilatedFilterShape.map(function (s) { return s - 1; });\n    // When padding is odd, we pad more at end, following the same\n    // convention as conv2d.\n    var padExtraStart = padExtraShape.map(function (s) { return Math.floor(s / 2); });\n    var padExtraEnd = padExtraShape.map(function (s, i) { return s - padExtraStart[i]; });\n    return padExtraShape.map(function (_, i) {\n        return [padExtraStart[i], padExtraEnd[i]];\n    });\n}\n/**\n * Computes the 3D average pooling.\n *\n * ```js\n * const x = tf.tensor5d([1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 2, 2, 1]);\n * const result = tf.avgPool3d(x, 2, 1, 'valid');\n * result.print();\n * ```\n *\n * @param x The input tensor, of rank 5 or rank 4 of shape\n *     `[batch, depth, height, width, inChannels]`.\n * @param filterSize The filter size:\n *     `[filterDepth, filterHeight, filterWidth]`.\n *     If `filterSize` is a single number,\n *     then `filterDepth == filterHeight == filterWidth`.\n * @param strides The strides of the pooling:\n *     `[strideDepth, strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideDepth == strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n * @param dataFormat An optional string from: \"NDHWC\", \"NCDHW\". Defaults to\n *     \"NDHWC\". Specify the data format of the input and output data. With the\n *     default format \"NDHWC\", the data is stored in the order of: [batch,\n *     depth, height, width, channels]. Only \"NDHWC\" is currently supported.\n * @param dilations The dilation rates:\n *     `[dilationDepth, dilationHeight, dilationWidth]`\n *     in which we sample input values across the depth, height and width\n *     dimensions in dilated pooling.\n *     Defaults to `[1, 1, 1]`. If `dilations` is a single number,\n *     then `dilationDepth == dilationHeight == dilationWidth`.\n *     If it is greater than 1, then all values of `strides` must be 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction avgPool3d_(x, filterSize, strides, pad, dimRoundingMode, dataFormat, dilations) {\n    if (dataFormat === void 0) { dataFormat = 'NDHWC'; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'avgPool3d', 'float32');\n    var x5D = $x;\n    var reshapedTo5D = false;\n    if ($x.rank === 4) {\n        reshapedTo5D = true;\n        x5D = $x.as5D(1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]);\n    }\n    if (dilations == null) {\n        dilations = [1, 1, 1];\n    }\n    util.assert(x5D.rank === 5, function () { return \"Error in avgPool3d: x must be rank 5 but got rank \" + x5D.rank + \".\"; });\n    util.assert(dataFormat === 'NDHWC', function () { return \"Error in avgPool3d: Only NDHWC is currently supported, \" +\n        (\"but got dataFormat of \" + dataFormat); });\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in avgPool3d: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in avgPool3d: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computePool3DInfo(x5D.shape, filterSize, strides, dilations, pad, dimRoundingMode, dataFormat);\n    var grad = function (dy) {\n        return {\n            x: function () { return avgPool3dBackprop(dy, x5D, filterSize, strides, dilations, pad, dimRoundingMode); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.avgPool3d(x5D, convInfo); }, { x: x5D }, grad);\n    res = res.cast(x5D.dtype);\n    if (reshapedTo5D) {\n        return res.as4D(res.shape[1], res.shape[2], res.shape[3], res.shape[4]);\n    }\n    return res;\n}\n/**\n * Computes the backprop of a 3d avg pool.\n *\n * @param dy The dy error, of rank 5 of shape\n *     [batchSize, depth, height, width, channels].\n * assumed.\n * @param input The original input image, of rank 5 or rank4 of shape\n *     [batchSize, depth, height, width, channels].\n * @param filterSize The filter size:\n *     `[filterDepth, filterHeight, filterWidth]`.\n *     `filterSize` is a single number,\n *     then `filterDepth == filterHeight == filterWidth`.\n * @param strides The strides of the pooling:\n *     `[strideDepth, strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dilations The dilation rates:\n *     `[dilationDepth, dilationHeight, dilationWidth]`\n *     in which we sample input values across the depth, height and width\n *     dimensions in dilated pooling.\n *     Defaults to `[1, 1, 1]`. If `dilations` is a single number,\n *     then `dilationDepth == dilationHeight == dilationWidth`.\n *     If it is greater than 1, then all values of `strides` must be 1.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. The\n *     rounding mode used when computing output dimensions if pad is a\n *     number. If none is provided, it will not round and error if the output\n *     is of fractional size.\n */\nfunction avgPool3dBackprop(dy, input, filterSize, strides, dilations, pad, dimRoundingMode) {\n    var $dy = tensor_util_env_1.convertToTensor(dy, 'dy', 'avgPool3dBackprop');\n    var $input = tensor_util_env_1.convertToTensor(input, 'input', 'avgPool3dBackprop');\n    var dy5D = $dy;\n    var input5D = $input;\n    var reshapedTo5D = false;\n    if ($input.rank === 4) {\n        reshapedTo5D = true;\n        dy5D = $dy.as5D(1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]);\n        input5D = $input.as5D(1, $input.shape[0], $input.shape[1], $input.shape[2], $input.shape[3]);\n    }\n    util.assert(dy5D.rank === 5, function () { return \"Error in avgPool3dBackprop: dy must be rank 5 but got rank \" +\n        (dy5D.rank + \".\"); });\n    util.assert(input5D.rank === 5, function () { return \"Error in avgPool3dBackprop: input must be rank 5 but got rank \" +\n        (input5D.rank + \".\"); });\n    if (dilations == null) {\n        dilations = [1, 1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in avgPool3dBackprop: Either strides or dilations ' +\n        (\"must be 1. Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in maxPool3dBackprop: pad must be an integer when \" +\n            (\"using, dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computePool3DInfo(input5D.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.avgPool3dBackprop(dy5D, input5D, convInfo); }, { dy5D: dy5D, input5D: input5D });\n    if (reshapedTo5D) {\n        return res.as4D(res.shape[1], res.shape[2], res.shape[3], res.shape[4]);\n    }\n    return res;\n}\n/**\n * Computes the 3D max pooling.\n *\n * ```js\n * const x = tf.tensor5d([1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 2, 2, 1]);\n * const result = tf.maxPool3d(x, 2, 1, 'valid');\n * result.print();\n * ```\n *\n * @param x The input tensor, of rank 5 or rank 4 of shape\n *     `[batch, depth, height, width, inChannels]`.\n * @param filterSize The filter size:\n *     `[filterDepth, filterHeight, filterWidth]`.\n *     If `filterSize` is a single number,\n *     then `filterDepth == filterHeight == filterWidth`.\n * @param strides The strides of the pooling:\n *     `[strideDepth, strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideDepth == strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n * @param dataFormat An optional string from: \"NDHWC\", \"NCDHW\". Defaults to\n *     \"NDHWC\". Specify the data format of the input and output data. With the\n *     default format \"NDHWC\", the data is stored in the order of: [batch,\n *     depth, height, width, channels]. Only \"NDHWC\" is currently supported.\n * @param dilations The dilation rates:\n *     `[dilationDepth, dilationHeight, dilationWidth]`\n *     in which we sample input values across the depth, height and width\n *     dimensions in dilated pooling.\n *     Defaults to `[1, 1, 1]`. If `dilations` is a single number,\n *     then `dilationDepth == dilationHeight == dilationWidth`.\n *     If it is greater than 1, then all values of `strides` must be 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Convolution'} */\nfunction maxPool3d_(x, filterSize, strides, pad, dimRoundingMode, dataFormat, dilations) {\n    if (dataFormat === void 0) { dataFormat = 'NDHWC'; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'maxPool3d');\n    var x5D = $x;\n    var reshapedTo5D = false;\n    if ($x.rank === 4) {\n        reshapedTo5D = true;\n        x5D = $x.as5D(1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]);\n    }\n    if (dilations == null) {\n        dilations = [1, 1, 1];\n    }\n    util.assert(x5D.rank === 5, function () { return \"Error in maxPool3d: x must be rank 5 but got rank \" + x5D.rank + \".\"; });\n    util.assert(dataFormat === 'NDHWC', function () { return \"Error in maxPool3d: Only NDHWC is currently supported, \" +\n        (\"but got dataFormat of \" + dataFormat); });\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in maxPool3d: Either strides or dilations must be 1. ' +\n        (\"Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in maxPool3d: pad must be an integer when using, \" +\n            (\"dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computePool3DInfo(x5D.shape, filterSize, strides, dilations, pad, dimRoundingMode, dataFormat);\n    var grad = function (dy, saved) {\n        var x5D = saved[0], y = saved[1];\n        return {\n            x: function () { return maxPool3dBackprop(dy, x5D, y, filterSize, strides, dilations, pad, dimRoundingMode); }\n        };\n    };\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.maxPool3d(x5D, convInfo);\n        save([x5D, y]);\n        return y;\n    }, { x: x5D }, grad);\n    if (reshapedTo5D) {\n        return res.as4D(res.shape[1], res.shape[2], res.shape[3], res.shape[4]);\n    }\n    return res;\n}\n/**\n * Computes the backprop of a 3d max pool.\n *\n * @param dy The dy error, of rank 5 of shape\n *     [batchSize, depth, height, width, channels].\n * assumed.\n * @param input The original input image, of rank 5 or rank 4 of shape\n *     [batchSize, depth, height, width, channels].\n * @param output The original output image, of rank 5 of shape\n *     [batchSize, outDepth, outHeight, outWidth, channels].\n * @param filterSize The filter size:\n *     `[filterDepth, filterHeight, filterWidth]`.\n *     `filterSize` is a single number,\n *     then `filterDepth == filterHeight == filterWidth`.\n * @param strides The strides of the pooling:\n *     `[strideDepth, strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param dilations The dilation rates:\n *     `[dilationDepth, dilationHeight, dilationWidth]`\n *     in which we sample input values across the depth, height and width\n *     dimensions in dilated pooling.\n *     Defaults to `[1, 1, 1]`. If `dilations` is a single number,\n *     then `dilationDepth == dilationHeight == dilationWidth`.\n *     If it is greater than 1, then all values of `strides` must be 1.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. The\n *     rounding mode used when computing output dimensions if pad is a\n *     number. If none is provided, it will not round and error if the output\n *     is of fractional size.\n */\nfunction maxPool3dBackprop(dy, input, output, filterSize, strides, dilations, pad, dimRoundingMode) {\n    var $dy = tensor_util_env_1.convertToTensor(dy, 'dy', 'maxPool3dBackprop');\n    var $input = tensor_util_env_1.convertToTensor(input, 'input', 'maxPool3dBackprop');\n    var $output = tensor_util_env_1.convertToTensor(output, 'output', 'maxPool3dBackprop');\n    var dy5D = $dy;\n    var input5D = $input;\n    var output5D = $output;\n    var reshapedTo5D = false;\n    if ($input.rank === 4) {\n        reshapedTo5D = true;\n        dy5D = $dy.as5D(1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]);\n        input5D = $input.as5D(1, $input.shape[0], $input.shape[1], $input.shape[2], $input.shape[3]);\n        output5D = $output.as5D(1, $output.shape[0], $output.shape[1], $output.shape[2], $output.shape[3]);\n    }\n    util.assert(dy5D.rank === 5, function () { return \"Error in maxPool3dBackprop: dy must be rank 5 but got rank \" +\n        (dy5D.rank + \".\"); });\n    util.assert(input5D.rank === 5, function () { return \"Error in maxPool3dBackprop: input must be rank 5 but got rank \" +\n        (input5D.rank + \".\"); });\n    util.assert(output5D.rank === 5, function () { return \"Error in maxPool3dBackprop: output must be rank 5 but got rank \" +\n        (output5D.rank + \".\"); });\n    if (dilations == null) {\n        dilations = [1, 1, 1];\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () { return 'Error in maxPool3dBackprop: Either strides or dilations ' +\n        (\"must be 1. Got strides \" + strides + \" and dilations '\" + dilations + \"'\"); });\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), function () { return \"Error in maxPool3dBackprop: pad must be an integer when \" +\n            (\"using, dimRoundingMode \" + dimRoundingMode + \" but got pad \" + pad + \".\"); });\n    }\n    var convInfo = conv_util.computePool3DInfo(input5D.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.maxPool3dBackprop(dy5D, input5D, output5D, convInfo); }, { dy5D: dy5D, input5D: input5D });\n    if (reshapedTo5D) {\n        return res.as4D(res.shape[1], res.shape[2], res.shape[3], res.shape[4]);\n    }\n    return res;\n}\nexports.maxPool = operation_1.op({ maxPool_: maxPool_ });\nexports.avgPool = operation_1.op({ avgPool_: avgPool_ });\nexports.pool = operation_1.op({ pool_: pool_ });\nexports.maxPool3d = operation_1.op({ maxPool3d_: maxPool3d_ });\nexports.avgPool3d = operation_1.op({ avgPool3d_: avgPool3d_ });\n//# sourceMappingURL=pool.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/pool.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/rand.js":
/*!*************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/rand.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar seedrandom = __webpack_require__(/*! seedrandom */ \"./node_modules/seedrandom/index.js\");\n// https://en.wikipedia.org/wiki/Marsaglia_polar_method\nvar MPRandGauss = /** @class */ (function () {\n    function MPRandGauss(mean, stdDeviation, dtype, truncated, seed) {\n        this.mean = mean;\n        this.stdDev = stdDeviation;\n        this.dtype = dtype;\n        this.nextVal = NaN;\n        this.truncated = truncated;\n        if (this.truncated) {\n            this.upper = this.mean + this.stdDev * 2;\n            this.lower = this.mean - this.stdDev * 2;\n        }\n        var seedValue = seed ? seed : Math.random();\n        this.random = seedrandom.alea(seedValue.toString());\n    }\n    /** Returns next sample from a Gaussian distribution. */\n    MPRandGauss.prototype.nextValue = function () {\n        if (!isNaN(this.nextVal)) {\n            var value = this.nextVal;\n            this.nextVal = NaN;\n            return value;\n        }\n        var resultX, resultY;\n        var isValid = false;\n        while (!isValid) {\n            var v1 = void 0, v2 = void 0, s = void 0;\n            do {\n                v1 = 2 * this.random() - 1;\n                v2 = 2 * this.random() - 1;\n                s = v1 * v1 + v2 * v2;\n            } while (s >= 1 || s === 0);\n            var mul = Math.sqrt(-2.0 * Math.log(s) / s);\n            resultX = this.mean + this.stdDev * v1 * mul;\n            resultY = this.mean + this.stdDev * v2 * mul;\n            if (!this.truncated || this.isValidTruncated(resultX)) {\n                isValid = true;\n            }\n        }\n        if (!this.truncated || this.isValidTruncated(resultY)) {\n            this.nextVal = this.convertValue(resultY);\n        }\n        return this.convertValue(resultX);\n    };\n    /** Handles proper rounding for non-floating-point numbers. */\n    MPRandGauss.prototype.convertValue = function (value) {\n        if (this.dtype == null || this.dtype === 'float32') {\n            return value;\n        }\n        return Math.round(value);\n    };\n    /** Returns true if less than 2-standard-deviations from the mean. */\n    MPRandGauss.prototype.isValidTruncated = function (value) {\n        return value <= this.upper && value >= this.lower;\n    };\n    return MPRandGauss;\n}());\nexports.MPRandGauss = MPRandGauss;\n// Marsaglia, George, and Wai Wan Tsang. 2000. \"A Simple Method for Generating\n// Gamma Variables.\"\nvar RandGamma = /** @class */ (function () {\n    function RandGamma(alpha, beta, dtype, seed) {\n        this.alpha = alpha;\n        this.beta = 1 / beta; // convert rate to scale parameter\n        this.dtype = dtype;\n        var seedValue = seed ? seed : Math.random();\n        this.randu = seedrandom.alea(seedValue.toString());\n        this.randn = new MPRandGauss(0, 1, dtype, false, this.randu());\n        if (alpha < 1) {\n            this.d = alpha + (2 / 3);\n        }\n        else {\n            this.d = alpha - (1 / 3);\n        }\n        this.c = 1 / Math.sqrt(9 * this.d);\n    }\n    /** Returns next sample from a gamma distribution. */\n    RandGamma.prototype.nextValue = function () {\n        var x2, v0, v1, x, u, v;\n        while (true) {\n            do {\n                x = this.randn.nextValue();\n                v = 1 + (this.c * x);\n            } while (v <= 0);\n            v *= v * v;\n            x2 = x * x;\n            v0 = 1 - (0.331 * x2 * x2);\n            v1 = (0.5 * x2) + (this.d * (1 - v + Math.log(v)));\n            u = this.randu();\n            if (u < v0 || Math.log(u) < v1) {\n                break;\n            }\n        }\n        v = (1 / this.beta) * this.d * v;\n        if (this.alpha < 1) {\n            v *= Math.pow(this.randu(), 1 / this.alpha);\n        }\n        return this.convertValue(v);\n    };\n    /** Handles proper rounding for non-floating-point numbers. */\n    RandGamma.prototype.convertValue = function (value) {\n        if (this.dtype === 'float32') {\n            return value;\n        }\n        return Math.round(value);\n    };\n    return RandGamma;\n}());\nexports.RandGamma = RandGamma;\nvar UniformRandom = /** @class */ (function () {\n    function UniformRandom(min, max, dtype, seed) {\n        var _this = this;\n        if (min === void 0) { min = 0; }\n        if (max === void 0) { max = 1; }\n        /** Handles proper rounding for non floating point numbers. */\n        this.canReturnFloat = function () {\n            return (_this.dtype == null || _this.dtype === 'float32');\n        };\n        this.min = min;\n        this.range = max - min;\n        this.dtype = dtype;\n        if (seed == null) {\n            seed = Math.random();\n        }\n        if (typeof seed === 'number') {\n            seed = seed.toString();\n        }\n        if (!this.canReturnFloat() && this.range <= 1) {\n            throw new Error(\"The difference between \" + min + \" - \" + max + \" <= 1 and dtype is not float\");\n        }\n        this.random = seedrandom.alea(seed);\n    }\n    UniformRandom.prototype.convertValue = function (value) {\n        if (this.canReturnFloat()) {\n            return value;\n        }\n        return Math.round(value);\n    };\n    UniformRandom.prototype.nextValue = function () {\n        return this.convertValue(this.min + this.range * this.random());\n    };\n    return UniformRandom;\n}());\nexports.UniformRandom = UniformRandom;\n//# sourceMappingURL=rand.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/rand.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js":
/*!********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Inputs of size above this threshold will be parallelized by calling multiple\n * shader programs.\n */\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nexports.PARALLELIZE_THRESHOLD = 30;\nfunction computeOptimalWindowSize(inSize) {\n    if (inSize <= exports.PARALLELIZE_THRESHOLD) {\n        return inSize;\n    }\n    return util_1.nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n}\nexports.computeOptimalWindowSize = computeOptimalWindowSize;\n//# sourceMappingURL=reduce_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/reduction_ops.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/reduction_ops.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar gradients_1 = __webpack_require__(/*! ../gradients */ \"./node_modules/@tensorflow/tfjs-core/dist/gradients.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar axis_util = __webpack_require__(/*! ./axis_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Computes the log(sum(exp(elements across the reduction dimensions)).\n *\n * Reduces the input along the dimensions given in `axis`. Unless `keepDims`\n * is true, the rank of the array is reduced by 1 for each entry in `axis`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axis` has no entries, all dimensions are reduced, and an array with a\n * single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.logSumExp().print();  // or tf.logSumExp(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.logSumExp(axis).print();  // or tf.logSumExp(a, axis)\n * ```\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. If null (the default),\n *     reduces all dimensions.\n * @param keepDims If true, retains reduced dimensions with length\n *     of 1. Defaults to false.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction logSumExp_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'logSumExp');\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var xMax = $x.max(axes, true /* keepDims */);\n    var a = $x.sub(xMax);\n    var b = a.exp();\n    var c = b.sum(axes);\n    var d = c.log();\n    var res = xMax.reshape(d.shape).add(d);\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(res.shape, axes);\n        return res.reshape(newShape);\n    }\n    return res;\n}\n/**\n * Computes the sum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If axes has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.sum().print();  // or tf.sum(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.sum(axis).print();  // or tf.sum(x, axis)\n * ```\n *\n * @param x The input tensor to compute the sum over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction sum_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sum');\n    if ($x.dtype === 'bool') {\n        $x = $x.toInt();\n    }\n    var axes = util.parseAxisParam(axis, $x.shape);\n    // Use a custom gradient to bypass 2 gradient backprops since sum is used\n    // extremely often.\n    var customOp = gradients_1.customGrad(function (x) {\n        var permutation = axis_util.getAxesPermutation(axes, x.rank);\n        var reductionAxes = axes;\n        var permutedX = x;\n        if (permutation != null) {\n            permutedX = x.transpose(permutation);\n            reductionAxes = axis_util.getInnerMostAxes(reductionAxes.length, x.rank);\n        }\n        var gradFunc = function (dy) {\n            var expandedDyShape = x.shape.slice();\n            axes.forEach(function (axis) {\n                expandedDyShape[axis] = 1;\n            });\n            var expandedDy = dy.reshape(expandedDyShape);\n            var derX = expandedDy.mul(tensor_ops_1.ones(x.shape, 'float32'));\n            return derX;\n        };\n        var gradInputs = function (dy) {\n            return { x: function () { return gradFunc(dy); } };\n        };\n        var attrs = { axes: reductionAxes };\n        var value = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.sum(permutedX, reductionAxes); }, { x: permutedX }, gradInputs, 'Sum', attrs);\n        if (keepDims) {\n            var newShape = axis_util.expandShapeToKeepDim(value.shape, axes);\n            value = value.reshape(newShape);\n        }\n        return { value: value, gradFunc: gradFunc };\n    });\n    return customOp($x);\n}\n/**\n * Computes the product of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and a\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.prod().print();  // or tf.prod(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.prod(axis).print();  // or tf.prod(x, axis)\n * ```\n *\n * @param x The input tensor to compute the product over. If the dtype is `bool`\n *   it will be converted to `int32` and the output dtype will be `int32`.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction prod_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'prod');\n    if ($x.dtype === 'bool') {\n        $x = $x.toInt();\n    }\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var permutation = axis_util.getAxesPermutation(axes, $x.rank);\n    var reductionAxes = axes;\n    var permutedX = $x;\n    if (permutation != null) {\n        permutedX = $x.transpose(permutation);\n        reductionAxes = axis_util.getInnerMostAxes(reductionAxes.length, $x.rank);\n    }\n    var value = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.prod(permutedX, reductionAxes); }, { permutedX: permutedX });\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(value.shape, axes);\n        value = value.reshape(newShape);\n    }\n    return value;\n}\n/**\n * Computes the mean of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces `x` along the dimensions given in `axis`. Unless `keepDims` is\n * true, the rank of the `tf.Tensor` is reduced by 1 for each entry in `axis`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axis` has no entries, all dimensions are reduced, and a `tf.Tensor` with\n * a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.mean().print();  // or tf.mean(a)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.mean(axis).print();  // or tf.mean(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction mean_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'mean');\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var shapes = axis_util.computeOutAndReduceShapes($x.shape, axes);\n    var reduceShape = shapes[1];\n    var reduceSize = util.sizeFromShape(reduceShape);\n    // Use a custom gradient to bypass 2 gradient backprops since mean is used\n    // extremely often.\n    var customOp = gradients_1.customGrad(function (x) {\n        var reduceSizeScalar = tensor_ops_1.scalar(reduceSize);\n        // Cast if needed.\n        var xReduce = reduceSizeScalar.dtype === x.dtype ? x : x.cast(reduceSizeScalar.dtype);\n        var res = xReduce.div(reduceSizeScalar);\n        var value = res.sum(axis, keepDims);\n        var gradFunc = function (dy) {\n            var expandedDyShape = x.shape.slice();\n            axes.forEach(function (axis) {\n                expandedDyShape[axis] = 1;\n            });\n            var expandedDy = dy.reshape(expandedDyShape);\n            var derX = expandedDy.mul(tensor_ops_1.ones(x.shape, 'float32')).div(reduceSize);\n            return derX;\n        };\n        return { value: value, gradFunc: gradFunc };\n    });\n    return customOp($x);\n}\n/**\n * Gradient helper function for the min and max operations.\n */\nfunction gradForMinAndMax(dy, y, xOrig, origAxes, permutedAxes) {\n    if (y.rank < xOrig.rank) {\n        y = y.reshape(axis_util.expandShapeToKeepDim(y.shape, origAxes));\n    }\n    if (dy.rank < xOrig.rank) {\n        dy = dy.reshape(axis_util.expandShapeToKeepDim(dy.shape, origAxes));\n    }\n    return {\n        x: function () {\n            var dx = dy.mul(xOrig.equal(y).cast(dy.dtype));\n            return permutedAxes == null ? dx : dx.transpose(permutedAxes);\n        }\n    };\n}\n/**\n * Computes the minimum value from the input.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the array is reduced by 1 for each entry in `axes`.\n * If `keepDims` is true, the reduced dimensions are retained with length 1.\n * If `axes` has no entries, all dimensions are reduced, and an array with a\n * single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.min().print();  // or tf.min(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.min(axis).print();  // or tf.min(x, axis)\n * ```\n *\n * @param x The input Tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction min_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'min');\n    var xOrig = $x;\n    var origAxes = util.parseAxisParam(axis, $x.shape);\n    var axes = origAxes;\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var grad = function (dy, saved) {\n        return gradForMinAndMax(dy, saved[1], saved[0], origAxes, permutedAxes);\n    };\n    var inputsToSave = [$x];\n    var outputsToSave = [true];\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.min($x, axes);\n        save([xOrig, y]);\n        return y;\n    }, { x: $x }, grad, 'Min', { axes: axes }, inputsToSave, outputsToSave);\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(res.shape, origAxes);\n        res = res.reshape(newShape);\n    }\n    return res;\n}\n/**\n * Computes the maximum of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.max().print();  // or tf.max(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.max(axis).print();  // or tf.max(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction max_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'max');\n    var xOrig = $x;\n    var origAxes = util.parseAxisParam(axis, $x.shape);\n    var axes = origAxes;\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var grad = function (dy, saved) {\n        return gradForMinAndMax(dy, saved[1], saved[0], origAxes, permutedAxes);\n    };\n    var inputsToSave = [$x];\n    var outputsToSave = [true];\n    var res = engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.max($x, axes);\n        save([xOrig, y]);\n        return y;\n    }, { x: $x }, grad, 'Max', { axes: axes }, inputsToSave, outputsToSave);\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(res.shape, origAxes);\n        res = res.reshape(newShape);\n    }\n    return res;\n}\n/**\n * Returns the indices of the minimum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMin().print();  // or tf.argMin(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMin(axis).print();  // or tf.argMin(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n *\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction argMin_(x, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'argMin');\n    if (axis == null) {\n        axis = 0;\n    }\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return tensor_ops_1.zerosLike($x); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.argMin($x, axes[0]);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Returns the indices of the maximum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMax().print();  // or tf.argMax(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMax(axis).print();  // or tf.argMax(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction argMax_(x, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'argMax');\n    if (axis == null) {\n        axis = 0;\n    }\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { x: function () { return tensor_ops_1.zerosLike($x); } };\n    };\n    var attrs = { axis: axes[0] };\n    var inputsToSave = [$x];\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.argMax($x, axes[0]);\n        save([$x]);\n        return res;\n    }, { x: $x }, grad, 'ArgMax', attrs, inputsToSave);\n}\n/**\n * Computes the logical and of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.all().print();  // or tf.all(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.all(axis).print();  // or tf.all(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction all_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'all', 'bool');\n    var origAxes = util.parseAxisParam(axis, $x.shape);\n    var axes = origAxes;\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.all($x, axes); }, { $x: $x });\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(res.shape, origAxes);\n        return res.reshape(newShape);\n    }\n    return res;\n}\n/**\n * Computes the logical or of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.any().print();  // or tf.any(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.any(axis).print();  // or tf.any(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n */\n/** @doc {heading: 'Operations', subheading: 'Reduction'} */\nfunction any_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'any', 'bool');\n    var origAxes = util.parseAxisParam(axis, $x.shape);\n    var axes = origAxes;\n    var permutedAxes = axis_util.getAxesPermutation(axes, $x.rank);\n    if (permutedAxes != null) {\n        $x = $x.transpose(permutedAxes);\n        axes = axis_util.getInnerMostAxes(axes.length, $x.rank);\n    }\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.any($x, axes); }, { $x: $x });\n    if (keepDims) {\n        var newShape = axis_util.expandShapeToKeepDim(res.shape, origAxes);\n        return res.reshape(newShape);\n    }\n    return res;\n}\n/**\n * Calculates the mean and variance of `x`. The mean and variance are\n * calculated by aggregating the contents of `x` across `axes`. If `x` is\n * 1-D and `axes = [0]` this is just the mean and variance of a vector.\n *\n * @param x The input tensor.\n * @param axis The dimension(s) along with to compute mean and\n *     variance. By default it reduces all dimensions.\n * @param keepDims If true, the moments have the same dimensionality as the\n *     input.\n * @return An object with two keys: `mean` and `variance`.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction moments_(x, axis, keepDims) {\n    if (axis === void 0) { axis = null; }\n    if (keepDims === void 0) { keepDims = false; }\n    x = tensor_util_env_1.convertToTensor(x, 'x', 'moments');\n    var axes = util.parseAxisParam(axis, x.shape);\n    var mean = x.mean(axes, keepDims);\n    var keepDimsShape = mean.shape;\n    if (!keepDims) {\n        keepDimsShape = axis_util.expandShapeToKeepDim(mean.shape, axes);\n    }\n    var devSquared = x.toFloat().sub(mean.reshape(keepDimsShape)).square();\n    var variance = devSquared.mean(axes, keepDims);\n    return { mean: mean, variance: variance };\n}\nexports.all = operation_1.op({ all_: all_ });\n// tslint:disable-next-line:variable-name\nexports.any = operation_1.op({ any_: any_ });\nexports.argMax = operation_1.op({ argMax_: argMax_ });\nexports.argMin = operation_1.op({ argMin_: argMin_ });\nexports.logSumExp = operation_1.op({ logSumExp_: logSumExp_ });\nexports.max = operation_1.op({ max_: max_ });\nexports.mean = operation_1.op({ mean_: mean_ });\nexports.min = operation_1.op({ min_: min_ });\nexports.moments = operation_1.op({ moments_: moments_ });\nexports.sum = operation_1.op({ sum_: sum_ });\nexports.prod = operation_1.op({ prod_: prod_ });\n//# sourceMappingURL=reduction_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reduction_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/relu_ops.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/relu_ops.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar binary_ops_1 = __webpack_require__(/*! ./binary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js\");\nvar broadcast_util_1 = __webpack_require__(/*! ./broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar logical_ops_1 = __webpack_require__(/*! ./logical_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/logical_ops.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar selu_util_1 = __webpack_require__(/*! ./selu_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Computes rectified linear element-wise: `max(x, 0)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.relu().print();  // or tf.relu(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction relu_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'relu');\n    if ($x.dtype === 'bool') {\n        return $x.toInt();\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { x: function () { return dy.mulStrict($x.step().toFloat()); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.relu($x);\n        save([$x]);\n        return res;\n    }, { x: $x }, grad, 'Relu');\n}\n/**\n * Computes rectified linear 6 element-wise: `min(max(x, 0), 6)`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 8]);\n *\n * x.relu6().print();  // or tf.relu6(x)\n * ```\n * @param x The input tensor. If the dtype is `bool`, the output dtype will be\n *     `int32'.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction relu6_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'relu6');\n    if ($x.dtype === 'bool') {\n        return $x.toInt();\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        var mask = $x.lessEqual(6).mul($x.step());\n        return { x: function () { return dy.mulStrict(mask.toFloat()); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.relu6($x);\n        save([$x]);\n        return res;\n    }, { x: $x }, grad, 'Relu6');\n}\n/**\n * Computes exponential linear element-wise: `x > 0 ? e ^ x - 1 : 0`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 1, -3, 2]);\n *\n * x.elu().print();  // or tf.elu(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction elu_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'elu');\n    var grad = function (dy, saved) {\n        var y = saved[0];\n        return {\n            $x: function () {\n                return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.eluDer(dy, y); }, { dy: dy, y: y });\n            }\n        };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.elu($x);\n        save([y]);\n        return y;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes scaled exponential linear element-wise.\n *\n * `x < 0 ? scale * alpha * (exp(x) - 1) : x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.selu().print();  // or tf.selu(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction selu_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'selu');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () {\n                var mask = $x.greater(tensor_ops_1.scalar(0));\n                var scaleAlpha = tensor_ops_1.scalar(selu_util_1.SELU_SCALEALPHA);\n                var scale = tensor_ops_1.scalar(selu_util_1.SELU_SCALE);\n                var greaterThanZeroDer = dy.mul(scale);\n                var lessEqualZeroDer = dy.mul(scaleAlpha).mul($x.toFloat().exp());\n                return logical_ops_1.where(mask, greaterThanZeroDer, lessEqualZeroDer);\n            }\n        };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.selu($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes leaky rectified linear element-wise.\n *\n * See\n * [http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf](\n *     http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf)\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.leakyRelu(0.1).print();  // or tf.leakyRelu(x, 0.1)\n * ```\n * @param x The input tensor.\n * @param alpha The scaling factor for negative values, defaults to 0.2.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction leakyRelu_(x, alpha) {\n    if (alpha === void 0) { alpha = 0.2; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'leakyRelu');\n    return binary_ops_1.maximum(tensor_ops_1.scalar(alpha).mul($x), $x);\n}\n/**\n * Computes leaky rectified linear element-wise with parametric alphas.\n *\n * `x < 0 ? alpha * x : f(x) = x`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n * const alpha = tf.scalar(0.1);\n *\n * x.prelu(alpha).print();  // or tf.prelu(x, alpha)\n * ```\n * @param x The input tensor.\n * @param alpha Scaling factor for negative values.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction prelu_(x, alpha) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'prelu');\n    var $alpha = tensor_util_env_1.convertToTensor(alpha, 'alpha', 'prelu');\n    var grad = function (dy, saved) {\n        var $x = saved[0], $alpha = saved[1];\n        var mask = $x.greater(0);\n        return {\n            x: function () { return logical_ops_1.where(mask, dy, dy.mul($alpha)); },\n            alpha: function () {\n                var res = logical_ops_1.where(mask, tensor_ops_1.zerosLike(dy), dy.mul($x));\n                var reduceAxes = broadcast_util_1.getReductionAxes($alpha.shape, dy.shape);\n                if (reduceAxes.length > 0) {\n                    res = res.sum(reduceAxes);\n                }\n                return res.reshape($alpha.shape);\n            }\n        };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.prelu($x, $alpha);\n        save([$x, $alpha]);\n        return res;\n    }, { x: $x, alpha: $alpha }, grad, 'Prelu');\n}\nexports.elu = operation_1.op({ elu_: elu_ });\nexports.leakyRelu = operation_1.op({ leakyRelu_: leakyRelu_ });\nexports.prelu = operation_1.op({ prelu_: prelu_ });\nexports.relu = operation_1.op({ relu_: relu_ });\nexports.relu6 = operation_1.op({ relu6_: relu6_ });\nexports.selu = operation_1.op({ selu_: selu_ });\n//# sourceMappingURL=relu_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/relu_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Reverses a `tf.Tensor1D`.\n *\n * @param x The input tensor.\n */\nfunction reverse1d_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reverse');\n    util.assert($x.rank === 1, function () { return \"Error in reverse1D: x must be rank 1 but got rank \" + $x.rank + \".\"; });\n    return exports.reverse($x, 0);\n}\n/**\n * Reverses a `tf.Tensor2D` along a specified axis.\n *\n * @param x The input tensor.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\nfunction reverse2d_(x, axis) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reverse');\n    util.assert($x.rank === 2, function () { return \"Error in reverse2D: x must be rank 2 but got rank \" + $x.rank + \".\"; });\n    return exports.reverse($x, axis);\n}\n/**\n * Reverses a `tf.Tensor3D` along a specified axis.\n *\n * @param x The input tensor.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\nfunction reverse3d_(x, axis) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reverse');\n    util.assert($x.rank === 3, function () { return \"Error in reverse3D: x must be rank 3 but got rank \" + $x.rank + \".\"; });\n    return exports.reverse($x, axis);\n}\n/**\n * Reverses a `tf.Tensor4D` along a specified axis.\n *\n * @param x The input tensor.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\nfunction reverse4d_(x, axis) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reverse');\n    util.assert($x.rank === 4, function () { return \"Error in reverse4D: x must be rank 4 but got rank \" + $x.rank + \".\"; });\n    return exports.reverse($x, axis);\n}\n/**\n * Reverses a `tf.Tensor` along a specified axis.\n *\n * Also available are stricter rank-specific methods that assert that `x` is\n * of the given rank:\n *   - `tf.reverse1d`\n *   - `tf.reverse2d`\n *   - `tf.reverse3d`\n *   - `tf.reverse4d`\n *\n * Except `tf.reverse1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.reverse().print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * const axis = 1;\n * x.reverse(axis).print();\n * ```\n * @param x The input tensor to be reversed.\n * @param axis The set of dimensions to reverse. Must be in the\n *     range [-rank(x), rank(x)). Defaults to all axes.\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction reverse_(x, axis) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reverse');\n    if ($x.rank === 0) {\n        return $x.clone();\n    }\n    var axes = util.parseAxisParam(axis, $x.shape);\n    var grad = function (dy) {\n        return { $x: function () { return dy.reverse(axes); } };\n    };\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.reverse($x, axes); }, { $x: $x }, grad);\n    return res.reshapeAs($x);\n}\nexports.reverse = operation_1.op({ reverse_: reverse_ });\nexports.reverse1d = operation_1.op({ reverse1d_: reverse1d_ });\nexports.reverse2d = operation_1.op({ reverse2d_: reverse2d_ });\nexports.reverse3d = operation_1.op({ reverse3d_: reverse3d_ });\nexports.reverse4d = operation_1.op({ reverse4d_: reverse4d_ });\n//# sourceMappingURL=reverse.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar scatter_nd_util = __webpack_require__(/*! ./scatter_nd_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js\");\n/**\n * Creates a new tensor by applying sparse updates to individual\n * values or slices within a zero tensor of the given shape tensor according to\n * indices. This operator is the inverse of the `tf.gatherND` operator which\n * extracts values or slices from a given tensor.\n *\n * ```js\n * const indices = tf.tensor2d([4, 3, 1, 7], [4, 1], 'int32');\n * const updates = tf.tensor1d([9, 10, 11, 12]);\n * const shape = [8];\n * tf.scatterND(indices, updates, shape).print() //[0, 11, 0, 10, 9, 0, 0, 12]\n * ```\n *\n * @param indices The tensor contains the indices into the output tensor.\n * @param updates The tensor contains the value for the indices.\n * @param shape: The shape of the output tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Slicing and Joining'} */\nfunction scatterND_(indices, updates, shape) {\n    var $indices = tensor_util_env_1.convertToTensor(indices, 'indices', 'scatterND', 'int32');\n    var $updates = tensor_util_env_1.convertToTensor(updates, 'updates', 'scatterND');\n    scatter_nd_util.validateInput($updates, $indices, shape);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.scatterND($indices, $updates, shape); }, { indices: $indices, updates: $updates }, null /* backward */, 'ScatterNd', { shape: shape });\n}\nexports.scatterND = operation_1.op({ scatterND_: scatterND_ });\n//# sourceMappingURL=scatter_nd.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js":
/*!************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nfunction validateUpdateShape(shape, indices, updates) {\n    var sliceDim = (indices.rank > 1) ? indices.shape[indices.rank - 1] : 1;\n    var batchDim = (indices.rank > 1) ? indices.rank - 1 : 1;\n    var shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' +\n        (\"shape[sliceDim:], got updates.shape: \" + updates.shape) +\n        (\", indices.shape: \" + indices.shape + \", shape: \" + shape) +\n        (\", sliceDim: \" + sliceDim + \", and batchDim: \" + batchDim + \".\");\n    if (updates.rank < batchDim) {\n        throw new Error(shapeError + (\" update.rank < \" + batchDim + \". \"));\n    }\n    if (shape.length < sliceDim + (updates.rank - batchDim)) {\n        throw new Error(shapeError +\n            (\" Output shape length < \" + (sliceDim + (updates.rank - batchDim))));\n    }\n    if (updates.rank !== batchDim + shape.length - sliceDim) {\n        throw new Error(shapeError + (\" update.rank != \" + (batchDim + shape.length - sliceDim)));\n    }\n    for (var d = 0; d < batchDim; ++d) {\n        if (updates.shape[d] !== indices.shape[d]) {\n            throw new Error(shapeError +\n                (\" updates.shape[\" + d + \"] (\" + updates.shape[d] + \") != indices.shape[\" + d + \"] (\" + indices.shape[d] + \").\"));\n        }\n    }\n    for (var d = 0; d < updates.rank - batchDim; ++d) {\n        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n            throw new Error(shapeError +\n                (\" updates.shape[\" + (d + batchDim) + \"] (\" + updates.shape[d + batchDim] + \") != shape[\" + (d + batchDim) + \"] (\" + shape[d + batchDim] + \")\"));\n        }\n    }\n}\nexports.validateUpdateShape = validateUpdateShape;\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nfunction validateInput(updates, indices, shape) {\n    if (indices.rank < 1) {\n        throw new Error('tf.scatterND() expects the indices to be rank 1 or higher,' +\n            (\" but the rank was \" + indices.rank + \".\"));\n    }\n    if (updates.rank < 1) {\n        throw new Error('tf.scatterND() expects the updates to be rank 1 or higher,' +\n            (\" but the rank was \" + updates.rank + \".\"));\n    }\n    if (indices.dtype !== 'int32') {\n        throw new Error(\"The dtype of 'indices' should be int32, but got dtype: \" + indices.dtype);\n    }\n    if (shape.length < 1) {\n        throw new Error(\"Output rank must be greater or equal to 1, but got shape: \" + shape);\n    }\n    if (shape.length === 0) {\n        if (indices.size === 0) {\n            throw new Error(\"Indices specified for empty output. indices shape: \" + indices.shape);\n        }\n        if (updates.size === 0) {\n            throw new Error(\"Updates specified for empty output. updates shape: \" + updates.shape);\n        }\n    }\n    validateUpdateShape(shape, indices, updates);\n}\nexports.validateInput = validateInput;\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nfunction calculateShapes(updates, indices, shape) {\n    // Calculate the number of dimensions in indices\n    var indicesRank = indices.shape.length;\n    var sliceRank = (indicesRank > 1) ? indices.shape[indicesRank - 1] : 1;\n    // Calculate the number of elements that make up each slice of our updated\n    // tensor. This allows us to work with flattened tensors and copy over whole\n    // slices at a time.\n    var totalNd = shape.length;\n    var sliceSize = 1;\n    for (var i = sliceRank; i < totalNd; ++i) {\n        sliceSize *= shape[i];\n    }\n    var safeSliceDim = (sliceRank < 1) ? 1 : sliceRank;\n    var numUpdates = util_1.sizeFromShape(indices.shape) / safeSliceDim;\n    var strides = util_1.computeStrides(shape.slice(0, sliceRank)).concat([1]);\n    var outputSize = util_1.sizeFromShape(shape);\n    return { sliceRank: sliceRank, numUpdates: numUpdates, sliceSize: sliceSize, strides: strides, outputSize: outputSize };\n}\nexports.calculateShapes = calculateShapes;\n//# sourceMappingURL=scatter_nd_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/segment_ops.js":
/*!********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/segment_ops.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar array_ops_1 = __webpack_require__(/*! ./array_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops.js\");\nvar axis_util_1 = __webpack_require__(/*! ./axis_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js\");\nvar binary_ops_1 = __webpack_require__(/*! ./binary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js\");\nvar compare_1 = __webpack_require__(/*! ./compare */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/compare.js\");\nvar logical_ops_1 = __webpack_require__(/*! ./logical_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/logical_ops.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar segment_util_1 = __webpack_require__(/*! ./segment_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Computes the sum along segments of a `tf.Tensor`.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const segmentIds = tf.tensor1d([1, 2, 0, 1], 'int32');\n * const numSegments = 3;\n *\n * x.unsortedSegmentSum(segmentIds, numSegments).print()\n * //or tf.unsortedSegmentSum(x, segmentIds, numSegments)\n * ```\n * @param x The `tf.Tensor` that will be summed along its segments.\n * @param segmentIds A `tf.Tensor1D` whose rank is equal to the rank of `x`'s\n * dimension along the `axis`.  Maps each element of `x` to a segment.\n * @param numSegments The number of distinct `segmentIds`.\n */\n/** @doc {heading: 'Operations', subheading: 'Segment'} */\nfunction unsortedSegmentSum_(x, segmentIds, numSegments) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'unsortedSegmentSum');\n    var $segmentIds = tensor_util_env_1.convertToTensor(segmentIds, 'segmentIds', 'unsortedSegmentSum', 'int32');\n    util_1.assert(util_1.isInt(numSegments), function () { return 'numSegments must be of dtype int'; });\n    var gradFunc = function (dy, saved) {\n        var $segmentIds = saved[0];\n        var derX = function () {\n            return gatherDropNegatives(dy, $segmentIds);\n        };\n        return { $x: derX };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.unsortedSegmentSum($x, $segmentIds, numSegments);\n        save([$segmentIds]);\n        return res;\n    }, { $x: $x }, gradFunc);\n}\n/**\n * Gather slices from tensor `x`'s axis `axis` according to `indices`.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const indices = tf.tensor1d([1, 3, 3], 'int32');\n *\n * x.gather(indices).print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const indices = tf.tensor1d([1, 1, 0], 'int32');\n *\n * x.gather(indices).print();\n * ```\n * @param x The input tensor whose slices to be gathered.\n * @param indices The indices of the values to extract.\n * @param axis The axis over which to select values. Defaults to 0.\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction gather_(x, indices, axis) {\n    if (axis === void 0) { axis = 0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'gather');\n    var $indices = tensor_util_env_1.convertToTensor(indices, 'indices', 'gather', 'int32');\n    axis = util_1.parseAxisParam(axis, $x.shape)[0];\n    var shapeInfo = segment_util_1.collectGatherOpShapeInfo($x, $indices, axis);\n    var grad = function (dy, saved) {\n        var $indices = saved[0];\n        var derX = function () {\n            var paramsShape = $x.shape;\n            var indicesSize = $indices.size;\n            var outerShape = paramsShape.slice(0, axis);\n            var outerDims = outerShape.length;\n            var innerShape = paramsShape.slice(axis, paramsShape.length).slice(1);\n            var innerDims = innerShape.length;\n            var outerAxesIndices = arrayRange(0, outerDims);\n            var innerAxesIndices = arrayRange(outerDims + 1, outerDims + 1 + innerDims);\n            var valuesShape = arrayConcat([outerShape, [indicesSize], innerShape]);\n            var values = dy.reshape(valuesShape);\n            var reshapedIndices = $indices.reshape([indicesSize]);\n            var transposeDims = arrayConcat([[outerDims], outerAxesIndices, innerAxesIndices]);\n            var valuesTranspose = values.transpose(transposeDims);\n            var paramsGrad = exports.unsortedSegmentSum(valuesTranspose, reshapedIndices, $x.shape[axis]);\n            var invertTransposeDims = axis_util_1.getUndoAxesPermutation(transposeDims);\n            paramsGrad = paramsGrad.transpose(invertTransposeDims);\n            return paramsGrad;\n        };\n        return { x: derX, indices: function () { return $indices; } };\n    };\n    return (engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.gather($x, $indices.flatten(), axis);\n        save([$indices]);\n        return res;\n    }, { x: $x, indices: $indices }, grad, 'Gather', { axis: axis }))\n        .reshape(shapeInfo.outputShape);\n}\nfunction arrayRange(start, stop) {\n    var result = [];\n    for (var i = start; i < stop; ++i) {\n        result.push(i);\n    }\n    return result;\n}\nfunction arrayConcat(arrays) {\n    var result = [];\n    for (var i = 0; i < arrays.length; ++i) {\n        for (var j = 0; j < arrays[i].length; ++j) {\n            result.push(arrays[i][j]);\n        }\n    }\n    return result;\n}\nfunction gatherDropNegatives(x, indices) {\n    // Helper function for unsorted segment ops. Gathers params for\n    // positive segment ids and gathers 0 for inputs with negative segment id.\n    // Mirrors _GatherDropNegatives from tensorflow/python/ops/math_grad.py\n    var zeroClippedIndices = binary_ops_1.maximum(indices, tensor_ops_1.zerosLike(indices));\n    var gathered = exports.gather(x, zeroClippedIndices);\n    var isPositive = compare_1.greaterEqual(indices, tensor_ops_1.scalar(0, 'int32'));\n    var numIters = gathered.rank - isPositive.rank;\n    for (var i = 0; i < numIters; ++i) {\n        isPositive = array_ops_1.expandDims(isPositive, i + 1);\n    }\n    isPositive = logical_ops_1.logicalAnd(isPositive, tensor_ops_1.ones(gathered.shape, 'bool'));\n    var zeroSlice = tensor_ops_1.zerosLike(gathered);\n    return logical_ops_1.where(isPositive, gathered, zeroSlice);\n}\nexports.gather = operation_1.op({ gather_: gather_ });\nexports.unsortedSegmentSum = operation_1.op({ unsortedSegmentSum_: unsortedSegmentSum_ });\n//# sourceMappingURL=segment_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/segment_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar reduce_util_1 = __webpack_require__(/*! ./reduce_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js\");\nfunction segOpComputeOptimalWindowSize(inSize, numSegments) {\n    var done = false;\n    var res;\n    if (inSize <= reduce_util_1.PARALLELIZE_THRESHOLD) {\n        res = inSize;\n        done = true;\n    }\n    else {\n        res = util_1.nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));\n    }\n    while (!done) {\n        if (res > numSegments || res === inSize) {\n            done = true;\n        }\n        else {\n            res = util_1.nearestDivisor(inSize, res + 1);\n        }\n    }\n    return res;\n}\nexports.segOpComputeOptimalWindowSize = segOpComputeOptimalWindowSize;\nfunction computeOutShape(aShape, axis, numSegments) {\n    var outShape = [];\n    var rank = aShape.length;\n    for (var dim = 0; dim < rank; dim++) {\n        if (dim !== axis) {\n            outShape.push(aShape[dim]);\n        }\n        else {\n            outShape.push(numSegments);\n        }\n    }\n    return outShape;\n}\nexports.computeOutShape = computeOutShape;\nfunction collectGatherOpShapeInfo(x, indices, axis) {\n    var dimSize = x.shape[axis];\n    var outputShape = [];\n    var batchSize = 1;\n    var sliceSize = 1;\n    for (var i = 0; i < axis; i++) {\n        outputShape.push(x.shape[i]);\n        batchSize *= x.shape[i];\n    }\n    for (var i = 0; i < indices.rank; i++) {\n        outputShape.push(indices.shape[i]);\n    }\n    for (var i = axis + 1; i < x.rank; i++) {\n        outputShape.push(x.shape[i]);\n        sliceSize *= x.shape[i];\n    }\n    return { batchSize: batchSize, sliceSize: sliceSize, dimSize: dimSize, outputShape: outputShape };\n}\nexports.collectGatherOpShapeInfo = collectGatherOpShapeInfo;\n//# sourceMappingURL=segment_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.SELU_SCALEALPHA = 1.7580993408473768599402175208123;\nexports.SELU_SCALE = 1.0507009873554804934193349852946;\n//# sourceMappingURL=selu_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar operation_1 = __webpack_require__(/*! ../ops/operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar binary_ops_1 = __webpack_require__(/*! ./binary_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/binary_ops.js\");\nvar concat_split_1 = __webpack_require__(/*! ./concat_split */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/concat_split.js\");\nvar slice_1 = __webpack_require__(/*! ./slice */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js\");\nvar spectral_ops_1 = __webpack_require__(/*! ./spectral_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/spectral_ops.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Generate a Hann window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hannWindow(10).print();\n * ```\n * @param The length of window\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hannWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.5, 0.5);\n}\n/**\n * Generate a hamming window.\n *\n * See: https://en.wikipedia.org/wiki/Window_function#Hann_and_Hamming_windows\n *\n * ```js\n * tf.signal.hammingWindow(10).print();\n * ```\n * @param The length of window\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction hammingWindow_(windowLength) {\n    return cosineWindow(windowLength, 0.54, 0.46);\n}\n/**\n * Expands input into frames of frameLength.\n * Slides a window size with frameStep.\n *\n * ```js\n * tf.signal.frame([1, 2, 3], 2, 1).print();\n * ```\n * @param signal The input tensor to be expanded\n * @param frameLength Length of each frame\n * @param frameStep The frame hop size in samples.\n * @param padEnd Whether to pad the end of signal with padValue.\n * @param padValue An number to use where the input signal does\n *     not exist when padEnd is True.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction frame_(signal, frameLength, frameStep, padEnd, padValue) {\n    if (padEnd === void 0) { padEnd = false; }\n    if (padValue === void 0) { padValue = 0; }\n    var start = 0;\n    var output = [];\n    while (start + frameLength <= signal.size) {\n        output.push(slice_1.slice(signal, start, frameLength));\n        start += frameStep;\n    }\n    if (padEnd) {\n        while (start < signal.size) {\n            var padLen = (start + frameLength) - signal.size;\n            var pad = concat_split_1.concat([slice_1.slice(signal, start, frameLength - padLen),\n                tensor_ops_1.fill([padLen], padValue)]);\n            output.push(pad);\n            start += frameStep;\n        }\n    }\n    if (output.length === 0) {\n        return tensor_ops_1.tensor2d([], [0, frameLength]);\n    }\n    return concat_split_1.concat(output).as2D(output.length, frameLength);\n}\n/**\n * Computes the Short-time Fourier Transform of signals\n * See: https://en.wikipedia.org/wiki/Short-time_Fourier_transform\n *\n * ```js\n * const input = tf.tensor1d([1, 1, 1, 1, 1])\n * tf.signal.stft(input, 3, 1).print();\n * ```\n * @param signal 1-dimensional real value tensor.\n * @param frameLength The window length of samples.\n * @param frameStep The number of samples to step.\n * @param fftLength The size of the FFT to apply.\n * @param windowFn A callable that takes a window length and returns 1-d tensor.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Signal', namespace: 'signal'}\n */\nfunction stft_(signal, frameLength, frameStep, fftLength, windowFn) {\n    if (windowFn === void 0) { windowFn = exports.hannWindow; }\n    if (fftLength == null) {\n        fftLength = enclosingPowerOfTwo(frameLength);\n    }\n    var framedSignal = exports.frame(signal, frameLength, frameStep);\n    var windowedSignal = binary_ops_1.mul(framedSignal, windowFn(frameLength));\n    var output = [];\n    for (var i = 0; i < framedSignal.shape[0]; i++) {\n        output.push(spectral_ops_1.rfft(windowedSignal.slice([i, 0], [1, frameLength]), fftLength));\n    }\n    return concat_split_1.concat(output);\n}\nfunction enclosingPowerOfTwo(value) {\n    // Return 2**N for integer N such that 2**N >= value.\n    return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2.0))));\n}\nfunction cosineWindow(windowLength, a, b) {\n    var even = 1 - windowLength % 2;\n    var newValues = new Float32Array(windowLength);\n    for (var i = 0; i < windowLength; ++i) {\n        var cosArg = (2.0 * Math.PI * i) / (windowLength + even - 1);\n        newValues[i] = a - b * Math.cos(cosArg);\n    }\n    return tensor_ops_1.tensor1d(newValues, 'float32');\n}\nexports.hannWindow = operation_1.op({ hannWindow_: hannWindow_ });\nexports.hammingWindow = operation_1.op({ hammingWindow_: hammingWindow_ });\nexports.frame = operation_1.op({ frame_: frame_ });\nexports.stft = operation_1.op({ stft_: stft_ });\n//# sourceMappingURL=signal_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js":
/*!**************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar slice_util = __webpack_require__(/*! ./slice_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js\");\n/**\n * Extracts a 1D slice from 1D array starting at coordinates `begin` and is\n * of length `size`. See `slice` for details.\n */\nfunction slice1d_(x, begin, size) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'slice1d');\n    util.assert($x.rank === 1, function () {\n        return \"slice1d expects a rank-1 tensor, but got a rank-\" + $x.rank + \" tensor\";\n    });\n    return exports.slice($x, [begin], [size]);\n}\n/**\n * Extracts a 2D slice from a 2D array starting at coordinates `begin` and\n * is of size `size`. See `slice` for details.\n */\nfunction slice2d_(x, begin, size) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'slice2d');\n    util.assert($x.rank === 2, function () {\n        return \"slice2d expects a rank-2 tensor, but got a rank-\" + $x.rank + \" tensor\";\n    });\n    return exports.slice($x, begin, size);\n}\n/**\n * Extracts a 3D slice from a 3D array starting at coordinates `begin` and\n * is of size `size`. See `slice` for details.\n */\nfunction slice3d_(x, begin, size) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'slice3d');\n    util.assert($x.rank === 3, function () {\n        return \"slice3d expects a rank-3 tensor, but got a rank-\" + $x.rank + \" tensor\";\n    });\n    return exports.slice($x, begin, size);\n}\n/**\n * Extracts a 4D slice from a 4D array starting at coordinates `begin` and\n * is of size `size`. See `slice` for details.\n */\nfunction slice4d_(x, begin, size) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'slice4d');\n    util.assert($x.rank === 4, function () {\n        return \"slice4d expects a rank-4 tensor, but got a rank-\" + $x.rank + \" tensor\";\n    });\n    return exports.slice($x, begin, size);\n}\n/**\n * Extracts a slice from a `tf.Tensor` starting at coordinates `begin`\n * and is of size `size`.\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `x` is of the given rank:\n *   - `tf.slice1d`\n *   - `tf.slice2d`\n *   - `tf.slice3d`\n *   - `tf.slice4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.slice([1], [2]).print();\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n *\n * x.slice([1, 0], [1, 2]).print();\n * ```\n * @param x The input `tf.Tensor` to slice from.\n * @param begin The coordinates to start the slice from. The length can be\n *     less than the rank of x - the rest of the axes will have implicit 0 as\n *     start. Can also be a single number, in which case it specifies the\n *     first axis.\n * @param size The size of the slice. The length can be less than the rank of\n *     x - the rest of the axes will have implicit -1. A value of -1 requests\n *     the rest of the dimensions in the axis. Can also be a single number,\n *     in which case it specifies the size of the first axis.\n */\n/** @doc {heading: 'Tensors', subheading: 'Slicing and Joining'} */\nfunction slice_(x, begin, size) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'slice');\n    if ($x.rank === 0) {\n        throw new Error('Slicing scalar is not possible');\n    }\n    // The following logic allows for more ergonomic calls.\n    var begin_;\n    if (typeof begin === 'number') {\n        begin_ = [begin].concat(new Array($x.rank - 1).fill(0));\n    }\n    else if (begin.length < $x.rank) {\n        begin_ = begin.concat(new Array($x.rank - begin.length).fill(0));\n    }\n    else {\n        begin_ = begin.slice();\n    }\n    begin_.forEach(function (d) {\n        util.assert(d !== -1, function () { return 'slice() does not support negative begin indexing.'; });\n    });\n    var size_;\n    if (size == null) {\n        size_ = new Array($x.rank).fill(-1);\n    }\n    else if (typeof size === 'number') {\n        size_ = [size].concat(new Array($x.rank - 1).fill(-1));\n    }\n    else if (size.length < $x.rank) {\n        size_ = size.concat(new Array($x.rank - size.length).fill(-1));\n    }\n    else {\n        size_ = size;\n    }\n    size_ = size_.map(function (d, i) {\n        if (d >= 0) {\n            return d;\n        }\n        else {\n            util.assert(d === -1, function () { return \"Negative size values should be exactly -1 but got \" +\n                (d + \" for the slice() size at index \" + i + \".\"); });\n            return $x.shape[i] - begin_[i];\n        }\n    });\n    slice_util.assertParamsValid($x, begin_, size_);\n    var inputShape = $x.shape;\n    var grad = function (dy) {\n        // Create an Nx2 padding where the first column represents how many\n        // zeros are prepended (at start) for each dimension, and the second\n        // column indicates how many zeros are appended (at end).\n        // The number of zeros to append is the shape of the input\n        // elementwise-subtracted by both the begin vector and sizes vector.\n        var paddings = [];\n        for (var i = 0; i < dy.rank; i++) {\n            paddings.push([begin_[i], inputShape[i] - begin_[i] - size_[i]]);\n        }\n        return { x: function () { return dy.pad(paddings); } };\n    };\n    var attrs = { begin: begin_, size: size_ };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.slice($x, begin_, size_); }, { x: $x }, grad, 'Slice', attrs);\n}\nexports.slice = operation_1.op({ slice_: slice_ });\nexports.slice1d = operation_1.op({ slice1d_: slice1d_ });\nexports.slice2d = operation_1.op({ slice2d_: slice2d_ });\nexports.slice3d = operation_1.op({ slice3d_: slice3d_ });\nexports.slice4d = operation_1.op({ slice4d_: slice4d_ });\n//# sourceMappingURL=slice.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nfunction assertParamsValid(input, begin, size) {\n    util.assert(input.rank === begin.length, function () { return \"Error in slice\" + input.rank + \"D: Length of begin \" + begin + \" must \" +\n        (\"match the rank of the array (\" + input.rank + \").\"); });\n    util.assert(input.rank === size.length, function () { return \"Error in slice\" + input.rank + \"D: Length of size \" + size + \" must \" +\n        (\"match the rank of the array (\" + input.rank + \").\"); });\n    var _loop_1 = function (i) {\n        util.assert(begin[i] + size[i] <= input.shape[i], function () { return \"Error in slice\" + input.rank + \"D: begin[\" + i + \"] + size[\" + i + \"] \" +\n            (\"(\" + (begin[i] + size[i]) + \") would overflow input.shape[\" + i + \"] (\" + input.shape[i] + \")\"); });\n    };\n    for (var i = 0; i < input.rank; ++i) {\n        _loop_1(i);\n    }\n}\nexports.assertParamsValid = assertParamsValid;\n/** Converts a binary mask to an array of axes. Used in stridedSlice(). */\nfunction maskToAxes(mask) {\n    var axes = [];\n    var axis = 0;\n    while (mask > 0) {\n        if (mask & 1) {\n            axes.push(axis);\n        }\n        mask /= 2;\n        axis++;\n    }\n    return axes;\n}\nexports.maskToAxes = maskToAxes;\n/** Computes the output shape given the strided slice params. */\nfunction computeOutShape(begin, end, strides) {\n    var size = [];\n    for (var axis = 0; axis < begin.length; axis++) {\n        size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);\n    }\n    return size;\n}\nexports.computeOutShape = computeOutShape;\nfunction startForAxis(beginMask, startIndices, strides, inputShape, axis) {\n    // Begin with the specified index\n    var start = startIndices[axis];\n    var stride = strides[axis] || 1;\n    // Check the axis bit from right of beginMask or the begin index is not set\n    // for the axis.\n    if (beginMask & 1 << axis || start == null) {\n        if (stride > 0) {\n            // Forward iteration - use the first element. These values will get\n            // clamped below (Note: We could have set them to 0 and axis_size-1, but\n            // use lowest() and max() to maintain symmetry with StopForAxis())\n            start = Number.MIN_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the last element.\n            start = Number.MAX_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    var axisSize = inputShape[axis];\n    if (start < 0) {\n        start += axisSize;\n    }\n    // Clamping\n    start = util.clamp(0, start, axisSize - 1);\n    return start;\n}\nexports.startForAxis = startForAxis;\nfunction stopForAxis(endMask, stopIndices, strides, inputShape, axis) {\n    // Begin with the specified index\n    var stop = stopIndices[axis];\n    var stride = strides[axis] || 1;\n    // Check the axis bit from right of endMask or if the stop index is not set\n    // for this axis.\n    if (endMask & (1 << axis) || stop == null) {\n        if (stride > 0) {\n            // Forward iteration - use the last element. These values will get\n            // clamped below\n            stop = Number.MAX_SAFE_INTEGER;\n        }\n        else {\n            // Backward iteration - use the first element.\n            stop = Number.MIN_SAFE_INTEGER;\n        }\n    }\n    // Handle negative indices\n    var axisSize = inputShape[axis];\n    if (stop < 0) {\n        stop += axisSize;\n    }\n    // Clamping\n    // Because the end index points one past the last element, we need slightly\n    // different clamping ranges depending on the direction.\n    if (stride > 0) {\n        // Forward iteration\n        stop = util.clamp(0, stop, axisSize);\n    }\n    else {\n        // Backward iteration\n        stop = util.clamp(-1, stop, axisSize - 1);\n    }\n    return stop;\n}\nexports.stopForAxis = stopForAxis;\n/**\n * Returns true if the slice occupies a continous set of elements in the\n * 'flat' space.\n */\nfunction isSliceContinous(shape, begin, size) {\n    // Index of the first axis that has size > 1.\n    var firstNonOneAxis = size.length;\n    for (var i = 0; i < size.length; i++) {\n        if (size[i] > 1) {\n            firstNonOneAxis = i;\n            break;\n        }\n    }\n    for (var i = firstNonOneAxis + 1; i < size.length; i++) {\n        if (begin[i] > 0 || size[i] !== shape[i]) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.isSliceContinous = isSliceContinous;\nfunction computeFlatOffset(begin, strides) {\n    var flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;\n    for (var i = 0; i < begin.length - 1; i++) {\n        flatOffset += begin[i] * strides[i];\n    }\n    return flatOffset;\n}\nexports.computeFlatOffset = computeFlatOffset;\n//# sourceMappingURL=slice_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar gradients_1 = __webpack_require__(/*! ../gradients */ \"./node_modules/@tensorflow/tfjs-core/dist/gradients.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Computes the softmax normalized vector given the logits.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.softmax().print();  // or tf.softmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param dim The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction softmax_(logits, dim) {\n    if (dim === void 0) { dim = -1; }\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'softmax', 'float32');\n    if (dim === -1) {\n        dim = $logits.rank - 1;\n    }\n    if (dim !== $logits.rank - 1) {\n        throw Error('Softmax along a non-last dimension is not yet supported. ' +\n            (\"Logits was rank \" + $logits.rank + \" and dim was \" + dim));\n    }\n    var inputsToSave = [];\n    var outputsToSave = [true];\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.softmax($logits, dim);\n        save([y]);\n        return y;\n    }, { logits: $logits }, function (dy, saved) {\n        var y = saved[0];\n        var dyTimesY = dy.mul(y);\n        var keepDims = true;\n        return {\n            logits: function () { return dyTimesY.sub(dyTimesY.sum([dim], keepDims).mul(y)); }\n        };\n    }, 'Softmax', { dim: dim }, inputsToSave, outputsToSave);\n}\n/**\n * Computes the log softmax.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param axis The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction logSoftmax_(logits, axis) {\n    if (axis === void 0) { axis = -1; }\n    var $logits = tensor_util_env_1.convertToTensor(logits, 'logits', 'logSoftmax');\n    if (axis === -1) {\n        axis = $logits.rank - 1;\n    }\n    if (axis !== $logits.rank - 1) {\n        throw Error('Log Softmax along a non-last dimension is not yet supported. ' +\n            (\"Logits was rank \" + $logits.rank + \" and axis was \" + axis));\n    }\n    var customOp = gradients_1.customGrad(function (logits, save) {\n        var keepDims = true;\n        var xMax = logits.max(axis, true);\n        var shifted = logits.sub(xMax);\n        var value = shifted.toFloat().sub(shifted.exp().sum(axis, keepDims).log());\n        save([value]);\n        var gradFunc = function (dy, saved) {\n            var value = saved[0];\n            var softmax = value.exp();\n            return dy.sub(dy.sum(axis, keepDims).mul(softmax));\n        };\n        return { value: value, gradFunc: gradFunc };\n    });\n    return customOp($logits);\n}\nexports.softmax = operation_1.op({ softmax_: softmax_ });\nexports.logSoftmax = operation_1.op({ logSoftmax_: logSoftmax_ });\n//# sourceMappingURL=softmax.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js":
/*!************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar sparse_to_dense = __webpack_require__(/*! ../ops/sparse_to_dense_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense_util.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Converts a sparse representation into a dense tensor.\n *\n * Builds an array dense with shape outputShape such that:\n *\n * // If sparseIndices is scalar\n * dense[i] = (i == sparseIndices ? sparseValues : defaultValue)\n *\n * // If sparseIndices is a vector, then for each i\n * dense[sparseIndices[i]] = sparseValues[i]\n *\n * // If sparseIndices is an n by d matrix, then for each i in [0, n)\n * dense[sparseIndices[i][0], ..., sparseIndices[i][d-1]] = sparseValues[i]\n * All other values in dense are set to defaultValue. If sparseValues is a\n * scalar, all sparse indices are set to this single value.\n *\n * If indices are repeated the final value is summed over all values for those\n * indices.\n *\n * ```js\n * const indices = tf.tensor1d([4, 5, 6, 1, 2, 3], 'int32');\n * const values = tf.tensor1d([10, 11, 12, 13, 14, 15], 'float32');\n * const shape = [8];\n * tf.sparseToDense(indices, values, shape).print();\n * ```\n *\n * @param sparseIndices A 0-D, 1-D, or 2-D Tensor of type int32.\n * sparseIndices[i] contains the complete index where sparseValues[i] will be\n * placed.\n * @param sparseValues A 0-D or 1-D Tensor. Values\n * corresponding to each row of sparseIndices, or a scalar value to be used for\n * all sparse indices.\n * @param outputShape Shape of the dense output tensor. the type is inferred.\n * @param defaultValue Scalar. Value to set for indices not specified in\n * sparseIndices. Defaults to zero.\n */\n/** @doc {heading: 'Operations', subheading: 'Normalization'} */\nfunction sparseToDense_(sparseIndices, sparseValues, outputShape, defaultValue) {\n    if (defaultValue === void 0) { defaultValue = 0; }\n    var $sparseIndices = tensor_util_env_1.convertToTensor(sparseIndices, 'sparseIndices', 'sparseToDense', 'int32');\n    var $sparseValues = tensor_util_env_1.convertToTensor(sparseValues, 'sparseValues', 'sparseToDense');\n    var $defaultValue = tensor_util_env_1.convertToTensor(defaultValue, 'defaultValue', 'sparseToDense', $sparseValues.dtype);\n    sparse_to_dense.validateInput($sparseIndices, $sparseValues, outputShape, $defaultValue);\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.sparseToDense($sparseIndices, $sparseValues, outputShape, $defaultValue); }, { $sparseIndices: $sparseIndices, $sparseValues: $sparseValues, $defaultValue: $defaultValue });\n}\nexports.sparseToDense = operation_1.op({ sparseToDense_: sparseToDense_ });\n//# sourceMappingURL=sparse_to_dense.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense_util.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense_util.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Validate sparseToDense inputs.\n *\n * @param sparseIndices A 0-D, 1-D, or 2-D Tensor of type int32.\n * sparseIndices[i] contains the complete index where sparseValues[i] will be\n * placed.\n * @param sparseValues A 0-D or 1-D Tensor. Values\n * corresponding to each row of sparseIndices, or a scalar value to be used for\n * all sparse indices.\n * @param outputShape number[]. Shape of the dense output tensor.\n * @param validateIndices boolean. indice validation is not supported, error\n * will be thrown if it is set.\n */\nfunction validateInput(sparseIndices, sparseValues, outputShape, defaultValues) {\n    if (sparseIndices.dtype !== 'int32') {\n        throw new Error('tf.sparseToDense() expects the indices to be int32 type,' +\n            (\" but the dtype was \" + sparseIndices.dtype + \".\"));\n    }\n    if (sparseIndices.rank > 2) {\n        throw new Error('sparseIndices should be a scalar, vector, or matrix,' +\n            (\" but got shape \" + sparseIndices.shape + \".\"));\n    }\n    var numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;\n    var numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;\n    if (outputShape.length !== numDims) {\n        throw new Error('outputShape has incorrect number of elements:,' +\n            (\" \" + outputShape.length + \", should be: \" + numDims + \".\"));\n    }\n    var numValues = sparseValues.size;\n    if (!(sparseValues.rank === 0 ||\n        sparseValues.rank === 1 && numValues === numElems)) {\n        throw new Error('sparseValues has incorrect shape ' +\n            (sparseValues.shape + \", should be [] or [\" + numElems + \"]\"));\n    }\n    if (sparseValues.dtype !== defaultValues.dtype) {\n        throw new Error('sparseValues.dtype must match defaultValues.dtype');\n    }\n}\nexports.validateInput = validateInput;\n//# sourceMappingURL=sparse_to_dense_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/spectral_ops.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/spectral_ops.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar complex_ops_1 = __webpack_require__(/*! ../ops/complex_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/complex_ops.js\");\nvar operation_1 = __webpack_require__(/*! ../ops/operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the inner-most\n * dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.fft().print();  // tf.spectral.fft(x).print();\n * ```\n * @param input The complex input to compute an fft over.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction fft_(input) {\n    util_1.assert(input.dtype === 'complex64', function () { return \"The dtype for tf.spectral.fft() must be complex64 \" +\n        (\"but got \" + input.dtype + \".\"); });\n    // Collapse all outer dimensions to a single batch dimension.\n    var innerDimensionSize = input.shape[input.shape.length - 1];\n    var batch = input.size / innerDimensionSize;\n    var input2D = input.as2D(batch, innerDimensionSize);\n    var ret = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.fft(input2D); }, { input: input });\n    return ret.reshape(input.shape);\n}\n/**\n * Inverse fast Fourier transform.\n *\n * Computes the inverse 1-dimensional discrete Fourier transform over the\n * inner-most dimension of input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([1, 2, 3]);\n * const x = tf.complex(real, imag);\n *\n * x.ifft().print();  // tf.spectral.ifft(x).print();\n * ```\n * @param input The complex input to compute an ifft over.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction ifft_(input) {\n    util_1.assert(input.dtype === 'complex64', function () { return \"The dtype for tf.spectral.ifft() must be complex64 \" +\n        (\"but got \" + input.dtype + \".\"); });\n    // Collapse all outer dimensions to a single batch dimension.\n    var innerDimensionSize = input.shape[input.shape.length - 1];\n    var batch = input.size / innerDimensionSize;\n    var input2D = input.as2D(batch, innerDimensionSize);\n    var ret = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.ifft(input2D); }, { input: input });\n    return ret.reshape(input.shape);\n}\n/**\n * Real value input fast Fourier transform.\n *\n * Computes the 1-dimensional discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n *\n * real.rfft().print();\n * ```\n * @param input The real value input to compute an rfft over.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction rfft_(input, fftLength) {\n    util_1.assert(input.dtype === 'float32', function () { return \"The dtype for rfft() must be real value but got \" + input.dtype; });\n    var innerDimensionSize = input.shape[input.shape.length - 1];\n    var batch = input.size / innerDimensionSize;\n    var adjustedInput;\n    if (fftLength != null && fftLength < innerDimensionSize) {\n        // Need to crop\n        var begin = input.shape.map(function (v) { return 0; });\n        var size = input.shape.map(function (v) { return v; });\n        size[input.shape.length - 1] = fftLength;\n        adjustedInput = input.slice(begin, size);\n        innerDimensionSize = fftLength;\n    }\n    else if (fftLength != null && fftLength > innerDimensionSize) {\n        // Need to pad with zeros\n        var zerosShape = input.shape.map(function (v) { return v; });\n        zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;\n        adjustedInput = input.concat(tensor_ops_1.zeros(zerosShape), input.shape.length - 1);\n        innerDimensionSize = fftLength;\n    }\n    else {\n        adjustedInput = input;\n    }\n    // Complement the input with zero imaginary numbers.\n    var zerosInput = adjustedInput.zerosLike();\n    var complexInput = complex_ops_1.complex(adjustedInput, zerosInput).as2D(batch, innerDimensionSize);\n    var ret = exports.fft(complexInput);\n    // Exclude complex conjugations. These conjugations are put symmetrically.\n    var half = Math.floor(innerDimensionSize / 2) + 1;\n    var realValues = complex_ops_1.real(ret);\n    var imagValues = complex_ops_1.imag(ret);\n    var realComplexConjugate = realValues.split([half, innerDimensionSize - half], realValues.shape.length - 1);\n    var imagComplexConjugate = imagValues.split([half, innerDimensionSize - half], imagValues.shape.length - 1);\n    var outputShape = adjustedInput.shape.slice();\n    outputShape[adjustedInput.shape.length - 1] = half;\n    return complex_ops_1.complex(realComplexConjugate[0], imagComplexConjugate[0])\n        .reshape(outputShape);\n}\n/**\n * Inversed real value input fast Fourier transform.\n *\n * Computes the 1-dimensional inversed discrete Fourier transform over the\n * inner-most dimension of the real input.\n *\n * ```js\n * const real = tf.tensor1d([1, 2, 3]);\n * const imag = tf.tensor1d([0, 0, 0]);\n * const x = tf.complex(real, imag);\n *\n * x.irfft().print();\n * ```\n * @param input The real value input to compute an irfft over.\n */\n/**\n * @doc {heading: 'Operations', subheading: 'Spectral', namespace: 'spectral'}\n */\nfunction irfft_(input) {\n    var innerDimensionSize = input.shape[input.shape.length - 1];\n    var batch = input.size / innerDimensionSize;\n    if (innerDimensionSize <= 2) {\n        var complexInput = input.as2D(batch, innerDimensionSize);\n        var ret = exports.ifft(complexInput);\n        return complex_ops_1.real(ret);\n    }\n    else {\n        // The length of unique components of the DFT of a real-valued signal\n        // is 2 * (input_len - 1)\n        var outputShape = [batch, 2 * (innerDimensionSize - 1)];\n        var realInput = complex_ops_1.real(input).as2D(batch, innerDimensionSize);\n        var imagInput = complex_ops_1.imag(input).as2D(batch, innerDimensionSize);\n        var realConjugate = realInput.slice([0, 1], [batch, innerDimensionSize - 2]).reverse(1);\n        var imagConjugate = imagInput.slice([0, 1], [batch, innerDimensionSize - 2])\n            .reverse(1)\n            .mul(tensor_ops_1.scalar(-1));\n        var r = realInput.concat(realConjugate, 1);\n        var i = imagInput.concat(imagConjugate, 1);\n        var complexInput = complex_ops_1.complex(r, i).as2D(outputShape[0], outputShape[1]);\n        var ret = exports.ifft(complexInput);\n        return complex_ops_1.real(ret);\n    }\n}\nexports.fft = operation_1.op({ fft_: fft_ });\nexports.ifft = operation_1.op({ ifft_: ifft_ });\nexports.rfft = operation_1.op({ rfft_: rfft_ });\nexports.irfft = operation_1.op({ irfft_: irfft_ });\n//# sourceMappingURL=spectral_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/spectral_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/square.js":
/*!***************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/square.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Computes square of `x` element-wise: `x ^ 2`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.sqrt(2), -1]);\n *\n * x.square().print();  // or tf.square(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction square_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'square');\n    var attrs = {};\n    var inputsToSave = [$x];\n    var outputsToSave = [];\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        save([$x]);\n        return backend.square($x);\n    }, { x: $x }, null /* grad */, 'Square', attrs, inputsToSave, outputsToSave);\n}\nexports.square = operation_1.op({ square_: square_ });\n//# sourceMappingURL=square.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/square.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar kernel_names_1 = __webpack_require__(/*! ../kernel_names */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_names.js\");\nvar tensor_util_1 = __webpack_require__(/*! ../tensor_util */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar broadcast_util_1 = __webpack_require__(/*! ./broadcast_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Returns (a - b) * (a - b) element-wise.\n * Supports broadcasting.\n *\n * We also expose `tf.squaredDifferenceStrict` which has the same signature as\n * this op and asserts that `a` and `b` are the same shape (does not\n * broadcast).\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 3, 16]);\n * const b = tf.tensor1d([1, 2, 9, 4]);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * ```js\n * // Broadcast squared difference  a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(5);\n *\n * a.squaredDifference(b).print();  // or tf.squaredDifference(a, b)\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Arithmetic'} */\nfunction squaredDifference_(a, b) {\n    var _a;\n    var $a = tensor_util_env_1.convertToTensor(a, 'a', 'squaredDifference');\n    var $b = tensor_util_env_1.convertToTensor(b, 'b', 'squaredDifference');\n    _a = tensor_util_1.makeTypesMatch($a, $b), $a = _a[0], $b = _a[1];\n    broadcast_util_1.assertAndGetBroadcastShape($a.shape, $b.shape);\n    var der = function (dy, saved) {\n        var $a = saved[0], $b = saved[1];\n        var two = tensor_ops_1.scalar(2);\n        var derA = function () { return dy.mul($a.sub($b).mul(two)); };\n        var derB = function () { return dy.mul($b.sub($a).mul(two)); };\n        return { a: derA, b: derB };\n    };\n    var forward = function (backend, save) {\n        var res = backend.squaredDifference($a, $b);\n        save([$a, $b]);\n        return res;\n    };\n    var inputs = { a: $a, b: $b };\n    var attrs = {};\n    var inputsToSave = [$a, $b];\n    var outputToSave = [];\n    return engine_1.ENGINE.runKernelFunc(forward, inputs, der, kernel_names_1.SquaredDifference, attrs, inputsToSave, outputToSave);\n}\nexports.squaredDifference = operation_1.op({ squaredDifference_: squaredDifference_ });\n//# sourceMappingURL=squared_difference.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar slice_1 = __webpack_require__(/*! ./slice */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/slice.js\");\nvar slice_util_1 = __webpack_require__(/*! ./slice_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js\");\n/**\n * Extracts a strided slice of a tensor.\n *\n * Roughly speaking, this op extracts a slice of size (end-begin)/stride from\n * the given input tensor (x). Starting at the location specified by begin the\n * slice continues by adding stride to the index until all dimensions are not\n * less than end. Note that a stride can be negative, which causes a reverse\n * slice.\n *\n * ```js\n * const t = tf.tensor3d([1, 1, 1 ,2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n *    [3, 2, 3]);\n * t.stridedSlice([1, 0, 0], [2, 1, 3], [1, 1, 1]).print()  // [[[3, 3, 3]]]\n * t.stridedSlice([1, 0, 0], [2, 2, 3], [1, 1, 1]).print()  // [[[3, 3, 3],\n *                                                     // [4, 4, 4]]]\n * t.stridedSlice([1, -1, 0], [2, -3, 3], [1, -1, 1]).print() // [[[4, 4, 4],\n *                                                     // [3, 3, 3]]]\n * ```\n *\n * @param x The tensor to stride slice.\n * @param begin The coordinates to start the slice from.\n * @param end: The coordinates to end the slice at.\n * @param strides: The size of the slice.\n * @param beginMask: If the ith bit of beginMask is set, begin[i] is ignored\n *      and the fullest possible range in that dimension is used instead.\n * @param endMask: If the ith bit of endMask is set, end[i] is ignored\n *      and the fullest possible range in that dimension is used instead.\n * @param shrinkAxisMask: a bitmask where bit i implies that\n * the ith specification should shrink the dimensionality. begin and end must\n * imply a slice of size 1 in the dimension.\n */\n/** @doc {heading: 'Operations', subheading: 'Slicing and Joining'} */\nfunction stridedSlice_(x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n    if (beginMask === void 0) { beginMask = 0; }\n    if (endMask === void 0) { endMask = 0; }\n    if (ellipsisMask === void 0) { ellipsisMask = 0; }\n    if (newAxisMask === void 0) { newAxisMask = 0; }\n    if (shrinkAxisMask === void 0) { shrinkAxisMask = 0; }\n    if (strides == null) {\n        strides = new Array(begin.length);\n    }\n    if (ellipsisMask !== 0) {\n        throw new Error('ellipsis mask is not yet supported');\n    }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'stridedSlice');\n    // Expand the dims of x based on the newAxisMask.\n    var expandAxes = slice_util_1.maskToAxes(newAxisMask);\n    var newShape = $x.shape.slice();\n    expandAxes.forEach(function (axis) {\n        begin[axis] = 0;\n        end[axis] = 1;\n        newShape.splice(axis, 0, 1);\n    });\n    $x = $x.reshape(newShape);\n    // Normalize the start, end and strides.\n    for (var axis = 0; axis < $x.rank; axis++) {\n        begin[axis] = slice_util_1.startForAxis(beginMask, begin, strides, $x.shape, axis);\n        end[axis] = slice_util_1.stopForAxis(endMask, end, strides, $x.shape, axis);\n        strides[axis] = strides[axis] || 1;\n    }\n    var shrinkAxes = slice_util_1.maskToAxes(shrinkAxisMask);\n    // Adjust the ends based on the shrink mask.\n    shrinkAxes.forEach(function (axis) {\n        end[axis] = begin[axis] + 1;\n        strides[axis] = 1;\n    });\n    // Figure out the output shape.\n    var size = slice_util_1.computeOutShape(begin, end, strides);\n    // Remove the axes based on shrinkMask.\n    var outShape = size.filter(function (_, axis) { return shrinkAxes.indexOf(axis) === -1; });\n    var nonStrided = strides.every(function (v) { return v === 1; });\n    if (nonStrided) {\n        return slice_1.slice($x, begin, size).reshape(outShape);\n    }\n    var res = engine_1.ENGINE.runKernelFunc(function (backend) { return backend.stridedSlice($x, begin, end, strides); }, { $x: $x });\n    return res.reshape(outShape);\n}\nexports.stridedSlice = operation_1.op({ stridedSlice_: stridedSlice_ });\n//# sourceMappingURL=strided_slice.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar environment_1 = __webpack_require__(/*! ../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util_1 = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar complex_ops_1 = __webpack_require__(/*! ./complex_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/complex_ops.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Creates a `tf.Tensor` with the provided values, shape and dtype.\n *\n * ```js\n * // Pass an array of values to create a vector.\n * tf.tensor([1, 2, 3, 4]).print();\n * ```\n *\n * ```js\n * // Pass a nested array of values to make a matrix or a higher\n * // dimensional tensor.\n * tf.tensor([[1, 2], [3, 4]]).print();\n * ```\n *\n * ```js\n * // Pass a flat array and specify a shape yourself.\n * tf.tensor([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`. If the values are strings,\n *     they will be encoded as utf-8 and kept as `Uint8Array[]`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor(values, shape, dtype) {\n    var inferredShape = tensor_util_env_1.inferShape(values, dtype);\n    return makeTensor(values, shape, inferredShape, dtype);\n}\nexports.tensor = tensor;\n/** This is shared code across all tensor creation methods. */\nfunction makeTensor(values, shape, inferredShape, dtype) {\n    if (dtype == null) {\n        dtype = util_1.inferDtype(values);\n    }\n    if (dtype === 'complex64') {\n        throw new Error(\"Cannot construct a complex64 tensor directly. \" +\n            \"Please use tf.complex(real, imag).\");\n    }\n    if (!util_1.isTypedArray(values) && !Array.isArray(values) &&\n        typeof values !== 'number' && typeof values !== 'boolean' &&\n        typeof values !== 'string') {\n        throw new Error('values passed to tensor(values) must be a number/boolean/string or ' +\n            'an array of numbers/booleans/strings, or a TypedArray');\n    }\n    if (shape != null) {\n        util_1.assertNonNegativeIntegerDimensions(shape);\n        var providedSize_1 = util_1.sizeFromShape(shape);\n        var inferredSize_1 = util_1.sizeFromShape(inferredShape);\n        util_1.assert(providedSize_1 === inferredSize_1, function () {\n            return \"Based on the provided shape, [\" + shape + \"], the tensor should have \" +\n                (providedSize_1 + \" values but has \" + inferredSize_1);\n        });\n        for (var i = 0; i < inferredShape.length; ++i) {\n            var inferred = inferredShape[i];\n            var flatDimsDontMatch = i === inferredShape.length - 1 ?\n                inferred !== util_1.sizeFromShape(shape.slice(i)) :\n                true;\n            util_1.assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, function () { return \"Error creating a new Tensor. Inferred shape \" +\n                (\"(\" + inferredShape + \") does not match the provided \") +\n                (\"shape (\" + shape + \"). \"); });\n        }\n    }\n    if (!util_1.isTypedArray(values) && !Array.isArray(values)) {\n        values = [values];\n    }\n    shape = shape || inferredShape;\n    values = dtype !== 'string' ?\n        util_1.toTypedArray(values, dtype, environment_1.env().getBool('DEBUG')) :\n        util_1.flatten(values, [], true);\n    return engine_1.ENGINE.makeTensor(values, shape, dtype);\n}\n/**\n * Creates rank-0 `tf.Tensor` (scalar) with the provided value and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.scalar` as it makes the code more readable.\n *\n * ```js\n * tf.scalar(3.14).print();\n * ```\n *\n * @param value The value of the scalar.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction scalar(value, dtype) {\n    if (((util_1.isTypedArray(value) && dtype !== 'string') || Array.isArray(value)) &&\n        dtype !== 'complex64') {\n        throw new Error('Error creating a new Scalar: value must be a primitive ' +\n            '(number|boolean|string)');\n    }\n    if (dtype === 'string' && util_1.isTypedArray(value) &&\n        !(value instanceof Uint8Array)) {\n        throw new Error('When making a scalar from encoded string, ' +\n            'the value must be `Uint8Array`.');\n    }\n    var shape = [];\n    var inferredShape = [];\n    return makeTensor(value, shape, inferredShape, dtype);\n}\nexports.scalar = scalar;\n/**\n * Creates rank-1 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor1d` as it makes the code more readable.\n *\n * ```js\n * tf.tensor1d([1, 2, 3]).print();\n * ```\n *\n * @param values The values of the tensor. Can be array of numbers,\n *     or a `TypedArray`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor1d(values, dtype) {\n    util_1.assertNonNull(values);\n    var inferredShape = tensor_util_env_1.inferShape(values, dtype);\n    if (inferredShape.length !== 1) {\n        throw new Error('tensor1d() requires values to be a flat/TypedArray');\n    }\n    var shape = null;\n    return makeTensor(values, shape, inferredShape, dtype);\n}\nexports.tensor1d = tensor1d;\n/**\n * Creates rank-2 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor2d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor2d([[1, 2], [3, 4]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor2d([1, 2, 3, 4], [2, 2]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided, it is inferred from\n *     `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor2d(values, shape, dtype) {\n    util_1.assertNonNull(values);\n    if (shape != null && shape.length !== 2) {\n        throw new Error('tensor2d() requires shape to have two numbers');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values, dtype);\n    if (inferredShape.length !== 2 && inferredShape.length !== 1) {\n        throw new Error('tensor2d() requires values to be number[][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor2d() requires shape to be provided when `values` ' +\n            'are a flat/TypedArray');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\nexports.tensor2d = tensor2d;\n/**\n * Creates rank-3 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor3d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor3d([[[1], [2]], [[3], [4]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor3d([1, 2, 3, 4], [2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. If not provided,  it is inferred from\n *     `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor3d(values, shape, dtype) {\n    util_1.assertNonNull(values);\n    if (shape != null && shape.length !== 3) {\n        throw new Error('tensor3d() requires shape to have three numbers');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values, dtype);\n    if (inferredShape.length !== 3 && inferredShape.length !== 1) {\n        throw new Error('tensor3d() requires values to be number[][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor3d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\nexports.tensor3d = tensor3d;\n/**\n * Creates rank-4 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor4d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor4d([[[[1], [2]], [[3], [4]]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor4d([1, 2, 3, 4], [1, 2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor4d(values, shape, dtype) {\n    util_1.assertNonNull(values);\n    if (shape != null && shape.length !== 4) {\n        throw new Error('tensor4d() requires shape to have four numbers');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values, dtype);\n    if (inferredShape.length !== 4 && inferredShape.length !== 1) {\n        throw new Error('tensor4d() requires values to be number[][][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor4d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\nexports.tensor4d = tensor4d;\n/**\n * Creates rank-5 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor5d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor5d([[[[[1], [2]], [[3], [4]]]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor5d([1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor5d(values, shape, dtype) {\n    util_1.assertNonNull(values);\n    if (shape != null && shape.length !== 5) {\n        throw new Error('tensor5d() requires shape to have five numbers');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values, dtype);\n    if (inferredShape.length !== 5 && inferredShape.length !== 1) {\n        throw new Error('tensor5d() requires values to be ' +\n            'number[][][][][] or flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor5d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    return makeTensor(values, shape, inferredShape, dtype);\n}\nexports.tensor5d = tensor5d;\n/**\n * Creates rank-6 `tf.Tensor` with the provided values, shape and dtype.\n *\n * The same functionality can be achieved with `tf.tensor`, but in general\n * we recommend using `tf.tensor6d` as it makes the code more readable.\n *\n *  ```js\n * // Pass a nested array.\n * tf.tensor6d([[[[[[1],[2]],[[3],[4]]],[[[5],[6]],[[7],[8]]]]]]).print();\n * ```\n * ```js\n * // Pass a flat array and specify a shape.\n * tf.tensor6d([1, 2, 3, 4, 5, 6, 7, 8], [1, 1, 2, 2, 2, 1]).print();\n * ```\n *\n * @param values The values of the tensor. Can be nested array of numbers,\n *     or a flat array, or a `TypedArray`.\n * @param shape The shape of the tensor. Optional. If not provided,\n *   it is inferred from `values`.\n * @param dtype The data type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction tensor6d(values, shape, dtype) {\n    util_1.assertNonNull(values);\n    if (shape != null && shape.length !== 6) {\n        throw new Error('tensor6d() requires shape to have six numbers');\n    }\n    var inferredShape = tensor_util_env_1.inferShape(values, dtype);\n    if (inferredShape.length !== 6 && inferredShape.length !== 1) {\n        throw new Error('tensor6d() requires values to be number[][][][][][] or ' +\n            'flat/TypedArray');\n    }\n    if (inferredShape.length === 1 && shape == null) {\n        throw new Error('tensor6d() requires shape to be provided when `values` ' +\n            'are a flat array');\n    }\n    shape = shape ||\n        inferredShape;\n    return makeTensor(values, shape, inferredShape, dtype);\n}\nexports.tensor6d = tensor6d;\n/**\n * Creates a new variable with the provided initial value.\n * ```js\n * const x = tf.variable(tf.tensor([1, 2, 3]));\n * x.assign(tf.tensor([4, 5, 6]));\n *\n * x.print();\n * ```\n *\n * @param initialValue Initial value for the tensor.\n * @param trainable If true, optimizers are allowed to update it.\n * @param name Name of the variable. Defaults to a unique id.\n * @param dtype If set, initialValue will be converted to the given type.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction variable(initialValue, trainable, name, dtype) {\n    if (trainable === void 0) { trainable = true; }\n    return engine_1.ENGINE.makeVariable(initialValue, trainable, name, dtype);\n}\nexports.variable = variable;\n/**\n * Creates a `tf.Tensor` with all elements set to 1.\n *\n * ```js\n * tf.ones([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n *     'float'.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction ones(shape, dtype) {\n    if (dtype === void 0) { dtype = 'float32'; }\n    if (dtype === 'complex64') {\n        var real_1 = ones(shape, 'float32');\n        var imag_1 = zeros(shape, 'float32');\n        return complex_ops_1.complex(real_1, imag_1);\n    }\n    var values = util_1.makeOnesTypedArray(util_1.sizeFromShape(shape), dtype);\n    return engine_1.ENGINE.makeTensor(values, shape, dtype);\n}\nexports.ones = ones;\n/**\n * Creates a `tf.Tensor` with all elements set to 0.\n *\n * ```js\n * tf.zeros([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Can\n *     be 'float32', 'int32' or 'bool'. Defaults to 'float'.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction zeros(shape, dtype) {\n    if (dtype === void 0) { dtype = 'float32'; }\n    if (dtype === 'complex64') {\n        var real_2 = zeros(shape, 'float32');\n        var imag_2 = zeros(shape, 'float32');\n        return complex_ops_1.complex(real_2, imag_2);\n    }\n    var values = util_1.makeZerosTypedArray(util_1.sizeFromShape(shape), dtype);\n    return engine_1.ENGINE.makeTensor(values, shape, dtype);\n}\nexports.zeros = zeros;\n/**\n * Creates a `tf.Tensor` filled with a scalar value.\n *\n * ```js\n * tf.fill([2, 2], 4).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param value The scalar value to fill the tensor with.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n * 'float'.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction fill(shape, value, dtype) {\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.fill(shape, value, dtype); }, {});\n}\nexports.fill = fill;\n/**\n * Creates a `tf.Tensor` with all elements set to 1 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.onesLike(x).print();\n * ```\n * @param x A tensor.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction onesLike_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'onesLike');\n    if ($x.dtype === 'complex64') {\n        var r = exports.onesLike(complex_ops_1.real($x));\n        var i = exports.zerosLike(complex_ops_1.imag($x));\n        return complex_ops_1.complex(r, i);\n    }\n    var der = function (dy, saved) { return ({ $x: function () { return exports.zerosLike(dy); } }); };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.onesLike($x); }, { $x: $x }, der);\n}\n/**\n * Creates a `tf.Tensor` with all elements set to 0 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.zerosLike(x).print();\n * ```\n *\n * @param x The tensor of required shape.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction zerosLike_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'zerosLike');\n    var der = function (dy, saved) { return ({ $x: function () { return exports.zerosLike(dy); } }); };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.zerosLike($x); }, { $x: $x }, der);\n}\n/**\n * Return an evenly spaced sequence of numbers over the given interval.\n *\n * ```js\n * tf.linspace(0, 9, 10).print();\n * ```\n * @param start The start value of the sequence.\n * @param stop The end value of the sequence.\n * @param num The number of values to generate.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction linspace(start, stop, num) {\n    if (num <= 0) {\n        throw new Error('The number of values should be positive.');\n    }\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.linspace(start, stop, num); }, {});\n}\nexports.linspace = linspace;\n/**\n * Creates a new `tf.Tensor1D` filled with the numbers in the range provided.\n *\n * The tensor is a is half-open interval meaning it includes start, but\n * excludes stop. Decrementing ranges and negative step values are also\n * supported.\n *\n * ```js\n * tf.range(0, 9, 2).print();\n * ```\n *\n * @param start An integer start value\n * @param stop An integer stop value\n * @param step An integer increment (will default to 1 or -1)\n * @param dtype The data type of the output tensor. Defaults to 'float32'.\n */\n/** @doc {heading: 'Tensors', subheading: 'Creation'} */\nfunction range(start, stop, step, dtype) {\n    if (step === void 0) { step = 1; }\n    if (dtype === void 0) { dtype = 'float32'; }\n    if (step === 0) {\n        throw new Error('Cannot have a step of zero');\n    }\n    var sameStartStop = start === stop;\n    var increasingRangeNegativeStep = start < stop && step < 0;\n    var decreasingRangePositiveStep = stop < start && step > 1;\n    if (sameStartStop || increasingRangeNegativeStep ||\n        decreasingRangePositiveStep) {\n        return zeros([0], dtype);\n    }\n    var numElements = Math.abs(Math.ceil((stop - start) / step));\n    var values = util_1.makeZerosTypedArray(numElements, dtype);\n    if (stop < start && step === 1) {\n        // Auto adjust the step's sign if it hasn't been set\n        // (or was set to 1)\n        step = -1;\n    }\n    values[0] = start;\n    for (var i = 1; i < values.length; i++) {\n        values[i] = values[i - 1] + step;\n    }\n    return tensor1d(values, dtype);\n}\nexports.range = range;\nexports.onesLike = operation_1.op({ onesLike_: onesLike_ });\nexports.zerosLike = operation_1.op({ zerosLike_: zerosLike_ });\n//# sourceMappingURL=tensor_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/topk.js":
/*!*************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/topk.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Finds the values and indices of the `k` largest entries along the last\n * dimension.\n *\n * If the input is a vector (rank=1), finds the k largest entries in the vector\n * and outputs their values and indices as vectors. Thus values[j] is the j-th\n * largest entry in input, and its index is indices[j].\n * For higher rank inputs, computes the top k entries along the last dimension.\n *\n * If two elements are equal, the lower-index element appears first.\n *\n * ```js\n * const a = tf.tensor2d([[1, 5], [4, 3]]);\n * const {values, indices} = tf.topk(a);\n * values.print();\n * indices.print();\n * ```\n * @param x 1-D or higher `tf.Tensor` with last dimension being at least `k`.\n * @param k Number of top elements to look for along the last dimension.\n * @param sorted If true, the resulting `k` elements will be sorted by the\n *     values in descending order.\n */\n/** @doc {heading: 'Operations', subheading: 'Evaluation'} */\nfunction topk_(x, k, sorted) {\n    if (k === void 0) { k = 1; }\n    if (sorted === void 0) { sorted = true; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'topk');\n    if ($x.rank === 0) {\n        throw new Error('topk() expects the input to be of rank 1 or higher');\n    }\n    var lastDim = $x.shape[$x.shape.length - 1];\n    if (k > lastDim) {\n        throw new Error(\"'k' passed to topk() must be <= the last dimension (\" + lastDim + \") \" +\n            (\"but got \" + k));\n    }\n    var _a = engine_1.ENGINE.runKernelFunc(function (b) { return b.topk($x, k, sorted); }, { $x: $x }), values = _a[0], indices = _a[1];\n    return { values: values, indices: indices };\n}\nexports.topk = operation_1.op({ topk_: topk_ });\n//# sourceMappingURL=topk.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/topk.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar axis_util = __webpack_require__(/*! ./axis_util */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\n/**\n * Transposes the `tf.Tensor`. Permutes the dimensions according to `perm`.\n *\n * The returned `tf.Tensor`'s dimension `i` will correspond to the input\n * dimension `perm[i]`. If `perm` is not given, it is set to `[n-1...0]`,\n * where `n` is the rank of the input `tf.Tensor`. Hence by default, this\n * operation performs a regular matrix transpose on 2-D input `tf.Tensor`s.\n *\n * ```js\n * const a = tf.tensor2d([1, 2, 3, 4, 5, 6], [2, 3]);\n *\n * a.transpose().print();  // or tf.transpose(a)\n * ```\n *\n * @param x The tensor to transpose.\n * @param perm The permutation of the dimensions of a.\n */\n/** @doc {heading: 'Operations', subheading: 'Matrices'} */\nfunction transpose_(x, perm) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'transpose');\n    if (perm == null) {\n        perm = $x.shape.map(function (s, i) { return i; }).reverse();\n    }\n    util.assert($x.rank === perm.length, function () { return \"Error in transpose: rank of input \" + $x.rank + \" \" +\n        (\"must match length of perm \" + perm + \".\"); });\n    perm.forEach(function (axis) {\n        util.assert(axis >= 0 && axis < $x.rank, function () { return \"All entries in 'perm' must be between 0 and \" + ($x.rank - 1) +\n            (\" but got \" + perm); });\n    });\n    if ($x.rank <= 1) {\n        return $x.clone();\n    }\n    var der = function (dy) {\n        var undoPerm = axis_util.getUndoAxesPermutation(perm);\n        return { x: function () { return dy.transpose(undoPerm); } };\n    };\n    var attrs = { perm: perm };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.transpose($x, perm); }, { x: $x }, der, 'Transpose', attrs);\n}\nexports.transpose = operation_1.op({ transpose_: transpose_ });\n//# sourceMappingURL=transpose.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/ops/unary_ops.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/ops/unary_ops.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ../tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util = __webpack_require__(/*! ../util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar operation_1 = __webpack_require__(/*! ./operation */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js\");\nvar tensor_ops_1 = __webpack_require__(/*! ./tensor_ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops.js\");\n/**\n * Computes `-1 * x` element-wise.\n *\n * ```js\n * const x = tf.tensor2d([1, 2, -2, 0], [2, 2]);\n *\n * x.neg().print();  // or tf.neg(x)\n * ```\n *\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction neg_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'neg');\n    var grad = function (dy) {\n        return { x: function () { return dy.neg(); } };\n    };\n    var attrs = {};\n    var inputsToSave = [$x];\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.neg($x); }, { x: $x }, grad, 'Neg', attrs, inputsToSave);\n}\n/**\n * Computes ceiling of input `tf.Tensor` element-wise: `ceil(x)`\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.ceil().print();  // or tf.ceil(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction ceil_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'ceil');\n    // TODO(manrajgrover): Return null for gradients when backprop supports it.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.ceil($x); }, { $x: $x }, grad);\n}\n/**\n * Computes floor of input `tf.Tensor` element-wise: `floor(x)`.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.floor().print();  // or tf.floor(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction floor_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'floor');\n    // TODO(nsthorat): Let gradients be null for cases where we want to stop\n    // backpropgation.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.floor($x); }, { $x: $x }, grad);\n}\n/**\n * Returns an element-wise indication of the sign of a number.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3, NaN, 0]);\n *\n * x.sign().print();  // or tf.sign(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction sign_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sign');\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.sign($x); }, { $x: $x }, grad);\n}\n/**\n * RReturns which elements of x are NaN.\n *\n * ```js\n * const x = tf.tensor1d([NaN, Infinity, -Infinity, 0, 1]);\n *\n * x.isNaN().print();  // or tf.isNaN(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction isNaN_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'isNaN');\n    // TODO(nsthorat): Let gradients be null for cases where we want to stop\n    // backpropgation.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.isNaN($x); }, { $x: $x }, grad);\n}\n/**\n * Returns which elements of x are Infinity or -Infinity.\n *\n * ```js\n * const x = tf.tensor1d([NaN, Infinity, -Infinity, 0, 1]);\n *\n * x.isInf().print();  // or tf.isNaN(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction isInf_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'isInf');\n    // TODO(nsthorat): Let gradients be null for cases where we want to stop\n    // backpropgation.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.isInf($x); }, { $x: $x }, grad);\n}\n/**\n * Returns which elements of x are finite.\n *\n * ```js\n * const x = tf.tensor1d([NaN, Infinity, -Infinity, 0, 1]);\n *\n * x.isFinite().print();  // or tf.isNaN(x)\n * ```\n * @param x The input Tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction isFinite_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'isFinite');\n    // TODO(nsthorat): Let gradients be null for cases where we want to stop\n    // backpropgation.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.isFinite($x); }, { $x: $x }, grad);\n}\n/**\n * Computes round of input `tf.Tensor` element-wise: `round(x)`.\n * It implements banker's rounding.\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.round().print();  // or tf.round(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction round_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'round');\n    // TODO(nsthorat): Let gradients be null for cases where we want to stop\n    // backpropgation.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.round($x); }, { $x: $x }, grad);\n}\n/**\n * Computes exponential of the input `tf.Tensor` element-wise. `e ^ x`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.exp().print();  // or tf.exp(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction exp_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'exp');\n    var bck = function (dy, saved) {\n        return { x: function () { return dy.mulStrict(saved[0]); } };\n    };\n    var attrs = {};\n    var inputsToSave = [];\n    var outputsToSave = [true];\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.exp($x);\n        save([y]);\n        return y;\n    }, { x: $x }, bck, 'Exp', attrs, inputsToSave, outputsToSave);\n}\n/**\n * Computes exponential of the input `tf.Tensor` minus one element-wise.\n * `e ^ x - 1`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.expm1().print();  // or tf.expm1(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction expm1_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'expm1');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.mul($x.exp()); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.expm1($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes natural logarithm of the input `tf.Tensor` element-wise: `ln(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.E]);\n *\n * x.log().print();  // or tf.log(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction log_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'log');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { x: function () { return dy.div($x.toFloat()); } };\n    };\n    var attrs = {};\n    var inputsToSave = [$x];\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.log($x);\n        save([$x]);\n        return res;\n    }, { x: $x }, grad, 'Log', attrs, inputsToSave);\n}\n/**\n * Computes natural logarithm of the input `tf.Tensor` plus one\n * element-wise: `ln(1 + x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, Math.E - 1]);\n *\n * x.log1p().print();  // or tf.log1p(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction log1p_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'log1p');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.add(1)); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.log1p($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes square root of the input `tf.Tensor` element-wise: `y = sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.sqrt().print();  // or tf.sqrt(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction sqrt_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sqrt');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.toFloat().sqrt().mul(2)); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.sqrt($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes reciprocal of square root of the input `tf.Tensor` element-wise:\n * `y = 1 / sqrt(x)`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 4, -1]);\n *\n * x.rsqrt().print();  // or tf.rsqrt(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction rsqrt_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'rsqrt');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { x: function () { return dy.div($x.pow(1.5).mul(2)).neg(); } };\n    };\n    var inputsToSave = [$x];\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.rsqrt($x);\n        save([$x]);\n        return res;\n    }, { x: $x }, grad, 'Rsqrt', {} /* attrs */, inputsToSave);\n}\n/**\n * Computes reciprocal of x element-wise: `1 / x`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, 2]);\n *\n * x.reciprocal().print();  // or tf.reciprocal(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction reciprocal_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'reciprocal');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.square().neg()); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.reciprocal($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes absolute value element-wise: `abs(x)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.abs().print();  // or tf.abs(x)\n * ```\n * @param x The input `tf.Tensor`.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction abs_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'abs');\n    if ($x.dtype === 'complex64') {\n        return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.complexAbs($x); }, { $x: $x });\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { x: function () { return dy.mul($x.toFloat().step(-1)); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.abs($x);\n        save([$x]);\n        return res;\n    }, { x: $x }, grad, 'Abs');\n}\n/**\n * Clips values element-wise. `max(min(x, clipValueMax), clipValueMin)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.clipByValue(-2, 3).print();  // or tf.clipByValue(x, -2, 3)\n * ```\n * @param x The input tensor.\n * @param clipValueMin Lower-bound of range to be clipped to.\n * @param clipValueMax Upper-bound of range to be clipped to.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction clipByValue_(x, clipValueMin, clipValueMax) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'clipByValue');\n    util.assert((clipValueMin <= clipValueMax), function () { return \"Error in clip: min (\" + clipValueMin + \") must be \" +\n        (\"less than or equal to max (\" + clipValueMax + \").\"); });\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            x: function () { return dy.where($x.greaterEqual(clipValueMin)\n                .logicalAnd($x.lessEqual(clipValueMax)), tensor_ops_1.zerosLike(dy)); },\n        };\n    };\n    var inputsToSave = [$x];\n    var attr = { min: clipValueMin, max: clipValueMax };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.clip($x, clipValueMin, clipValueMax);\n        save([$x]);\n        return res;\n    }, { x: $x }, grad, 'ClipByValue', attr, inputsToSave);\n}\n/**\n * Computes sigmoid element-wise, `1 / (1 + exp(-x))`\n *\n * ```js\n * const x = tf.tensor1d([0, -1, 2, -3]);\n *\n * x.sigmoid().print();  // or tf.sigmoid(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction sigmoid_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sigmoid');\n    var grad = function (dy, saved) {\n        var y = saved[0];\n        return { x: function () { return dy.mul(y.mul(tensor_ops_1.scalar(1).sub(y))); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.sigmoid($x);\n        save([y]);\n        return y;\n    }, { x: $x }, grad, 'Sigmoid');\n}\n/**\n * Computes log sigmoid of the input `tf.Tensor` element-wise:\n * `logSigmoid(x)`. For numerical stability, we use `-tf.softplus(-x)`.\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.logSigmoid().print();  // or tf.logSigmoid(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction logSigmoid_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'logSigmoid');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.mul($x.neg().sigmoid()); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.softplus($x.neg()).neg();\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes softplus of the input `tf.Tensor` element-wise: `log(exp(x) + 1)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.softplus().print();  // or tf.softplus(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction softplus_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'softplus');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.mul($x.sigmoid()); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.softplus($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes sin of the input Tensor element-wise: `sin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.sin().print();  // or tf.sin(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction sin_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sin');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { x: function () { return $x.toFloat().cos().mul(dy); } };\n    };\n    var inputsToSave = [$x];\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.sin($x);\n        save([$x]);\n        return res;\n    }, { x: $x }, grad, 'Sin', {} /* attrs */, inputsToSave);\n}\n/**\n * Computes cos of the input `tf.Tensor` element-wise: `cos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.cos().print();  // or tf.cos(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction cos_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'cos');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { x: function () { return $x.toFloat().sin().neg().mul(dy); } };\n    };\n    var inputsToSave = [$x];\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.cos($x);\n        save([$x]);\n        return res;\n    }, { x: $x }, grad, 'Cos', {} /* attrs */, inputsToSave);\n}\n/**\n * Computes tan of the input `tf.Tensor` element-wise, `tan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.tan().print();  // or tf.tan(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction tan_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'tan');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.cos().square()); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.tan($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes asin of the input `tf.Tensor` element-wise: `asin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asin().print();  // or tf.asin(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction asin_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'asin');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () { return dy.divStrict(tensor_ops_1.scalar(1).sub($x.toFloat().square()).sqrt()); }\n        };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.asin($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes acos of the input `tf.Tensor` element-wise: `acos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.acos().print();  // or tf.acos(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction acos_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'acos');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () {\n                return dy.divStrict(tensor_ops_1.scalar(1).sub($x.toFloat().square()).sqrt()).neg();\n            }\n        };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.acos($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes atan of the input `tf.Tensor` element-wise: `atan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.atan().print();  // or tf.atan(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction atan_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'atan');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div($x.toFloat().square().add(1)); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.atan($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes hyperbolic sin of the input `tf.Tensor` element-wise: `sinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.sinh().print();  // or tf.sinh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction sinh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'sinh');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return $x.toFloat().cosh().mulStrict(dy); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.sinh($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes hyperbolic cos of the input `tf.Tensor` element-wise: `cosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.cosh().print();  // or tf.cosh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction cosh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'cosh');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return $x.toFloat().sinh().mulStrict(dy); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.cosh($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes hyperbolic tangent of the input `tf.Tensor` element-wise: `tanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, 70]);\n *\n * x.tanh().print();  // or tf.tanh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction tanh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'tanh');\n    var grad = function (dy, saved) {\n        var y = saved[0];\n        return { x: function () { return tensor_ops_1.scalar(1).sub(y.square()).mulStrict(dy); } };\n    };\n    var outputsToSave = [true];\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var y = backend.tanh($x);\n        save([y]);\n        return y;\n    }, { x: $x }, grad, 'Tanh', {} /* attrs */, null /* inputsToSave */, outputsToSave);\n}\n/**\n * Computes inverse hyperbolic sin of the input `tf.Tensor` element-wise:\n * `asinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asinh().print();  // or tf.asinh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction asinh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'asinh');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () { return dy.divStrict(tensor_ops_1.scalar(1).add($x.toFloat().square()).sqrt()); }\n        };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.asinh($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes the inverse hyperbolic cos of the input `tf.Tensor` element-wise:\n * `acosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([10, 1, 3, 5.7]);\n *\n * x.acosh().print();  // or tf.acosh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction acosh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'acosh');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.divStrict($x.toFloat().square().sub(1).sqrt()); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.acosh($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes inverse hyperbolic tan of the input `tf.Tensor` element-wise:\n * `atanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.atanh().print();  // or tf.atanh(x)\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction atanh_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'atanh');\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return { $x: function () { return dy.div(tensor_ops_1.scalar(1).sub($x.toFloat().square())); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.atanh($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes gause error function of the input `tf.Tensor` element-wise:\n * `erf(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.erf().print(); // or tf.erf(x);\n * ```\n * @param x The input tensor.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction erf_(x) {\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'erf');\n    util.assert($x.dtype === 'int32' || $x.dtype === 'float32', function () { return 'Input dtype must be `int32` or `float32`.'; });\n    if ($x.dtype === 'int32') {\n        $x = $x.toFloat();\n    }\n    var grad = function (dy, saved) {\n        var $x = saved[0];\n        return {\n            $x: function () { return dy.mul($x.square().neg().exp().mul(2 / Math.sqrt(Math.PI))); }\n        };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend, save) {\n        var res = backend.erf($x);\n        save([$x]);\n        return res;\n    }, { $x: $x }, grad);\n}\n/**\n * Computes step of the input `tf.Tensor` element-wise: `x > 0 ? 1 : alpha * x`\n *\n * ```js\n * const x = tf.tensor1d([0, 2, -1, -3]);\n *\n * x.step(.5).print();  // or tf.step(x, .5)\n * ```\n * @param x The input tensor.\n * @param alpha The gradient when input is negative.\n */\n/** @doc {heading: 'Operations', subheading: 'Basic math'} */\nfunction step_(x, alpha) {\n    if (alpha === void 0) { alpha = 0.0; }\n    var $x = tensor_util_env_1.convertToTensor(x, 'x', 'step');\n    // TODO(manrajgrover): Return null for gradients when backprop supports\n    // it.\n    var grad = function (dy) {\n        return { $x: function () { return tensor_ops_1.zerosLike(dy); } };\n    };\n    return engine_1.ENGINE.runKernelFunc(function (backend) { return backend.step($x, alpha); }, { $x: $x }, grad);\n}\nexports.abs = operation_1.op({ abs_: abs_ });\nexports.acos = operation_1.op({ acos_: acos_ });\nexports.acosh = operation_1.op({ acosh_: acosh_ });\nexports.asin = operation_1.op({ asin_: asin_ });\nexports.asinh = operation_1.op({ asinh_: asinh_ });\nexports.atan = operation_1.op({ atan_: atan_ });\nexports.atanh = operation_1.op({ atanh_: atanh_ });\nexports.ceil = operation_1.op({ ceil_: ceil_ });\nexports.clipByValue = operation_1.op({ clipByValue_: clipByValue_ });\nexports.cos = operation_1.op({ cos_: cos_ });\nexports.cosh = operation_1.op({ cosh_: cosh_ });\nexports.erf = operation_1.op({ erf_: erf_ });\nexports.exp = operation_1.op({ exp_: exp_ });\nexports.expm1 = operation_1.op({ expm1_: expm1_ });\nexports.floor = operation_1.op({ floor_: floor_ });\nexports.log = operation_1.op({ log_: log_ });\nexports.log1p = operation_1.op({ log1p_: log1p_ });\nexports.logSigmoid = operation_1.op({ logSigmoid_: logSigmoid_ });\nexports.neg = operation_1.op({ neg_: neg_ });\nexports.reciprocal = operation_1.op({ reciprocal_: reciprocal_ });\nexports.round = operation_1.op({ round_: round_ });\nexports.rsqrt = operation_1.op({ rsqrt_: rsqrt_ });\nexports.sigmoid = operation_1.op({ sigmoid_: sigmoid_ });\nexports.sign = operation_1.op({ sign_: sign_ });\nexports.isNaN = operation_1.op({ isNaN_: isNaN_ });\nexports.isInf = operation_1.op({ isInf_: isInf_ });\nexports.isFinite = operation_1.op({ isFinite_: isFinite_ });\nexports.sin = operation_1.op({ sin_: sin_ });\nexports.sinh = operation_1.op({ sinh_: sinh_ });\nexports.softplus = operation_1.op({ softplus_: softplus_ });\nexports.sqrt = operation_1.op({ sqrt_: sqrt_ });\nexports.step = operation_1.op({ step_: step_ });\nexports.tan = operation_1.op({ tan_: tan_ });\nexports.tanh = operation_1.op({ tanh_: tanh_ });\n//# sourceMappingURL=unary_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/ops/unary_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar globals_1 = __webpack_require__(/*! ../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar ops_1 = __webpack_require__(/*! ../ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\nvar serialization_1 = __webpack_require__(/*! ../serialization */ \"./node_modules/@tensorflow/tfjs-core/dist/serialization.js\");\nvar optimizer_1 = __webpack_require__(/*! ./optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js\");\n/** @doclink Optimizer */\nvar AdadeltaOptimizer = /** @class */ (function (_super) {\n    __extends(AdadeltaOptimizer, _super);\n    function AdadeltaOptimizer(learningRate, rho, epsilon) {\n        if (epsilon === void 0) { epsilon = null; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.rho = rho;\n        _this.epsilon = epsilon;\n        _this.accumulatedGrads = [];\n        _this.accumulatedUpdates = [];\n        if (epsilon == null) {\n            _this.epsilon = engine_1.ENGINE.backend.epsilon();\n        }\n        return _this;\n    }\n    AdadeltaOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (item) { return item.name; }) :\n            Object.keys(variableGradients);\n        variableNames.forEach(function (name, i) {\n            var value = engine_1.ENGINE.registeredVariables[name];\n            var trainable = false;\n            if (_this.accumulatedGrads[i] == null) {\n                _this.accumulatedGrads[i] = {\n                    originalName: name + \"/accum_grad\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                };\n            }\n            if (_this.accumulatedUpdates[i] == null) {\n                _this.accumulatedUpdates[i] = {\n                    originalName: name + \"/accum_var\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                };\n            }\n            var gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            var accumulatedGrad = _this.accumulatedGrads[i].variable;\n            var accumulatedUpdate = _this.accumulatedUpdates[i].variable;\n            globals_1.tidy(function () {\n                var newAccumulatedGrad = accumulatedGrad.mul(_this.rho).add(gradient.square().mul(1 - _this.rho));\n                var updates = accumulatedUpdate.add(_this.epsilon)\n                    .sqrt()\n                    .div(accumulatedGrad.add(_this.epsilon).sqrt())\n                    .mul(gradient);\n                var newAccumulatedUpdate = accumulatedUpdate.mul(_this.rho).add(updates.square().mul(1 - _this.rho));\n                accumulatedGrad.assign(newAccumulatedGrad);\n                accumulatedUpdate.assign(newAccumulatedUpdate);\n                var newValue = updates.mul(-_this.learningRate).add(value);\n                value.assign(newValue);\n            });\n        });\n        this.incrementIterations();\n    };\n    AdadeltaOptimizer.prototype.dispose = function () {\n        if (this.accumulatedUpdates != null) {\n            globals_1.dispose(this.accumulatedGrads.map(function (v) { return v.variable; }));\n            globals_1.dispose(this.accumulatedUpdates.map(function (v) { return v.variable; }));\n        }\n    };\n    AdadeltaOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var variables;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        variables = this.accumulatedGrads.concat(this.accumulatedUpdates);\n                        return [4 /*yield*/, this.saveIterations()];\n                    case 1: return [2 /*return*/, [_a.sent()].concat(variables.map(function (v) { return ({ name: v.originalName, tensor: v.variable }); }))];\n                }\n            });\n        });\n    };\n    AdadeltaOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var variableCount, trainable;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        variableCount = weightValues.length / 2;\n                        trainable = false;\n                        this.accumulatedGrads =\n                            weightValues.slice(0, variableCount).map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        this.accumulatedUpdates =\n                            weightValues.slice(variableCount, variableCount * 2)\n                                .map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    AdadeltaOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'rho': this.rho,\n            'epsilon': this.epsilon\n        };\n    };\n    /** @nocollapse */\n    AdadeltaOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['rho'], config['epsilon']);\n    };\n    /** @nocollapse */\n    AdadeltaOptimizer.className = 'Adadelta'; // Name matters for Python compatibility.\n    return AdadeltaOptimizer;\n}(optimizer_1.Optimizer));\nexports.AdadeltaOptimizer = AdadeltaOptimizer;\nserialization_1.registerClass(AdadeltaOptimizer);\n//# sourceMappingURL=adadelta_optimizer.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar globals_1 = __webpack_require__(/*! ../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar ops_1 = __webpack_require__(/*! ../ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\nvar serialization_1 = __webpack_require__(/*! ../serialization */ \"./node_modules/@tensorflow/tfjs-core/dist/serialization.js\");\nvar optimizer_1 = __webpack_require__(/*! ./optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js\");\n/** @doclink Optimizer */\nvar AdagradOptimizer = /** @class */ (function (_super) {\n    __extends(AdagradOptimizer, _super);\n    function AdagradOptimizer(learningRate, initialAccumulatorValue) {\n        if (initialAccumulatorValue === void 0) { initialAccumulatorValue = 0.1; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.initialAccumulatorValue = initialAccumulatorValue;\n        _this.accumulatedGrads = [];\n        return _this;\n    }\n    AdagradOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (item) { return item.name; }) :\n            Object.keys(variableGradients);\n        variableNames.forEach(function (name, i) {\n            var value = engine_1.ENGINE.registeredVariables[name];\n            if (_this.accumulatedGrads[i] == null) {\n                var trainable_1 = false;\n                _this.accumulatedGrads[i] = {\n                    originalName: name + \"/accumulator\",\n                    variable: globals_1.tidy(function () { return ops_1.fill(value.shape, _this.initialAccumulatorValue)\n                        .variable(trainable_1); })\n                };\n            }\n            var gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            var accumulatedGrad = _this.accumulatedGrads[i].variable;\n            globals_1.tidy(function () {\n                var newAccumulatedGrad = accumulatedGrad.add(gradient.square());\n                accumulatedGrad.assign(newAccumulatedGrad);\n                var newValue = gradient\n                    .div(newAccumulatedGrad.add(engine_1.ENGINE.backend.epsilon()).sqrt())\n                    .mul(-_this.learningRate)\n                    .add(value);\n                value.assign(newValue);\n            });\n        });\n        this.incrementIterations();\n    };\n    AdagradOptimizer.prototype.dispose = function () {\n        if (this.accumulatedGrads != null) {\n            globals_1.dispose(this.accumulatedGrads.map(function (v) { return v.variable; }));\n        }\n    };\n    AdagradOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.saveIterations()];\n                    case 1: \n                    // Order matters for Python compatibility.\n                    return [2 /*return*/, [_a.sent()].concat(this.accumulatedGrads.map(function (v) { return ({ name: v.originalName, tensor: v.variable }); }))];\n                }\n            });\n        });\n    };\n    AdagradOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var trainable;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        trainable = false;\n                        this.accumulatedGrads = weightValues.map(function (v) { return ({ originalName: v.name, variable: v.tensor.variable(trainable) }); });\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    AdagradOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'initialAccumulatorValue': this.initialAccumulatorValue,\n        };\n    };\n    /** @nocollapse */\n    AdagradOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['initialAccumulatorValue']);\n    };\n    /** @nocollapse */\n    AdagradOptimizer.className = 'Adagrad'; // Note: Name matters for Python compatibility.\n    return AdagradOptimizer;\n}(optimizer_1.Optimizer));\nexports.AdagradOptimizer = AdagradOptimizer;\nserialization_1.registerClass(AdagradOptimizer);\n//# sourceMappingURL=adagrad_optimizer.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js":
/*!******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar globals_1 = __webpack_require__(/*! ../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar ops_1 = __webpack_require__(/*! ../ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\nvar serialization_1 = __webpack_require__(/*! ../serialization */ \"./node_modules/@tensorflow/tfjs-core/dist/serialization.js\");\nvar optimizer_1 = __webpack_require__(/*! ./optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js\");\nvar AdamOptimizer = /** @class */ (function (_super) {\n    __extends(AdamOptimizer, _super);\n    function AdamOptimizer(learningRate, beta1, beta2, epsilon) {\n        if (epsilon === void 0) { epsilon = null; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.beta1 = beta1;\n        _this.beta2 = beta2;\n        _this.epsilon = epsilon;\n        _this.accumulatedFirstMoment = [];\n        _this.accumulatedSecondMoment = [];\n        globals_1.tidy(function () {\n            // accB* will be updated by batch.\n            _this.accBeta1 = ops_1.scalar(beta1).variable();\n            _this.accBeta2 = ops_1.scalar(beta2).variable();\n        });\n        if (epsilon == null) {\n            _this.epsilon = engine_1.ENGINE.backend.epsilon();\n        }\n        return _this;\n    }\n    AdamOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var varNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (v) { return v.name; }) :\n            Object.keys(variableGradients);\n        globals_1.tidy(function () {\n            var oneMinusAccBeta1 = ops_1.sub(1, _this.accBeta1);\n            var oneMinusAccBeta2 = ops_1.sub(1, _this.accBeta2);\n            varNames.forEach(function (name, i) {\n                var value = engine_1.ENGINE.registeredVariables[name];\n                var trainable = false;\n                if (_this.accumulatedFirstMoment[i] == null) {\n                    _this.accumulatedFirstMoment[i] = {\n                        originalName: name + \"/m\",\n                        variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                    };\n                }\n                if (_this.accumulatedSecondMoment[i] == null) {\n                    _this.accumulatedSecondMoment[i] = {\n                        originalName: name + \"/v\",\n                        variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                    };\n                }\n                var gradient = Array.isArray(variableGradients) ?\n                    variableGradients[i].tensor :\n                    variableGradients[name];\n                if (gradient == null) {\n                    return;\n                }\n                var firstMoment = _this.accumulatedFirstMoment[i].variable;\n                var secondMoment = _this.accumulatedSecondMoment[i].variable;\n                var newFirstMoment = firstMoment.mul(_this.beta1).add(gradient.mul(1 - _this.beta1));\n                var newSecondMoment = secondMoment.mul(_this.beta2)\n                    .add(gradient.square().mul(1 - _this.beta2));\n                var biasCorrectedFirstMoment = newFirstMoment.div(oneMinusAccBeta1);\n                var biasCorrectedSecondMoment = newSecondMoment.div(oneMinusAccBeta2);\n                firstMoment.assign(newFirstMoment);\n                secondMoment.assign(newSecondMoment);\n                var newValue = biasCorrectedFirstMoment\n                    .div(biasCorrectedSecondMoment.sqrt().add(_this.epsilon))\n                    .mul(-_this.learningRate)\n                    .add(value);\n                value.assign(newValue);\n            });\n            _this.accBeta1.assign(_this.accBeta1.mul(_this.beta1));\n            _this.accBeta2.assign(_this.accBeta2.mul(_this.beta2));\n        });\n        this.incrementIterations();\n    };\n    AdamOptimizer.prototype.dispose = function () {\n        this.accBeta1.dispose();\n        this.accBeta2.dispose();\n        if (this.accumulatedFirstMoment != null) {\n            globals_1.dispose(this.accumulatedFirstMoment.map(function (v) { return v.variable; }));\n        }\n        if (this.accumulatedSecondMoment != null) {\n            globals_1.dispose(this.accumulatedSecondMoment.map(function (v) { return v.variable; }));\n        }\n    };\n    AdamOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var variables;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        variables = this.accumulatedFirstMoment.concat(this.accumulatedSecondMoment);\n                        return [4 /*yield*/, this.saveIterations()];\n                    case 1: return [2 /*return*/, [_a.sent()].concat(variables.map(function (v) { return ({ name: v.originalName, tensor: v.variable }); }))];\n                }\n            });\n        });\n    };\n    AdamOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var variableCount, trainable;\n            var _this = this;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        globals_1.tidy(function () {\n                            _this.accBeta1.assign(ops_1.pow(_this.beta1, _this.iterations_ + 1));\n                            _this.accBeta2.assign(ops_1.pow(_this.beta2, _this.iterations_ + 1));\n                        });\n                        variableCount = weightValues.length / 2;\n                        trainable = false;\n                        this.accumulatedFirstMoment =\n                            weightValues.slice(0, variableCount).map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        this.accumulatedSecondMoment =\n                            weightValues.slice(variableCount, variableCount * 2)\n                                .map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    AdamOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'beta1': this.beta1,\n            'beta2': this.beta2,\n            'epsilon': this.epsilon,\n        };\n    };\n    /** @nocollapse */\n    AdamOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['beta1'], config['beta2'], config['epsilon']);\n    };\n    /** @nocollapse */\n    AdamOptimizer.className = 'Adam'; // Note: Name matters for Python compatibility.\n    return AdamOptimizer;\n}(optimizer_1.Optimizer));\nexports.AdamOptimizer = AdamOptimizer;\nserialization_1.registerClass(AdamOptimizer);\n//# sourceMappingURL=adam_optimizer.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar globals_1 = __webpack_require__(/*! ../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar ops_1 = __webpack_require__(/*! ../ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\nvar serialization_1 = __webpack_require__(/*! ../serialization */ \"./node_modules/@tensorflow/tfjs-core/dist/serialization.js\");\nvar optimizer_1 = __webpack_require__(/*! ./optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js\");\nvar AdamaxOptimizer = /** @class */ (function (_super) {\n    __extends(AdamaxOptimizer, _super);\n    function AdamaxOptimizer(learningRate, beta1, beta2, epsilon, decay) {\n        if (epsilon === void 0) { epsilon = null; }\n        if (decay === void 0) { decay = 0.0; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.beta1 = beta1;\n        _this.beta2 = beta2;\n        _this.epsilon = epsilon;\n        _this.decay = decay;\n        _this.accumulatedFirstMoment = [];\n        _this.accumulatedWeightedInfNorm = [];\n        globals_1.tidy(function () {\n            _this.iteration = ops_1.scalar(0).variable();\n            _this.accBeta1 = ops_1.scalar(beta1).variable();\n        });\n        if (epsilon == null) {\n            _this.epsilon = engine_1.ENGINE.backend.epsilon();\n        }\n        return _this;\n    }\n    AdamaxOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (item) { return item.name; }) :\n            Object.keys(variableGradients);\n        globals_1.tidy(function () {\n            var oneMinusAccBeta1 = ops_1.sub(1, _this.accBeta1);\n            var lr = ops_1.div(-_this.learningRate, _this.iteration.mul(_this.decay).add(1));\n            variableNames.forEach(function (name, i) {\n                var value = engine_1.ENGINE.registeredVariables[name];\n                var trainable = false;\n                if (_this.accumulatedFirstMoment[i] == null) {\n                    _this.accumulatedFirstMoment[i] = {\n                        originalName: name + \"/m\",\n                        variable: ops_1.zerosLike(value).variable(trainable)\n                    };\n                }\n                if (_this.accumulatedWeightedInfNorm[i] == null) {\n                    _this.accumulatedWeightedInfNorm[i] = {\n                        originalName: name + \"/v\",\n                        variable: ops_1.zerosLike(value).variable(trainable)\n                    };\n                }\n                var gradient = Array.isArray(variableGradients) ?\n                    variableGradients[i].tensor :\n                    variableGradients[name];\n                if (gradient == null) {\n                    return;\n                }\n                var firstMoment = _this.accumulatedFirstMoment[i].variable;\n                var weightedInfNorm = _this.accumulatedWeightedInfNorm[i].variable;\n                var newFirstMoment = firstMoment.mul(_this.beta1).add(gradient.mul(1 - _this.beta1));\n                var ut0 = weightedInfNorm.mul(_this.beta2);\n                var ut1 = gradient.abs();\n                var newWeightedInfNorm = ut0.maximum(ut1);\n                firstMoment.assign(newFirstMoment);\n                weightedInfNorm.assign(newWeightedInfNorm);\n                var newValue = lr.div(oneMinusAccBeta1)\n                    .mul(newFirstMoment.div(newWeightedInfNorm.add(_this.epsilon)))\n                    .add(value);\n                value.assign(newValue);\n            });\n            _this.iteration.assign(_this.iteration.add(1));\n            _this.accBeta1.assign(_this.accBeta1.mul(_this.beta1));\n        });\n        this.incrementIterations();\n    };\n    AdamaxOptimizer.prototype.dispose = function () {\n        this.accBeta1.dispose();\n        this.iteration.dispose();\n        if (this.accumulatedFirstMoment != null) {\n            globals_1.dispose(this.accumulatedFirstMoment.map(function (v) { return v.variable; }));\n        }\n        if (this.accumulatedWeightedInfNorm != null) {\n            globals_1.dispose(this.accumulatedWeightedInfNorm.map(function (v) { return v.variable; }));\n        }\n    };\n    AdamaxOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                throw new Error('getWeights() is not implemented for Adamax yet.');\n            });\n        });\n    };\n    AdamaxOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                throw new Error('setWeights() is not implemented for Adamax yet.');\n            });\n        });\n    };\n    AdamaxOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'beta1': this.beta1,\n            'beta2': this.beta2,\n            'epsilon': this.epsilon,\n            'decay': this.decay\n        };\n    };\n    /** @nocollapse */\n    AdamaxOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['beta1'], config['beta2'], config['epsilon'], config['decay']);\n    };\n    /** @nocollapse */\n    AdamaxOptimizer.className = 'Adamax'; // Note: Name matters for Python compatbility.\n    return AdamaxOptimizer;\n}(optimizer_1.Optimizer));\nexports.AdamaxOptimizer = AdamaxOptimizer;\nserialization_1.registerClass(AdamaxOptimizer);\n//# sourceMappingURL=adamax_optimizer.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar globals_1 = __webpack_require__(/*! ../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar ops_1 = __webpack_require__(/*! ../ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\nvar serialization_1 = __webpack_require__(/*! ../serialization */ \"./node_modules/@tensorflow/tfjs-core/dist/serialization.js\");\nvar sgd_optimizer_1 = __webpack_require__(/*! ./sgd_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js\");\n/** @doclink Optimizer */\nvar MomentumOptimizer = /** @class */ (function (_super) {\n    __extends(MomentumOptimizer, _super);\n    function MomentumOptimizer(learningRate, momentum, useNesterov) {\n        if (useNesterov === void 0) { useNesterov = false; }\n        var _this = _super.call(this, learningRate) || this;\n        _this.learningRate = learningRate;\n        _this.momentum = momentum;\n        _this.useNesterov = useNesterov;\n        _this.accumulations = [];\n        _this.m = ops_1.scalar(_this.momentum);\n        return _this;\n    }\n    MomentumOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (item) { return item.name; }) :\n            Object.keys(variableGradients);\n        variableNames.forEach(function (name, i) {\n            var value = engine_1.ENGINE.registeredVariables[name];\n            if (_this.accumulations[i] == null) {\n                var trainable_1 = false;\n                _this.accumulations[i] = {\n                    originalName: name + \"/momentum\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable_1); })\n                };\n            }\n            var accumulation = _this.accumulations[i].variable;\n            var gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            globals_1.tidy(function () {\n                var newValue;\n                var newAccumulation = _this.m.mul(accumulation).add(gradient);\n                if (_this.useNesterov) {\n                    newValue =\n                        _this.c.mul(gradient.add(newAccumulation.mul(_this.m))).add(value);\n                }\n                else {\n                    newValue = _this.c.mul(newAccumulation).add(value);\n                }\n                accumulation.assign(newAccumulation);\n                value.assign(newValue);\n            });\n        });\n        this.incrementIterations();\n    };\n    MomentumOptimizer.prototype.dispose = function () {\n        this.m.dispose();\n        if (this.accumulations != null) {\n            globals_1.dispose(this.accumulations.map(function (v) { return v.variable; }));\n        }\n    };\n    /**\n     * Sets the momentum of the optimizer.\n     *\n     * @param momentum\n     */\n    MomentumOptimizer.prototype.setMomentum = function (momentum) {\n        this.momentum = momentum;\n    };\n    MomentumOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.saveIterations()];\n                    case 1: \n                    // Order matters for Python compatibility.\n                    return [2 /*return*/, [_a.sent()].concat(this.accumulations.map(function (v) { return ({ name: v.originalName, tensor: v.variable }); }))];\n                }\n            });\n        });\n    };\n    MomentumOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var trainable;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        trainable = false;\n                        this.accumulations = weightValues.map(function (v) { return ({ originalName: v.name, variable: v.tensor.variable(trainable) }); });\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    MomentumOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'momentum': this.momentum,\n            'useNesterov': this.useNesterov\n        };\n    };\n    /** @nocollapse */\n    MomentumOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['momentum'], config['useNesterov']);\n    };\n    /** @nocollapse */\n    MomentumOptimizer.className = 'Momentum'; // Name matters for Python compatibility.\n    return MomentumOptimizer;\n}(sgd_optimizer_1.SGDOptimizer));\nexports.MomentumOptimizer = MomentumOptimizer;\nserialization_1.registerClass(MomentumOptimizer);\n//# sourceMappingURL=momentum_optimizer.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar globals_1 = __webpack_require__(/*! ../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar gradients_1 = __webpack_require__(/*! ../gradients */ \"./node_modules/@tensorflow/tfjs-core/dist/gradients.js\");\nvar ops_1 = __webpack_require__(/*! ../ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\nvar serialization_1 = __webpack_require__(/*! ../serialization */ \"./node_modules/@tensorflow/tfjs-core/dist/serialization.js\");\n/** @doc {heading: 'Training', subheading: 'Classes', namespace: 'train'} */\nvar Optimizer = /** @class */ (function (_super) {\n    __extends(Optimizer, _super);\n    function Optimizer() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    /**\n     * Executes `f()` and minimizes the scalar output of `f()` by computing\n     * gradients of y with respect to the list of trainable variables provided by\n     * `varList`. If no list is provided, it defaults to all trainable variables.\n     *\n     * @param f The function to execute and whose output to minimize.\n     * @param returnCost Whether to return the scalar cost value produced by\n     * executing `f()`.\n     * @param varList An optional list of variables to update. If specified, only\n     * the trainable variables in varList will be updated by minimize. Defaults to\n     * all trainable variables.\n     */\n    /** @doc {heading: 'Training', subheading: 'Optimizers'} */\n    Optimizer.prototype.minimize = function (f, returnCost, varList) {\n        if (returnCost === void 0) { returnCost = false; }\n        var _a = this.computeGradients(f, varList), value = _a.value, grads = _a.grads;\n        if (varList != null) {\n            var gradArray = varList.map(function (v) { return ({ name: v.name, tensor: grads[v.name] }); });\n            this.applyGradients(gradArray);\n        }\n        else {\n            this.applyGradients(grads);\n        }\n        // Dispose gradients.\n        globals_1.dispose(grads);\n        if (returnCost) {\n            return value;\n        }\n        else {\n            value.dispose();\n            return null;\n        }\n    };\n    Object.defineProperty(Optimizer.prototype, \"iterations\", {\n        /**\n         * The number of iterations that this optimizer instance has been invoked for.\n         */\n        get: function () {\n            if (this.iterations_ == null) {\n                this.iterations_ = 0;\n            }\n            return this.iterations_;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Optimizer.prototype.incrementIterations = function () {\n        this.iterations_ = this.iterations + 1;\n    };\n    /**\n     * Executes f() and computes the gradient of the scalar output of f() with\n     * respect to the list of trainable variables provided by `varList`. If no\n     * list is provided, it defaults to all trainable variables.\n     *\n     * @param f The function to execute and whose output to use for computing\n     * gradients with respect to variables.\n     * @param varList An optional list of variables to compute gradients with\n     * respect to. If specified, only the trainable variables in varList will have\n     * gradients computed with respect to. Defaults to all trainable variables.\n     */\n    Optimizer.prototype.computeGradients = function (f, varList) {\n        return gradients_1.variableGrads(f, varList);\n    };\n    /**\n     * Dispose the variables (if any) owned by this optimizer instance.\n     */\n    Optimizer.prototype.dispose = function () {\n        if (this.iterations_ != null) {\n            globals_1.dispose(this.iterations_);\n        }\n    };\n    Optimizer.prototype.saveIterations = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                if (this.iterations_ == null) {\n                    this.iterations_ = 0;\n                }\n                return [2 /*return*/, {\n                        name: 'iter',\n                        // TODO(cais): Use 'int64' type when available.\n                        tensor: ops_1.scalar(this.iterations_, 'int32')\n                    }];\n            });\n        });\n    };\n    Optimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                throw new Error('getWeights() is not implemented for this optimizer yet.');\n            });\n        });\n    };\n    Optimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                throw new Error(\"setWeights() is not implemented for this optimizer class \" +\n                    (\"\" + this.getClassName()));\n            });\n        });\n    };\n    /**\n     * Extract the first element of the weight values and set it\n     * as the iterations counter variable of this instance of optimizer.\n     *\n     * @param weightValues\n     * @returns Weight values with the first element consumed and excluded.\n     */\n    Optimizer.prototype.extractIterations = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var _a;\n            return __generator(this, function (_b) {\n                switch (_b.label) {\n                    case 0:\n                        _a = this;\n                        return [4 /*yield*/, weightValues[0].tensor.data()];\n                    case 1:\n                        _a.iterations_ = (_b.sent())[0];\n                        return [2 /*return*/, weightValues.slice(1)];\n                }\n            });\n        });\n    };\n    return Optimizer;\n}(serialization_1.Serializable));\nexports.Optimizer = Optimizer;\nObject.defineProperty(Optimizer, Symbol.hasInstance, {\n    value: function (instance) {\n        return instance.minimize != null && instance.computeGradients != null &&\n            instance.applyGradients != null;\n    }\n});\n//# sourceMappingURL=optimizer.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar adadelta_optimizer_1 = __webpack_require__(/*! ./adadelta_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js\");\nvar adagrad_optimizer_1 = __webpack_require__(/*! ./adagrad_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js\");\nvar adam_optimizer_1 = __webpack_require__(/*! ./adam_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js\");\nvar adamax_optimizer_1 = __webpack_require__(/*! ./adamax_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js\");\nvar momentum_optimizer_1 = __webpack_require__(/*! ./momentum_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js\");\nvar rmsprop_optimizer_1 = __webpack_require__(/*! ./rmsprop_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js\");\nvar sgd_optimizer_1 = __webpack_require__(/*! ./sgd_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js\");\nvar OptimizerConstructors = /** @class */ (function () {\n    function OptimizerConstructors() {\n    }\n    /**\n     * Constructs a `tf.SGDOptimizer` that uses stochastic gradient descent.\n     *\n     * ```js\n     * // Fit a quadratic function by learning the coefficients a, b, c.\n     * const xs = tf.tensor1d([0, 1, 2, 3]);\n     * const ys = tf.tensor1d([1.1, 5.9, 16.8, 33.9]);\n     *\n     * const a = tf.scalar(Math.random()).variable();\n     * const b = tf.scalar(Math.random()).variable();\n     * const c = tf.scalar(Math.random()).variable();\n     *\n     * // y = a * x^2 + b * x + c.\n     * const f = x => a.mul(x.square()).add(b.mul(x)).add(c);\n     * const loss = (pred, label) => pred.sub(label).square().mean();\n     *\n     * const learningRate = 0.01;\n     * const optimizer = tf.train.sgd(learningRate);\n     *\n     * // Train the model.\n     * for (let i = 0; i < 10; i++) {\n     *   optimizer.minimize(() => loss(f(xs), ys));\n     * }\n     *\n     * // Make predictions.\n     * console.log(\n     *     `a: ${a.dataSync()}, b: ${b.dataSync()}, c: ${c.dataSync()}`);\n     * const preds = f(xs).dataSync();\n     * preds.forEach((pred, i) => {\n     *   console.log(`x: ${i}, pred: ${pred}`);\n     * });\n     * ```\n     *\n     * @param learningRate The learning rate to use for the SGD algorithm.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.sgd = function (learningRate) {\n        return new sgd_optimizer_1.SGDOptimizer(learningRate);\n    };\n    /**\n     * Constructs a `tf.MomentumOptimizer` that uses momentum gradient\n     * descent.\n     *\n     * See\n     * [http://proceedings.mlr.press/v28/sutskever13.pdf](\n     * http://proceedings.mlr.press/v28/sutskever13.pdf)\n     *\n     * @param learningRate The learning rate to use for the Momentum gradient\n     * descent algorithm.\n     * @param momentum The momentum to use for the momentum gradient descent\n     * algorithm.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.momentum = function (learningRate, momentum, useNesterov) {\n        if (useNesterov === void 0) { useNesterov = false; }\n        return new momentum_optimizer_1.MomentumOptimizer(learningRate, momentum, useNesterov);\n    };\n    /**\n     * Constructs a `tf.RMSPropOptimizer` that uses RMSProp gradient\n     * descent. This implementation uses plain momentum and is not centered\n     * version of RMSProp.\n     *\n     * See\n     * [http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf](\n     * http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n     *\n     * @param learningRate The learning rate to use for the RMSProp gradient\n     * descent algorithm.\n     * @param decay The discounting factor for the history/coming gradient.\n     * @param momentum The momentum to use for the RMSProp gradient descent\n     * algorithm.\n     * @param epsilon Small value to avoid zero denominator.\n     * @param centered If true, gradients are normalized by the estimated\n     * variance of the gradient.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.rmsprop = function (learningRate, decay, momentum, epsilon, centered) {\n        if (decay === void 0) { decay = .9; }\n        if (momentum === void 0) { momentum = 0.0; }\n        if (epsilon === void 0) { epsilon = null; }\n        if (centered === void 0) { centered = false; }\n        return new rmsprop_optimizer_1.RMSPropOptimizer(learningRate, decay, momentum, epsilon, centered);\n    };\n    /**\n     * Constructs a `tf.AdamOptimizer` that uses the Adam algorithm.\n     * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)\n     *\n     * @param learningRate The learning rate to use for the Adam gradient\n     * descent algorithm.\n     * @param beta1 The exponential decay rate for the 1st moment estimates.\n     * @param beta2 The exponential decay rate for the 2nd moment estimates.\n     * @param epsilon A small constant for numerical stability.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.adam = function (learningRate, beta1, beta2, epsilon) {\n        if (learningRate === void 0) { learningRate = 0.001; }\n        if (beta1 === void 0) { beta1 = 0.9; }\n        if (beta2 === void 0) { beta2 = 0.999; }\n        if (epsilon === void 0) { epsilon = null; }\n        return new adam_optimizer_1.AdamOptimizer(learningRate, beta1, beta2, epsilon);\n    };\n    /**\n     * Constructs a `tf.AdadeltaOptimizer` that uses the Adadelta algorithm.\n     * See [https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701)\n     *\n     * @param learningRate The learning rate to use for the Adadelta gradient\n     * descent algorithm.\n     * @param rho The learning rate decay over each update.\n     * @param epsilon A constant epsilon used to better condition the grad\n     * update.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.adadelta = function (learningRate, rho, epsilon) {\n        if (learningRate === void 0) { learningRate = .001; }\n        if (rho === void 0) { rho = .95; }\n        if (epsilon === void 0) { epsilon = null; }\n        return new adadelta_optimizer_1.AdadeltaOptimizer(learningRate, rho, epsilon);\n    };\n    /**\n     * Constructs a `tf.AdamaxOptimizer` that uses the Adamax algorithm.\n     * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)\n     *\n     * @param learningRate The learning rate to use for the Adamax gradient\n     * descent algorithm.\n     * @param beta1 The exponential decay rate for the 1st moment estimates.\n     * @param beta2 The exponential decay rate for the 2nd moment estimates.\n     * @param epsilon A small constant for numerical stability.\n     * @param decay The learning rate decay over each update.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.adamax = function (learningRate, beta1, beta2, epsilon, decay) {\n        if (learningRate === void 0) { learningRate = 0.002; }\n        if (beta1 === void 0) { beta1 = 0.9; }\n        if (beta2 === void 0) { beta2 = 0.999; }\n        if (epsilon === void 0) { epsilon = null; }\n        if (decay === void 0) { decay = 0.0; }\n        return new adamax_optimizer_1.AdamaxOptimizer(learningRate, beta1, beta2, epsilon, decay);\n    };\n    /**\n     * Constructs a `tf.AdagradOptimizer` that uses the Adagrad algorithm.\n     * See\n     * [http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf](\n     * http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n     * or\n     * [http://ruder.io/optimizing-gradient-descent/index.html#adagrad](\n     * http://ruder.io/optimizing-gradient-descent/index.html#adagrad)\n     *\n     * @param learningRate The learning rate to use for the Adagrad gradient\n     * descent algorithm.\n     * @param initialAccumulatorValue Starting value for the accumulators, must be\n     * positive.\n     */\n    /**\n     * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}\n     */\n    OptimizerConstructors.adagrad = function (learningRate, initialAccumulatorValue) {\n        if (initialAccumulatorValue === void 0) { initialAccumulatorValue = 0.1; }\n        return new adagrad_optimizer_1.AdagradOptimizer(learningRate, initialAccumulatorValue);\n    };\n    return OptimizerConstructors;\n}());\nexports.OptimizerConstructors = OptimizerConstructors;\n//# sourceMappingURL=optimizer_constructors.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar globals_1 = __webpack_require__(/*! ../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar ops_1 = __webpack_require__(/*! ../ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\nvar serialization_1 = __webpack_require__(/*! ../serialization */ \"./node_modules/@tensorflow/tfjs-core/dist/serialization.js\");\nvar optimizer_1 = __webpack_require__(/*! ./optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js\");\n/** @doclink Optimizer */\nvar RMSPropOptimizer = /** @class */ (function (_super) {\n    __extends(RMSPropOptimizer, _super);\n    function RMSPropOptimizer(learningRate, decay, momentum, epsilon, centered) {\n        if (decay === void 0) { decay = 0.9; }\n        if (momentum === void 0) { momentum = 0.0; }\n        if (epsilon === void 0) { epsilon = null; }\n        if (centered === void 0) { centered = false; }\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.decay = decay;\n        _this.momentum = momentum;\n        _this.epsilon = epsilon;\n        _this.accumulatedMeanSquares = [];\n        _this.accumulatedMoments = [];\n        _this.accumulatedMeanGrads = [];\n        _this.centered = centered;\n        if (epsilon == null) {\n            _this.epsilon = engine_1.ENGINE.backend.epsilon();\n        }\n        if (learningRate == null) {\n            throw new Error(\"learningRate for RMSPropOptimizer must be defined.\");\n        }\n        return _this;\n    }\n    RMSPropOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (item) { return item.name; }) :\n            Object.keys(variableGradients);\n        variableNames.forEach(function (name, i) {\n            var value = engine_1.ENGINE.registeredVariables[name];\n            var trainable = false;\n            if (_this.accumulatedMeanSquares[i] == null) {\n                _this.accumulatedMeanSquares[i] = {\n                    originalName: name + \"/rms\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                };\n            }\n            if (_this.accumulatedMoments[i] == null) {\n                _this.accumulatedMoments[i] = {\n                    originalName: name + \"/momentum\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                };\n            }\n            if (_this.accumulatedMeanGrads[i] == null && _this.centered) {\n                _this.accumulatedMeanGrads[i] = {\n                    originalName: name + \"/mg\",\n                    variable: globals_1.tidy(function () { return ops_1.zerosLike(value).variable(trainable); })\n                };\n            }\n            var gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            var accumulatedMeanSquare = _this.accumulatedMeanSquares[i].variable;\n            var accumulatedMoments = _this.accumulatedMoments[i].variable;\n            globals_1.tidy(function () {\n                var newAccumulatedMeanSquare = accumulatedMeanSquare.mul(_this.decay)\n                    .add(gradient.square().mul(1 - _this.decay));\n                if (_this.centered) {\n                    var accumulatedMeanGrad = _this.accumulatedMeanGrads[i].variable;\n                    // Centered gradient\n                    var newAccumulatedMeanGrad = accumulatedMeanGrad.mul(_this.decay)\n                        .add(gradient.mul(1 - _this.decay));\n                    var newAccumulatedMoments = accumulatedMoments.mul(_this.momentum)\n                        .add(gradient.mul(_this.learningRate)\n                        .div(newAccumulatedMeanSquare\n                        .sub(newAccumulatedMeanGrad.square().add(_this.epsilon))\n                        .sqrt()));\n                    accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n                    accumulatedMeanGrad.assign(newAccumulatedMeanGrad);\n                    accumulatedMoments.assign(newAccumulatedMoments);\n                    var newValue = value.sub(newAccumulatedMoments);\n                    value.assign(newValue);\n                }\n                else {\n                    // Plain gradient\n                    var newAccumulatedMeanSquare_1 = accumulatedMeanSquare.mul(_this.decay)\n                        .add(gradient.square().mul(1 - _this.decay));\n                    var newAccumulatedMoments = accumulatedMoments.mul(_this.momentum)\n                        .add(gradient.mul(_this.learningRate)\n                        .div(newAccumulatedMeanSquare_1.add(_this.epsilon)\n                        .sqrt()));\n                    accumulatedMeanSquare.assign(newAccumulatedMeanSquare_1);\n                    accumulatedMoments.assign(newAccumulatedMoments);\n                    var newValue = value.sub(newAccumulatedMoments);\n                    value.assign(newValue);\n                }\n            });\n        });\n        this.incrementIterations();\n    };\n    RMSPropOptimizer.prototype.dispose = function () {\n        if (this.accumulatedMeanSquares != null) {\n            globals_1.dispose(this.accumulatedMeanSquares.map(function (v) { return v.variable; }));\n        }\n        if (this.accumulatedMeanGrads != null && this.centered) {\n            globals_1.dispose(this.accumulatedMeanGrads.map(function (v) { return v.variable; }));\n        }\n        if (this.accumulatedMoments != null) {\n            globals_1.dispose(this.accumulatedMoments.map(function (v) { return v.variable; }));\n        }\n    };\n    RMSPropOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var variables;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        variables = this.accumulatedMeanSquares.concat(this.accumulatedMoments);\n                        if (this.centered) {\n                            variables.push.apply(variables, this.accumulatedMeanGrads);\n                        }\n                        return [4 /*yield*/, this.saveIterations()];\n                    case 1: return [2 /*return*/, [_a.sent()].concat(variables.map(function (v) { return ({ name: v.originalName, tensor: v.variable }); }))];\n                }\n            });\n        });\n    };\n    RMSPropOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            var variableCount, trainable;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;\n                        trainable = false;\n                        this.accumulatedMeanSquares =\n                            weightValues.slice(0, variableCount).map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        this.accumulatedMoments =\n                            weightValues.slice(variableCount, variableCount * 2)\n                                .map(function (v) { return ({\n                                originalName: v.name,\n                                variable: v.tensor.variable(trainable)\n                            }); });\n                        if (this.centered) {\n                            this.accumulatedMeanGrads =\n                                weightValues.slice(variableCount * 2, variableCount * 3)\n                                    .map(function (v) { return ({\n                                    originalName: v.name,\n                                    variable: v.tensor.variable(trainable)\n                                }); });\n                        }\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    RMSPropOptimizer.prototype.getConfig = function () {\n        return {\n            'learningRate': this.learningRate,\n            'decay': this.decay,\n            'momentum': this.momentum,\n            'epsilon': this.epsilon,\n            'centered': this.centered\n        };\n    };\n    /** @nocollapse */\n    RMSPropOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate'], config['decay'], config['momentum'], config['epsilon'], config['centered']);\n    };\n    /** @nocollapse */\n    RMSPropOptimizer.className = 'RMSProp'; // Note: Name matters for Python compatibility.\n    return RMSPropOptimizer;\n}(optimizer_1.Optimizer));\nexports.RMSPropOptimizer = RMSPropOptimizer;\nserialization_1.registerClass(RMSPropOptimizer);\n//# sourceMappingURL=rmsprop_optimizer.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ../engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar globals_1 = __webpack_require__(/*! ../globals */ \"./node_modules/@tensorflow/tfjs-core/dist/globals.js\");\nvar ops_1 = __webpack_require__(/*! ../ops/ops */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js\");\nvar serialization_1 = __webpack_require__(/*! ../serialization */ \"./node_modules/@tensorflow/tfjs-core/dist/serialization.js\");\nvar optimizer_1 = __webpack_require__(/*! ./optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js\");\n/** @doclink Optimizer */\nvar SGDOptimizer = /** @class */ (function (_super) {\n    __extends(SGDOptimizer, _super);\n    function SGDOptimizer(learningRate) {\n        var _this = _super.call(this) || this;\n        _this.learningRate = learningRate;\n        _this.setLearningRate(learningRate);\n        return _this;\n    }\n    SGDOptimizer.prototype.applyGradients = function (variableGradients) {\n        var _this = this;\n        var varNames = Array.isArray(variableGradients) ?\n            variableGradients.map(function (v) { return v.name; }) :\n            Object.keys(variableGradients);\n        varNames.forEach(function (name, i) {\n            var gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            var value = engine_1.ENGINE.registeredVariables[name];\n            globals_1.tidy(function () {\n                var newValue = _this.c.mul(gradient).add(value);\n                value.assign(newValue);\n            });\n        });\n        this.incrementIterations();\n    };\n    /**\n     * Sets the learning rate of the optimizer.\n     */\n    SGDOptimizer.prototype.setLearningRate = function (learningRate) {\n        this.learningRate = learningRate;\n        if (this.c != null) {\n            this.c.dispose();\n        }\n        this.c = globals_1.keep(ops_1.scalar(-learningRate));\n    };\n    SGDOptimizer.prototype.dispose = function () {\n        this.c.dispose();\n    };\n    SGDOptimizer.prototype.getWeights = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.saveIterations()];\n                    case 1: return [2 /*return*/, [_a.sent()]];\n                }\n            });\n        });\n    };\n    SGDOptimizer.prototype.setWeights = function (weightValues) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.extractIterations(weightValues)];\n                    case 1:\n                        weightValues = _a.sent();\n                        if (weightValues.length !== 0) {\n                            throw new Error('SGD optimizer does not have settable weights.');\n                        }\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    SGDOptimizer.prototype.getConfig = function () {\n        return { 'learningRate': this.learningRate };\n    };\n    /** @nocollapse */\n    SGDOptimizer.fromConfig = function (cls, config) {\n        return new cls(config['learningRate']);\n    };\n    /** @nocollapse */\n    SGDOptimizer.className = 'SGD'; // Note: Name matters for Python compatibility.\n    return SGDOptimizer;\n}(optimizer_1.Optimizer));\nexports.SGDOptimizer = SGDOptimizer;\nserialization_1.registerClass(SGDOptimizer);\n//# sourceMappingURL=sgd_optimizer.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar PlatformBrowser = /** @class */ (function () {\n    function PlatformBrowser() {\n    }\n    PlatformBrowser.prototype.fetch = function (path, init) {\n        return fetch(path, init);\n    };\n    PlatformBrowser.prototype.now = function () {\n        return performance.now();\n    };\n    PlatformBrowser.prototype.encode = function (text, encoding) {\n        if (encoding !== 'utf-8' && encoding !== 'utf8') {\n            throw new Error(\"Browser's encoder only supports utf-8, but got \" + encoding);\n        }\n        if (this.textEncoder == null) {\n            this.textEncoder = new TextEncoder();\n        }\n        return this.textEncoder.encode(text);\n    };\n    PlatformBrowser.prototype.decode = function (bytes, encoding) {\n        return new TextDecoder(encoding).decode(bytes);\n    };\n    return PlatformBrowser;\n}());\nexports.PlatformBrowser = PlatformBrowser;\nif (environment_1.env().get('IS_BROWSER')) {\n    environment_1.env().setPlatform('browser', new PlatformBrowser());\n}\n//# sourceMappingURL=platform_browser.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar environment_1 = __webpack_require__(/*! ../environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\n// We are wrapping this within an object so it can be stubbed by Jasmine.\nexports.getNodeFetch = {\n    // tslint:disable-next-line:no-require-imports\n    importFetch: function () { return __webpack_require__(/*! node-fetch */ \"./node_modules/node-fetch/lib/index.js\"); }\n};\nvar systemFetch;\n// These getters and setters are for testing so we don't export a mutable\n// variable.\nfunction resetSystemFetch() {\n    systemFetch = null;\n}\nexports.resetSystemFetch = resetSystemFetch;\nfunction setSystemFetch(fetchFn) {\n    systemFetch = fetchFn;\n}\nexports.setSystemFetch = setSystemFetch;\nfunction getSystemFetch() {\n    return systemFetch;\n}\nexports.getSystemFetch = getSystemFetch;\nvar PlatformNode = /** @class */ (function () {\n    function PlatformNode() {\n        // tslint:disable-next-line:no-require-imports\n        this.util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\");\n        // According to the spec, the built-in encoder can do only UTF-8 encoding.\n        // https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/TextEncoder\n        this.textEncoder = new this.util.TextEncoder();\n    }\n    PlatformNode.prototype.fetch = function (path, requestInits) {\n        if (environment_1.env().global.fetch != null) {\n            return environment_1.env().global.fetch(path, requestInits);\n        }\n        if (systemFetch == null) {\n            systemFetch = exports.getNodeFetch.importFetch();\n        }\n        return systemFetch(path, requestInits);\n    };\n    PlatformNode.prototype.now = function () {\n        var time = process.hrtime();\n        return time[0] * 1000 + time[1] / 1000000;\n    };\n    PlatformNode.prototype.encode = function (text, encoding) {\n        if (encoding !== 'utf-8' && encoding !== 'utf8') {\n            throw new Error(\"Node built-in encoder only supports utf-8, but got \" + encoding);\n        }\n        return this.textEncoder.encode(text);\n    };\n    PlatformNode.prototype.decode = function (bytes, encoding) {\n        if (bytes.length === 0) {\n            return '';\n        }\n        return new this.util.TextDecoder(encoding).decode(bytes);\n    };\n    return PlatformNode;\n}());\nexports.PlatformNode = PlatformNode;\nif (environment_1.env().get('IS_NODE')) {\n    environment_1.env().setPlatform('node', new PlatformNode());\n}\n//# sourceMappingURL=platform_node.js.map\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/profiler.js":
/*!*************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/profiler.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar Profiler = /** @class */ (function () {\n    function Profiler(backendTimer, logger) {\n        this.backendTimer = backendTimer;\n        this.logger = logger;\n        if (logger == null) {\n            this.logger = new Logger();\n        }\n    }\n    Profiler.prototype.profileKernel = function (kernelName, inputs, f) {\n        var _this = this;\n        var outputs;\n        var holdResultWrapperFn = function () {\n            outputs = f();\n        };\n        var timer = this.backendTimer.time(holdResultWrapperFn);\n        outputs.forEach(function (r) {\n            // Dangling promise here because we don't want to propagate up\n            // asynchronicity.\n            r.data().then(function (vals) {\n                checkComputationForErrors(vals, r.dtype, kernelName);\n                timer.then(function (timing) {\n                    var extraInfo = '';\n                    if (timing.getExtraProfileInfo != null) {\n                        extraInfo = timing.getExtraProfileInfo();\n                    }\n                    _this.logger.logKernelProfile(kernelName, r, vals, timing.kernelMs, inputs, extraInfo);\n                });\n            });\n        });\n        return outputs;\n    };\n    return Profiler;\n}());\nexports.Profiler = Profiler;\nfunction checkComputationForErrors(vals, dtype, kernelName) {\n    if (dtype !== 'float32') {\n        // Only floating point computations will generate NaN values\n        return false;\n    }\n    for (var i = 0; i < vals.length; i++) {\n        var num = vals[i];\n        if (isNaN(num) || !isFinite(num)) {\n            // Throwing custom exception so behavior is testable.\n            console.warn(\"Found \" + num + \" in the result of '\" + kernelName + \"'\");\n            return true;\n        }\n    }\n    return false;\n}\nexports.checkComputationForErrors = checkComputationForErrors;\nvar Logger = /** @class */ (function () {\n    function Logger() {\n    }\n    Logger.prototype.logKernelProfile = function (name, result, vals, timeMs, inputs, extraInfo) {\n        var time = typeof timeMs === 'number' ? util.rightPad(timeMs + \"ms\", 9) :\n            timeMs['error'];\n        var paddedName = util.rightPad(name, 25);\n        var rank = result.rank;\n        var size = result.size;\n        var shape = util.rightPad(result.shape.toString(), 14);\n        var inputShapesDescription = '';\n        for (var name_1 in inputs) {\n            var input = inputs[name_1];\n            // The input might be a non-tensor (e.g HTMLImageElement), in which case\n            // we claim the output shape as input shape.\n            var inputShape = input.shape || result.shape;\n            var inputRank = inputShape.length;\n            inputShapesDescription +=\n                name_1 + \": \" + inputRank + \"D \" + (inputRank > 0 ? inputShape : '') + \" \";\n        }\n        console.log(\"%c\" + paddedName + \"\\t%c\" + time + \"\\t%c\" + rank + \"D \" + shape + \"\\t%c\" + size + \"\\t%c\" + inputShapesDescription + \"\\t%c\" + extraInfo, 'font-weight:bold', 'color:red', 'color:blue', 'color: orange', 'color: green', 'color: steelblue');\n    };\n    return Logger;\n}());\nexports.Logger = Logger;\n//# sourceMappingURL=profiler.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/profiler.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/register_all_chained_ops.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/register_all_chained_ops.js ***!
  \************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__webpack_require__(/*! ./squared_difference */ \"./node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/squared_difference.js\");\n//# sourceMappingURL=register_all_chained_ops.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/register_all_chained_ops.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/squared_difference.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/squared_difference.js ***!
  \******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar squared_difference_1 = __webpack_require__(/*! ../../ops/squared_difference */ \"./node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js\");\nvar tensor_1 = __webpack_require__(/*! ../../tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\ntensor_1.Tensor.prototype.squaredDifference = function (b) {\n    return squared_difference_1.squaredDifference(this, b);\n};\n//# sourceMappingURL=squared_difference.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/squared_difference.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/register_all_gradients.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/register_all_gradients.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar Square_grad_1 = __webpack_require__(/*! ./gradients/Square_grad */ \"./node_modules/@tensorflow/tfjs-core/dist/gradients/Square_grad.js\");\nvar SquaredDifference_grad_1 = __webpack_require__(/*! ./gradients/SquaredDifference_grad */ \"./node_modules/@tensorflow/tfjs-core/dist/gradients/SquaredDifference_grad.js\");\nvar kernel_registry_1 = __webpack_require__(/*! ./kernel_registry */ \"./node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js\");\n// Export all kernel configs here so that the package can auto register them\nvar gradConfigs = [\n    Square_grad_1.squareGradConfig,\n    SquaredDifference_grad_1.squaredDifferenceGradConfig,\n];\nfor (var _i = 0, gradConfigs_1 = gradConfigs; _i < gradConfigs_1.length; _i++) {\n    var gradientConfig = gradConfigs_1[_i];\n    kernel_registry_1.registerGradient(gradientConfig);\n}\n//# sourceMappingURL=register_all_gradients.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/register_all_gradients.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/serialization.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/serialization.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n/**\n * Serializable defines the serialization contract.\n *\n * TFJS requires serializable classes to return their className when asked\n * to avoid issues with minification.\n */\nvar Serializable = /** @class */ (function () {\n    function Serializable() {\n    }\n    /**\n     * Return the class name for this class to use in serialization contexts.\n     *\n     * Generally speaking this will be the same thing that constructor.name\n     * would have returned.  However, the class name needs to be robust\n     * against minification for serialization/deserialization to work properly.\n     *\n     * There's also places such as initializers.VarianceScaling, where\n     * implementation details between different languages led to different\n     * class hierarchies and a non-leaf node is used for serialization purposes.\n     */\n    Serializable.prototype.getClassName = function () {\n        return this.constructor\n            .className;\n    };\n    /**\n     * Creates an instance of T from a ConfigDict.\n     *\n     * This works for most descendants of serializable.  A few need to\n     * provide special handling.\n     * @param cls A Constructor for the class to instantiate.\n     * @param config The Configuration for the object.\n     */\n    /** @nocollapse */\n    Serializable.fromConfig = function (cls, config) {\n        return new cls(config);\n    };\n    return Serializable;\n}());\nexports.Serializable = Serializable;\n/**\n * Maps string keys to class constructors.\n *\n * Used during (de)serialization from the cross-language JSON format, which\n * requires the class name in the serialization format matches the class\n * names as used in Python, should it exist.\n */\nvar SerializationMap = /** @class */ (function () {\n    function SerializationMap() {\n        this.classNameMap = {};\n    }\n    /**\n     * Returns the singleton instance of the map.\n     */\n    SerializationMap.getMap = function () {\n        if (SerializationMap.instance == null) {\n            SerializationMap.instance = new SerializationMap();\n        }\n        return SerializationMap.instance;\n    };\n    /**\n     * Registers the class as serializable.\n     */\n    SerializationMap.register = function (cls) {\n        SerializationMap.getMap().classNameMap[cls.className] =\n            [cls, cls.fromConfig];\n    };\n    return SerializationMap;\n}());\nexports.SerializationMap = SerializationMap;\n/**\n * Register a class with the serialization map of TensorFlow.js.\n *\n * This is often used for registering custom Layers, so they can be\n * serialized and deserialized.\n *\n * Example:\n *\n * ```js\n * class MyCustomLayer extends tf.layers.Layer {\n *   static className = 'MyCustomLayer';\n *\n *   constructor(config) {\n *     super(config);\n *   }\n * }\n * tf.serialization.registerClass(MyCustomLayer);\n * ```\n *\n * @param cls The class to be registered. It must have a public static member\n *   called `className` defined and the value must be a non-empty string.\n */\n/** @doc {heading: 'Models', subheading: 'Serialization', ignoreCI: true} */\nfunction registerClass(cls) {\n    util_1.assert(cls.className != null, function () { return \"Class being registered does not have the static className \" +\n        \"property defined.\"; });\n    util_1.assert(typeof cls.className === 'string', function () { return \"className is required to be a string, but got type \" +\n        typeof cls.className; });\n    util_1.assert(cls.className.length > 0, function () { return \"Class being registered has an empty-string as its className, \" +\n        \"which is disallowed.\"; });\n    SerializationMap.register(cls);\n}\nexports.registerClass = registerClass;\n//# sourceMappingURL=serialization.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/serialization.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/tape.js":
/*!*********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/tape.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n/**\n * Computes a list of TapeNodes that connect x to y, filtering everything else\n * out and preserving the order of the original tape elements.\n *\n * @param tape The tape elements to filter.\n * @param xs The input Tensors.\n * @param y The output Tensor.\n */\nfunction getFilteredNodesXToY(tape, xs, y) {\n    // Forward pass to compute all the nodes and Tensors that are transitively a\n    // function of x.\n    var tensorsFromX = {};\n    var nodesFromX = {};\n    for (var i = 0; i < xs.length; i++) {\n        tensorsFromX[xs[i].id] = true;\n    }\n    for (var i = 0; i < tape.length; i++) {\n        var node = tape[i];\n        var nodeInputs = node.inputs;\n        for (var inputName in nodeInputs) {\n            var input = nodeInputs[inputName];\n            var anyInputFromX = false;\n            for (var j = 0; j < xs.length; j++) {\n                if (tensorsFromX[input.id]) {\n                    node.outputs.forEach(function (output) { return tensorsFromX[output.id] = true; });\n                    anyInputFromX = true;\n                    nodesFromX[node.id] = true;\n                    break;\n                }\n            }\n            if (anyInputFromX) {\n                break;\n            }\n        }\n    }\n    // Backward pass to find all of the nodes and Tensors that lead to y.\n    var tensorsLeadToY = {};\n    tensorsLeadToY[y.id] = true;\n    var nodesToY = {};\n    for (var i = tape.length - 1; i >= 0; i--) {\n        var node = tape[i];\n        var nodeInputs = node.inputs;\n        // If any of the outputs lead to y, mark all of the inputs as leading to y.\n        for (var j = 0; j < node.outputs.length; j++) {\n            if (tensorsLeadToY[node.outputs[j].id]) {\n                for (var inputName in nodeInputs) {\n                    tensorsLeadToY[nodeInputs[inputName].id] = true;\n                    nodesToY[node.id] = true;\n                }\n                break;\n            }\n        }\n    }\n    // Return the paths that come from x and lead to y.\n    var filteredTape = [];\n    for (var i = 0; i < tape.length; i++) {\n        var node = tape[i];\n        if (nodesFromX[node.id] && nodesToY[node.id]) {\n            // Prune the inputs from the node that aren't a function of x.\n            var prunedInputs = {};\n            for (var inputName in node.inputs) {\n                var nodeInput = node.inputs[inputName];\n                if (tensorsFromX[nodeInput.id]) {\n                    prunedInputs[inputName] = nodeInput;\n                }\n            }\n            // Copy the node and overwrite inputsAndArgs to the pruned version.\n            var prunedNode = Object.assign({}, node);\n            prunedNode.inputs = prunedInputs;\n            prunedNode.outputs = node.outputs;\n            filteredTape.push(prunedNode);\n        }\n    }\n    return filteredTape;\n}\nexports.getFilteredNodesXToY = getFilteredNodesXToY;\n/**\n * Backpropagate gradients through the filtered TapeNodes.\n *\n * @param tensorAccumulatedGradientMap A map of Tensor to its gradient. This map\n * is mutated by this method.\n * @param filteredTape The filtered TapeNodes to backprop through.\n */\nfunction backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy) {\n    var _loop_1 = function (i) {\n        var node = filteredTape[i];\n        var dys = [];\n        node.outputs.forEach(function (o) {\n            var gradTensor = tensorAccumulatedGradientMap[o.id];\n            if (gradTensor != null) {\n                dys.push(gradTensor);\n            }\n            else {\n                // This particular output is not in the back-propagation subgraph, so it\n                // does not affect the final output, thus we put null for its dy.\n                dys.push(null);\n            }\n        });\n        if (node.gradient == null) {\n            throw new Error(\"Cannot compute gradient: gradient function not found \" +\n                (\"for \" + node.kernelName + \".\"));\n        }\n        // Backprop dy through this node and accumulate gradients over the inputs.\n        var inputGradients = node.gradient(dys);\n        var _loop_2 = function (inputName) {\n            if (!(inputName in inputGradients)) {\n                throw new Error(\"Cannot backprop through input \" + inputName + \". \" +\n                    (\"Available gradients found: \" + Object.keys(inputGradients) + \".\"));\n            }\n            // Call the gradient function.\n            var dx = tidy(function () { return inputGradients[inputName](); });\n            if (dx.dtype !== 'float32') {\n                throw new Error(\"Error in gradient for op \" + node.kernelName + \". The gradient of input \" +\n                    (inputName + \" must have 'float32' dtype, but has '\" + dx.dtype + \"'\"));\n            }\n            var x = node.inputs[inputName];\n            if (!util.arraysEqual(dx.shape, x.shape)) {\n                throw new Error(\"Error in gradient for op \" + node.kernelName + \". The gradient of input \" +\n                    (\"'\" + inputName + \"' has shape '\" + dx.shape + \"', which does not match \") +\n                    (\"the shape of the input '\" + x.shape + \"'\"));\n            }\n            if (tensorAccumulatedGradientMap[x.id] == null) {\n                tensorAccumulatedGradientMap[x.id] = dx;\n            }\n            else {\n                var curGradient = tensorAccumulatedGradientMap[x.id];\n                tensorAccumulatedGradientMap[x.id] = curGradient.add(dx);\n                curGradient.dispose();\n            }\n        };\n        for (var inputName in node.inputs) {\n            _loop_2(inputName);\n        }\n    };\n    // Walk the tape backward and keep a map of Tensor to its gradient.\n    for (var i = filteredTape.length - 1; i >= 0; i--) {\n        _loop_1(i);\n    }\n}\nexports.backpropagateGradients = backpropagateGradients;\n//# sourceMappingURL=tape.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/tape.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/tensor.js":
/*!***********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/tensor.js ***!
  \***********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = function (d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_format_1 = __webpack_require__(/*! ./tensor_format */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_format.js\");\nvar util = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar util_1 = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n */\n/** @doc {heading: 'Tensors', subheading: 'Classes'} */\nvar TensorBuffer = /** @class */ (function () {\n    function TensorBuffer(shape, dtype, values) {\n        var _this = this;\n        this.dtype = dtype;\n        this.shape = shape.slice();\n        this.size = util.sizeFromShape(shape);\n        if (values != null) {\n            var n_1 = values.length;\n            util.assert(n_1 === this.size, function () { return \"Length of values '\" + n_1 + \"' does not match the size \" +\n                (\"inferred by the shape '\" + _this.size + \"'.\"); });\n        }\n        if (dtype === 'complex64') {\n            throw new Error(\"complex64 dtype TensorBuffers are not supported. Please create \" +\n                \"a TensorBuffer for the real and imaginary parts separately and \" +\n                \"call tf.complex(real, imag).\");\n        }\n        this.values = values || util.getArrayFromDType(dtype, this.size);\n        this.strides = util_1.computeStrides(shape);\n    }\n    /**\n     * Sets a value in the buffer at a given location.\n     *\n     * @param value The value to set.\n     * @param locs  The location indices.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Creation'} */\n    TensorBuffer.prototype.set = function (value) {\n        var _this = this;\n        var locs = [];\n        for (var _i = 1; _i < arguments.length; _i++) {\n            locs[_i - 1] = arguments[_i];\n        }\n        if (locs.length === 0) {\n            locs = [0];\n        }\n        util.assert(locs.length === this.rank, function () { return \"The number of provided coordinates (\" + locs.length + \") must \" +\n            (\"match the rank (\" + _this.rank + \")\"); });\n        var index = this.locToIndex(locs);\n        this.values[index] = value;\n    };\n    /**\n     * Returns the value in the buffer at the provided location.\n     *\n     * @param locs The location indices.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Creation'} */\n    TensorBuffer.prototype.get = function () {\n        var locs = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            locs[_i] = arguments[_i];\n        }\n        if (locs.length === 0) {\n            locs = [0];\n        }\n        var i = 0;\n        for (var _a = 0, locs_1 = locs; _a < locs_1.length; _a++) {\n            var loc = locs_1[_a];\n            if (loc < 0 || loc >= this.shape[i]) {\n                var msg = \"Requested out of range element at \" + locs + \". \" +\n                    (\"  Buffer shape=\" + this.shape);\n                throw new Error(msg);\n            }\n            i++;\n        }\n        var index = locs[locs.length - 1];\n        for (var i_1 = 0; i_1 < locs.length - 1; ++i_1) {\n            index += this.strides[i_1] * locs[i_1];\n        }\n        return this.values[index];\n    };\n    TensorBuffer.prototype.locToIndex = function (locs) {\n        if (this.rank === 0) {\n            return 0;\n        }\n        else if (this.rank === 1) {\n            return locs[0];\n        }\n        var index = locs[locs.length - 1];\n        for (var i = 0; i < locs.length - 1; ++i) {\n            index += this.strides[i] * locs[i];\n        }\n        return index;\n    };\n    TensorBuffer.prototype.indexToLoc = function (index) {\n        if (this.rank === 0) {\n            return [];\n        }\n        else if (this.rank === 1) {\n            return [index];\n        }\n        var locs = new Array(this.shape.length);\n        for (var i = 0; i < locs.length - 1; ++i) {\n            locs[i] = Math.floor(index / this.strides[i]);\n            index -= locs[i] * this.strides[i];\n        }\n        locs[locs.length - 1] = index;\n        return locs;\n    };\n    Object.defineProperty(TensorBuffer.prototype, \"rank\", {\n        get: function () {\n            return this.shape.length;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    /**\n     * Creates an immutable `tf.Tensor` object from the buffer.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Creation'} */\n    TensorBuffer.prototype.toTensor = function () {\n        return trackerFn().makeTensor(this.values, this.shape, this.dtype);\n    };\n    return TensorBuffer;\n}());\nexports.TensorBuffer = TensorBuffer;\n// For tracking tensor creation and disposal.\nvar trackerFn = null;\n// Used by chaining methods to call into ops.\nvar opHandler = null;\n// Used to warn about deprecated methods.\nvar deprecationWarningFn = null;\n// This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n[deprecationWarningFn];\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\nfunction setTensorTracker(fn) {\n    trackerFn = fn;\n}\nexports.setTensorTracker = setTensorTracker;\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op\n * handler.\n */\nfunction setOpHandler(handler) {\n    opHandler = handler;\n}\nexports.setOpHandler = setOpHandler;\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\nfunction setDeprecationWarningFn(fn) {\n    deprecationWarningFn = fn;\n}\nexports.setDeprecationWarningFn = setDeprecationWarningFn;\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n */\n/** @doc {heading: 'Tensors', subheading: 'Classes'} */\nvar Tensor = /** @class */ (function () {\n    function Tensor(shape, dtype, dataId, id) {\n        /** Whether this tensor has been globally kept. */\n        this.kept = false;\n        this.isDisposedInternal = false;\n        this.shape = shape.slice();\n        this.dtype = dtype || 'float32';\n        this.size = util.sizeFromShape(shape);\n        this.strides = util_1.computeStrides(shape);\n        this.dataId = dataId;\n        this.id = id;\n        this.rankType = (this.rank < 5 ? this.rank.toString() : 'higher');\n    }\n    /** Flatten a Tensor to a 1D array. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.flatten = function () {\n        this.throwIfDisposed();\n        return this.as1D();\n    };\n    /** Converts a size-1 `tf.Tensor` to a `tf.Scalar`. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.asScalar = function () {\n        this.throwIfDisposed();\n        util.assert(this.size === 1, function () { return 'The array must have only 1 element.'; });\n        return this.reshape([]);\n    };\n    /** Converts a `tf.Tensor` to a `tf.Tensor1D`. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.as1D = function () {\n        this.throwIfDisposed();\n        return this.reshape([this.size]);\n    };\n    /**\n     * Converts a `tf.Tensor` to a `tf.Tensor2D`.\n     *\n     * @param rows Number of rows in `tf.Tensor2D`.\n     * @param columns Number of columns in `tf.Tensor2D`.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.as2D = function (rows, columns) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns]);\n    };\n    /**\n     * Converts a `tf.Tensor` to a `tf.Tensor3D`.\n     *\n     * @param rows Number of rows in `tf.Tensor3D`.\n     * @param columns Number of columns in `tf.Tensor3D`.\n     * @param depth Depth of `tf.Tensor3D`.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.as3D = function (rows, columns, depth) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns, depth]);\n    };\n    /**\n     * Converts a `tf.Tensor` to a `tf.Tensor4D`.\n     *\n     * @param rows Number of rows in `tf.Tensor4D`.\n     * @param columns Number of columns in `tf.Tensor4D`.\n     * @param depth Depth of `tf.Tensor4D`.\n     * @param depth2 4th dimension of `tf.Tensor4D`.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.as4D = function (rows, columns, depth, depth2) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns, depth, depth2]);\n    };\n    /**\n     * Converts a `tf.Tensor` to a `tf.Tensor5D`.\n     *\n     * @param rows Number of rows in `tf.Tensor5D`.\n     * @param columns Number of columns in `tf.Tensor5D`.\n     * @param depth Depth of `tf.Tensor5D`.\n     * @param depth2 4th dimension of `tf.Tensor5D`.\n     * @param depth3 5th dimension of 'tf.Tensor5D'\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.as5D = function (rows, columns, depth, depth2, depth3) {\n        this.throwIfDisposed();\n        return this.reshape([rows, columns, depth, depth2, depth3]);\n    };\n    /**\n     * Casts a `tf.Tensor` to a specified dtype.\n     *\n     * @param dtype Data-type to cast the tensor to.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.asType = function (dtype) {\n        this.throwIfDisposed();\n        return opHandler.cast(this, dtype);\n    };\n    Object.defineProperty(Tensor.prototype, \"rank\", {\n        get: function () {\n            return this.shape.length;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    /**\n     * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.buffer = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var vals;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.data()];\n                    case 1:\n                        vals = _a.sent();\n                        return [2 /*return*/, opHandler.buffer(this.shape, this.dtype, vals)];\n                }\n            });\n        });\n    };\n    /** Returns a `tf.TensorBuffer` that holds the underlying data. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.bufferSync = function () {\n        return opHandler.buffer(this.shape, this.dtype, this.dataSync());\n    };\n    /**\n     * Returns the tensor data as a nested array. The transfer of data is done\n     * asynchronously.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.array = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var vals;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0: return [4 /*yield*/, this.data()];\n                    case 1:\n                        vals = _a.sent();\n                        return [2 /*return*/, util_1.toNestedArray(this.shape, vals)];\n                }\n            });\n        });\n    };\n    /**\n     * Returns the tensor data as a nested array. The transfer of data is done\n     * synchronously.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.arraySync = function () {\n        return util_1.toNestedArray(this.shape, this.dataSync());\n    };\n    /**\n     * Asynchronously downloads the values from the `tf.Tensor`. Returns a\n     * promise of `TypedArray` that resolves when the computation has finished.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.data = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var data, bytes;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        this.throwIfDisposed();\n                        data = trackerFn().read(this.dataId);\n                        if (!(this.dtype === 'string')) return [3 /*break*/, 2];\n                        return [4 /*yield*/, data];\n                    case 1:\n                        bytes = _a.sent();\n                        try {\n                            return [2 /*return*/, bytes.map(function (b) { return util.decodeString(b); })];\n                        }\n                        catch (_b) {\n                            throw new Error('Failed to decode the string bytes into utf-8. ' +\n                                'To get the original bytes, call tensor.bytes().');\n                        }\n                        _a.label = 2;\n                    case 2: return [2 /*return*/, data];\n                }\n            });\n        });\n    };\n    /**\n     * Synchronously downloads the values from the `tf.Tensor`. This blocks the\n     * UI thread until the values are ready, which can cause performance issues.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.dataSync = function () {\n        this.throwIfDisposed();\n        var data = trackerFn().readSync(this.dataId);\n        if (this.dtype === 'string') {\n            try {\n                return data.map(function (b) { return util.decodeString(b); });\n            }\n            catch (_a) {\n                throw new Error('Failed to decode the string bytes into utf-8. ' +\n                    'To get the original bytes, call tensor.bytes().');\n            }\n        }\n        return data;\n    };\n    /** Returns the underlying bytes of the tensor's data. */\n    Tensor.prototype.bytes = function () {\n        return __awaiter(this, void 0, void 0, function () {\n            var data;\n            return __generator(this, function (_a) {\n                switch (_a.label) {\n                    case 0:\n                        this.throwIfDisposed();\n                        return [4 /*yield*/, trackerFn().read(this.dataId)];\n                    case 1:\n                        data = _a.sent();\n                        if (this.dtype === 'string') {\n                            return [2 /*return*/, data];\n                        }\n                        else {\n                            return [2 /*return*/, new Uint8Array(data.buffer)];\n                        }\n                        return [2 /*return*/];\n                }\n            });\n        });\n    };\n    /**\n     * Disposes `tf.Tensor` from memory.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.dispose = function () {\n        if (this.isDisposed) {\n            return;\n        }\n        trackerFn().disposeTensor(this);\n        this.isDisposedInternal = true;\n    };\n    Object.defineProperty(Tensor.prototype, \"isDisposed\", {\n        get: function () {\n            return this.isDisposedInternal;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Tensor.prototype.throwIfDisposed = function () {\n        if (this.isDisposed) {\n            throw new Error(\"Tensor is disposed.\");\n        }\n    };\n    /** Casts the array to type `float32` */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.toFloat = function () {\n        return this.asType('float32');\n    };\n    /** Casts the array to type `int32` */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.toInt = function () {\n        return this.asType('int32');\n    };\n    /** Casts the array to type `bool` */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.toBool = function () {\n        return this.asType('bool');\n    };\n    /**\n     * Prints the `tf.Tensor`. See `tf.print` for details.\n     *\n     * @param verbose Whether to print verbose information about the tensor,\n     *    including dtype and size.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.print = function (verbose) {\n        if (verbose === void 0) { verbose = false; }\n        return opHandler.print(this, verbose);\n    };\n    /**\n     * Reshapes the tensor into the provided shape.\n     * See `tf.reshape` for more details.\n     *\n     * @param newShape An array of integers defining the output tensor shape.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.reshape = function (newShape) {\n        this.throwIfDisposed();\n        return opHandler.reshape(this, newShape);\n    };\n    /**\n     * Reshapes the tensor into the shape of the provided tensor.\n     *\n     * @param x The tensor of required shape.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.reshapeAs = function (x) {\n        this.throwIfDisposed();\n        return this.reshape(x.shape);\n    };\n    /**\n     * Returns a `tf.Tensor` that has expanded rank, by inserting a dimension\n     * into the tensor's shape. See `tf.expandDims` for details.\n     *\n     * @param axis The dimension index at which to insert shape of 1. Defaults to\n     *     0 (the first dimension).\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.expandDims = function (axis) {\n        if (axis === void 0) { axis = 0; }\n        return opHandler.expandDims(this, axis);\n    };\n    /**\n     * Returns the cumulative sum of the `tf.Tensor` along `axis`.\n     *\n     * @param axis The axis along which to sum. Optional. Defaults to 0.\n     * @param exclusive Whether to perform exclusive cumulative sum. Defaults to\n     *    false. If set to true then the sum of each tensor entry does not\n     * include its own value, but only the values previous to it along the\n     * specified axis.\n     * @param reverse Whether to sum in the opposite direction. Defaults to\n     *    false.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.cumsum = function (axis, exclusive, reverse) {\n        if (axis === void 0) { axis = 0; }\n        if (exclusive === void 0) { exclusive = false; }\n        if (reverse === void 0) { reverse = false; }\n        return opHandler.cumsum(this, axis, exclusive, reverse);\n    };\n    /**\n     * Returns a `tf.Tensor` with dimensions of size 1 removed from the shape.\n     * See `tf.squeeze` for more details.\n     *\n     * @param axis A list of numbers. If specified, only squeezes the\n     *    dimensions listed. The dimension index starts at 0. It is an error to\n     *    squeeze a dimension that is not 1.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.squeeze = function (axis) {\n        this.throwIfDisposed();\n        return opHandler.squeeze(this, axis);\n    };\n    /** Returns a copy of the tensor. See `tf.clone` for details. */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.clone = function () {\n        this.throwIfDisposed();\n        return opHandler.clone(this);\n    };\n    Tensor.prototype.oneHot = function (depth, onValue, offValue) {\n        this.throwIfDisposed();\n        return opHandler.oneHot(this, depth, onValue, offValue);\n    };\n    /**\n     * Returns a human-readable description of the tensor. Useful for logging.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Tensor.prototype.toString = function (verbose) {\n        if (verbose === void 0) { verbose = false; }\n        var vals = this.dataSync();\n        return tensor_format_1.tensorToString(vals, this.shape, this.dtype, verbose);\n    };\n    // Below is chain API that is not exposed to docs to avoid repetition. To\n    // expose a method, move it above this comment and add @doc and jsdoc.\n    Tensor.prototype.tile = function (reps) {\n        this.throwIfDisposed();\n        return opHandler.tile(this, reps);\n    };\n    Tensor.prototype.gather = function (indices, axis) {\n        if (axis === void 0) { axis = 0; }\n        this.throwIfDisposed();\n        return opHandler.gather(this, indices, axis);\n    };\n    Tensor.prototype.matMul = function (b, transposeA, transposeB) {\n        if (transposeA === void 0) { transposeA = false; }\n        if (transposeB === void 0) { transposeB = false; }\n        this.throwIfDisposed();\n        return opHandler.matMul(this, b, transposeA, transposeB);\n    };\n    Tensor.prototype.dot = function (b) {\n        this.throwIfDisposed();\n        return opHandler.dot(this, b);\n    };\n    Tensor.prototype.norm = function (ord, axis, keepDims) {\n        if (ord === void 0) { ord = 'euclidean'; }\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.norm(this, ord, axis, keepDims);\n    };\n    Tensor.prototype.slice = function (begin, size) {\n        this.throwIfDisposed();\n        return opHandler.slice(this, begin, size);\n    };\n    Tensor.prototype.reverse = function (axis) {\n        this.throwIfDisposed();\n        return opHandler.reverse(this, axis);\n    };\n    Tensor.prototype.concat = function (x, axis) {\n        if (axis === void 0) { axis = 0; }\n        this.throwIfDisposed();\n        if (x instanceof Tensor) {\n            x = [x];\n        }\n        return opHandler.concat([this].concat(x), axis);\n    };\n    Tensor.prototype.split = function (numOrSizeSplits, axis) {\n        if (axis === void 0) { axis = 0; }\n        this.throwIfDisposed();\n        return opHandler.split(this, numOrSizeSplits, axis);\n    };\n    Tensor.prototype.stack = function (x, axis) {\n        if (axis === void 0) { axis = 0; }\n        return opHandler.stack([this, x], axis);\n    };\n    Tensor.prototype.unstack = function (axis) {\n        if (axis === void 0) { axis = 0; }\n        return opHandler.unstack(this, axis);\n    };\n    Tensor.prototype.pad = function (paddings, constantValue) {\n        if (constantValue === void 0) { constantValue = 0; }\n        return opHandler.pad(this, paddings, constantValue);\n    };\n    /**\n     * @deprecated Use `tf.batchNorm` instead, and note the positional argument\n     *     change of scale, offset, and varianceEpsilon.\n     */\n    Tensor.prototype.batchNormalization = function (mean, variance, varianceEpsilon, scale, offset) {\n        if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n        deprecationWarningFn('tf.batchNormalization() is going away. ' +\n            'Use tf.batchNorm() instead, and note the positional argument change ' +\n            'of scale, offset, and varianceEpsilon');\n        return this.batchNorm(mean, variance, offset, scale, varianceEpsilon);\n    };\n    Tensor.prototype.batchNorm = function (mean, variance, offset, scale, varianceEpsilon) {\n        if (varianceEpsilon === void 0) { varianceEpsilon = .001; }\n        this.throwIfDisposed();\n        return opHandler.batchNorm(this, mean, variance, offset, scale, varianceEpsilon);\n    };\n    // Reduction ops.\n    Tensor.prototype.all = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.all(this, axis, keepDims);\n    };\n    Tensor.prototype.any = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.any(this, axis, keepDims);\n    };\n    Tensor.prototype.logSumExp = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.logSumExp(this, axis, keepDims);\n    };\n    Tensor.prototype.sum = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.sum(this, axis, keepDims);\n    };\n    Tensor.prototype.prod = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.prod(this, axis, keepDims);\n    };\n    Tensor.prototype.mean = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.mean(this, axis, keepDims);\n    };\n    Tensor.prototype.min = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.min(this, axis, keepDims);\n    };\n    Tensor.prototype.max = function (axis, keepDims) {\n        if (axis === void 0) { axis = null; }\n        if (keepDims === void 0) { keepDims = false; }\n        this.throwIfDisposed();\n        return opHandler.max(this, axis, keepDims);\n    };\n    Tensor.prototype.argMin = function (axis) {\n        if (axis === void 0) { axis = null; }\n        this.throwIfDisposed();\n        return opHandler.argMin(this, axis);\n    };\n    Tensor.prototype.argMax = function (axis) {\n        if (axis === void 0) { axis = null; }\n        this.throwIfDisposed();\n        return opHandler.argMax(this, axis);\n    };\n    // Transformations\n    Tensor.prototype.cast = function (dtype) {\n        this.throwIfDisposed();\n        return opHandler.cast(this, dtype);\n    };\n    // Binary ops.\n    Tensor.prototype.add = function (x) {\n        this.throwIfDisposed();\n        return opHandler.add(this, x);\n    };\n    Tensor.prototype.addStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.addStrict(this, x);\n    };\n    Tensor.prototype.atan2 = function (x) {\n        this.throwIfDisposed();\n        return opHandler.atan2(this, x);\n    };\n    Tensor.prototype.sub = function (x) {\n        this.throwIfDisposed();\n        return opHandler.sub(this, x);\n    };\n    Tensor.prototype.subStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.subStrict(this, x);\n    };\n    Tensor.prototype.pow = function (exp) {\n        this.throwIfDisposed();\n        return opHandler.pow(this, exp);\n    };\n    Tensor.prototype.powStrict = function (exp) {\n        this.throwIfDisposed();\n        return opHandler.powStrict(this, exp);\n    };\n    Tensor.prototype.mul = function (x) {\n        this.throwIfDisposed();\n        return opHandler.mul(this, x);\n    };\n    Tensor.prototype.mulStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.mulStrict(this, x);\n    };\n    Tensor.prototype.div = function (x) {\n        this.throwIfDisposed();\n        return opHandler.div(this, x);\n    };\n    Tensor.prototype.divNoNan = function (x) {\n        this.throwIfDisposed();\n        return opHandler.divNoNan(this, x);\n    };\n    Tensor.prototype.floorDiv = function (x) {\n        this.throwIfDisposed();\n        return opHandler.floorDiv(this, x);\n    };\n    Tensor.prototype.divStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.divStrict(this, x);\n    };\n    Tensor.prototype.minimum = function (x) {\n        this.throwIfDisposed();\n        return opHandler.minimum(this, x);\n    };\n    Tensor.prototype.minimumStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.minimumStrict(this, x);\n    };\n    Tensor.prototype.maximum = function (x) {\n        this.throwIfDisposed();\n        return opHandler.maximum(this, x);\n    };\n    Tensor.prototype.maximumStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.maximumStrict(this, x);\n    };\n    Tensor.prototype.mod = function (x) {\n        this.throwIfDisposed();\n        return opHandler.mod(this, x);\n    };\n    Tensor.prototype.modStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.modStrict(this, x);\n    };\n    Tensor.prototype.squaredDifferenceStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.squaredDifferenceStrict(this, x);\n    };\n    Tensor.prototype.transpose = function (perm) {\n        this.throwIfDisposed();\n        return opHandler.transpose(this, perm);\n    };\n    // Compare ops.\n    Tensor.prototype.notEqual = function (x) {\n        this.throwIfDisposed();\n        return opHandler.notEqual(this, x);\n    };\n    Tensor.prototype.notEqualStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.notEqualStrict(this, x);\n    };\n    Tensor.prototype.less = function (x) {\n        this.throwIfDisposed();\n        return opHandler.less(this, x);\n    };\n    Tensor.prototype.lessStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.lessStrict(this, x);\n    };\n    Tensor.prototype.equal = function (x) {\n        this.throwIfDisposed();\n        return opHandler.equal(this, x);\n    };\n    Tensor.prototype.equalStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.equalStrict(this, x);\n    };\n    Tensor.prototype.lessEqual = function (x) {\n        this.throwIfDisposed();\n        return opHandler.lessEqual(this, x);\n    };\n    Tensor.prototype.lessEqualStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.lessEqualStrict(this, x);\n    };\n    Tensor.prototype.greater = function (x) {\n        this.throwIfDisposed();\n        return opHandler.greater(this, x);\n    };\n    Tensor.prototype.greaterStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.greaterStrict(this, x);\n    };\n    Tensor.prototype.greaterEqual = function (x) {\n        this.throwIfDisposed();\n        return opHandler.greaterEqual(this, x);\n    };\n    Tensor.prototype.greaterEqualStrict = function (x) {\n        this.throwIfDisposed();\n        return opHandler.greaterEqualStrict(this, x);\n    };\n    // Compare ops.\n    Tensor.prototype.logicalAnd = function (x) {\n        this.throwIfDisposed();\n        return opHandler.logicalAnd(this, x);\n    };\n    Tensor.prototype.logicalOr = function (x) {\n        this.throwIfDisposed();\n        return opHandler.logicalOr(this, x);\n    };\n    Tensor.prototype.logicalNot = function () {\n        this.throwIfDisposed();\n        return opHandler.logicalNot(this);\n    };\n    Tensor.prototype.logicalXor = function (x) {\n        this.throwIfDisposed();\n        return opHandler.logicalXor(this, x);\n    };\n    Tensor.prototype.where = function (condition, x) {\n        this.throwIfDisposed();\n        return opHandler.where(condition, this, x);\n    };\n    // Unary ops.\n    Tensor.prototype.neg = function () {\n        this.throwIfDisposed();\n        return opHandler.neg(this);\n    };\n    Tensor.prototype.ceil = function () {\n        this.throwIfDisposed();\n        return opHandler.ceil(this);\n    };\n    Tensor.prototype.floor = function () {\n        this.throwIfDisposed();\n        return opHandler.floor(this);\n    };\n    Tensor.prototype.sign = function () {\n        this.throwIfDisposed();\n        return opHandler.sign(this);\n    };\n    Tensor.prototype.isNaN = function () {\n        this.throwIfDisposed();\n        return opHandler.isNaN(this);\n    };\n    Tensor.prototype.isInf = function () {\n        this.throwIfDisposed();\n        return opHandler.isInf(this);\n    };\n    Tensor.prototype.isFinite = function () {\n        this.throwIfDisposed();\n        return opHandler.isFinite(this);\n    };\n    Tensor.prototype.exp = function () {\n        this.throwIfDisposed();\n        return opHandler.exp(this);\n    };\n    Tensor.prototype.expm1 = function () {\n        this.throwIfDisposed();\n        return opHandler.expm1(this);\n    };\n    Tensor.prototype.log = function () {\n        this.throwIfDisposed();\n        return opHandler.log(this);\n    };\n    Tensor.prototype.log1p = function () {\n        this.throwIfDisposed();\n        return opHandler.log1p(this);\n    };\n    Tensor.prototype.sqrt = function () {\n        this.throwIfDisposed();\n        return opHandler.sqrt(this);\n    };\n    Tensor.prototype.rsqrt = function () {\n        this.throwIfDisposed();\n        return opHandler.rsqrt(this);\n    };\n    Tensor.prototype.square = function () {\n        this.throwIfDisposed();\n        return opHandler.square(this);\n    };\n    Tensor.prototype.reciprocal = function () {\n        this.throwIfDisposed();\n        return opHandler.reciprocal(this);\n    };\n    Tensor.prototype.abs = function () {\n        this.throwIfDisposed();\n        return opHandler.abs(this);\n    };\n    Tensor.prototype.clipByValue = function (min, max) {\n        this.throwIfDisposed();\n        return opHandler.clipByValue(this, min, max);\n    };\n    Tensor.prototype.relu = function () {\n        this.throwIfDisposed();\n        return opHandler.relu(this);\n    };\n    Tensor.prototype.relu6 = function () {\n        this.throwIfDisposed();\n        return opHandler.relu6(this);\n    };\n    Tensor.prototype.elu = function () {\n        this.throwIfDisposed();\n        return opHandler.elu(this);\n    };\n    Tensor.prototype.selu = function () {\n        this.throwIfDisposed();\n        return opHandler.selu(this);\n    };\n    Tensor.prototype.leakyRelu = function (alpha) {\n        if (alpha === void 0) { alpha = 0.2; }\n        this.throwIfDisposed();\n        return opHandler.leakyRelu(this, alpha);\n    };\n    Tensor.prototype.prelu = function (alpha) {\n        this.throwIfDisposed();\n        return opHandler.prelu(this, alpha);\n    };\n    Tensor.prototype.sigmoid = function () {\n        this.throwIfDisposed();\n        return opHandler.sigmoid(this);\n    };\n    Tensor.prototype.logSigmoid = function () {\n        this.throwIfDisposed();\n        return opHandler.logSigmoid(this);\n    };\n    Tensor.prototype.softplus = function () {\n        this.throwIfDisposed();\n        return opHandler.softplus(this);\n    };\n    Tensor.prototype.zerosLike = function () {\n        this.throwIfDisposed();\n        return opHandler.zerosLike(this);\n    };\n    Tensor.prototype.onesLike = function () {\n        this.throwIfDisposed();\n        return opHandler.onesLike(this);\n    };\n    Tensor.prototype.sin = function () {\n        this.throwIfDisposed();\n        return opHandler.sin(this);\n    };\n    Tensor.prototype.cos = function () {\n        this.throwIfDisposed();\n        return opHandler.cos(this);\n    };\n    Tensor.prototype.tan = function () {\n        this.throwIfDisposed();\n        return opHandler.tan(this);\n    };\n    Tensor.prototype.asin = function () {\n        this.throwIfDisposed();\n        return opHandler.asin(this);\n    };\n    Tensor.prototype.acos = function () {\n        this.throwIfDisposed();\n        return opHandler.acos(this);\n    };\n    Tensor.prototype.atan = function () {\n        this.throwIfDisposed();\n        return opHandler.atan(this);\n    };\n    Tensor.prototype.sinh = function () {\n        this.throwIfDisposed();\n        return opHandler.sinh(this);\n    };\n    Tensor.prototype.cosh = function () {\n        this.throwIfDisposed();\n        return opHandler.cosh(this);\n    };\n    Tensor.prototype.tanh = function () {\n        this.throwIfDisposed();\n        return opHandler.tanh(this);\n    };\n    Tensor.prototype.asinh = function () {\n        this.throwIfDisposed();\n        return opHandler.asinh(this);\n    };\n    Tensor.prototype.acosh = function () {\n        this.throwIfDisposed();\n        return opHandler.acosh(this);\n    };\n    Tensor.prototype.atanh = function () {\n        this.throwIfDisposed();\n        return opHandler.atanh(this);\n    };\n    Tensor.prototype.erf = function () {\n        this.throwIfDisposed();\n        return opHandler.erf(this);\n    };\n    Tensor.prototype.round = function () {\n        this.throwIfDisposed();\n        return opHandler.round(this);\n    };\n    Tensor.prototype.step = function (alpha) {\n        if (alpha === void 0) { alpha = 0.0; }\n        this.throwIfDisposed();\n        return opHandler.step(this, alpha);\n    };\n    Tensor.prototype.softmax = function (dim) {\n        if (dim === void 0) { dim = -1; }\n        this.throwIfDisposed();\n        return opHandler.softmax(this, dim);\n    };\n    Tensor.prototype.logSoftmax = function (axis) {\n        if (axis === void 0) { axis = -1; }\n        this.throwIfDisposed();\n        return opHandler.logSoftmax(this, axis);\n    };\n    // Image ops.\n    Tensor.prototype.resizeBilinear = function (newShape2D, alignCorners) {\n        if (alignCorners === void 0) { alignCorners = false; }\n        this.throwIfDisposed();\n        return opHandler.image.resizeBilinear(this, newShape2D, alignCorners);\n    };\n    Tensor.prototype.resizeNearestNeighbor = function (newShape2D, alignCorners) {\n        if (alignCorners === void 0) { alignCorners = false; }\n        this.throwIfDisposed();\n        return opHandler.image.resizeNearestNeighbor(this, newShape2D, alignCorners);\n    };\n    // Convolutions.\n    Tensor.prototype.conv1d = function (filter, stride, pad, dataFormat, dilation, dimRoundingMode) {\n        if (dataFormat === void 0) { dataFormat = 'NWC'; }\n        if (dilation === void 0) { dilation = 1; }\n        this.throwIfDisposed();\n        return opHandler.conv1d(this, filter, stride, pad, dataFormat, dilation, dimRoundingMode);\n    };\n    Tensor.prototype.conv2d = function (filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n        if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n        if (dilations === void 0) { dilations = [1, 1]; }\n        this.throwIfDisposed();\n        return opHandler.conv2d(this, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n    };\n    Tensor.prototype.conv2dTranspose = function (filter, outputShape, strides, pad, dimRoundingMode) {\n        this.throwIfDisposed();\n        return opHandler.conv2dTranspose(this, filter, outputShape, strides, pad, dimRoundingMode);\n    };\n    Tensor.prototype.depthwiseConv2D = function (filter, strides, pad, dataFormat, dilations, dimRoundingMode) {\n        if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n        if (dilations === void 0) { dilations = [1, 1]; }\n        this.throwIfDisposed();\n        return opHandler.depthwiseConv2d(this, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n    };\n    Tensor.prototype.separableConv2d = function (depthwiseFilter, pointwiseFilter, strides, pad, dilation, dataFormat) {\n        if (dilation === void 0) { dilation = [1, 1]; }\n        if (dataFormat === void 0) { dataFormat = 'NHWC'; }\n        this.throwIfDisposed();\n        return opHandler.separableConv2d(this, depthwiseFilter, pointwiseFilter, strides, pad, dilation, dataFormat);\n    };\n    // Pooling.\n    Tensor.prototype.avgPool = function (filterSize, strides, pad, dimRoundingMode) {\n        this.throwIfDisposed();\n        return opHandler.avgPool(this, filterSize, strides, pad, dimRoundingMode);\n    };\n    Tensor.prototype.maxPool = function (filterSize, strides, pad, dimRoundingMode) {\n        this.throwIfDisposed();\n        return opHandler.maxPool(this, filterSize, strides, pad, dimRoundingMode);\n    };\n    Tensor.prototype.localResponseNormalization = function (radius, bias, alpha, beta) {\n        if (radius === void 0) { radius = 5; }\n        if (bias === void 0) { bias = 1; }\n        if (alpha === void 0) { alpha = 1; }\n        if (beta === void 0) { beta = 0.5; }\n        return opHandler.localResponseNormalization(this, radius, bias, alpha, beta);\n    };\n    Tensor.prototype.pool = function (windowShape, poolingType, padding, dilationRate, strides) {\n        this.throwIfDisposed();\n        return opHandler.pool(this, windowShape, poolingType, padding, dilationRate, strides);\n    };\n    Tensor.prototype.variable = function (trainable, name, dtype) {\n        if (trainable === void 0) { trainable = true; }\n        this.throwIfDisposed();\n        return trackerFn().makeVariable(this, trainable, name, dtype);\n    };\n    Tensor.prototype.unsortedSegmentSum = function (segmentIds, numSegments) {\n        this.throwIfDisposed();\n        return opHandler.unsortedSegmentSum(this, segmentIds, numSegments);\n    };\n    Tensor.prototype.batchToSpaceND = function (blockShape, crops) {\n        this.throwIfDisposed();\n        return opHandler.batchToSpaceND(this, blockShape, crops);\n    };\n    Tensor.prototype.spaceToBatchND = function (blockShape, paddings) {\n        this.throwIfDisposed();\n        return opHandler.spaceToBatchND(this, blockShape, paddings);\n    };\n    Tensor.prototype.topk = function (k, sorted) {\n        if (k === void 0) { k = 1; }\n        if (sorted === void 0) { sorted = true; }\n        this.throwIfDisposed();\n        return opHandler.topk(this, k, sorted);\n    };\n    Tensor.prototype.stridedSlice = function (begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {\n        if (beginMask === void 0) { beginMask = 0; }\n        if (endMask === void 0) { endMask = 0; }\n        if (ellipsisMask === void 0) { ellipsisMask = 0; }\n        if (newAxisMask === void 0) { newAxisMask = 0; }\n        if (shrinkAxisMask === void 0) { shrinkAxisMask = 0; }\n        this.throwIfDisposed();\n        return opHandler.stridedSlice(this, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);\n    };\n    Tensor.prototype.depthToSpace = function (blockSize, dataFormat) {\n        this.throwIfDisposed();\n        return opHandler.depthToSpace(this, blockSize, dataFormat);\n    };\n    Tensor.prototype.fft = function () {\n        this.throwIfDisposed();\n        return opHandler.spectral.fft(this);\n    };\n    Tensor.prototype.ifft = function () {\n        this.throwIfDisposed();\n        return opHandler.spectral.ifft(this);\n    };\n    Tensor.prototype.rfft = function () {\n        this.throwIfDisposed();\n        return opHandler.spectral.rfft(this);\n    };\n    Tensor.prototype.irfft = function () {\n        this.throwIfDisposed();\n        return opHandler.spectral.irfft(this);\n    };\n    return Tensor;\n}());\nexports.Tensor = Tensor;\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n    value: function (instance) {\n        return !!instance && instance.dataId != null && instance.shape != null &&\n            instance.dtype != null;\n    }\n});\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n */\n/** @doc {heading: 'Tensors', subheading: 'Classes'} */\nvar Variable = /** @class */ (function (_super) {\n    __extends(Variable, _super);\n    function Variable(initialValue, trainable, name, tensorId) {\n        var _this = _super.call(this, initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId) || this;\n        _this.trainable = trainable;\n        _this.name = name;\n        return _this;\n    }\n    /**\n     * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n     * the same shape and dtype as the old `tf.Tensor`.\n     *\n     * @param newValue New tensor to be assigned to this variable.\n     */\n    /** @doc {heading: 'Tensors', subheading: 'Classes'} */\n    Variable.prototype.assign = function (newValue) {\n        if (newValue.dtype !== this.dtype) {\n            throw new Error(\"dtype of the new value (\" + newValue.dtype + \") and \" +\n                (\"previous value (\" + this.dtype + \") must match\"));\n        }\n        if (!util.arraysEqual(newValue.shape, this.shape)) {\n            throw new Error(\"shape of the new value (\" + newValue.shape + \") and \" +\n                (\"previous value (\" + this.shape + \") must match\"));\n        }\n        trackerFn().disposeTensor(this);\n        this.dataId = newValue.dataId;\n        trackerFn().incRef(this, null /* backend */);\n    };\n    Variable.prototype.dispose = function () {\n        trackerFn().disposeVariable(this);\n        this.isDisposedInternal = true;\n    };\n    return Variable;\n}(Tensor));\nexports.Variable = Variable;\nObject.defineProperty(Variable, Symbol.hasInstance, {\n    value: function (instance) {\n        return instance instanceof Tensor && instance.assign != null &&\n            instance.assign instanceof Function;\n    }\n});\n//# sourceMappingURL=tensor.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/tensor.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/tensor_format.js":
/*!******************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/tensor_format.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar util_1 = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\n// Maximum number of values before we decide to show ellipsis.\nvar FORMAT_LIMIT_NUM_VALS = 20;\n// Number of first and last values to show when displaying a, b,...,y, z.\nvar FORMAT_NUM_FIRST_LAST_VALS = 3;\n// Number of significant digits to show.\nvar FORMAT_NUM_SIG_DIGITS = 7;\nfunction tensorToString(vals, shape, dtype, verbose) {\n    var strides = util_1.computeStrides(shape);\n    var padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);\n    var rank = shape.length;\n    var valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);\n    var lines = ['Tensor'];\n    if (verbose) {\n        lines.push(\"  dtype: \" + dtype);\n        lines.push(\"  rank: \" + rank);\n        lines.push(\"  shape: [\" + shape + \"]\");\n        lines.push(\"  values:\");\n    }\n    lines.push(valsLines.map(function (l) { return '    ' + l; }).join('\\n'));\n    return lines.join('\\n');\n}\nexports.tensorToString = tensorToString;\nfunction computeMaxSizePerColumn(vals, shape, dtype, strides) {\n    var n = util_1.sizeFromShape(shape);\n    var numCols = strides[strides.length - 1];\n    var padPerCol = new Array(numCols).fill(0);\n    var rank = shape.length;\n    var valuesOrTuples = dtype === 'complex64' ? createComplexTuples(vals) : vals;\n    if (rank > 1) {\n        for (var row = 0; row < n / numCols; row++) {\n            var offset = row * numCols;\n            for (var j = 0; j < numCols; j++) {\n                padPerCol[j] = Math.max(padPerCol[j], valToString(valuesOrTuples[offset + j], 0, dtype).length);\n            }\n        }\n    }\n    return padPerCol;\n}\nfunction valToString(val, pad, dtype) {\n    var valStr;\n    if (Array.isArray(val)) {\n        valStr = parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS)) + \" + \" +\n            (parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS)) + \"j\");\n    }\n    else if (util_1.isString(val)) {\n        valStr = \"'\" + val + \"'\";\n    }\n    else if (dtype === 'bool') {\n        valStr = boolNumToString(val);\n    }\n    else {\n        valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();\n    }\n    return util_1.rightPad(valStr, pad);\n}\nfunction boolNumToString(v) {\n    return v === 0 ? 'false' : 'true';\n}\nfunction subTensorToString(vals, shape, dtype, strides, padPerCol, isLast) {\n    if (isLast === void 0) { isLast = true; }\n    var storagePerElement = dtype === 'complex64' ? 2 : 1;\n    var size = shape[0];\n    var rank = shape.length;\n    if (rank === 0) {\n        if (dtype === 'complex64') {\n            var complexTuple = createComplexTuples(vals);\n            return [valToString(complexTuple[0], 0, dtype)];\n        }\n        if (dtype === 'bool') {\n            return [boolNumToString(vals[0])];\n        }\n        return [vals[0].toString()];\n    }\n    if (rank === 1) {\n        if (size > FORMAT_LIMIT_NUM_VALS) {\n            var firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;\n            var firstVals = Array.from(vals.slice(0, firstValsSize));\n            var lastVals = Array.from(vals.slice((size - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement, size * storagePerElement));\n            if (dtype === 'complex64') {\n                firstVals = createComplexTuples(firstVals);\n                lastVals = createComplexTuples(lastVals);\n            }\n            return [\n                '[' +\n                    firstVals.map(function (x, i) { return valToString(x, padPerCol[i], dtype); })\n                        .join(', ') +\n                    ', ..., ' +\n                    lastVals\n                        .map(function (x, i) { return valToString(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i], dtype); })\n                        .join(', ') +\n                    ']'\n            ];\n        }\n        var displayVals = dtype === 'complex64' ? createComplexTuples(vals) :\n            Array.from(vals);\n        return [\n            '[' +\n                displayVals.map(function (x, i) { return valToString(x, padPerCol[i], dtype); })\n                    .join(', ') +\n                ']'\n        ];\n    }\n    // The array is rank 2 or more.\n    var subshape = shape.slice(1);\n    var substrides = strides.slice(1);\n    var stride = strides[0] * storagePerElement;\n    var lines = [];\n    if (size > FORMAT_LIMIT_NUM_VALS) {\n        for (var i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {\n            var start = i * stride;\n            var end = start + stride;\n            lines.push.apply(lines, subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, false /* isLast */));\n        }\n        lines.push('...');\n        for (var i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {\n            var start = i * stride;\n            var end = start + stride;\n            lines.push.apply(lines, subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, i === size - 1 /* isLast */));\n        }\n    }\n    else {\n        for (var i = 0; i < size; i++) {\n            var start = i * stride;\n            var end = start + stride;\n            lines.push.apply(lines, subTensorToString(vals.slice(start, end), subshape, dtype, substrides, padPerCol, i === size - 1 /* isLast */));\n        }\n    }\n    var sep = rank === 2 ? ',' : '';\n    lines[0] = '[' + lines[0] + sep;\n    for (var i = 1; i < lines.length - 1; i++) {\n        lines[i] = ' ' + lines[i] + sep;\n    }\n    var newLineSep = ',\\n';\n    for (var i = 2; i < rank; i++) {\n        newLineSep += '\\n';\n    }\n    lines[lines.length - 1] =\n        ' ' + lines[lines.length - 1] + ']' + (isLast ? '' : newLineSep);\n    return lines;\n}\nfunction createComplexTuples(vals) {\n    var complexTuples = [];\n    for (var i = 0; i < vals.length; i += 2) {\n        complexTuples.push([vals[i], vals[i + 1]]);\n    }\n    return complexTuples;\n}\n//# sourceMappingURL=tensor_format.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/tensor_format.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js":
/*!****************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tensor_1 = __webpack_require__(/*! ./tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nvar types_1 = __webpack_require__(/*! ./types */ \"./node_modules/@tensorflow/tfjs-core/dist/types.js\");\nvar util_1 = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nfunction makeTypesMatch(a, b) {\n    if (a.dtype === b.dtype) {\n        return [a, b];\n    }\n    var dtype = types_1.upcastType(a.dtype, b.dtype);\n    return [a.cast(dtype), b.cast(dtype)];\n}\nexports.makeTypesMatch = makeTypesMatch;\nfunction assertTypesMatch(a, b) {\n    util_1.assert(a.dtype === b.dtype, function () { return \"The dtypes of the first(\" + a.dtype + \") and\" +\n        (\" second(\" + b.dtype + \") input must match\"); });\n}\nexports.assertTypesMatch = assertTypesMatch;\nfunction isTensorInList(tensor, tensorList) {\n    return tensorList.some(function (x) { return x.id === tensor.id; });\n}\nexports.isTensorInList = isTensorInList;\n/**\n * Extracts any `Tensor`s found within the provided object.\n *\n * @param container an object that may be a `Tensor` or may directly contain\n *   `Tensor`s, such as a `Tensor[]` or `{key: Tensor, ...}`. In general it\n *   is safe to pass any object here, except that `Promise`s are not\n *   supported.\n * @returns An array of `Tensors` found within the passed object. If the\n *   argument is simply a `Tensor', a list containing that `Tensor` is\n *   returned. If the object is not a `Tensor` or does not\n *   contain `Tensors`, an empty list is returned.\n */\nfunction getTensorsInContainer(result) {\n    var list = [];\n    var seen = new Set();\n    walkTensorContainer(result, list, seen);\n    return list;\n}\nexports.getTensorsInContainer = getTensorsInContainer;\nfunction walkTensorContainer(container, list, seen) {\n    if (container == null) {\n        return;\n    }\n    if (container instanceof tensor_1.Tensor) {\n        list.push(container);\n        return;\n    }\n    if (!isIterable(container)) {\n        return;\n    }\n    // Iteration over keys works also for arrays.\n    var iterable = container;\n    for (var k in iterable) {\n        var val = iterable[k];\n        if (!seen.has(val)) {\n            seen.add(val);\n            walkTensorContainer(val, list, seen);\n        }\n    }\n}\n// tslint:disable-next-line:no-any\nfunction isIterable(obj) {\n    return Array.isArray(obj) || typeof obj === 'object';\n}\n//# sourceMappingURL=tensor_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/tensor_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js":
/*!********************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ./engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar environment_1 = __webpack_require__(/*! ./environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar tensor_1 = __webpack_require__(/*! ./tensor */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor.js\");\nvar util_1 = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nfunction inferShape(val, dtype) {\n    var firstElem = val;\n    if (util_1.isTypedArray(val)) {\n        return dtype === 'string' ? [] : [val.length];\n    }\n    if (!Array.isArray(val)) {\n        return []; // Scalar.\n    }\n    var shape = [];\n    while (Array.isArray(firstElem) ||\n        util_1.isTypedArray(firstElem) && dtype !== 'string') {\n        shape.push(firstElem.length);\n        firstElem = firstElem[0];\n    }\n    if (Array.isArray(val) &&\n        environment_1.env().getBool('TENSORLIKE_CHECK_SHAPE_CONSISTENCY')) {\n        deepAssertShapeConsistency(val, shape, []);\n    }\n    return shape;\n}\nexports.inferShape = inferShape;\nfunction deepAssertShapeConsistency(val, shape, indices) {\n    indices = indices || [];\n    if (!(Array.isArray(val)) && !util_1.isTypedArray(val)) {\n        util_1.assert(shape.length === 0, function () { return \"Element arr[\" + indices.join('][') + \"] is a primitive, \" +\n            (\"but should be an array/TypedArray of \" + shape[0] + \" elements\"); });\n        return;\n    }\n    util_1.assert(shape.length > 0, function () { return \"Element arr[\" + indices.join('][') + \"] should be a primitive, \" +\n        (\"but is an array of \" + val.length + \" elements\"); });\n    util_1.assert(val.length === shape[0], function () { return \"Element arr[\" + indices.join('][') + \"] should have \" + shape[0] + \" \" +\n        (\"elements, but has \" + val.length + \" elements\"); });\n    var subShape = shape.slice(1);\n    for (var i = 0; i < val.length; ++i) {\n        deepAssertShapeConsistency(val[i], subShape, indices.concat(i));\n    }\n}\nfunction assertDtype(expectedDtype, actualDType, argName, functionName) {\n    if (expectedDtype == null) {\n        return;\n    }\n    if (expectedDtype !== 'numeric' && expectedDtype !== actualDType ||\n        expectedDtype === 'numeric' && actualDType === 'string') {\n        throw new Error(\"Argument '\" + argName + \"' passed to '\" + functionName + \"' must \" +\n            (\"be \" + expectedDtype + \" tensor, but got \" + actualDType + \" tensor\"));\n    }\n}\nfunction convertToTensor(x, argName, functionName, parseAsDtype) {\n    if (parseAsDtype === void 0) { parseAsDtype = 'numeric'; }\n    if (x instanceof tensor_1.Tensor) {\n        assertDtype(parseAsDtype, x.dtype, argName, functionName);\n        return x;\n    }\n    var inferredDtype = util_1.inferDtype(x);\n    // If the user expects a bool/int/float, use that info to update the\n    // inferredDtype when it is not a string.\n    if (inferredDtype !== 'string' &&\n        ['bool', 'int32', 'float32'].indexOf(parseAsDtype) >= 0) {\n        inferredDtype = parseAsDtype;\n    }\n    assertDtype(parseAsDtype, inferredDtype, argName, functionName);\n    if ((x == null) ||\n        (!util_1.isTypedArray(x) && !Array.isArray(x) && typeof x !== 'number' &&\n            typeof x !== 'boolean' && typeof x !== 'string')) {\n        var type = x == null ? 'null' : x.constructor.name;\n        throw new Error(\"Argument '\" + argName + \"' passed to '\" + functionName + \"' must be a \" +\n            (\"Tensor or TensorLike, but got '\" + type + \"'\"));\n    }\n    var inferredShape = inferShape(x, inferredDtype);\n    if (!util_1.isTypedArray(x) && !Array.isArray(x)) {\n        x = [x];\n    }\n    var skipTypedArray = true;\n    var values = inferredDtype !== 'string' ?\n        util_1.toTypedArray(x, inferredDtype, environment_1.env().getBool('DEBUG')) :\n        util_1.flatten(x, [], skipTypedArray);\n    return engine_1.ENGINE.makeTensor(values, inferredShape, inferredDtype);\n}\nexports.convertToTensor = convertToTensor;\nfunction convertToTensorArray(arg, argName, functionName, parseAsDtype) {\n    if (parseAsDtype === void 0) { parseAsDtype = 'numeric'; }\n    if (!Array.isArray(arg)) {\n        throw new Error(\"Argument \" + argName + \" passed to \" + functionName + \" must be a \" +\n            '`Tensor[]` or `TensorLike[]`');\n    }\n    var tensors = arg;\n    return tensors.map(function (t, i) { return convertToTensor(t, argName + \"[\" + i + \"]\", functionName); }, parseAsDtype);\n}\nexports.convertToTensorArray = convertToTensorArray;\n//# sourceMappingURL=tensor_util_env.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/test_util.js":
/*!**************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/test_util.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar engine_1 = __webpack_require__(/*! ./engine */ \"./node_modules/@tensorflow/tfjs-core/dist/engine.js\");\nvar tensor_util_env_1 = __webpack_require__(/*! ./tensor_util_env */ \"./node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js\");\nvar util_1 = __webpack_require__(/*! ./util */ \"./node_modules/@tensorflow/tfjs-core/dist/util.js\");\nvar TEST_EPSILON_FLOAT32 = 1e-3;\nexports.TEST_EPSILON_FLOAT16 = 1e-1;\nfunction expectArraysClose(actual, expected, epsilon) {\n    if (epsilon == null) {\n        epsilon = testEpsilon();\n    }\n    return expectArraysPredicate(actual, expected, function (a, b) { return areClose(a, b, epsilon); });\n}\nexports.expectArraysClose = expectArraysClose;\nfunction testEpsilon() {\n    return engine_1.ENGINE.backend.floatPrecision() === 32 ? TEST_EPSILON_FLOAT32 :\n        exports.TEST_EPSILON_FLOAT16;\n}\nexports.testEpsilon = testEpsilon;\nfunction expectArraysPredicate(actual, expected, predicate) {\n    var checkClassType = true;\n    if (util_1.isTypedArray(actual) || util_1.isTypedArray(expected)) {\n        checkClassType = false;\n    }\n    if (util_1.isTypedArray(actual) && util_1.isTypedArray(expected)) {\n        checkClassType = true;\n    }\n    if (checkClassType) {\n        var aType = actual.constructor.name;\n        var bType = expected.constructor.name;\n        if (aType !== bType) {\n            throw new Error(\"Arrays are of different type. Actual: \" + aType + \". \" +\n                (\"Expected: \" + bType));\n        }\n    }\n    if (Array.isArray(actual) && Array.isArray(expected)) {\n        var actualShape = tensor_util_env_1.inferShape(actual);\n        var expectedShape = tensor_util_env_1.inferShape(expected);\n        if (!util_1.arraysEqual(actualShape, expectedShape)) {\n            throw new Error(\"Arrays have different shapes. \" +\n                (\"Actual: [\" + actualShape + \"]. Expected: [\" + expectedShape + \"]\"));\n        }\n    }\n    var actualFlat = util_1.isTypedArray(actual) ? actual : util_1.flatten(actual);\n    var expectedFlat = util_1.isTypedArray(expected) ?\n        expected :\n        util_1.flatten(expected);\n    if (actualFlat.length !== expectedFlat.length) {\n        throw new Error(\"Arrays have different lengths actual: \" + actualFlat.length + \" vs \" +\n            (\"expected: \" + expectedFlat.length + \".\\n\") +\n            (\"Actual:   \" + actualFlat + \".\\n\") +\n            (\"Expected: \" + expectedFlat + \".\"));\n    }\n    for (var i = 0; i < expectedFlat.length; ++i) {\n        var a = actualFlat[i];\n        var e = expectedFlat[i];\n        if (!predicate(a, e)) {\n            throw new Error(\"Arrays differ: actual[\" + i + \"] = \" + a + \", expected[\" + i + \"] = \" + e + \".\\n\" +\n                (\"Actual:   \" + actualFlat + \".\\n\") +\n                (\"Expected: \" + expectedFlat + \".\"));\n        }\n    }\n}\nfunction expectPromiseToFail(fn, done) {\n    fn().then(function () { return done.fail(); }, function () { return done(); });\n}\nexports.expectPromiseToFail = expectPromiseToFail;\nfunction expectArraysEqual(actual, expected) {\n    var exp = typeof expected === 'string' || typeof expected === 'number' ||\n        typeof expected === 'boolean' ?\n        [expected] :\n        expected;\n    if (util_1.isString(actual) || util_1.isString(actual[0]) ||\n        util_1.isString(expected) || util_1.isString(expected[0])) {\n        // tslint:disable-next-line: triple-equals\n        return expectArraysPredicate(actual, exp, function (a, b) { return a == b; });\n    }\n    return expectArraysPredicate(actual, expected, function (a, b) { return areClose(a, b, 0); });\n}\nexports.expectArraysEqual = expectArraysEqual;\nfunction expectNumbersClose(a, e, epsilon) {\n    if (epsilon == null) {\n        epsilon = testEpsilon();\n    }\n    if (!areClose(a, e, epsilon)) {\n        throw new Error(\"Numbers differ: actual === \" + a + \", expected === \" + e);\n    }\n}\nexports.expectNumbersClose = expectNumbersClose;\nfunction areClose(a, e, epsilon) {\n    if (!isFinite(a) && !isFinite(e)) {\n        return true;\n    }\n    if (isNaN(a) || isNaN(e) || Math.abs(a - e) > epsilon) {\n        return false;\n    }\n    return true;\n}\nfunction expectValuesInRange(actual, low, high) {\n    for (var i = 0; i < actual.length; i++) {\n        if (actual[i] < low || actual[i] > high) {\n            throw new Error(\"Value out of range:\" + actual[i] + \" low: \" + low + \", high: \" + high);\n        }\n    }\n}\nexports.expectValuesInRange = expectValuesInRange;\nfunction expectArrayBuffersEqual(actual, expected) {\n    // Safari & Jasmine don't like comparing ArrayBuffers directly. Wrapping in\n    // a Float32Array solves this issue.\n    expect(new Float32Array(actual)).toEqual(new Float32Array(expected));\n}\nexports.expectArrayBuffersEqual = expectArrayBuffersEqual;\n//# sourceMappingURL=test_util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/test_util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/train.js":
/*!**********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/train.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// So typings can propagate.\nvar adadelta_optimizer_1 = __webpack_require__(/*! ./optimizers/adadelta_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js\");\nvar adagrad_optimizer_1 = __webpack_require__(/*! ./optimizers/adagrad_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js\");\nvar adam_optimizer_1 = __webpack_require__(/*! ./optimizers/adam_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js\");\nvar adamax_optimizer_1 = __webpack_require__(/*! ./optimizers/adamax_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js\");\nvar momentum_optimizer_1 = __webpack_require__(/*! ./optimizers/momentum_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js\");\nvar optimizer_constructors_1 = __webpack_require__(/*! ./optimizers/optimizer_constructors */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js\");\nvar rmsprop_optimizer_1 = __webpack_require__(/*! ./optimizers/rmsprop_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js\");\nvar sgd_optimizer_1 = __webpack_require__(/*! ./optimizers/sgd_optimizer */ \"./node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js\");\n// tslint:disable-next-line:no-unused-expression\n[momentum_optimizer_1.MomentumOptimizer, sgd_optimizer_1.SGDOptimizer, adadelta_optimizer_1.AdadeltaOptimizer, adagrad_optimizer_1.AdagradOptimizer,\n    rmsprop_optimizer_1.RMSPropOptimizer, adamax_optimizer_1.AdamaxOptimizer, adam_optimizer_1.AdamOptimizer];\nexports.train = {\n    sgd: optimizer_constructors_1.OptimizerConstructors.sgd,\n    momentum: optimizer_constructors_1.OptimizerConstructors.momentum,\n    adadelta: optimizer_constructors_1.OptimizerConstructors.adadelta,\n    adagrad: optimizer_constructors_1.OptimizerConstructors.adagrad,\n    rmsprop: optimizer_constructors_1.OptimizerConstructors.rmsprop,\n    adamax: optimizer_constructors_1.OptimizerConstructors.adamax,\n    adam: optimizer_constructors_1.OptimizerConstructors.adam\n};\n//# sourceMappingURL=train.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/train.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/types.js":
/*!**********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/types.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar Rank;\n(function (Rank) {\n    Rank[\"R0\"] = \"R0\";\n    Rank[\"R1\"] = \"R1\";\n    Rank[\"R2\"] = \"R2\";\n    Rank[\"R3\"] = \"R3\";\n    Rank[\"R4\"] = \"R4\";\n    Rank[\"R5\"] = \"R5\";\n    Rank[\"R6\"] = \"R6\";\n})(Rank = exports.Rank || (exports.Rank = {}));\n// Looks for upcasting types. Used, for example, in operations with mixed dtype\n// inputs.\nvar UpcastInt32AndMap;\n(function (UpcastInt32AndMap) {\n    UpcastInt32AndMap[\"float32\"] = \"float32\";\n    UpcastInt32AndMap[\"int32\"] = \"int32\";\n    UpcastInt32AndMap[\"bool\"] = \"int32\";\n    UpcastInt32AndMap[\"complex64\"] = \"complex64\";\n})(UpcastInt32AndMap || (UpcastInt32AndMap = {}));\nvar UpcastBoolAndMap;\n(function (UpcastBoolAndMap) {\n    UpcastBoolAndMap[\"float32\"] = \"float32\";\n    UpcastBoolAndMap[\"int32\"] = \"int32\";\n    UpcastBoolAndMap[\"bool\"] = \"bool\";\n    UpcastBoolAndMap[\"complex64\"] = \"complex64\";\n})(UpcastBoolAndMap || (UpcastBoolAndMap = {}));\nvar UpcastFloat32AndMap;\n(function (UpcastFloat32AndMap) {\n    UpcastFloat32AndMap[\"float32\"] = \"float32\";\n    UpcastFloat32AndMap[\"int32\"] = \"float32\";\n    UpcastFloat32AndMap[\"bool\"] = \"float32\";\n    UpcastFloat32AndMap[\"complex64\"] = \"complex64\";\n})(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));\nvar UpcastComplex64AndMap;\n(function (UpcastComplex64AndMap) {\n    UpcastComplex64AndMap[\"float32\"] = \"complex64\";\n    UpcastComplex64AndMap[\"int32\"] = \"complex64\";\n    UpcastComplex64AndMap[\"bool\"] = \"complex64\";\n    UpcastComplex64AndMap[\"complex64\"] = \"complex64\";\n})(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));\nvar upcastTypeMap = {\n    'float32': UpcastFloat32AndMap,\n    'int32': UpcastInt32AndMap,\n    'bool': UpcastBoolAndMap,\n    'complex64': UpcastComplex64AndMap\n};\nfunction upcastType(typeA, typeB) {\n    if (typeA === 'string' || typeB === 'string') {\n        if (typeA === 'string' && typeB === 'string') {\n            return 'string';\n        }\n        throw new Error(\"Can not upcast \" + typeA + \" with \" + typeB);\n    }\n    return upcastTypeMap[typeA][typeB];\n}\nexports.upcastType = upcastType;\n/** Returns the output type after summation. */\nfunction sumOutType(type) {\n    return upcastType(type, 'int32');\n}\nexports.sumOutType = sumOutType;\n//# sourceMappingURL=types.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/types.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/util.js":
/*!*********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/util.js ***!
  \*********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2017 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar environment_1 = __webpack_require__(/*! ./environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\n/**\n * Shuffles the array in-place using Fisher-Yates algorithm.\n *\n * ```js\n * const a = [1, 2, 3, 4, 5];\n * tf.util.shuffle(a);\n * console.log(a);\n * ```\n *\n * @param array The array to shuffle in-place.\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\n// tslint:disable-next-line:no-any\nfunction shuffle(array) {\n    var counter = array.length;\n    var temp = 0;\n    var index = 0;\n    // While there are elements in the array\n    while (counter > 0) {\n        // Pick a random index\n        index = (Math.random() * counter) | 0;\n        // Decrease counter by 1\n        counter--;\n        // And swap the last element with it\n        temp = array[counter];\n        array[counter] = array[index];\n        array[index] = temp;\n    }\n}\nexports.shuffle = shuffle;\n/** Clamps a value to a specified range. */\nfunction clamp(min, x, max) {\n    return Math.max(min, Math.min(x, max));\n}\nexports.clamp = clamp;\nfunction nearestLargerEven(val) {\n    return val % 2 === 0 ? val : val + 1;\n}\nexports.nearestLargerEven = nearestLargerEven;\nfunction sum(arr) {\n    var sum = 0;\n    for (var i = 0; i < arr.length; i++) {\n        sum += arr[i];\n    }\n    return sum;\n}\nexports.sum = sum;\n/**\n * Returns a sample from a uniform [a, b) distribution.\n *\n * @param a The minimum support (inclusive).\n * @param b The maximum support (exclusive).\n * @return A pseudorandom number on the half-open interval [a,b).\n */\nfunction randUniform(a, b) {\n    var r = Math.random();\n    return (b * r) + (1 - r) * a;\n}\nexports.randUniform = randUniform;\n/** Returns the squared Euclidean distance between two vectors. */\nfunction distSquared(a, b) {\n    var result = 0;\n    for (var i = 0; i < a.length; i++) {\n        var diff = Number(a[i]) - Number(b[i]);\n        result += diff * diff;\n    }\n    return result;\n}\nexports.distSquared = distSquared;\n/**\n * Asserts that the expression is true. Otherwise throws an error with the\n * provided message.\n *\n * ```js\n * const x = 2;\n * tf.util.assert(x === 2, 'x is not 2');\n * ```\n *\n * @param expr The expression to assert (as a boolean).\n * @param msg A function that returns the message to report when throwing an\n *     error. We use a function for performance reasons.\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\nfunction assert(expr, msg) {\n    if (!expr) {\n        throw new Error(typeof msg === 'string' ? msg : msg());\n    }\n}\nexports.assert = assert;\nfunction assertShapesMatch(shapeA, shapeB, errorMessagePrefix) {\n    if (errorMessagePrefix === void 0) { errorMessagePrefix = ''; }\n    assert(arraysEqual(shapeA, shapeB), function () { return errorMessagePrefix + (\" Shapes \" + shapeA + \" and \" + shapeB + \" must match\"); });\n}\nexports.assertShapesMatch = assertShapesMatch;\nfunction assertNonNull(a) {\n    assert(a != null, function () { return \"The input to the tensor constructor must be a non-null value.\"; });\n}\nexports.assertNonNull = assertNonNull;\n// NOTE: We explicitly type out what T extends instead of any so that\n// util.flatten on a nested array of number doesn't try to infer T as a\n// number[][], causing us to explicitly type util.flatten<number>().\n/**\n *  Flattens an arbitrarily nested array.\n *\n * ```js\n * const a = [[1, 2], [3, 4], [5, [6, [7]]]];\n * const flat = tf.util.flatten(a);\n * console.log(flat);\n * ```\n *\n *  @param arr The nested array to flatten.\n *  @param result The destination array which holds the elements.\n *  @param skipTypedArray If true, avoids flattening the typed arrays. Defaults\n *      to false.\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\nfunction flatten(arr, result, skipTypedArray) {\n    if (result === void 0) { result = []; }\n    if (skipTypedArray === void 0) { skipTypedArray = false; }\n    if (result == null) {\n        result = [];\n    }\n    if (Array.isArray(arr) || isTypedArray(arr) && !skipTypedArray) {\n        for (var i = 0; i < arr.length; ++i) {\n            flatten(arr[i], result, skipTypedArray);\n        }\n    }\n    else {\n        result.push(arr);\n    }\n    return result;\n}\nexports.flatten = flatten;\n/**\n * Returns the size (number of elements) of the tensor given its shape.\n *\n * ```js\n * const shape = [3, 4, 2];\n * const size = tf.util.sizeFromShape(shape);\n * console.log(size);\n * ```\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\nfunction sizeFromShape(shape) {\n    if (shape.length === 0) {\n        // Scalar.\n        return 1;\n    }\n    var size = shape[0];\n    for (var i = 1; i < shape.length; i++) {\n        size *= shape[i];\n    }\n    return size;\n}\nexports.sizeFromShape = sizeFromShape;\nfunction isScalarShape(shape) {\n    return shape.length === 0;\n}\nexports.isScalarShape = isScalarShape;\nfunction arraysEqual(n1, n2) {\n    if (n1 === n2) {\n        return true;\n    }\n    if (n1 == null || n2 == null) {\n        return false;\n    }\n    if (n1.length !== n2.length) {\n        return false;\n    }\n    for (var i = 0; i < n1.length; i++) {\n        if (n1[i] !== n2[i]) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.arraysEqual = arraysEqual;\nfunction isInt(a) {\n    return a % 1 === 0;\n}\nexports.isInt = isInt;\nfunction tanh(x) {\n    // tslint:disable-next-line:no-any\n    if (Math.tanh != null) {\n        // tslint:disable-next-line:no-any\n        return Math.tanh(x);\n    }\n    if (x === Infinity) {\n        return 1;\n    }\n    else if (x === -Infinity) {\n        return -1;\n    }\n    else {\n        var e2x = Math.exp(2 * x);\n        return (e2x - 1) / (e2x + 1);\n    }\n}\nexports.tanh = tanh;\nfunction sizeToSquarishShape(size) {\n    var width = Math.ceil(Math.sqrt(size));\n    return [width, Math.ceil(size / width)];\n}\nexports.sizeToSquarishShape = sizeToSquarishShape;\n/**\n * Creates a new array with randomized indicies to a given quantity.\n *\n * ```js\n * const randomTen = tf.util.createShuffledIndices(10);\n * console.log(randomTen);\n * ```\n *\n * @param number Quantity of how many shuffled indicies to create.\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\nfunction createShuffledIndices(n) {\n    var shuffledIndices = new Uint32Array(n);\n    for (var i = 0; i < n; ++i) {\n        shuffledIndices[i] = i;\n    }\n    shuffle(shuffledIndices);\n    return shuffledIndices;\n}\nexports.createShuffledIndices = createShuffledIndices;\nfunction rightPad(a, size) {\n    if (size <= a.length) {\n        return a;\n    }\n    return a + ' '.repeat(size - a.length);\n}\nexports.rightPad = rightPad;\nfunction repeatedTry(checkFn, delayFn, maxCounter) {\n    if (delayFn === void 0) { delayFn = function (counter) { return 0; }; }\n    return new Promise(function (resolve, reject) {\n        var tryCount = 0;\n        var tryFn = function () {\n            if (checkFn()) {\n                resolve();\n                return;\n            }\n            tryCount++;\n            var nextBackoff = delayFn(tryCount);\n            if (maxCounter != null && tryCount >= maxCounter) {\n                reject();\n                return;\n            }\n            setTimeout(tryFn, nextBackoff);\n        };\n        tryFn();\n    });\n}\nexports.repeatedTry = repeatedTry;\n/**\n * Given the full size of the array and a shape that may contain -1 as the\n * implicit dimension, returns the inferred shape where -1 is replaced.\n * E.g. For shape=[2, -1, 3] and size=24, it will return [2, 4, 3].\n *\n * @param shape The shape, which may contain -1 in some dimension.\n * @param size The full size (number of elements) of the array.\n * @return The inferred shape where -1 is replaced with the inferred size.\n */\nfunction inferFromImplicitShape(shape, size) {\n    var shapeProd = 1;\n    var implicitIdx = -1;\n    for (var i = 0; i < shape.length; ++i) {\n        if (shape[i] >= 0) {\n            shapeProd *= shape[i];\n        }\n        else if (shape[i] === -1) {\n            if (implicitIdx !== -1) {\n                throw Error(\"Shapes can only have 1 implicit size. \" +\n                    (\"Found -1 at dim \" + implicitIdx + \" and dim \" + i));\n            }\n            implicitIdx = i;\n        }\n        else if (shape[i] < 0) {\n            throw Error(\"Shapes can not be < 0. Found \" + shape[i] + \" at dim \" + i);\n        }\n    }\n    if (implicitIdx === -1) {\n        if (size > 0 && size !== shapeProd) {\n            throw Error(\"Size(\" + size + \") must match the product of shape \" + shape);\n        }\n        return shape;\n    }\n    if (shapeProd === 0) {\n        throw Error(\"Cannot infer the missing size in [\" + shape + \"] when \" +\n            \"there are 0 elements\");\n    }\n    if (size % shapeProd !== 0) {\n        throw Error(\"The implicit shape can't be a fractional number. \" +\n            (\"Got \" + size + \" / \" + shapeProd));\n    }\n    var newShape = shape.slice();\n    newShape[implicitIdx] = size / shapeProd;\n    return newShape;\n}\nexports.inferFromImplicitShape = inferFromImplicitShape;\nfunction parseAxisParam(axis, shape) {\n    var rank = shape.length;\n    // Normalize input\n    axis = axis == null ? shape.map(function (s, i) { return i; }) : [].concat(axis);\n    // Check for valid range\n    assert(axis.every(function (ax) { return ax >= -rank && ax < rank; }), function () {\n        return \"All values in axis param must be in range [-\" + rank + \", \" + rank + \") but \" +\n            (\"got axis \" + axis);\n    });\n    // Check for only integers\n    assert(axis.every(function (ax) { return isInt(ax); }), function () { return \"All values in axis param must be integers but \" +\n        (\"got axis \" + axis); });\n    // Handle negative axis.\n    return axis.map(function (a) { return a < 0 ? rank + a : a; });\n}\nexports.parseAxisParam = parseAxisParam;\n/** Reduces the shape by removing all dimensions of shape 1. */\nfunction squeezeShape(shape, axis) {\n    var newShape = [];\n    var keptDims = [];\n    var isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;\n    var axes = (axis == null || isEmptyArray) ?\n        null :\n        parseAxisParam(axis, shape).sort();\n    var j = 0;\n    for (var i = 0; i < shape.length; ++i) {\n        if (axes != null) {\n            if (axes[j] === i && shape[i] !== 1) {\n                throw new Error(\"Can't squeeze axis \" + i + \" since its dim '\" + shape[i] + \"' is not 1\");\n            }\n            if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {\n                newShape.push(shape[i]);\n                keptDims.push(i);\n            }\n            if (axes[j] <= i) {\n                j++;\n            }\n        }\n        if (shape[i] !== 1) {\n            newShape.push(shape[i]);\n            keptDims.push(i);\n        }\n    }\n    return { newShape: newShape, keptDims: keptDims };\n}\nexports.squeezeShape = squeezeShape;\nfunction getTypedArrayFromDType(dtype, size) {\n    var values = null;\n    if (dtype == null || dtype === 'float32') {\n        values = new Float32Array(size);\n    }\n    else if (dtype === 'int32') {\n        values = new Int32Array(size);\n    }\n    else if (dtype === 'bool') {\n        values = new Uint8Array(size);\n    }\n    else {\n        throw new Error(\"Unknown data type \" + dtype);\n    }\n    return values;\n}\nexports.getTypedArrayFromDType = getTypedArrayFromDType;\nfunction getArrayFromDType(dtype, size) {\n    var values = null;\n    if (dtype == null || dtype === 'float32') {\n        values = new Float32Array(size);\n    }\n    else if (dtype === 'int32') {\n        values = new Int32Array(size);\n    }\n    else if (dtype === 'bool') {\n        values = new Uint8Array(size);\n    }\n    else if (dtype === 'string') {\n        values = new Array(size);\n    }\n    else {\n        throw new Error(\"Unknown data type \" + dtype);\n    }\n    return values;\n}\nexports.getArrayFromDType = getArrayFromDType;\nfunction checkConversionForErrors(vals, dtype) {\n    for (var i = 0; i < vals.length; i++) {\n        var num = vals[i];\n        if (isNaN(num) || !isFinite(num)) {\n            throw Error(\"A tensor of type \" + dtype + \" being uploaded contains \" + num + \".\");\n        }\n    }\n}\nexports.checkConversionForErrors = checkConversionForErrors;\n/** Returns true if the dtype is valid. */\nfunction isValidDtype(dtype) {\n    return dtype === 'bool' || dtype === 'complex64' || dtype === 'float32' ||\n        dtype === 'int32' || dtype === 'string';\n}\nexports.isValidDtype = isValidDtype;\n/**\n * Returns true if the new type can't encode the old type without loss of\n * precision.\n */\nfunction hasEncodingLoss(oldType, newType) {\n    if (newType === 'complex64') {\n        return false;\n    }\n    if (newType === 'float32' && oldType !== 'complex64') {\n        return false;\n    }\n    if (newType === 'int32' && oldType !== 'float32' && oldType !== 'complex64') {\n        return false;\n    }\n    if (newType === 'bool' && oldType === 'bool') {\n        return false;\n    }\n    return true;\n}\nexports.hasEncodingLoss = hasEncodingLoss;\nfunction isTypedArray(a) {\n    return a instanceof Float32Array || a instanceof Int32Array ||\n        a instanceof Uint8Array;\n}\nexports.isTypedArray = isTypedArray;\nfunction bytesPerElement(dtype) {\n    if (dtype === 'float32' || dtype === 'int32') {\n        return 4;\n    }\n    else if (dtype === 'complex64') {\n        return 8;\n    }\n    else if (dtype === 'bool') {\n        return 1;\n    }\n    else {\n        throw new Error(\"Unknown dtype \" + dtype);\n    }\n}\nexports.bytesPerElement = bytesPerElement;\n/**\n * Returns the approximate number of bytes allocated in the string array - 2\n * bytes per character. Computing the exact bytes for a native string in JS is\n * not possible since it depends on the encoding of the html page that serves\n * the website.\n */\nfunction bytesFromStringArray(arr) {\n    if (arr == null) {\n        return 0;\n    }\n    var bytes = 0;\n    arr.forEach(function (x) { return bytes += x.length; });\n    return bytes;\n}\nexports.bytesFromStringArray = bytesFromStringArray;\n/** Returns true if the value is a string. */\nfunction isString(value) {\n    return typeof value === 'string' || value instanceof String;\n}\nexports.isString = isString;\nfunction isBoolean(value) {\n    return typeof value === 'boolean';\n}\nexports.isBoolean = isBoolean;\nfunction isNumber(value) {\n    return typeof value === 'number';\n}\nexports.isNumber = isNumber;\nfunction inferDtype(values) {\n    if (Array.isArray(values)) {\n        return inferDtype(values[0]);\n    }\n    if (values instanceof Float32Array) {\n        return 'float32';\n    }\n    else if (values instanceof Int32Array || values instanceof Uint8Array) {\n        return 'int32';\n    }\n    else if (isNumber(values)) {\n        return 'float32';\n    }\n    else if (isString(values)) {\n        return 'string';\n    }\n    else if (isBoolean(values)) {\n        return 'bool';\n    }\n    return 'float32';\n}\nexports.inferDtype = inferDtype;\nfunction isFunction(f) {\n    return !!(f && f.constructor && f.call && f.apply);\n}\nexports.isFunction = isFunction;\nfunction nearestDivisor(size, start) {\n    for (var i = start; i < size; ++i) {\n        if (size % i === 0) {\n            return i;\n        }\n    }\n    return size;\n}\nexports.nearestDivisor = nearestDivisor;\nfunction computeStrides(shape) {\n    var rank = shape.length;\n    if (rank < 2) {\n        return [];\n    }\n    // Last dimension has implicit stride of 1, thus having D-1 (instead of D)\n    // strides.\n    var strides = new Array(rank - 1);\n    strides[rank - 2] = shape[rank - 1];\n    for (var i = rank - 3; i >= 0; --i) {\n        strides[i] = strides[i + 1] * shape[i + 1];\n    }\n    return strides;\n}\nexports.computeStrides = computeStrides;\nfunction toTypedArray(a, dtype, debugMode) {\n    if (dtype === 'string') {\n        throw new Error('Cannot convert a string[] to a TypedArray');\n    }\n    if (Array.isArray(a)) {\n        a = flatten(a);\n    }\n    if (debugMode) {\n        checkConversionForErrors(a, dtype);\n    }\n    if (noConversionNeeded(a, dtype)) {\n        return a;\n    }\n    if (dtype == null || dtype === 'float32' || dtype === 'complex64') {\n        return new Float32Array(a);\n    }\n    else if (dtype === 'int32') {\n        return new Int32Array(a);\n    }\n    else if (dtype === 'bool') {\n        var bool = new Uint8Array(a.length);\n        for (var i = 0; i < bool.length; ++i) {\n            if (Math.round(a[i]) !== 0) {\n                bool[i] = 1;\n            }\n        }\n        return bool;\n    }\n    else {\n        throw new Error(\"Unknown data type \" + dtype);\n    }\n}\nexports.toTypedArray = toTypedArray;\nfunction createNestedArray(offset, shape, a) {\n    var ret = new Array();\n    if (shape.length === 1) {\n        var d = shape[0];\n        for (var i = 0; i < d; i++) {\n            ret[i] = a[offset + i];\n        }\n    }\n    else {\n        var d = shape[0];\n        var rest = shape.slice(1);\n        var len = rest.reduce(function (acc, c) { return acc * c; });\n        for (var i = 0; i < d; i++) {\n            ret[i] = createNestedArray(offset + i * len, rest, a);\n        }\n    }\n    return ret;\n}\n// Provide a nested array of TypedArray in given shape.\nfunction toNestedArray(shape, a) {\n    if (shape.length === 0) {\n        // Scalar type should return a single number.\n        return a[0];\n    }\n    var size = shape.reduce(function (acc, c) { return acc * c; });\n    if (size === 0) {\n        // A tensor with shape zero should be turned into empty list.\n        return [];\n    }\n    if (size !== a.length) {\n        throw new Error(\"[\" + shape + \"] does not match the input size.\");\n    }\n    return createNestedArray(0, shape, a);\n}\nexports.toNestedArray = toNestedArray;\nfunction noConversionNeeded(a, dtype) {\n    return (a instanceof Float32Array && dtype === 'float32') ||\n        (a instanceof Int32Array && dtype === 'int32') ||\n        (a instanceof Uint8Array && dtype === 'bool');\n}\nfunction makeOnesTypedArray(size, dtype) {\n    var array = makeZerosTypedArray(size, dtype);\n    for (var i = 0; i < array.length; i++) {\n        array[i] = 1;\n    }\n    return array;\n}\nexports.makeOnesTypedArray = makeOnesTypedArray;\nfunction makeZerosTypedArray(size, dtype) {\n    if (dtype == null || dtype === 'float32' || dtype === 'complex64') {\n        return new Float32Array(size);\n    }\n    else if (dtype === 'int32') {\n        return new Int32Array(size);\n    }\n    else if (dtype === 'bool') {\n        return new Uint8Array(size);\n    }\n    else {\n        throw new Error(\"Unknown data type \" + dtype);\n    }\n}\nexports.makeZerosTypedArray = makeZerosTypedArray;\n/**\n * Returns the current high-resolution time in milliseconds relative to an\n * arbitrary time in the past. It works across different platforms (node.js,\n * browsers).\n *\n * ```js\n * console.log(tf.util.now());\n * ```\n */\n/** @doc {heading: 'Util', namespace: 'util'} */\nfunction now() {\n    return environment_1.env().platform.now();\n}\nexports.now = now;\nfunction assertNonNegativeIntegerDimensions(shape) {\n    shape.forEach(function (dimSize) {\n        assert(Number.isInteger(dimSize) && dimSize >= 0, function () {\n            return \"Tensor must have a shape comprised of positive integers but got \" +\n                (\"shape [\" + shape + \"].\");\n        });\n    });\n}\nexports.assertNonNegativeIntegerDimensions = assertNonNegativeIntegerDimensions;\n/**\n * Returns a platform-specific implementation of\n * [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n *\n * If `fetch` is defined on the global object (`window`, `process`, etc.),\n * `tf.util.fetch` returns that function.\n *\n * If not, `tf.util.fetch` returns a platform-specific solution.\n *\n * ```js\n * const resource = await tf.util.fetch('https://unpkg.com/@tensorflow/tfjs');\n * // handle response\n * ```\n */\n/** @doc {heading: 'Util'} */\nfunction fetch(path, requestInits) {\n    return environment_1.env().platform.fetch(path, requestInits);\n}\nexports.fetch = fetch;\n/**\n * Encodes the provided string into bytes using the provided encoding scheme.\n *\n * @param s The string to encode.\n * @param encoding The encoding scheme. Defaults to utf-8.\n *\n */\n/** @doc {heading: 'Util'} */\nfunction encodeString(s, encoding) {\n    if (encoding === void 0) { encoding = 'utf-8'; }\n    encoding = encoding || 'utf-8';\n    return environment_1.env().platform.encode(s, encoding);\n}\nexports.encodeString = encodeString;\n/**\n * Decodes the provided bytes into a string using the provided encoding scheme.\n * @param bytes The bytes to decode.\n *\n * @param encoding The encoding scheme. Defaults to utf-8.\n */\n/** @doc {heading: 'Util'} */\nfunction decodeString(bytes, encoding) {\n    if (encoding === void 0) { encoding = 'utf-8'; }\n    encoding = encoding || 'utf-8';\n    return environment_1.env().platform.decode(bytes, encoding);\n}\nexports.decodeString = decodeString;\n/**\n * Computes flat index for a given location (multidimentionsal index) in a\n * Tensor/multidimensional array.\n *\n * @param locs Location in the tensor.\n * @param rank Rank of the tensor.\n * @param strides Tensor strides.\n */\nfunction locToIndex(locs, rank, strides) {\n    if (rank === 0) {\n        return 0;\n    }\n    else if (rank === 1) {\n        return locs[0];\n    }\n    var index = locs[locs.length - 1];\n    for (var i = 0; i < locs.length - 1; ++i) {\n        index += strides[i] * locs[i];\n    }\n    return index;\n}\nexports.locToIndex = locToIndex;\n/**\n * Computes the location (multidimensional index) in a tensor/multidimentional\n * array for a given flat index.\n *\n * @param index Index in flat array.\n * @param rank Rank of tensor.\n * @param strides Strides of tensor.\n */\nfunction indexToLoc(index, rank, strides) {\n    if (rank === 0) {\n        return [];\n    }\n    else if (rank === 1) {\n        return [index];\n    }\n    var locs = new Array(rank);\n    for (var i = 0; i < locs.length - 1; ++i) {\n        locs[i] = Math.floor(index / strides[i]);\n        index -= locs[i] * strides[i];\n    }\n    locs[locs.length - 1] = index;\n    return locs;\n}\nexports.indexToLoc = indexToLoc;\n//# sourceMappingURL=util.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/util.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/version.js":
/*!************************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/version.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/** @license See the LICENSE file. */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// This code is auto-generated, do not modify this file!\nvar version = '1.7.0';\nexports.version = version;\n//# sourceMappingURL=version.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/version.js?");

/***/ }),

/***/ "./node_modules/@tensorflow/tfjs-core/dist/webgl.js":
/*!**********************************************************!*\
  !*** ./node_modules/@tensorflow/tfjs-core/dist/webgl.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar gpgpu_util = __webpack_require__(/*! ./backends/webgl/gpgpu_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_util.js\");\nexports.gpgpu_util = gpgpu_util;\nvar webgl_util = __webpack_require__(/*! ./backends/webgl/webgl_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/webgl_util.js\");\nexports.webgl_util = webgl_util;\nvar environment_1 = __webpack_require__(/*! ./environment */ \"./node_modules/@tensorflow/tfjs-core/dist/environment.js\");\nvar backend_webgl_1 = __webpack_require__(/*! ./backends/webgl/backend_webgl */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/backend_webgl.js\");\nexports.MathBackendWebGL = backend_webgl_1.MathBackendWebGL;\nvar canvas_util_1 = __webpack_require__(/*! ./backends/webgl/canvas_util */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/canvas_util.js\");\nexports.setWebGLContext = canvas_util_1.setWebGLContext;\nvar gpgpu_context_1 = __webpack_require__(/*! ./backends/webgl/gpgpu_context */ \"./node_modules/@tensorflow/tfjs-core/dist/backends/webgl/gpgpu_context.js\");\nexports.GPGPUContext = gpgpu_context_1.GPGPUContext;\n/**\n * Enforce use of half precision textures if available on the platform.\n */\n/** @doc {heading: 'Environment', namespace: 'webgl'} */\nfunction forceHalfFloat() {\n    environment_1.env().set('WEBGL_FORCE_F16_TEXTURES', true);\n}\nexports.forceHalfFloat = forceHalfFloat;\n//# sourceMappingURL=webgl.js.map\n\n//# sourceURL=webpack:///./node_modules/@tensorflow/tfjs-core/dist/webgl.js?");

/***/ }),

/***/ "./node_modules/assert/assert.js":
/*!***************************************!*\
  !*** ./node_modules/assert/assert.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(global) {\n\nvar objectAssign = __webpack_require__(/*! object-assign */ \"./node_modules/object-assign/index.js\");\n\n// compare and isBuffer taken from https://github.com/feross/buffer/blob/680e9e5e488f22aac27599a57dc844a6315928dd/index.js\n// original notice:\n\n/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>\n * @license  MIT\n */\nfunction compare(a, b) {\n  if (a === b) {\n    return 0;\n  }\n\n  var x = a.length;\n  var y = b.length;\n\n  for (var i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i];\n      y = b[i];\n      break;\n    }\n  }\n\n  if (x < y) {\n    return -1;\n  }\n  if (y < x) {\n    return 1;\n  }\n  return 0;\n}\nfunction isBuffer(b) {\n  if (global.Buffer && typeof global.Buffer.isBuffer === 'function') {\n    return global.Buffer.isBuffer(b);\n  }\n  return !!(b != null && b._isBuffer);\n}\n\n// based on node assert, original notice:\n// NB: The URL to the CommonJS spec is kept just for tradition.\n//     node-assert has evolved a lot since then, both in API and behavior.\n\n// http://wiki.commonjs.org/wiki/Unit_Testing/1.0\n//\n// THIS IS NOT TESTED NOR LIKELY TO WORK OUTSIDE V8!\n//\n// Originally from narwhal.js (http://narwhaljs.org)\n// Copyright (c) 2009 Thomas Robinson <280north.com>\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the 'Software'), to\n// deal in the Software without restriction, including without limitation the\n// rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n// sell copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n// ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n// WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar util = __webpack_require__(/*! util/ */ \"./node_modules/util/util.js\");\nvar hasOwn = Object.prototype.hasOwnProperty;\nvar pSlice = Array.prototype.slice;\nvar functionsHaveNames = (function () {\n  return function foo() {}.name === 'foo';\n}());\nfunction pToString (obj) {\n  return Object.prototype.toString.call(obj);\n}\nfunction isView(arrbuf) {\n  if (isBuffer(arrbuf)) {\n    return false;\n  }\n  if (typeof global.ArrayBuffer !== 'function') {\n    return false;\n  }\n  if (typeof ArrayBuffer.isView === 'function') {\n    return ArrayBuffer.isView(arrbuf);\n  }\n  if (!arrbuf) {\n    return false;\n  }\n  if (arrbuf instanceof DataView) {\n    return true;\n  }\n  if (arrbuf.buffer && arrbuf.buffer instanceof ArrayBuffer) {\n    return true;\n  }\n  return false;\n}\n// 1. The assert module provides functions that throw\n// AssertionError's when particular conditions are not met. The\n// assert module must conform to the following interface.\n\nvar assert = module.exports = ok;\n\n// 2. The AssertionError is defined in assert.\n// new assert.AssertionError({ message: message,\n//                             actual: actual,\n//                             expected: expected })\n\nvar regex = /\\s*function\\s+([^\\(\\s]*)\\s*/;\n// based on https://github.com/ljharb/function.prototype.name/blob/adeeeec8bfcc6068b187d7d9fb3d5bb1d3a30899/implementation.js\nfunction getName(func) {\n  if (!util.isFunction(func)) {\n    return;\n  }\n  if (functionsHaveNames) {\n    return func.name;\n  }\n  var str = func.toString();\n  var match = str.match(regex);\n  return match && match[1];\n}\nassert.AssertionError = function AssertionError(options) {\n  this.name = 'AssertionError';\n  this.actual = options.actual;\n  this.expected = options.expected;\n  this.operator = options.operator;\n  if (options.message) {\n    this.message = options.message;\n    this.generatedMessage = false;\n  } else {\n    this.message = getMessage(this);\n    this.generatedMessage = true;\n  }\n  var stackStartFunction = options.stackStartFunction || fail;\n  if (Error.captureStackTrace) {\n    Error.captureStackTrace(this, stackStartFunction);\n  } else {\n    // non v8 browsers so we can have a stacktrace\n    var err = new Error();\n    if (err.stack) {\n      var out = err.stack;\n\n      // try to strip useless frames\n      var fn_name = getName(stackStartFunction);\n      var idx = out.indexOf('\\n' + fn_name);\n      if (idx >= 0) {\n        // once we have located the function frame\n        // we need to strip out everything before it (and its line)\n        var next_line = out.indexOf('\\n', idx + 1);\n        out = out.substring(next_line + 1);\n      }\n\n      this.stack = out;\n    }\n  }\n};\n\n// assert.AssertionError instanceof Error\nutil.inherits(assert.AssertionError, Error);\n\nfunction truncate(s, n) {\n  if (typeof s === 'string') {\n    return s.length < n ? s : s.slice(0, n);\n  } else {\n    return s;\n  }\n}\nfunction inspect(something) {\n  if (functionsHaveNames || !util.isFunction(something)) {\n    return util.inspect(something);\n  }\n  var rawname = getName(something);\n  var name = rawname ? ': ' + rawname : '';\n  return '[Function' +  name + ']';\n}\nfunction getMessage(self) {\n  return truncate(inspect(self.actual), 128) + ' ' +\n         self.operator + ' ' +\n         truncate(inspect(self.expected), 128);\n}\n\n// At present only the three keys mentioned above are used and\n// understood by the spec. Implementations or sub modules can pass\n// other keys to the AssertionError's constructor - they will be\n// ignored.\n\n// 3. All of the following functions must throw an AssertionError\n// when a corresponding condition is not met, with a message that\n// may be undefined if not provided.  All assertion methods provide\n// both the actual and expected values to the assertion error for\n// display purposes.\n\nfunction fail(actual, expected, message, operator, stackStartFunction) {\n  throw new assert.AssertionError({\n    message: message,\n    actual: actual,\n    expected: expected,\n    operator: operator,\n    stackStartFunction: stackStartFunction\n  });\n}\n\n// EXTENSION! allows for well behaved errors defined elsewhere.\nassert.fail = fail;\n\n// 4. Pure assertion tests whether a value is truthy, as determined\n// by !!guard.\n// assert.ok(guard, message_opt);\n// This statement is equivalent to assert.equal(true, !!guard,\n// message_opt);. To test strictly for the value true, use\n// assert.strictEqual(true, guard, message_opt);.\n\nfunction ok(value, message) {\n  if (!value) fail(value, true, message, '==', assert.ok);\n}\nassert.ok = ok;\n\n// 5. The equality assertion tests shallow, coercive equality with\n// ==.\n// assert.equal(actual, expected, message_opt);\n\nassert.equal = function equal(actual, expected, message) {\n  if (actual != expected) fail(actual, expected, message, '==', assert.equal);\n};\n\n// 6. The non-equality assertion tests for whether two objects are not equal\n// with != assert.notEqual(actual, expected, message_opt);\n\nassert.notEqual = function notEqual(actual, expected, message) {\n  if (actual == expected) {\n    fail(actual, expected, message, '!=', assert.notEqual);\n  }\n};\n\n// 7. The equivalence assertion tests a deep equality relation.\n// assert.deepEqual(actual, expected, message_opt);\n\nassert.deepEqual = function deepEqual(actual, expected, message) {\n  if (!_deepEqual(actual, expected, false)) {\n    fail(actual, expected, message, 'deepEqual', assert.deepEqual);\n  }\n};\n\nassert.deepStrictEqual = function deepStrictEqual(actual, expected, message) {\n  if (!_deepEqual(actual, expected, true)) {\n    fail(actual, expected, message, 'deepStrictEqual', assert.deepStrictEqual);\n  }\n};\n\nfunction _deepEqual(actual, expected, strict, memos) {\n  // 7.1. All identical values are equivalent, as determined by ===.\n  if (actual === expected) {\n    return true;\n  } else if (isBuffer(actual) && isBuffer(expected)) {\n    return compare(actual, expected) === 0;\n\n  // 7.2. If the expected value is a Date object, the actual value is\n  // equivalent if it is also a Date object that refers to the same time.\n  } else if (util.isDate(actual) && util.isDate(expected)) {\n    return actual.getTime() === expected.getTime();\n\n  // 7.3 If the expected value is a RegExp object, the actual value is\n  // equivalent if it is also a RegExp object with the same source and\n  // properties (`global`, `multiline`, `lastIndex`, `ignoreCase`).\n  } else if (util.isRegExp(actual) && util.isRegExp(expected)) {\n    return actual.source === expected.source &&\n           actual.global === expected.global &&\n           actual.multiline === expected.multiline &&\n           actual.lastIndex === expected.lastIndex &&\n           actual.ignoreCase === expected.ignoreCase;\n\n  // 7.4. Other pairs that do not both pass typeof value == 'object',\n  // equivalence is determined by ==.\n  } else if ((actual === null || typeof actual !== 'object') &&\n             (expected === null || typeof expected !== 'object')) {\n    return strict ? actual === expected : actual == expected;\n\n  // If both values are instances of typed arrays, wrap their underlying\n  // ArrayBuffers in a Buffer each to increase performance\n  // This optimization requires the arrays to have the same type as checked by\n  // Object.prototype.toString (aka pToString). Never perform binary\n  // comparisons for Float*Arrays, though, since e.g. +0 === -0 but their\n  // bit patterns are not identical.\n  } else if (isView(actual) && isView(expected) &&\n             pToString(actual) === pToString(expected) &&\n             !(actual instanceof Float32Array ||\n               actual instanceof Float64Array)) {\n    return compare(new Uint8Array(actual.buffer),\n                   new Uint8Array(expected.buffer)) === 0;\n\n  // 7.5 For all other Object pairs, including Array objects, equivalence is\n  // determined by having the same number of owned properties (as verified\n  // with Object.prototype.hasOwnProperty.call), the same set of keys\n  // (although not necessarily the same order), equivalent values for every\n  // corresponding key, and an identical 'prototype' property. Note: this\n  // accounts for both named and indexed properties on Arrays.\n  } else if (isBuffer(actual) !== isBuffer(expected)) {\n    return false;\n  } else {\n    memos = memos || {actual: [], expected: []};\n\n    var actualIndex = memos.actual.indexOf(actual);\n    if (actualIndex !== -1) {\n      if (actualIndex === memos.expected.indexOf(expected)) {\n        return true;\n      }\n    }\n\n    memos.actual.push(actual);\n    memos.expected.push(expected);\n\n    return objEquiv(actual, expected, strict, memos);\n  }\n}\n\nfunction isArguments(object) {\n  return Object.prototype.toString.call(object) == '[object Arguments]';\n}\n\nfunction objEquiv(a, b, strict, actualVisitedObjects) {\n  if (a === null || a === undefined || b === null || b === undefined)\n    return false;\n  // if one is a primitive, the other must be same\n  if (util.isPrimitive(a) || util.isPrimitive(b))\n    return a === b;\n  if (strict && Object.getPrototypeOf(a) !== Object.getPrototypeOf(b))\n    return false;\n  var aIsArgs = isArguments(a);\n  var bIsArgs = isArguments(b);\n  if ((aIsArgs && !bIsArgs) || (!aIsArgs && bIsArgs))\n    return false;\n  if (aIsArgs) {\n    a = pSlice.call(a);\n    b = pSlice.call(b);\n    return _deepEqual(a, b, strict);\n  }\n  var ka = objectKeys(a);\n  var kb = objectKeys(b);\n  var key, i;\n  // having the same number of owned properties (keys incorporates\n  // hasOwnProperty)\n  if (ka.length !== kb.length)\n    return false;\n  //the same set of keys (although not necessarily the same order),\n  ka.sort();\n  kb.sort();\n  //~~~cheap key test\n  for (i = ka.length - 1; i >= 0; i--) {\n    if (ka[i] !== kb[i])\n      return false;\n  }\n  //equivalent values for every corresponding key, and\n  //~~~possibly expensive deep test\n  for (i = ka.length - 1; i >= 0; i--) {\n    key = ka[i];\n    if (!_deepEqual(a[key], b[key], strict, actualVisitedObjects))\n      return false;\n  }\n  return true;\n}\n\n// 8. The non-equivalence assertion tests for any deep inequality.\n// assert.notDeepEqual(actual, expected, message_opt);\n\nassert.notDeepEqual = function notDeepEqual(actual, expected, message) {\n  if (_deepEqual(actual, expected, false)) {\n    fail(actual, expected, message, 'notDeepEqual', assert.notDeepEqual);\n  }\n};\n\nassert.notDeepStrictEqual = notDeepStrictEqual;\nfunction notDeepStrictEqual(actual, expected, message) {\n  if (_deepEqual(actual, expected, true)) {\n    fail(actual, expected, message, 'notDeepStrictEqual', notDeepStrictEqual);\n  }\n}\n\n\n// 9. The strict equality assertion tests strict equality, as determined by ===.\n// assert.strictEqual(actual, expected, message_opt);\n\nassert.strictEqual = function strictEqual(actual, expected, message) {\n  if (actual !== expected) {\n    fail(actual, expected, message, '===', assert.strictEqual);\n  }\n};\n\n// 10. The strict non-equality assertion tests for strict inequality, as\n// determined by !==.  assert.notStrictEqual(actual, expected, message_opt);\n\nassert.notStrictEqual = function notStrictEqual(actual, expected, message) {\n  if (actual === expected) {\n    fail(actual, expected, message, '!==', assert.notStrictEqual);\n  }\n};\n\nfunction expectedException(actual, expected) {\n  if (!actual || !expected) {\n    return false;\n  }\n\n  if (Object.prototype.toString.call(expected) == '[object RegExp]') {\n    return expected.test(actual);\n  }\n\n  try {\n    if (actual instanceof expected) {\n      return true;\n    }\n  } catch (e) {\n    // Ignore.  The instanceof check doesn't work for arrow functions.\n  }\n\n  if (Error.isPrototypeOf(expected)) {\n    return false;\n  }\n\n  return expected.call({}, actual) === true;\n}\n\nfunction _tryBlock(block) {\n  var error;\n  try {\n    block();\n  } catch (e) {\n    error = e;\n  }\n  return error;\n}\n\nfunction _throws(shouldThrow, block, expected, message) {\n  var actual;\n\n  if (typeof block !== 'function') {\n    throw new TypeError('\"block\" argument must be a function');\n  }\n\n  if (typeof expected === 'string') {\n    message = expected;\n    expected = null;\n  }\n\n  actual = _tryBlock(block);\n\n  message = (expected && expected.name ? ' (' + expected.name + ').' : '.') +\n            (message ? ' ' + message : '.');\n\n  if (shouldThrow && !actual) {\n    fail(actual, expected, 'Missing expected exception' + message);\n  }\n\n  var userProvidedMessage = typeof message === 'string';\n  var isUnwantedException = !shouldThrow && util.isError(actual);\n  var isUnexpectedException = !shouldThrow && actual && !expected;\n\n  if ((isUnwantedException &&\n      userProvidedMessage &&\n      expectedException(actual, expected)) ||\n      isUnexpectedException) {\n    fail(actual, expected, 'Got unwanted exception' + message);\n  }\n\n  if ((shouldThrow && actual && expected &&\n      !expectedException(actual, expected)) || (!shouldThrow && actual)) {\n    throw actual;\n  }\n}\n\n// 11. Expected to throw an error:\n// assert.throws(block, Error_opt, message_opt);\n\nassert.throws = function(block, /*optional*/error, /*optional*/message) {\n  _throws(true, block, error, message);\n};\n\n// EXTENSION! This is annoying to write outside this module.\nassert.doesNotThrow = function(block, /*optional*/error, /*optional*/message) {\n  _throws(false, block, error, message);\n};\n\nassert.ifError = function(err) { if (err) throw err; };\n\n// Expose a strict only variant of assert\nfunction strict(value, message) {\n  if (!value) fail(value, true, message, '==', strict);\n}\nassert.strict = objectAssign(strict, assert, {\n  equal: assert.strictEqual,\n  deepEqual: assert.deepStrictEqual,\n  notEqual: assert.notStrictEqual,\n  notDeepEqual: assert.notDeepStrictEqual\n});\nassert.strict.strict = assert.strict;\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    if (hasOwn.call(obj, key)) keys.push(key);\n  }\n  return keys;\n};\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/assert/assert.js?");

/***/ }),

/***/ "./node_modules/base64-js/index.js":
/*!*****************************************!*\
  !*** ./node_modules/base64-js/index.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nexports.byteLength = byteLength\nexports.toByteArray = toByteArray\nexports.fromByteArray = fromByteArray\n\nvar lookup = []\nvar revLookup = []\nvar Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array\n\nvar code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\nfor (var i = 0, len = code.length; i < len; ++i) {\n  lookup[i] = code[i]\n  revLookup[code.charCodeAt(i)] = i\n}\n\n// Support decoding URL-safe base64 strings, as Node.js does.\n// See: https://en.wikipedia.org/wiki/Base64#URL_applications\nrevLookup['-'.charCodeAt(0)] = 62\nrevLookup['_'.charCodeAt(0)] = 63\n\nfunction getLens (b64) {\n  var len = b64.length\n\n  if (len % 4 > 0) {\n    throw new Error('Invalid string. Length must be a multiple of 4')\n  }\n\n  // Trim off extra bytes after placeholder bytes are found\n  // See: https://github.com/beatgammit/base64-js/issues/42\n  var validLen = b64.indexOf('=')\n  if (validLen === -1) validLen = len\n\n  var placeHoldersLen = validLen === len\n    ? 0\n    : 4 - (validLen % 4)\n\n  return [validLen, placeHoldersLen]\n}\n\n// base64 is 4/3 + up to two characters of the original data\nfunction byteLength (b64) {\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction _byteLength (b64, validLen, placeHoldersLen) {\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction toByteArray (b64) {\n  var tmp\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n\n  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))\n\n  var curByte = 0\n\n  // if there are placeholders, only get up to the last complete 4 chars\n  var len = placeHoldersLen > 0\n    ? validLen - 4\n    : validLen\n\n  var i\n  for (i = 0; i < len; i += 4) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 18) |\n      (revLookup[b64.charCodeAt(i + 1)] << 12) |\n      (revLookup[b64.charCodeAt(i + 2)] << 6) |\n      revLookup[b64.charCodeAt(i + 3)]\n    arr[curByte++] = (tmp >> 16) & 0xFF\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 2) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 2) |\n      (revLookup[b64.charCodeAt(i + 1)] >> 4)\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 1) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 10) |\n      (revLookup[b64.charCodeAt(i + 1)] << 4) |\n      (revLookup[b64.charCodeAt(i + 2)] >> 2)\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  return arr\n}\n\nfunction tripletToBase64 (num) {\n  return lookup[num >> 18 & 0x3F] +\n    lookup[num >> 12 & 0x3F] +\n    lookup[num >> 6 & 0x3F] +\n    lookup[num & 0x3F]\n}\n\nfunction encodeChunk (uint8, start, end) {\n  var tmp\n  var output = []\n  for (var i = start; i < end; i += 3) {\n    tmp =\n      ((uint8[i] << 16) & 0xFF0000) +\n      ((uint8[i + 1] << 8) & 0xFF00) +\n      (uint8[i + 2] & 0xFF)\n    output.push(tripletToBase64(tmp))\n  }\n  return output.join('')\n}\n\nfunction fromByteArray (uint8) {\n  var tmp\n  var len = uint8.length\n  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes\n  var parts = []\n  var maxChunkLength = 16383 // must be multiple of 3\n\n  // go through the array every three bytes, we'll deal with trailing stuff later\n  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {\n    parts.push(encodeChunk(\n      uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)\n    ))\n  }\n\n  // pad the end with zeros, but make sure to not forget the extra bytes\n  if (extraBytes === 1) {\n    tmp = uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 2] +\n      lookup[(tmp << 4) & 0x3F] +\n      '=='\n    )\n  } else if (extraBytes === 2) {\n    tmp = (uint8[len - 2] << 8) + uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 10] +\n      lookup[(tmp >> 4) & 0x3F] +\n      lookup[(tmp << 2) & 0x3F] +\n      '='\n    )\n  }\n\n  return parts.join('')\n}\n\n\n//# sourceURL=webpack:///./node_modules/base64-js/index.js?");

/***/ }),

/***/ "./node_modules/browserify-zlib/lib/binding.js":
/*!*****************************************************!*\
  !*** ./node_modules/browserify-zlib/lib/binding.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(Buffer, process) {\n/* eslint camelcase: \"off\" */\n\nvar assert = __webpack_require__(/*! assert */ \"./node_modules/assert/assert.js\");\n\nvar Zstream = __webpack_require__(/*! pako/lib/zlib/zstream */ \"./node_modules/pako/lib/zlib/zstream.js\");\nvar zlib_deflate = __webpack_require__(/*! pako/lib/zlib/deflate.js */ \"./node_modules/pako/lib/zlib/deflate.js\");\nvar zlib_inflate = __webpack_require__(/*! pako/lib/zlib/inflate.js */ \"./node_modules/pako/lib/zlib/inflate.js\");\nvar constants = __webpack_require__(/*! pako/lib/zlib/constants */ \"./node_modules/pako/lib/zlib/constants.js\");\n\nfor (var key in constants) {\n  exports[key] = constants[key];\n}\n\n// zlib modes\nexports.NONE = 0;\nexports.DEFLATE = 1;\nexports.INFLATE = 2;\nexports.GZIP = 3;\nexports.GUNZIP = 4;\nexports.DEFLATERAW = 5;\nexports.INFLATERAW = 6;\nexports.UNZIP = 7;\n\nvar GZIP_HEADER_ID1 = 0x1f;\nvar GZIP_HEADER_ID2 = 0x8b;\n\n/**\n * Emulate Node's zlib C++ layer for use by the JS layer in index.js\n */\nfunction Zlib(mode) {\n  if (typeof mode !== 'number' || mode < exports.DEFLATE || mode > exports.UNZIP) {\n    throw new TypeError('Bad argument');\n  }\n\n  this.dictionary = null;\n  this.err = 0;\n  this.flush = 0;\n  this.init_done = false;\n  this.level = 0;\n  this.memLevel = 0;\n  this.mode = mode;\n  this.strategy = 0;\n  this.windowBits = 0;\n  this.write_in_progress = false;\n  this.pending_close = false;\n  this.gzip_id_bytes_read = 0;\n}\n\nZlib.prototype.close = function () {\n  if (this.write_in_progress) {\n    this.pending_close = true;\n    return;\n  }\n\n  this.pending_close = false;\n\n  assert(this.init_done, 'close before init');\n  assert(this.mode <= exports.UNZIP);\n\n  if (this.mode === exports.DEFLATE || this.mode === exports.GZIP || this.mode === exports.DEFLATERAW) {\n    zlib_deflate.deflateEnd(this.strm);\n  } else if (this.mode === exports.INFLATE || this.mode === exports.GUNZIP || this.mode === exports.INFLATERAW || this.mode === exports.UNZIP) {\n    zlib_inflate.inflateEnd(this.strm);\n  }\n\n  this.mode = exports.NONE;\n\n  this.dictionary = null;\n};\n\nZlib.prototype.write = function (flush, input, in_off, in_len, out, out_off, out_len) {\n  return this._write(true, flush, input, in_off, in_len, out, out_off, out_len);\n};\n\nZlib.prototype.writeSync = function (flush, input, in_off, in_len, out, out_off, out_len) {\n  return this._write(false, flush, input, in_off, in_len, out, out_off, out_len);\n};\n\nZlib.prototype._write = function (async, flush, input, in_off, in_len, out, out_off, out_len) {\n  assert.equal(arguments.length, 8);\n\n  assert(this.init_done, 'write before init');\n  assert(this.mode !== exports.NONE, 'already finalized');\n  assert.equal(false, this.write_in_progress, 'write already in progress');\n  assert.equal(false, this.pending_close, 'close is pending');\n\n  this.write_in_progress = true;\n\n  assert.equal(false, flush === undefined, 'must provide flush value');\n\n  this.write_in_progress = true;\n\n  if (flush !== exports.Z_NO_FLUSH && flush !== exports.Z_PARTIAL_FLUSH && flush !== exports.Z_SYNC_FLUSH && flush !== exports.Z_FULL_FLUSH && flush !== exports.Z_FINISH && flush !== exports.Z_BLOCK) {\n    throw new Error('Invalid flush value');\n  }\n\n  if (input == null) {\n    input = Buffer.alloc(0);\n    in_len = 0;\n    in_off = 0;\n  }\n\n  this.strm.avail_in = in_len;\n  this.strm.input = input;\n  this.strm.next_in = in_off;\n  this.strm.avail_out = out_len;\n  this.strm.output = out;\n  this.strm.next_out = out_off;\n  this.flush = flush;\n\n  if (!async) {\n    // sync version\n    this._process();\n\n    if (this._checkError()) {\n      return this._afterSync();\n    }\n    return;\n  }\n\n  // async version\n  var self = this;\n  process.nextTick(function () {\n    self._process();\n    self._after();\n  });\n\n  return this;\n};\n\nZlib.prototype._afterSync = function () {\n  var avail_out = this.strm.avail_out;\n  var avail_in = this.strm.avail_in;\n\n  this.write_in_progress = false;\n\n  return [avail_in, avail_out];\n};\n\nZlib.prototype._process = function () {\n  var next_expected_header_byte = null;\n\n  // If the avail_out is left at 0, then it means that it ran out\n  // of room.  If there was avail_out left over, then it means\n  // that all of the input was consumed.\n  switch (this.mode) {\n    case exports.DEFLATE:\n    case exports.GZIP:\n    case exports.DEFLATERAW:\n      this.err = zlib_deflate.deflate(this.strm, this.flush);\n      break;\n    case exports.UNZIP:\n      if (this.strm.avail_in > 0) {\n        next_expected_header_byte = this.strm.next_in;\n      }\n\n      switch (this.gzip_id_bytes_read) {\n        case 0:\n          if (next_expected_header_byte === null) {\n            break;\n          }\n\n          if (this.strm.input[next_expected_header_byte] === GZIP_HEADER_ID1) {\n            this.gzip_id_bytes_read = 1;\n            next_expected_header_byte++;\n\n            if (this.strm.avail_in === 1) {\n              // The only available byte was already read.\n              break;\n            }\n          } else {\n            this.mode = exports.INFLATE;\n            break;\n          }\n\n        // fallthrough\n        case 1:\n          if (next_expected_header_byte === null) {\n            break;\n          }\n\n          if (this.strm.input[next_expected_header_byte] === GZIP_HEADER_ID2) {\n            this.gzip_id_bytes_read = 2;\n            this.mode = exports.GUNZIP;\n          } else {\n            // There is no actual difference between INFLATE and INFLATERAW\n            // (after initialization).\n            this.mode = exports.INFLATE;\n          }\n\n          break;\n        default:\n          throw new Error('invalid number of gzip magic number bytes read');\n      }\n\n    // fallthrough\n    case exports.INFLATE:\n    case exports.GUNZIP:\n    case exports.INFLATERAW:\n      this.err = zlib_inflate.inflate(this.strm, this.flush\n\n      // If data was encoded with dictionary\n      );if (this.err === exports.Z_NEED_DICT && this.dictionary) {\n        // Load it\n        this.err = zlib_inflate.inflateSetDictionary(this.strm, this.dictionary);\n        if (this.err === exports.Z_OK) {\n          // And try to decode again\n          this.err = zlib_inflate.inflate(this.strm, this.flush);\n        } else if (this.err === exports.Z_DATA_ERROR) {\n          // Both inflateSetDictionary() and inflate() return Z_DATA_ERROR.\n          // Make it possible for After() to tell a bad dictionary from bad\n          // input.\n          this.err = exports.Z_NEED_DICT;\n        }\n      }\n      while (this.strm.avail_in > 0 && this.mode === exports.GUNZIP && this.err === exports.Z_STREAM_END && this.strm.next_in[0] !== 0x00) {\n        // Bytes remain in input buffer. Perhaps this is another compressed\n        // member in the same archive, or just trailing garbage.\n        // Trailing zero bytes are okay, though, since they are frequently\n        // used for padding.\n\n        this.reset();\n        this.err = zlib_inflate.inflate(this.strm, this.flush);\n      }\n      break;\n    default:\n      throw new Error('Unknown mode ' + this.mode);\n  }\n};\n\nZlib.prototype._checkError = function () {\n  // Acceptable error states depend on the type of zlib stream.\n  switch (this.err) {\n    case exports.Z_OK:\n    case exports.Z_BUF_ERROR:\n      if (this.strm.avail_out !== 0 && this.flush === exports.Z_FINISH) {\n        this._error('unexpected end of file');\n        return false;\n      }\n      break;\n    case exports.Z_STREAM_END:\n      // normal statuses, not fatal\n      break;\n    case exports.Z_NEED_DICT:\n      if (this.dictionary == null) {\n        this._error('Missing dictionary');\n      } else {\n        this._error('Bad dictionary');\n      }\n      return false;\n    default:\n      // something else.\n      this._error('Zlib error');\n      return false;\n  }\n\n  return true;\n};\n\nZlib.prototype._after = function () {\n  if (!this._checkError()) {\n    return;\n  }\n\n  var avail_out = this.strm.avail_out;\n  var avail_in = this.strm.avail_in;\n\n  this.write_in_progress = false;\n\n  // call the write() cb\n  this.callback(avail_in, avail_out);\n\n  if (this.pending_close) {\n    this.close();\n  }\n};\n\nZlib.prototype._error = function (message) {\n  if (this.strm.msg) {\n    message = this.strm.msg;\n  }\n  this.onerror(message, this.err\n\n  // no hope of rescue.\n  );this.write_in_progress = false;\n  if (this.pending_close) {\n    this.close();\n  }\n};\n\nZlib.prototype.init = function (windowBits, level, memLevel, strategy, dictionary) {\n  assert(arguments.length === 4 || arguments.length === 5, 'init(windowBits, level, memLevel, strategy, [dictionary])');\n\n  assert(windowBits >= 8 && windowBits <= 15, 'invalid windowBits');\n  assert(level >= -1 && level <= 9, 'invalid compression level');\n\n  assert(memLevel >= 1 && memLevel <= 9, 'invalid memlevel');\n\n  assert(strategy === exports.Z_FILTERED || strategy === exports.Z_HUFFMAN_ONLY || strategy === exports.Z_RLE || strategy === exports.Z_FIXED || strategy === exports.Z_DEFAULT_STRATEGY, 'invalid strategy');\n\n  this._init(level, windowBits, memLevel, strategy, dictionary);\n  this._setDictionary();\n};\n\nZlib.prototype.params = function () {\n  throw new Error('deflateParams Not supported');\n};\n\nZlib.prototype.reset = function () {\n  this._reset();\n  this._setDictionary();\n};\n\nZlib.prototype._init = function (level, windowBits, memLevel, strategy, dictionary) {\n  this.level = level;\n  this.windowBits = windowBits;\n  this.memLevel = memLevel;\n  this.strategy = strategy;\n\n  this.flush = exports.Z_NO_FLUSH;\n\n  this.err = exports.Z_OK;\n\n  if (this.mode === exports.GZIP || this.mode === exports.GUNZIP) {\n    this.windowBits += 16;\n  }\n\n  if (this.mode === exports.UNZIP) {\n    this.windowBits += 32;\n  }\n\n  if (this.mode === exports.DEFLATERAW || this.mode === exports.INFLATERAW) {\n    this.windowBits = -1 * this.windowBits;\n  }\n\n  this.strm = new Zstream();\n\n  switch (this.mode) {\n    case exports.DEFLATE:\n    case exports.GZIP:\n    case exports.DEFLATERAW:\n      this.err = zlib_deflate.deflateInit2(this.strm, this.level, exports.Z_DEFLATED, this.windowBits, this.memLevel, this.strategy);\n      break;\n    case exports.INFLATE:\n    case exports.GUNZIP:\n    case exports.INFLATERAW:\n    case exports.UNZIP:\n      this.err = zlib_inflate.inflateInit2(this.strm, this.windowBits);\n      break;\n    default:\n      throw new Error('Unknown mode ' + this.mode);\n  }\n\n  if (this.err !== exports.Z_OK) {\n    this._error('Init error');\n  }\n\n  this.dictionary = dictionary;\n\n  this.write_in_progress = false;\n  this.init_done = true;\n};\n\nZlib.prototype._setDictionary = function () {\n  if (this.dictionary == null) {\n    return;\n  }\n\n  this.err = exports.Z_OK;\n\n  switch (this.mode) {\n    case exports.DEFLATE:\n    case exports.DEFLATERAW:\n      this.err = zlib_deflate.deflateSetDictionary(this.strm, this.dictionary);\n      break;\n    default:\n      break;\n  }\n\n  if (this.err !== exports.Z_OK) {\n    this._error('Failed to set dictionary');\n  }\n};\n\nZlib.prototype._reset = function () {\n  this.err = exports.Z_OK;\n\n  switch (this.mode) {\n    case exports.DEFLATE:\n    case exports.DEFLATERAW:\n    case exports.GZIP:\n      this.err = zlib_deflate.deflateReset(this.strm);\n      break;\n    case exports.INFLATE:\n    case exports.INFLATERAW:\n    case exports.GUNZIP:\n      this.err = zlib_inflate.inflateReset(this.strm);\n      break;\n    default:\n      break;\n  }\n\n  if (this.err !== exports.Z_OK) {\n    this._error('Failed to reset stream');\n  }\n};\n\nexports.Zlib = Zlib;\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer, __webpack_require__(/*! ./../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/browserify-zlib/lib/binding.js?");

/***/ }),

/***/ "./node_modules/browserify-zlib/lib/index.js":
/*!***************************************************!*\
  !*** ./node_modules/browserify-zlib/lib/index.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\n\nvar Buffer = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\").Buffer;\nvar Transform = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\").Transform;\nvar binding = __webpack_require__(/*! ./binding */ \"./node_modules/browserify-zlib/lib/binding.js\");\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\");\nvar assert = __webpack_require__(/*! assert */ \"./node_modules/assert/assert.js\").ok;\nvar kMaxLength = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\").kMaxLength;\nvar kRangeErrorMessage = 'Cannot create final Buffer. It would be larger ' + 'than 0x' + kMaxLength.toString(16) + ' bytes';\n\n// zlib doesn't provide these, so kludge them in following the same\n// const naming scheme zlib uses.\nbinding.Z_MIN_WINDOWBITS = 8;\nbinding.Z_MAX_WINDOWBITS = 15;\nbinding.Z_DEFAULT_WINDOWBITS = 15;\n\n// fewer than 64 bytes per chunk is stupid.\n// technically it could work with as few as 8, but even 64 bytes\n// is absurdly low.  Usually a MB or more is best.\nbinding.Z_MIN_CHUNK = 64;\nbinding.Z_MAX_CHUNK = Infinity;\nbinding.Z_DEFAULT_CHUNK = 16 * 1024;\n\nbinding.Z_MIN_MEMLEVEL = 1;\nbinding.Z_MAX_MEMLEVEL = 9;\nbinding.Z_DEFAULT_MEMLEVEL = 8;\n\nbinding.Z_MIN_LEVEL = -1;\nbinding.Z_MAX_LEVEL = 9;\nbinding.Z_DEFAULT_LEVEL = binding.Z_DEFAULT_COMPRESSION;\n\n// expose all the zlib constants\nvar bkeys = Object.keys(binding);\nfor (var bk = 0; bk < bkeys.length; bk++) {\n  var bkey = bkeys[bk];\n  if (bkey.match(/^Z/)) {\n    Object.defineProperty(exports, bkey, {\n      enumerable: true, value: binding[bkey], writable: false\n    });\n  }\n}\n\n// translation table for return codes.\nvar codes = {\n  Z_OK: binding.Z_OK,\n  Z_STREAM_END: binding.Z_STREAM_END,\n  Z_NEED_DICT: binding.Z_NEED_DICT,\n  Z_ERRNO: binding.Z_ERRNO,\n  Z_STREAM_ERROR: binding.Z_STREAM_ERROR,\n  Z_DATA_ERROR: binding.Z_DATA_ERROR,\n  Z_MEM_ERROR: binding.Z_MEM_ERROR,\n  Z_BUF_ERROR: binding.Z_BUF_ERROR,\n  Z_VERSION_ERROR: binding.Z_VERSION_ERROR\n};\n\nvar ckeys = Object.keys(codes);\nfor (var ck = 0; ck < ckeys.length; ck++) {\n  var ckey = ckeys[ck];\n  codes[codes[ckey]] = ckey;\n}\n\nObject.defineProperty(exports, 'codes', {\n  enumerable: true, value: Object.freeze(codes), writable: false\n});\n\nexports.Deflate = Deflate;\nexports.Inflate = Inflate;\nexports.Gzip = Gzip;\nexports.Gunzip = Gunzip;\nexports.DeflateRaw = DeflateRaw;\nexports.InflateRaw = InflateRaw;\nexports.Unzip = Unzip;\n\nexports.createDeflate = function (o) {\n  return new Deflate(o);\n};\n\nexports.createInflate = function (o) {\n  return new Inflate(o);\n};\n\nexports.createDeflateRaw = function (o) {\n  return new DeflateRaw(o);\n};\n\nexports.createInflateRaw = function (o) {\n  return new InflateRaw(o);\n};\n\nexports.createGzip = function (o) {\n  return new Gzip(o);\n};\n\nexports.createGunzip = function (o) {\n  return new Gunzip(o);\n};\n\nexports.createUnzip = function (o) {\n  return new Unzip(o);\n};\n\n// Convenience methods.\n// compress/decompress a string or buffer in one step.\nexports.deflate = function (buffer, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return zlibBuffer(new Deflate(opts), buffer, callback);\n};\n\nexports.deflateSync = function (buffer, opts) {\n  return zlibBufferSync(new Deflate(opts), buffer);\n};\n\nexports.gzip = function (buffer, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return zlibBuffer(new Gzip(opts), buffer, callback);\n};\n\nexports.gzipSync = function (buffer, opts) {\n  return zlibBufferSync(new Gzip(opts), buffer);\n};\n\nexports.deflateRaw = function (buffer, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return zlibBuffer(new DeflateRaw(opts), buffer, callback);\n};\n\nexports.deflateRawSync = function (buffer, opts) {\n  return zlibBufferSync(new DeflateRaw(opts), buffer);\n};\n\nexports.unzip = function (buffer, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return zlibBuffer(new Unzip(opts), buffer, callback);\n};\n\nexports.unzipSync = function (buffer, opts) {\n  return zlibBufferSync(new Unzip(opts), buffer);\n};\n\nexports.inflate = function (buffer, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return zlibBuffer(new Inflate(opts), buffer, callback);\n};\n\nexports.inflateSync = function (buffer, opts) {\n  return zlibBufferSync(new Inflate(opts), buffer);\n};\n\nexports.gunzip = function (buffer, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return zlibBuffer(new Gunzip(opts), buffer, callback);\n};\n\nexports.gunzipSync = function (buffer, opts) {\n  return zlibBufferSync(new Gunzip(opts), buffer);\n};\n\nexports.inflateRaw = function (buffer, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return zlibBuffer(new InflateRaw(opts), buffer, callback);\n};\n\nexports.inflateRawSync = function (buffer, opts) {\n  return zlibBufferSync(new InflateRaw(opts), buffer);\n};\n\nfunction zlibBuffer(engine, buffer, callback) {\n  var buffers = [];\n  var nread = 0;\n\n  engine.on('error', onError);\n  engine.on('end', onEnd);\n\n  engine.end(buffer);\n  flow();\n\n  function flow() {\n    var chunk;\n    while (null !== (chunk = engine.read())) {\n      buffers.push(chunk);\n      nread += chunk.length;\n    }\n    engine.once('readable', flow);\n  }\n\n  function onError(err) {\n    engine.removeListener('end', onEnd);\n    engine.removeListener('readable', flow);\n    callback(err);\n  }\n\n  function onEnd() {\n    var buf;\n    var err = null;\n\n    if (nread >= kMaxLength) {\n      err = new RangeError(kRangeErrorMessage);\n    } else {\n      buf = Buffer.concat(buffers, nread);\n    }\n\n    buffers = [];\n    engine.close();\n    callback(err, buf);\n  }\n}\n\nfunction zlibBufferSync(engine, buffer) {\n  if (typeof buffer === 'string') buffer = Buffer.from(buffer);\n\n  if (!Buffer.isBuffer(buffer)) throw new TypeError('Not a string or buffer');\n\n  var flushFlag = engine._finishFlushFlag;\n\n  return engine._processChunk(buffer, flushFlag);\n}\n\n// generic zlib\n// minimal 2-byte header\nfunction Deflate(opts) {\n  if (!(this instanceof Deflate)) return new Deflate(opts);\n  Zlib.call(this, opts, binding.DEFLATE);\n}\n\nfunction Inflate(opts) {\n  if (!(this instanceof Inflate)) return new Inflate(opts);\n  Zlib.call(this, opts, binding.INFLATE);\n}\n\n// gzip - bigger header, same deflate compression\nfunction Gzip(opts) {\n  if (!(this instanceof Gzip)) return new Gzip(opts);\n  Zlib.call(this, opts, binding.GZIP);\n}\n\nfunction Gunzip(opts) {\n  if (!(this instanceof Gunzip)) return new Gunzip(opts);\n  Zlib.call(this, opts, binding.GUNZIP);\n}\n\n// raw - no header\nfunction DeflateRaw(opts) {\n  if (!(this instanceof DeflateRaw)) return new DeflateRaw(opts);\n  Zlib.call(this, opts, binding.DEFLATERAW);\n}\n\nfunction InflateRaw(opts) {\n  if (!(this instanceof InflateRaw)) return new InflateRaw(opts);\n  Zlib.call(this, opts, binding.INFLATERAW);\n}\n\n// auto-detect header.\nfunction Unzip(opts) {\n  if (!(this instanceof Unzip)) return new Unzip(opts);\n  Zlib.call(this, opts, binding.UNZIP);\n}\n\nfunction isValidFlushFlag(flag) {\n  return flag === binding.Z_NO_FLUSH || flag === binding.Z_PARTIAL_FLUSH || flag === binding.Z_SYNC_FLUSH || flag === binding.Z_FULL_FLUSH || flag === binding.Z_FINISH || flag === binding.Z_BLOCK;\n}\n\n// the Zlib class they all inherit from\n// This thing manages the queue of requests, and returns\n// true or false if there is anything in the queue when\n// you call the .write() method.\n\nfunction Zlib(opts, mode) {\n  var _this = this;\n\n  this._opts = opts = opts || {};\n  this._chunkSize = opts.chunkSize || exports.Z_DEFAULT_CHUNK;\n\n  Transform.call(this, opts);\n\n  if (opts.flush && !isValidFlushFlag(opts.flush)) {\n    throw new Error('Invalid flush flag: ' + opts.flush);\n  }\n  if (opts.finishFlush && !isValidFlushFlag(opts.finishFlush)) {\n    throw new Error('Invalid flush flag: ' + opts.finishFlush);\n  }\n\n  this._flushFlag = opts.flush || binding.Z_NO_FLUSH;\n  this._finishFlushFlag = typeof opts.finishFlush !== 'undefined' ? opts.finishFlush : binding.Z_FINISH;\n\n  if (opts.chunkSize) {\n    if (opts.chunkSize < exports.Z_MIN_CHUNK || opts.chunkSize > exports.Z_MAX_CHUNK) {\n      throw new Error('Invalid chunk size: ' + opts.chunkSize);\n    }\n  }\n\n  if (opts.windowBits) {\n    if (opts.windowBits < exports.Z_MIN_WINDOWBITS || opts.windowBits > exports.Z_MAX_WINDOWBITS) {\n      throw new Error('Invalid windowBits: ' + opts.windowBits);\n    }\n  }\n\n  if (opts.level) {\n    if (opts.level < exports.Z_MIN_LEVEL || opts.level > exports.Z_MAX_LEVEL) {\n      throw new Error('Invalid compression level: ' + opts.level);\n    }\n  }\n\n  if (opts.memLevel) {\n    if (opts.memLevel < exports.Z_MIN_MEMLEVEL || opts.memLevel > exports.Z_MAX_MEMLEVEL) {\n      throw new Error('Invalid memLevel: ' + opts.memLevel);\n    }\n  }\n\n  if (opts.strategy) {\n    if (opts.strategy != exports.Z_FILTERED && opts.strategy != exports.Z_HUFFMAN_ONLY && opts.strategy != exports.Z_RLE && opts.strategy != exports.Z_FIXED && opts.strategy != exports.Z_DEFAULT_STRATEGY) {\n      throw new Error('Invalid strategy: ' + opts.strategy);\n    }\n  }\n\n  if (opts.dictionary) {\n    if (!Buffer.isBuffer(opts.dictionary)) {\n      throw new Error('Invalid dictionary: it should be a Buffer instance');\n    }\n  }\n\n  this._handle = new binding.Zlib(mode);\n\n  var self = this;\n  this._hadError = false;\n  this._handle.onerror = function (message, errno) {\n    // there is no way to cleanly recover.\n    // continuing only obscures problems.\n    _close(self);\n    self._hadError = true;\n\n    var error = new Error(message);\n    error.errno = errno;\n    error.code = exports.codes[errno];\n    self.emit('error', error);\n  };\n\n  var level = exports.Z_DEFAULT_COMPRESSION;\n  if (typeof opts.level === 'number') level = opts.level;\n\n  var strategy = exports.Z_DEFAULT_STRATEGY;\n  if (typeof opts.strategy === 'number') strategy = opts.strategy;\n\n  this._handle.init(opts.windowBits || exports.Z_DEFAULT_WINDOWBITS, level, opts.memLevel || exports.Z_DEFAULT_MEMLEVEL, strategy, opts.dictionary);\n\n  this._buffer = Buffer.allocUnsafe(this._chunkSize);\n  this._offset = 0;\n  this._level = level;\n  this._strategy = strategy;\n\n  this.once('end', this.close);\n\n  Object.defineProperty(this, '_closed', {\n    get: function () {\n      return !_this._handle;\n    },\n    configurable: true,\n    enumerable: true\n  });\n}\n\nutil.inherits(Zlib, Transform);\n\nZlib.prototype.params = function (level, strategy, callback) {\n  if (level < exports.Z_MIN_LEVEL || level > exports.Z_MAX_LEVEL) {\n    throw new RangeError('Invalid compression level: ' + level);\n  }\n  if (strategy != exports.Z_FILTERED && strategy != exports.Z_HUFFMAN_ONLY && strategy != exports.Z_RLE && strategy != exports.Z_FIXED && strategy != exports.Z_DEFAULT_STRATEGY) {\n    throw new TypeError('Invalid strategy: ' + strategy);\n  }\n\n  if (this._level !== level || this._strategy !== strategy) {\n    var self = this;\n    this.flush(binding.Z_SYNC_FLUSH, function () {\n      assert(self._handle, 'zlib binding closed');\n      self._handle.params(level, strategy);\n      if (!self._hadError) {\n        self._level = level;\n        self._strategy = strategy;\n        if (callback) callback();\n      }\n    });\n  } else {\n    process.nextTick(callback);\n  }\n};\n\nZlib.prototype.reset = function () {\n  assert(this._handle, 'zlib binding closed');\n  return this._handle.reset();\n};\n\n// This is the _flush function called by the transform class,\n// internally, when the last chunk has been written.\nZlib.prototype._flush = function (callback) {\n  this._transform(Buffer.alloc(0), '', callback);\n};\n\nZlib.prototype.flush = function (kind, callback) {\n  var _this2 = this;\n\n  var ws = this._writableState;\n\n  if (typeof kind === 'function' || kind === undefined && !callback) {\n    callback = kind;\n    kind = binding.Z_FULL_FLUSH;\n  }\n\n  if (ws.ended) {\n    if (callback) process.nextTick(callback);\n  } else if (ws.ending) {\n    if (callback) this.once('end', callback);\n  } else if (ws.needDrain) {\n    if (callback) {\n      this.once('drain', function () {\n        return _this2.flush(kind, callback);\n      });\n    }\n  } else {\n    this._flushFlag = kind;\n    this.write(Buffer.alloc(0), '', callback);\n  }\n};\n\nZlib.prototype.close = function (callback) {\n  _close(this, callback);\n  process.nextTick(emitCloseNT, this);\n};\n\nfunction _close(engine, callback) {\n  if (callback) process.nextTick(callback);\n\n  // Caller may invoke .close after a zlib error (which will null _handle).\n  if (!engine._handle) return;\n\n  engine._handle.close();\n  engine._handle = null;\n}\n\nfunction emitCloseNT(self) {\n  self.emit('close');\n}\n\nZlib.prototype._transform = function (chunk, encoding, cb) {\n  var flushFlag;\n  var ws = this._writableState;\n  var ending = ws.ending || ws.ended;\n  var last = ending && (!chunk || ws.length === chunk.length);\n\n  if (chunk !== null && !Buffer.isBuffer(chunk)) return cb(new Error('invalid input'));\n\n  if (!this._handle) return cb(new Error('zlib binding closed'));\n\n  // If it's the last chunk, or a final flush, we use the Z_FINISH flush flag\n  // (or whatever flag was provided using opts.finishFlush).\n  // If it's explicitly flushing at some other time, then we use\n  // Z_FULL_FLUSH. Otherwise, use Z_NO_FLUSH for maximum compression\n  // goodness.\n  if (last) flushFlag = this._finishFlushFlag;else {\n    flushFlag = this._flushFlag;\n    // once we've flushed the last of the queue, stop flushing and\n    // go back to the normal behavior.\n    if (chunk.length >= ws.length) {\n      this._flushFlag = this._opts.flush || binding.Z_NO_FLUSH;\n    }\n  }\n\n  this._processChunk(chunk, flushFlag, cb);\n};\n\nZlib.prototype._processChunk = function (chunk, flushFlag, cb) {\n  var availInBefore = chunk && chunk.length;\n  var availOutBefore = this._chunkSize - this._offset;\n  var inOff = 0;\n\n  var self = this;\n\n  var async = typeof cb === 'function';\n\n  if (!async) {\n    var buffers = [];\n    var nread = 0;\n\n    var error;\n    this.on('error', function (er) {\n      error = er;\n    });\n\n    assert(this._handle, 'zlib binding closed');\n    do {\n      var res = this._handle.writeSync(flushFlag, chunk, // in\n      inOff, // in_off\n      availInBefore, // in_len\n      this._buffer, // out\n      this._offset, //out_off\n      availOutBefore); // out_len\n    } while (!this._hadError && callback(res[0], res[1]));\n\n    if (this._hadError) {\n      throw error;\n    }\n\n    if (nread >= kMaxLength) {\n      _close(this);\n      throw new RangeError(kRangeErrorMessage);\n    }\n\n    var buf = Buffer.concat(buffers, nread);\n    _close(this);\n\n    return buf;\n  }\n\n  assert(this._handle, 'zlib binding closed');\n  var req = this._handle.write(flushFlag, chunk, // in\n  inOff, // in_off\n  availInBefore, // in_len\n  this._buffer, // out\n  this._offset, //out_off\n  availOutBefore); // out_len\n\n  req.buffer = chunk;\n  req.callback = callback;\n\n  function callback(availInAfter, availOutAfter) {\n    // When the callback is used in an async write, the callback's\n    // context is the `req` object that was created. The req object\n    // is === this._handle, and that's why it's important to null\n    // out the values after they are done being used. `this._handle`\n    // can stay in memory longer than the callback and buffer are needed.\n    if (this) {\n      this.buffer = null;\n      this.callback = null;\n    }\n\n    if (self._hadError) return;\n\n    var have = availOutBefore - availOutAfter;\n    assert(have >= 0, 'have should not go down');\n\n    if (have > 0) {\n      var out = self._buffer.slice(self._offset, self._offset + have);\n      self._offset += have;\n      // serve some output to the consumer.\n      if (async) {\n        self.push(out);\n      } else {\n        buffers.push(out);\n        nread += out.length;\n      }\n    }\n\n    // exhausted the output buffer, or used all the input create a new one.\n    if (availOutAfter === 0 || self._offset >= self._chunkSize) {\n      availOutBefore = self._chunkSize;\n      self._offset = 0;\n      self._buffer = Buffer.allocUnsafe(self._chunkSize);\n    }\n\n    if (availOutAfter === 0) {\n      // Not actually done.  Need to reprocess.\n      // Also, update the availInBefore to the availInAfter value,\n      // so that if we have to hit it a third (fourth, etc.) time,\n      // it'll have the correct byte counts.\n      inOff += availInBefore - availInAfter;\n      availInBefore = availInAfter;\n\n      if (!async) return true;\n\n      var newReq = self._handle.write(flushFlag, chunk, inOff, availInBefore, self._buffer, self._offset, self._chunkSize);\n      newReq.callback = callback; // this same function\n      newReq.buffer = chunk;\n      return;\n    }\n\n    if (!async) return false;\n\n    // finished with the chunk.\n    cb();\n  }\n};\n\nutil.inherits(Deflate, Zlib);\nutil.inherits(Inflate, Zlib);\nutil.inherits(Gzip, Zlib);\nutil.inherits(Gunzip, Zlib);\nutil.inherits(DeflateRaw, Zlib);\nutil.inherits(InflateRaw, Zlib);\nutil.inherits(Unzip, Zlib);\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/browserify-zlib/lib/index.js?");

/***/ }),

/***/ "./node_modules/buffer/index.js":
/*!**************************************!*\
  !*** ./node_modules/buffer/index.js ***!
  \**************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(global) {/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <http://feross.org>\n * @license  MIT\n */\n/* eslint-disable no-proto */\n\n\n\nvar base64 = __webpack_require__(/*! base64-js */ \"./node_modules/base64-js/index.js\")\nvar ieee754 = __webpack_require__(/*! ieee754 */ \"./node_modules/ieee754/index.js\")\nvar isArray = __webpack_require__(/*! isarray */ \"./node_modules/isarray/index.js\")\n\nexports.Buffer = Buffer\nexports.SlowBuffer = SlowBuffer\nexports.INSPECT_MAX_BYTES = 50\n\n/**\n * If `Buffer.TYPED_ARRAY_SUPPORT`:\n *   === true    Use Uint8Array implementation (fastest)\n *   === false   Use Object implementation (most compatible, even IE6)\n *\n * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,\n * Opera 11.6+, iOS 4.2+.\n *\n * Due to various browser bugs, sometimes the Object implementation will be used even\n * when the browser supports typed arrays.\n *\n * Note:\n *\n *   - Firefox 4-29 lacks support for adding new properties to `Uint8Array` instances,\n *     See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438.\n *\n *   - Chrome 9-10 is missing the `TypedArray.prototype.subarray` function.\n *\n *   - IE10 has a broken `TypedArray.prototype.subarray` function which returns arrays of\n *     incorrect length in some situations.\n\n * We detect these buggy browsers and set `Buffer.TYPED_ARRAY_SUPPORT` to `false` so they\n * get the Object implementation, which is slower but behaves correctly.\n */\nBuffer.TYPED_ARRAY_SUPPORT = global.TYPED_ARRAY_SUPPORT !== undefined\n  ? global.TYPED_ARRAY_SUPPORT\n  : typedArraySupport()\n\n/*\n * Export kMaxLength after typed array support is determined.\n */\nexports.kMaxLength = kMaxLength()\n\nfunction typedArraySupport () {\n  try {\n    var arr = new Uint8Array(1)\n    arr.__proto__ = {__proto__: Uint8Array.prototype, foo: function () { return 42 }}\n    return arr.foo() === 42 && // typed array instances can be augmented\n        typeof arr.subarray === 'function' && // chrome 9-10 lack `subarray`\n        arr.subarray(1, 1).byteLength === 0 // ie10 has broken `subarray`\n  } catch (e) {\n    return false\n  }\n}\n\nfunction kMaxLength () {\n  return Buffer.TYPED_ARRAY_SUPPORT\n    ? 0x7fffffff\n    : 0x3fffffff\n}\n\nfunction createBuffer (that, length) {\n  if (kMaxLength() < length) {\n    throw new RangeError('Invalid typed array length')\n  }\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = new Uint8Array(length)\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    if (that === null) {\n      that = new Buffer(length)\n    }\n    that.length = length\n  }\n\n  return that\n}\n\n/**\n * The Buffer constructor returns instances of `Uint8Array` that have their\n * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of\n * `Uint8Array`, so the returned instances will have all the node `Buffer` methods\n * and the `Uint8Array` methods. Square bracket notation works as expected -- it\n * returns a single octet.\n *\n * The `Uint8Array` prototype remains unmodified.\n */\n\nfunction Buffer (arg, encodingOrOffset, length) {\n  if (!Buffer.TYPED_ARRAY_SUPPORT && !(this instanceof Buffer)) {\n    return new Buffer(arg, encodingOrOffset, length)\n  }\n\n  // Common case.\n  if (typeof arg === 'number') {\n    if (typeof encodingOrOffset === 'string') {\n      throw new Error(\n        'If encoding is specified then the first argument must be a string'\n      )\n    }\n    return allocUnsafe(this, arg)\n  }\n  return from(this, arg, encodingOrOffset, length)\n}\n\nBuffer.poolSize = 8192 // not used by this implementation\n\n// TODO: Legacy, not needed anymore. Remove in next major version.\nBuffer._augment = function (arr) {\n  arr.__proto__ = Buffer.prototype\n  return arr\n}\n\nfunction from (that, value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (typeof ArrayBuffer !== 'undefined' && value instanceof ArrayBuffer) {\n    return fromArrayBuffer(that, value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(that, value, encodingOrOffset)\n  }\n\n  return fromObject(that, value)\n}\n\n/**\n * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError\n * if value is a number.\n * Buffer.from(str[, encoding])\n * Buffer.from(array)\n * Buffer.from(buffer)\n * Buffer.from(arrayBuffer[, byteOffset[, length]])\n **/\nBuffer.from = function (value, encodingOrOffset, length) {\n  return from(null, value, encodingOrOffset, length)\n}\n\nif (Buffer.TYPED_ARRAY_SUPPORT) {\n  Buffer.prototype.__proto__ = Uint8Array.prototype\n  Buffer.__proto__ = Uint8Array\n  if (typeof Symbol !== 'undefined' && Symbol.species &&\n      Buffer[Symbol.species] === Buffer) {\n    // Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97\n    Object.defineProperty(Buffer, Symbol.species, {\n      value: null,\n      configurable: true\n    })\n  }\n}\n\nfunction assertSize (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('\"size\" argument must be a number')\n  } else if (size < 0) {\n    throw new RangeError('\"size\" argument must not be negative')\n  }\n}\n\nfunction alloc (that, size, fill, encoding) {\n  assertSize(size)\n  if (size <= 0) {\n    return createBuffer(that, size)\n  }\n  if (fill !== undefined) {\n    // Only pay attention to encoding if it's a string. This\n    // prevents accidentally sending in a number that would\n    // be interpretted as a start offset.\n    return typeof encoding === 'string'\n      ? createBuffer(that, size).fill(fill, encoding)\n      : createBuffer(that, size).fill(fill)\n  }\n  return createBuffer(that, size)\n}\n\n/**\n * Creates a new filled Buffer instance.\n * alloc(size[, fill[, encoding]])\n **/\nBuffer.alloc = function (size, fill, encoding) {\n  return alloc(null, size, fill, encoding)\n}\n\nfunction allocUnsafe (that, size) {\n  assertSize(size)\n  that = createBuffer(that, size < 0 ? 0 : checked(size) | 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) {\n    for (var i = 0; i < size; ++i) {\n      that[i] = 0\n    }\n  }\n  return that\n}\n\n/**\n * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.\n * */\nBuffer.allocUnsafe = function (size) {\n  return allocUnsafe(null, size)\n}\n/**\n * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.\n */\nBuffer.allocUnsafeSlow = function (size) {\n  return allocUnsafe(null, size)\n}\n\nfunction fromString (that, string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  var length = byteLength(string, encoding) | 0\n  that = createBuffer(that, length)\n\n  var actual = that.write(string, encoding)\n\n  if (actual !== length) {\n    // Writing a hex string, for example, that contains invalid characters will\n    // cause everything after the first invalid character to be ignored. (e.g.\n    // 'abxxcd' will be treated as 'ab')\n    that = that.slice(0, actual)\n  }\n\n  return that\n}\n\nfunction fromArrayLike (that, array) {\n  var length = array.length < 0 ? 0 : checked(array.length) | 0\n  that = createBuffer(that, length)\n  for (var i = 0; i < length; i += 1) {\n    that[i] = array[i] & 255\n  }\n  return that\n}\n\nfunction fromArrayBuffer (that, array, byteOffset, length) {\n  array.byteLength // this throws if `array` is not a valid ArrayBuffer\n\n  if (byteOffset < 0 || array.byteLength < byteOffset) {\n    throw new RangeError('\\'offset\\' is out of bounds')\n  }\n\n  if (array.byteLength < byteOffset + (length || 0)) {\n    throw new RangeError('\\'length\\' is out of bounds')\n  }\n\n  if (byteOffset === undefined && length === undefined) {\n    array = new Uint8Array(array)\n  } else if (length === undefined) {\n    array = new Uint8Array(array, byteOffset)\n  } else {\n    array = new Uint8Array(array, byteOffset, length)\n  }\n\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = array\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    that = fromArrayLike(that, array)\n  }\n  return that\n}\n\nfunction fromObject (that, obj) {\n  if (Buffer.isBuffer(obj)) {\n    var len = checked(obj.length) | 0\n    that = createBuffer(that, len)\n\n    if (that.length === 0) {\n      return that\n    }\n\n    obj.copy(that, 0, 0, len)\n    return that\n  }\n\n  if (obj) {\n    if ((typeof ArrayBuffer !== 'undefined' &&\n        obj.buffer instanceof ArrayBuffer) || 'length' in obj) {\n      if (typeof obj.length !== 'number' || isnan(obj.length)) {\n        return createBuffer(that, 0)\n      }\n      return fromArrayLike(that, obj)\n    }\n\n    if (obj.type === 'Buffer' && isArray(obj.data)) {\n      return fromArrayLike(that, obj.data)\n    }\n  }\n\n  throw new TypeError('First argument must be a string, Buffer, ArrayBuffer, Array, or array-like object.')\n}\n\nfunction checked (length) {\n  // Note: cannot use `length < kMaxLength()` here because that fails when\n  // length is NaN (which is otherwise coerced to zero.)\n  if (length >= kMaxLength()) {\n    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +\n                         'size: 0x' + kMaxLength().toString(16) + ' bytes')\n  }\n  return length | 0\n}\n\nfunction SlowBuffer (length) {\n  if (+length != length) { // eslint-disable-line eqeqeq\n    length = 0\n  }\n  return Buffer.alloc(+length)\n}\n\nBuffer.isBuffer = function isBuffer (b) {\n  return !!(b != null && b._isBuffer)\n}\n\nBuffer.compare = function compare (a, b) {\n  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {\n    throw new TypeError('Arguments must be Buffers')\n  }\n\n  if (a === b) return 0\n\n  var x = a.length\n  var y = b.length\n\n  for (var i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i]\n      y = b[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\nBuffer.isEncoding = function isEncoding (encoding) {\n  switch (String(encoding).toLowerCase()) {\n    case 'hex':\n    case 'utf8':\n    case 'utf-8':\n    case 'ascii':\n    case 'latin1':\n    case 'binary':\n    case 'base64':\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return true\n    default:\n      return false\n  }\n}\n\nBuffer.concat = function concat (list, length) {\n  if (!isArray(list)) {\n    throw new TypeError('\"list\" argument must be an Array of Buffers')\n  }\n\n  if (list.length === 0) {\n    return Buffer.alloc(0)\n  }\n\n  var i\n  if (length === undefined) {\n    length = 0\n    for (i = 0; i < list.length; ++i) {\n      length += list[i].length\n    }\n  }\n\n  var buffer = Buffer.allocUnsafe(length)\n  var pos = 0\n  for (i = 0; i < list.length; ++i) {\n    var buf = list[i]\n    if (!Buffer.isBuffer(buf)) {\n      throw new TypeError('\"list\" argument must be an Array of Buffers')\n    }\n    buf.copy(buffer, pos)\n    pos += buf.length\n  }\n  return buffer\n}\n\nfunction byteLength (string, encoding) {\n  if (Buffer.isBuffer(string)) {\n    return string.length\n  }\n  if (typeof ArrayBuffer !== 'undefined' && typeof ArrayBuffer.isView === 'function' &&\n      (ArrayBuffer.isView(string) || string instanceof ArrayBuffer)) {\n    return string.byteLength\n  }\n  if (typeof string !== 'string') {\n    string = '' + string\n  }\n\n  var len = string.length\n  if (len === 0) return 0\n\n  // Use a for loop to avoid recursion\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'ascii':\n      case 'latin1':\n      case 'binary':\n        return len\n      case 'utf8':\n      case 'utf-8':\n      case undefined:\n        return utf8ToBytes(string).length\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return len * 2\n      case 'hex':\n        return len >>> 1\n      case 'base64':\n        return base64ToBytes(string).length\n      default:\n        if (loweredCase) return utf8ToBytes(string).length // assume utf8\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\nBuffer.byteLength = byteLength\n\nfunction slowToString (encoding, start, end) {\n  var loweredCase = false\n\n  // No need to verify that \"this.length <= MAX_UINT32\" since it's a read-only\n  // property of a typed array.\n\n  // This behaves neither like String nor Uint8Array in that we set start/end\n  // to their upper/lower bounds if the value passed is out of range.\n  // undefined is handled specially as per ECMA-262 6th Edition,\n  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.\n  if (start === undefined || start < 0) {\n    start = 0\n  }\n  // Return early if start > this.length. Done here to prevent potential uint32\n  // coercion fail below.\n  if (start > this.length) {\n    return ''\n  }\n\n  if (end === undefined || end > this.length) {\n    end = this.length\n  }\n\n  if (end <= 0) {\n    return ''\n  }\n\n  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.\n  end >>>= 0\n  start >>>= 0\n\n  if (end <= start) {\n    return ''\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  while (true) {\n    switch (encoding) {\n      case 'hex':\n        return hexSlice(this, start, end)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Slice(this, start, end)\n\n      case 'ascii':\n        return asciiSlice(this, start, end)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Slice(this, start, end)\n\n      case 'base64':\n        return base64Slice(this, start, end)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return utf16leSlice(this, start, end)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = (encoding + '').toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\n// The property is used by `Buffer.isBuffer` and `is-buffer` (in Safari 5-7) to detect\n// Buffer instances.\nBuffer.prototype._isBuffer = true\n\nfunction swap (b, n, m) {\n  var i = b[n]\n  b[n] = b[m]\n  b[m] = i\n}\n\nBuffer.prototype.swap16 = function swap16 () {\n  var len = this.length\n  if (len % 2 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 16-bits')\n  }\n  for (var i = 0; i < len; i += 2) {\n    swap(this, i, i + 1)\n  }\n  return this\n}\n\nBuffer.prototype.swap32 = function swap32 () {\n  var len = this.length\n  if (len % 4 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 32-bits')\n  }\n  for (var i = 0; i < len; i += 4) {\n    swap(this, i, i + 3)\n    swap(this, i + 1, i + 2)\n  }\n  return this\n}\n\nBuffer.prototype.swap64 = function swap64 () {\n  var len = this.length\n  if (len % 8 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 64-bits')\n  }\n  for (var i = 0; i < len; i += 8) {\n    swap(this, i, i + 7)\n    swap(this, i + 1, i + 6)\n    swap(this, i + 2, i + 5)\n    swap(this, i + 3, i + 4)\n  }\n  return this\n}\n\nBuffer.prototype.toString = function toString () {\n  var length = this.length | 0\n  if (length === 0) return ''\n  if (arguments.length === 0) return utf8Slice(this, 0, length)\n  return slowToString.apply(this, arguments)\n}\n\nBuffer.prototype.equals = function equals (b) {\n  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')\n  if (this === b) return true\n  return Buffer.compare(this, b) === 0\n}\n\nBuffer.prototype.inspect = function inspect () {\n  var str = ''\n  var max = exports.INSPECT_MAX_BYTES\n  if (this.length > 0) {\n    str = this.toString('hex', 0, max).match(/.{2}/g).join(' ')\n    if (this.length > max) str += ' ... '\n  }\n  return '<Buffer ' + str + '>'\n}\n\nBuffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {\n  if (!Buffer.isBuffer(target)) {\n    throw new TypeError('Argument must be a Buffer')\n  }\n\n  if (start === undefined) {\n    start = 0\n  }\n  if (end === undefined) {\n    end = target ? target.length : 0\n  }\n  if (thisStart === undefined) {\n    thisStart = 0\n  }\n  if (thisEnd === undefined) {\n    thisEnd = this.length\n  }\n\n  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {\n    throw new RangeError('out of range index')\n  }\n\n  if (thisStart >= thisEnd && start >= end) {\n    return 0\n  }\n  if (thisStart >= thisEnd) {\n    return -1\n  }\n  if (start >= end) {\n    return 1\n  }\n\n  start >>>= 0\n  end >>>= 0\n  thisStart >>>= 0\n  thisEnd >>>= 0\n\n  if (this === target) return 0\n\n  var x = thisEnd - thisStart\n  var y = end - start\n  var len = Math.min(x, y)\n\n  var thisCopy = this.slice(thisStart, thisEnd)\n  var targetCopy = target.slice(start, end)\n\n  for (var i = 0; i < len; ++i) {\n    if (thisCopy[i] !== targetCopy[i]) {\n      x = thisCopy[i]\n      y = targetCopy[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\n// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,\n// OR the last index of `val` in `buffer` at offset <= `byteOffset`.\n//\n// Arguments:\n// - buffer - a Buffer to search\n// - val - a string, Buffer, or number\n// - byteOffset - an index into `buffer`; will be clamped to an int32\n// - encoding - an optional encoding, relevant is val is a string\n// - dir - true for indexOf, false for lastIndexOf\nfunction bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {\n  // Empty buffer means no match\n  if (buffer.length === 0) return -1\n\n  // Normalize byteOffset\n  if (typeof byteOffset === 'string') {\n    encoding = byteOffset\n    byteOffset = 0\n  } else if (byteOffset > 0x7fffffff) {\n    byteOffset = 0x7fffffff\n  } else if (byteOffset < -0x80000000) {\n    byteOffset = -0x80000000\n  }\n  byteOffset = +byteOffset  // Coerce to Number.\n  if (isNaN(byteOffset)) {\n    // byteOffset: it it's undefined, null, NaN, \"foo\", etc, search whole buffer\n    byteOffset = dir ? 0 : (buffer.length - 1)\n  }\n\n  // Normalize byteOffset: negative offsets start from the end of the buffer\n  if (byteOffset < 0) byteOffset = buffer.length + byteOffset\n  if (byteOffset >= buffer.length) {\n    if (dir) return -1\n    else byteOffset = buffer.length - 1\n  } else if (byteOffset < 0) {\n    if (dir) byteOffset = 0\n    else return -1\n  }\n\n  // Normalize val\n  if (typeof val === 'string') {\n    val = Buffer.from(val, encoding)\n  }\n\n  // Finally, search either indexOf (if dir is true) or lastIndexOf\n  if (Buffer.isBuffer(val)) {\n    // Special case: looking for empty string/buffer always fails\n    if (val.length === 0) {\n      return -1\n    }\n    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)\n  } else if (typeof val === 'number') {\n    val = val & 0xFF // Search for a byte value [0-255]\n    if (Buffer.TYPED_ARRAY_SUPPORT &&\n        typeof Uint8Array.prototype.indexOf === 'function') {\n      if (dir) {\n        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)\n      } else {\n        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)\n      }\n    }\n    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)\n  }\n\n  throw new TypeError('val must be string, number or Buffer')\n}\n\nfunction arrayIndexOf (arr, val, byteOffset, encoding, dir) {\n  var indexSize = 1\n  var arrLength = arr.length\n  var valLength = val.length\n\n  if (encoding !== undefined) {\n    encoding = String(encoding).toLowerCase()\n    if (encoding === 'ucs2' || encoding === 'ucs-2' ||\n        encoding === 'utf16le' || encoding === 'utf-16le') {\n      if (arr.length < 2 || val.length < 2) {\n        return -1\n      }\n      indexSize = 2\n      arrLength /= 2\n      valLength /= 2\n      byteOffset /= 2\n    }\n  }\n\n  function read (buf, i) {\n    if (indexSize === 1) {\n      return buf[i]\n    } else {\n      return buf.readUInt16BE(i * indexSize)\n    }\n  }\n\n  var i\n  if (dir) {\n    var foundIndex = -1\n    for (i = byteOffset; i < arrLength; i++) {\n      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {\n        if (foundIndex === -1) foundIndex = i\n        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize\n      } else {\n        if (foundIndex !== -1) i -= i - foundIndex\n        foundIndex = -1\n      }\n    }\n  } else {\n    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength\n    for (i = byteOffset; i >= 0; i--) {\n      var found = true\n      for (var j = 0; j < valLength; j++) {\n        if (read(arr, i + j) !== read(val, j)) {\n          found = false\n          break\n        }\n      }\n      if (found) return i\n    }\n  }\n\n  return -1\n}\n\nBuffer.prototype.includes = function includes (val, byteOffset, encoding) {\n  return this.indexOf(val, byteOffset, encoding) !== -1\n}\n\nBuffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)\n}\n\nBuffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)\n}\n\nfunction hexWrite (buf, string, offset, length) {\n  offset = Number(offset) || 0\n  var remaining = buf.length - offset\n  if (!length) {\n    length = remaining\n  } else {\n    length = Number(length)\n    if (length > remaining) {\n      length = remaining\n    }\n  }\n\n  // must be an even number of digits\n  var strLen = string.length\n  if (strLen % 2 !== 0) throw new TypeError('Invalid hex string')\n\n  if (length > strLen / 2) {\n    length = strLen / 2\n  }\n  for (var i = 0; i < length; ++i) {\n    var parsed = parseInt(string.substr(i * 2, 2), 16)\n    if (isNaN(parsed)) return i\n    buf[offset + i] = parsed\n  }\n  return i\n}\n\nfunction utf8Write (buf, string, offset, length) {\n  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nfunction asciiWrite (buf, string, offset, length) {\n  return blitBuffer(asciiToBytes(string), buf, offset, length)\n}\n\nfunction latin1Write (buf, string, offset, length) {\n  return asciiWrite(buf, string, offset, length)\n}\n\nfunction base64Write (buf, string, offset, length) {\n  return blitBuffer(base64ToBytes(string), buf, offset, length)\n}\n\nfunction ucs2Write (buf, string, offset, length) {\n  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nBuffer.prototype.write = function write (string, offset, length, encoding) {\n  // Buffer#write(string)\n  if (offset === undefined) {\n    encoding = 'utf8'\n    length = this.length\n    offset = 0\n  // Buffer#write(string, encoding)\n  } else if (length === undefined && typeof offset === 'string') {\n    encoding = offset\n    length = this.length\n    offset = 0\n  // Buffer#write(string, offset[, length][, encoding])\n  } else if (isFinite(offset)) {\n    offset = offset | 0\n    if (isFinite(length)) {\n      length = length | 0\n      if (encoding === undefined) encoding = 'utf8'\n    } else {\n      encoding = length\n      length = undefined\n    }\n  // legacy write(string, encoding, offset, length) - remove in v0.13\n  } else {\n    throw new Error(\n      'Buffer.write(string, encoding, offset[, length]) is no longer supported'\n    )\n  }\n\n  var remaining = this.length - offset\n  if (length === undefined || length > remaining) length = remaining\n\n  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {\n    throw new RangeError('Attempt to write outside buffer bounds')\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'hex':\n        return hexWrite(this, string, offset, length)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Write(this, string, offset, length)\n\n      case 'ascii':\n        return asciiWrite(this, string, offset, length)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Write(this, string, offset, length)\n\n      case 'base64':\n        // Warning: maxLength not taken into account in base64Write\n        return base64Write(this, string, offset, length)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return ucs2Write(this, string, offset, length)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\nBuffer.prototype.toJSON = function toJSON () {\n  return {\n    type: 'Buffer',\n    data: Array.prototype.slice.call(this._arr || this, 0)\n  }\n}\n\nfunction base64Slice (buf, start, end) {\n  if (start === 0 && end === buf.length) {\n    return base64.fromByteArray(buf)\n  } else {\n    return base64.fromByteArray(buf.slice(start, end))\n  }\n}\n\nfunction utf8Slice (buf, start, end) {\n  end = Math.min(buf.length, end)\n  var res = []\n\n  var i = start\n  while (i < end) {\n    var firstByte = buf[i]\n    var codePoint = null\n    var bytesPerSequence = (firstByte > 0xEF) ? 4\n      : (firstByte > 0xDF) ? 3\n      : (firstByte > 0xBF) ? 2\n      : 1\n\n    if (i + bytesPerSequence <= end) {\n      var secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = buf[i + 1]\n          if ((secondByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)\n            if (tempCodePoint > 0x7F) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)\n            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          fourthByte = buf[i + 3]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)\n            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n    }\n\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xFFFD\n      bytesPerSequence = 1\n    } else if (codePoint > 0xFFFF) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000\n      res.push(codePoint >>> 10 & 0x3FF | 0xD800)\n      codePoint = 0xDC00 | codePoint & 0x3FF\n    }\n\n    res.push(codePoint)\n    i += bytesPerSequence\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nvar MAX_ARGUMENTS_LENGTH = 0x1000\n\nfunction decodeCodePointsArray (codePoints) {\n  var len = codePoints.length\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  var res = ''\n  var i = 0\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    )\n  }\n  return res\n}\n\nfunction asciiSlice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i] & 0x7F)\n  }\n  return ret\n}\n\nfunction latin1Slice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i])\n  }\n  return ret\n}\n\nfunction hexSlice (buf, start, end) {\n  var len = buf.length\n\n  if (!start || start < 0) start = 0\n  if (!end || end < 0 || end > len) end = len\n\n  var out = ''\n  for (var i = start; i < end; ++i) {\n    out += toHex(buf[i])\n  }\n  return out\n}\n\nfunction utf16leSlice (buf, start, end) {\n  var bytes = buf.slice(start, end)\n  var res = ''\n  for (var i = 0; i < bytes.length; i += 2) {\n    res += String.fromCharCode(bytes[i] + bytes[i + 1] * 256)\n  }\n  return res\n}\n\nBuffer.prototype.slice = function slice (start, end) {\n  var len = this.length\n  start = ~~start\n  end = end === undefined ? len : ~~end\n\n  if (start < 0) {\n    start += len\n    if (start < 0) start = 0\n  } else if (start > len) {\n    start = len\n  }\n\n  if (end < 0) {\n    end += len\n    if (end < 0) end = 0\n  } else if (end > len) {\n    end = len\n  }\n\n  if (end < start) end = start\n\n  var newBuf\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    newBuf = this.subarray(start, end)\n    newBuf.__proto__ = Buffer.prototype\n  } else {\n    var sliceLen = end - start\n    newBuf = new Buffer(sliceLen, undefined)\n    for (var i = 0; i < sliceLen; ++i) {\n      newBuf[i] = this[i + start]\n    }\n  }\n\n  return newBuf\n}\n\n/*\n * Need to make sure that buffer isn't trying to write out of bounds.\n */\nfunction checkOffset (offset, ext, length) {\n  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')\n  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')\n}\n\nBuffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    checkOffset(offset, byteLength, this.length)\n  }\n\n  var val = this[offset + --byteLength]\n  var mul = 1\n  while (byteLength > 0 && (mul *= 0x100)) {\n    val += this[offset + --byteLength] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  return this[offset]\n}\n\nBuffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return this[offset] | (this[offset + 1] << 8)\n}\n\nBuffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return (this[offset] << 8) | this[offset + 1]\n}\n\nBuffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return ((this[offset]) |\n      (this[offset + 1] << 8) |\n      (this[offset + 2] << 16)) +\n      (this[offset + 3] * 0x1000000)\n}\n\nBuffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] * 0x1000000) +\n    ((this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    this[offset + 3])\n}\n\nBuffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var i = byteLength\n  var mul = 1\n  var val = this[offset + --i]\n  while (i > 0 && (mul *= 0x100)) {\n    val += this[offset + --i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readInt8 = function readInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  if (!(this[offset] & 0x80)) return (this[offset])\n  return ((0xff - this[offset] + 1) * -1)\n}\n\nBuffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset] | (this[offset + 1] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset + 1] | (this[offset] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset]) |\n    (this[offset + 1] << 8) |\n    (this[offset + 2] << 16) |\n    (this[offset + 3] << 24)\n}\n\nBuffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] << 24) |\n    (this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    (this[offset + 3])\n}\n\nBuffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, true, 23, 4)\n}\n\nBuffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, false, 23, 4)\n}\n\nBuffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, true, 52, 8)\n}\n\nBuffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, false, 52, 8)\n}\n\nfunction checkInt (buf, value, offset, ext, max, min) {\n  if (!Buffer.isBuffer(buf)) throw new TypeError('\"buffer\" argument must be a Buffer instance')\n  if (value > max || value < min) throw new RangeError('\"value\" argument is out of bounds')\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n}\n\nBuffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var mul = 1\n  var i = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nfunction objectWriteUInt16 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 2); i < j; ++i) {\n    buf[offset + i] = (value & (0xff << (8 * (littleEndian ? i : 1 - i)))) >>>\n      (littleEndian ? i : 1 - i) * 8\n  }\n}\n\nBuffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nfunction objectWriteUInt32 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffffffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 4); i < j; ++i) {\n    buf[offset + i] = (value >>> (littleEndian ? i : 3 - i) * 8) & 0xff\n  }\n}\n\nBuffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset + 3] = (value >>> 24)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 1] = (value >>> 8)\n    this[offset] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = 0\n  var mul = 1\n  var sub = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  var sub = 0\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  if (value < 0) value = 0xff + value + 1\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nBuffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 3] = (value >>> 24)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (value < 0) value = 0xffffffff + value + 1\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nfunction checkIEEE754 (buf, value, offset, ext, max, min) {\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n  if (offset < 0) throw new RangeError('Index out of range')\n}\n\nfunction writeFloat (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 23, 4)\n  return offset + 4\n}\n\nBuffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, false, noAssert)\n}\n\nfunction writeDouble (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 52, 8)\n  return offset + 8\n}\n\nBuffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, false, noAssert)\n}\n\n// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)\nBuffer.prototype.copy = function copy (target, targetStart, start, end) {\n  if (!start) start = 0\n  if (!end && end !== 0) end = this.length\n  if (targetStart >= target.length) targetStart = target.length\n  if (!targetStart) targetStart = 0\n  if (end > 0 && end < start) end = start\n\n  // Copy 0 bytes; we're done\n  if (end === start) return 0\n  if (target.length === 0 || this.length === 0) return 0\n\n  // Fatal error conditions\n  if (targetStart < 0) {\n    throw new RangeError('targetStart out of bounds')\n  }\n  if (start < 0 || start >= this.length) throw new RangeError('sourceStart out of bounds')\n  if (end < 0) throw new RangeError('sourceEnd out of bounds')\n\n  // Are we oob?\n  if (end > this.length) end = this.length\n  if (target.length - targetStart < end - start) {\n    end = target.length - targetStart + start\n  }\n\n  var len = end - start\n  var i\n\n  if (this === target && start < targetStart && targetStart < end) {\n    // descending copy from end\n    for (i = len - 1; i >= 0; --i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else if (len < 1000 || !Buffer.TYPED_ARRAY_SUPPORT) {\n    // ascending copy from start\n    for (i = 0; i < len; ++i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else {\n    Uint8Array.prototype.set.call(\n      target,\n      this.subarray(start, start + len),\n      targetStart\n    )\n  }\n\n  return len\n}\n\n// Usage:\n//    buffer.fill(number[, offset[, end]])\n//    buffer.fill(buffer[, offset[, end]])\n//    buffer.fill(string[, offset[, end]][, encoding])\nBuffer.prototype.fill = function fill (val, start, end, encoding) {\n  // Handle string cases:\n  if (typeof val === 'string') {\n    if (typeof start === 'string') {\n      encoding = start\n      start = 0\n      end = this.length\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = this.length\n    }\n    if (val.length === 1) {\n      var code = val.charCodeAt(0)\n      if (code < 256) {\n        val = code\n      }\n    }\n    if (encoding !== undefined && typeof encoding !== 'string') {\n      throw new TypeError('encoding must be a string')\n    }\n    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {\n      throw new TypeError('Unknown encoding: ' + encoding)\n    }\n  } else if (typeof val === 'number') {\n    val = val & 255\n  }\n\n  // Invalid ranges are not set to a default, so can range check early.\n  if (start < 0 || this.length < start || this.length < end) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (end <= start) {\n    return this\n  }\n\n  start = start >>> 0\n  end = end === undefined ? this.length : end >>> 0\n\n  if (!val) val = 0\n\n  var i\n  if (typeof val === 'number') {\n    for (i = start; i < end; ++i) {\n      this[i] = val\n    }\n  } else {\n    var bytes = Buffer.isBuffer(val)\n      ? val\n      : utf8ToBytes(new Buffer(val, encoding).toString())\n    var len = bytes.length\n    for (i = 0; i < end - start; ++i) {\n      this[i + start] = bytes[i % len]\n    }\n  }\n\n  return this\n}\n\n// HELPER FUNCTIONS\n// ================\n\nvar INVALID_BASE64_RE = /[^+\\/0-9A-Za-z-_]/g\n\nfunction base64clean (str) {\n  // Node strips out invalid characters like \\n and \\t from the string, base64-js does not\n  str = stringtrim(str).replace(INVALID_BASE64_RE, '')\n  // Node converts strings with length < 2 to ''\n  if (str.length < 2) return ''\n  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not\n  while (str.length % 4 !== 0) {\n    str = str + '='\n  }\n  return str\n}\n\nfunction stringtrim (str) {\n  if (str.trim) return str.trim()\n  return str.replace(/^\\s+|\\s+$/g, '')\n}\n\nfunction toHex (n) {\n  if (n < 16) return '0' + n.toString(16)\n  return n.toString(16)\n}\n\nfunction utf8ToBytes (string, units) {\n  units = units || Infinity\n  var codePoint\n  var length = string.length\n  var leadSurrogate = null\n  var bytes = []\n\n  for (var i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i)\n\n    // is surrogate component\n    if (codePoint > 0xD7FF && codePoint < 0xE000) {\n      // last char was a lead\n      if (!leadSurrogate) {\n        // no lead yet\n        if (codePoint > 0xDBFF) {\n          // unexpected trail\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        } else if (i + 1 === length) {\n          // unpaired lead\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        }\n\n        // valid lead\n        leadSurrogate = codePoint\n\n        continue\n      }\n\n      // 2 leads in a row\n      if (codePoint < 0xDC00) {\n        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n        leadSurrogate = codePoint\n        continue\n      }\n\n      // valid surrogate pair\n      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000\n    } else if (leadSurrogate) {\n      // valid bmp char, but last char was a lead\n      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n    }\n\n    leadSurrogate = null\n\n    // encode utf8\n    if (codePoint < 0x80) {\n      if ((units -= 1) < 0) break\n      bytes.push(codePoint)\n    } else if (codePoint < 0x800) {\n      if ((units -= 2) < 0) break\n      bytes.push(\n        codePoint >> 0x6 | 0xC0,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x10000) {\n      if ((units -= 3) < 0) break\n      bytes.push(\n        codePoint >> 0xC | 0xE0,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x110000) {\n      if ((units -= 4) < 0) break\n      bytes.push(\n        codePoint >> 0x12 | 0xF0,\n        codePoint >> 0xC & 0x3F | 0x80,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else {\n      throw new Error('Invalid code point')\n    }\n  }\n\n  return bytes\n}\n\nfunction asciiToBytes (str) {\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    // Node's code seems to be doing this and not & 0x7F..\n    byteArray.push(str.charCodeAt(i) & 0xFF)\n  }\n  return byteArray\n}\n\nfunction utf16leToBytes (str, units) {\n  var c, hi, lo\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    if ((units -= 2) < 0) break\n\n    c = str.charCodeAt(i)\n    hi = c >> 8\n    lo = c % 256\n    byteArray.push(lo)\n    byteArray.push(hi)\n  }\n\n  return byteArray\n}\n\nfunction base64ToBytes (str) {\n  return base64.toByteArray(base64clean(str))\n}\n\nfunction blitBuffer (src, dst, offset, length) {\n  for (var i = 0; i < length; ++i) {\n    if ((i + offset >= dst.length) || (i >= src.length)) break\n    dst[i + offset] = src[i]\n  }\n  return i\n}\n\nfunction isnan (val) {\n  return val !== val // eslint-disable-line no-self-compare\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/buffer/index.js?");

/***/ }),

/***/ "./node_modules/builtin-status-codes/index.js":
/*!****************************************************!*\
  !*** ./node_modules/builtin-status-codes/index.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nmodule.exports = __webpack_require__(/*! http */ \"./node_modules/stream-http/index.js\").STATUS_CODES\n\n\n//# sourceURL=webpack:///./node_modules/builtin-status-codes/index.js?");

/***/ }),

/***/ "./node_modules/core-util-is/lib/util.js":
/*!***********************************************!*\
  !*** ./node_modules/core-util-is/lib/util.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(Buffer) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer))\n\n//# sourceURL=webpack:///./node_modules/core-util-is/lib/util.js?");

/***/ }),

/***/ "./node_modules/events/events.js":
/*!***************************************!*\
  !*** ./node_modules/events/events.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar R = typeof Reflect === 'object' ? Reflect : null\nvar ReflectApply = R && typeof R.apply === 'function'\n  ? R.apply\n  : function ReflectApply(target, receiver, args) {\n    return Function.prototype.apply.call(target, receiver, args);\n  }\n\nvar ReflectOwnKeys\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target)\n      .concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n}\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\nmodule.exports.once = once;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nfunction checkListener(listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n}\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function() {\n    return defaultMaxListeners;\n  },\n  set: function(arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function() {\n\n  if (this._events === undefined ||\n      this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction _getMaxListeners(that) {\n  if (that._maxListeners === undefined)\n    return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return _getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = (type === 'error');\n\n  var events = this._events;\n  if (events !== undefined)\n    doError = (doError && events.error === undefined);\n  else if (!doError)\n    return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0)\n      er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined)\n    return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i)\n      ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  checkListener(listener);\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type,\n                  listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] =\n        prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = _getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' +\n                          existing.length + ' ' + String(type) + ' listeners ' +\n                          'added. Use emitter.setMaxListeners() to ' +\n                          'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    if (arguments.length === 0)\n      return this.listener.call(this.target);\n    return this.listener.apply(this.target, arguments);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  checkListener(listener);\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      checkListener(listener);\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      checkListener(listener);\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\nfunction once(emitter, name) {\n  return new Promise(function (resolve, reject) {\n    function eventListener() {\n      if (errorListener !== undefined) {\n        emitter.removeListener('error', errorListener);\n      }\n      resolve([].slice.call(arguments));\n    };\n    var errorListener;\n\n    // Adding an error listener is not optional because\n    // if an error is thrown on an event emitter we cannot\n    // guarantee that the actual event we are waiting will\n    // be fired. The result could be a silent way to create\n    // memory or file descriptor leaks, which is something\n    // we should avoid.\n    if (name !== 'error') {\n      errorListener = function errorListener(err) {\n        emitter.removeListener(name, eventListener);\n        reject(err);\n      };\n\n      emitter.once('error', errorListener);\n    }\n\n    emitter.once(name, eventListener);\n  });\n}\n\n\n//# sourceURL=webpack:///./node_modules/events/events.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/NeuralNetwork.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/NeuralNetwork.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar getModelUris_1 = __webpack_require__(/*! ./common/getModelUris */ \"./node_modules/face-api.js/build/commonjs/common/getModelUris.js\");\r\nvar dom_1 = __webpack_require__(/*! ./dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar env_1 = __webpack_require__(/*! ./env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nvar NeuralNetwork = /** @class */ (function () {\r\n    function NeuralNetwork(_name) {\r\n        this._name = _name;\r\n        this._params = undefined;\r\n        this._paramMappings = [];\r\n    }\r\n    Object.defineProperty(NeuralNetwork.prototype, \"params\", {\r\n        get: function () { return this._params; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NeuralNetwork.prototype, \"paramMappings\", {\r\n        get: function () { return this._paramMappings; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NeuralNetwork.prototype, \"isLoaded\", {\r\n        get: function () { return !!this.params; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    NeuralNetwork.prototype.getParamFromPath = function (paramPath) {\r\n        var _a = this.traversePropertyPath(paramPath), obj = _a.obj, objProp = _a.objProp;\r\n        return obj[objProp];\r\n    };\r\n    NeuralNetwork.prototype.reassignParamFromPath = function (paramPath, tensor) {\r\n        var _a = this.traversePropertyPath(paramPath), obj = _a.obj, objProp = _a.objProp;\r\n        obj[objProp].dispose();\r\n        obj[objProp] = tensor;\r\n    };\r\n    NeuralNetwork.prototype.getParamList = function () {\r\n        var _this = this;\r\n        return this._paramMappings.map(function (_a) {\r\n            var paramPath = _a.paramPath;\r\n            return ({\r\n                path: paramPath,\r\n                tensor: _this.getParamFromPath(paramPath)\r\n            });\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.getTrainableParams = function () {\r\n        return this.getParamList().filter(function (param) { return param.tensor instanceof tf.Variable; });\r\n    };\r\n    NeuralNetwork.prototype.getFrozenParams = function () {\r\n        return this.getParamList().filter(function (param) { return !(param.tensor instanceof tf.Variable); });\r\n    };\r\n    NeuralNetwork.prototype.variable = function () {\r\n        var _this = this;\r\n        this.getFrozenParams().forEach(function (_a) {\r\n            var path = _a.path, tensor = _a.tensor;\r\n            _this.reassignParamFromPath(path, tensor.variable());\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.freeze = function () {\r\n        var _this = this;\r\n        this.getTrainableParams().forEach(function (_a) {\r\n            var path = _a.path, variable = _a.tensor;\r\n            var tensor = tf.tensor(variable.dataSync());\r\n            variable.dispose();\r\n            _this.reassignParamFromPath(path, tensor);\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.dispose = function (throwOnRedispose) {\r\n        if (throwOnRedispose === void 0) { throwOnRedispose = true; }\r\n        this.getParamList().forEach(function (param) {\r\n            if (throwOnRedispose && param.tensor.isDisposed) {\r\n                throw new Error(\"param tensor has already been disposed for path \" + param.path);\r\n            }\r\n            param.tensor.dispose();\r\n        });\r\n        this._params = undefined;\r\n    };\r\n    NeuralNetwork.prototype.serializeParams = function () {\r\n        return new Float32Array(this.getParamList()\r\n            .map(function (_a) {\r\n            var tensor = _a.tensor;\r\n            return Array.from(tensor.dataSync());\r\n        })\r\n            .reduce(function (flat, arr) { return flat.concat(arr); }));\r\n    };\r\n    NeuralNetwork.prototype.load = function (weightsOrUrl) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0:\r\n                        if (weightsOrUrl instanceof Float32Array) {\r\n                            this.extractWeights(weightsOrUrl);\r\n                            return [2 /*return*/];\r\n                        }\r\n                        return [4 /*yield*/, this.loadFromUri(weightsOrUrl)];\r\n                    case 1:\r\n                        _a.sent();\r\n                        return [2 /*return*/];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.loadFromUri = function (uri) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var weightMap;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0:\r\n                        if (uri && typeof uri !== 'string') {\r\n                            throw new Error(this._name + \".loadFromUri - expected model uri\");\r\n                        }\r\n                        return [4 /*yield*/, dom_1.loadWeightMap(uri, this.getDefaultModelName())];\r\n                    case 1:\r\n                        weightMap = _a.sent();\r\n                        this.loadFromWeightMap(weightMap);\r\n                        return [2 /*return*/];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.loadFromDisk = function (filePath) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var readFile, _a, manifestUri, modelBaseUri, fetchWeightsFromDisk, loadWeights, manifest, _b, _c, weightMap;\r\n            return tslib_1.__generator(this, function (_d) {\r\n                switch (_d.label) {\r\n                    case 0:\r\n                        if (filePath && typeof filePath !== 'string') {\r\n                            throw new Error(this._name + \".loadFromDisk - expected model file path\");\r\n                        }\r\n                        readFile = env_1.env.getEnv().readFile;\r\n                        _a = getModelUris_1.getModelUris(filePath, this.getDefaultModelName()), manifestUri = _a.manifestUri, modelBaseUri = _a.modelBaseUri;\r\n                        fetchWeightsFromDisk = function (filePaths) { return Promise.all(filePaths.map(function (filePath) { return readFile(filePath).then(function (buf) { return buf.buffer; }); })); };\r\n                        loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk);\r\n                        _c = (_b = JSON).parse;\r\n                        return [4 /*yield*/, readFile(manifestUri)];\r\n                    case 1:\r\n                        manifest = _c.apply(_b, [(_d.sent()).toString()]);\r\n                        return [4 /*yield*/, loadWeights(manifest, modelBaseUri)];\r\n                    case 2:\r\n                        weightMap = _d.sent();\r\n                        this.loadFromWeightMap(weightMap);\r\n                        return [2 /*return*/];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    NeuralNetwork.prototype.loadFromWeightMap = function (weightMap) {\r\n        var _a = this.extractParamsFromWeigthMap(weightMap), paramMappings = _a.paramMappings, params = _a.params;\r\n        this._paramMappings = paramMappings;\r\n        this._params = params;\r\n    };\r\n    NeuralNetwork.prototype.extractWeights = function (weights) {\r\n        var _a = this.extractParams(weights), paramMappings = _a.paramMappings, params = _a.params;\r\n        this._paramMappings = paramMappings;\r\n        this._params = params;\r\n    };\r\n    NeuralNetwork.prototype.traversePropertyPath = function (paramPath) {\r\n        if (!this.params) {\r\n            throw new Error(\"traversePropertyPath - model has no loaded params\");\r\n        }\r\n        var result = paramPath.split('/').reduce(function (res, objProp) {\r\n            if (!res.nextObj.hasOwnProperty(objProp)) {\r\n                throw new Error(\"traversePropertyPath - object does not have property \" + objProp + \", for path \" + paramPath);\r\n            }\r\n            return { obj: res.nextObj, objProp: objProp, nextObj: res.nextObj[objProp] };\r\n        }, { nextObj: this.params });\r\n        var obj = result.obj, objProp = result.objProp;\r\n        if (!obj || !objProp || !(obj[objProp] instanceof tf.Tensor)) {\r\n            throw new Error(\"traversePropertyPath - parameter is not a tensor, for path \" + paramPath);\r\n        }\r\n        return { obj: obj, objProp: objProp };\r\n    };\r\n    return NeuralNetwork;\r\n}());\r\nexports.NeuralNetwork = NeuralNetwork;\r\n//# sourceMappingURL=NeuralNetwork.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/NeuralNetwork.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ageGenderNet/AgeGenderNet.js":
/*!******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ageGenderNet/AgeGenderNet.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar fullyConnectedLayer_1 = __webpack_require__(/*! ../common/fullyConnectedLayer */ \"./node_modules/face-api.js/build/commonjs/common/fullyConnectedLayer.js\");\r\nvar util_1 = __webpack_require__(/*! ../faceProcessor/util */ \"./node_modules/face-api.js/build/commonjs/faceProcessor/util.js\");\r\nvar TinyXception_1 = __webpack_require__(/*! ../xception/TinyXception */ \"./node_modules/face-api.js/build/commonjs/xception/TinyXception.js\");\r\nvar extractParams_1 = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/commonjs/ageGenderNet/extractParams.js\");\r\nvar extractParamsFromWeigthMap_1 = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/commonjs/ageGenderNet/extractParamsFromWeigthMap.js\");\r\nvar types_1 = __webpack_require__(/*! ./types */ \"./node_modules/face-api.js/build/commonjs/ageGenderNet/types.js\");\r\nvar NeuralNetwork_1 = __webpack_require__(/*! ../NeuralNetwork */ \"./node_modules/face-api.js/build/commonjs/NeuralNetwork.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar AgeGenderNet = /** @class */ (function (_super) {\r\n    tslib_1.__extends(AgeGenderNet, _super);\r\n    function AgeGenderNet(faceFeatureExtractor) {\r\n        if (faceFeatureExtractor === void 0) { faceFeatureExtractor = new TinyXception_1.TinyXception(2); }\r\n        var _this = _super.call(this, 'AgeGenderNet') || this;\r\n        _this._faceFeatureExtractor = faceFeatureExtractor;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(AgeGenderNet.prototype, \"faceFeatureExtractor\", {\r\n        get: function () {\r\n            return this._faceFeatureExtractor;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    AgeGenderNet.prototype.runNet = function (input) {\r\n        var _this = this;\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error(this._name + \" - load model before inference\");\r\n        }\r\n        return tf.tidy(function () {\r\n            var bottleneckFeatures = input instanceof dom_1.NetInput\r\n                ? _this.faceFeatureExtractor.forwardInput(input)\r\n                : input;\r\n            var pooled = tf.avgPool(bottleneckFeatures, [7, 7], [2, 2], 'valid').as2D(bottleneckFeatures.shape[0], -1);\r\n            var age = fullyConnectedLayer_1.fullyConnectedLayer(pooled, params.fc.age).as1D();\r\n            var gender = fullyConnectedLayer_1.fullyConnectedLayer(pooled, params.fc.gender);\r\n            return { age: age, gender: gender };\r\n        });\r\n    };\r\n    AgeGenderNet.prototype.forwardInput = function (input) {\r\n        var _this = this;\r\n        return tf.tidy(function () {\r\n            var _a = _this.runNet(input), age = _a.age, gender = _a.gender;\r\n            return { age: age, gender: tf.softmax(gender) };\r\n        });\r\n    };\r\n    AgeGenderNet.prototype.forward = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    AgeGenderNet.prototype.predictAgeAndGender = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var netInput, out, ages, genders, ageAndGenderTensors, predictionsByBatch;\r\n            var _this = this;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1:\r\n                        netInput = _a.sent();\r\n                        return [4 /*yield*/, this.forwardInput(netInput)];\r\n                    case 2:\r\n                        out = _a.sent();\r\n                        ages = tf.unstack(out.age);\r\n                        genders = tf.unstack(out.gender);\r\n                        ageAndGenderTensors = ages.map(function (ageTensor, i) { return ({\r\n                            ageTensor: ageTensor,\r\n                            genderTensor: genders[i]\r\n                        }); });\r\n                        return [4 /*yield*/, Promise.all(ageAndGenderTensors.map(function (_a) {\r\n                                var ageTensor = _a.ageTensor, genderTensor = _a.genderTensor;\r\n                                return tslib_1.__awaiter(_this, void 0, void 0, function () {\r\n                                    var age, probMale, isMale, gender, genderProbability;\r\n                                    return tslib_1.__generator(this, function (_b) {\r\n                                        switch (_b.label) {\r\n                                            case 0: return [4 /*yield*/, ageTensor.data()];\r\n                                            case 1:\r\n                                                age = (_b.sent())[0];\r\n                                                return [4 /*yield*/, genderTensor.data()];\r\n                                            case 2:\r\n                                                probMale = (_b.sent())[0];\r\n                                                isMale = probMale > 0.5;\r\n                                                gender = isMale ? types_1.Gender.MALE : types_1.Gender.FEMALE;\r\n                                                genderProbability = isMale ? probMale : (1 - probMale);\r\n                                                ageTensor.dispose();\r\n                                                genderTensor.dispose();\r\n                                                return [2 /*return*/, { age: age, gender: gender, genderProbability: genderProbability }];\r\n                                        }\r\n                                    });\r\n                                });\r\n                            }))];\r\n                    case 3:\r\n                        predictionsByBatch = _a.sent();\r\n                        out.age.dispose();\r\n                        out.gender.dispose();\r\n                        return [2 /*return*/, netInput.isBatchInput\r\n                                ? predictionsByBatch\r\n                                : predictionsByBatch[0]];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    AgeGenderNet.prototype.getDefaultModelName = function () {\r\n        return 'age_gender_model';\r\n    };\r\n    AgeGenderNet.prototype.dispose = function (throwOnRedispose) {\r\n        if (throwOnRedispose === void 0) { throwOnRedispose = true; }\r\n        this.faceFeatureExtractor.dispose(throwOnRedispose);\r\n        _super.prototype.dispose.call(this, throwOnRedispose);\r\n    };\r\n    AgeGenderNet.prototype.loadClassifierParams = function (weights) {\r\n        var _a = this.extractClassifierParams(weights), params = _a.params, paramMappings = _a.paramMappings;\r\n        this._params = params;\r\n        this._paramMappings = paramMappings;\r\n    };\r\n    AgeGenderNet.prototype.extractClassifierParams = function (weights) {\r\n        return extractParams_1.extractParams(weights);\r\n    };\r\n    AgeGenderNet.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        var _a = util_1.seperateWeightMaps(weightMap), featureExtractorMap = _a.featureExtractorMap, classifierMap = _a.classifierMap;\r\n        this.faceFeatureExtractor.loadFromWeightMap(featureExtractorMap);\r\n        return extractParamsFromWeigthMap_1.extractParamsFromWeigthMap(classifierMap);\r\n    };\r\n    AgeGenderNet.prototype.extractParams = function (weights) {\r\n        var classifierWeightSize = (512 * 1 + 1) + (512 * 2 + 2);\r\n        var featureExtractorWeights = weights.slice(0, weights.length - classifierWeightSize);\r\n        var classifierWeights = weights.slice(weights.length - classifierWeightSize);\r\n        this.faceFeatureExtractor.extractWeights(featureExtractorWeights);\r\n        return this.extractClassifierParams(classifierWeights);\r\n    };\r\n    return AgeGenderNet;\r\n}(NeuralNetwork_1.NeuralNetwork));\r\nexports.AgeGenderNet = AgeGenderNet;\r\n//# sourceMappingURL=AgeGenderNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ageGenderNet/AgeGenderNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ageGenderNet/extractParams.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ageGenderNet/extractParams.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nfunction extractParams(weights) {\r\n    var paramMappings = [];\r\n    var _a = common_1.extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var extractFCParams = common_1.extractFCParamsFactory(extractWeights, paramMappings);\r\n    var age = extractFCParams(512, 1, 'fc/age');\r\n    var gender = extractFCParams(512, 2, 'fc/gender');\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        paramMappings: paramMappings,\r\n        params: { fc: { age: age, gender: gender } }\r\n    };\r\n}\r\nexports.extractParams = extractParams;\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ageGenderNet/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ageGenderNet/extractParamsFromWeigthMap.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ageGenderNet/extractParamsFromWeigthMap.js ***!
  \********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var extractWeightEntry = common_1.extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractFcParams(prefix) {\r\n        var weights = extractWeightEntry(prefix + \"/weights\", 2);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { weights: weights, bias: bias };\r\n    }\r\n    var params = {\r\n        fc: {\r\n            age: extractFcParams('fc/age'),\r\n            gender: extractFcParams('fc/gender')\r\n        }\r\n    };\r\n    common_1.disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\nexports.extractParamsFromWeigthMap = extractParamsFromWeigthMap;\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ageGenderNet/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ageGenderNet/index.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ageGenderNet/index.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./AgeGenderNet */ \"./node_modules/face-api.js/build/commonjs/ageGenderNet/AgeGenderNet.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./types */ \"./node_modules/face-api.js/build/commonjs/ageGenderNet/types.js\"), exports);\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ageGenderNet/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ageGenderNet/types.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ageGenderNet/types.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar Gender;\r\n(function (Gender) {\r\n    Gender[\"FEMALE\"] = \"female\";\r\n    Gender[\"MALE\"] = \"male\";\r\n})(Gender = exports.Gender || (exports.Gender = {}));\r\n//# sourceMappingURL=types.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ageGenderNet/types.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/BoundingBox.js":
/*!************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/BoundingBox.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar Box_1 = __webpack_require__(/*! ./Box */ \"./node_modules/face-api.js/build/commonjs/classes/Box.js\");\r\nvar BoundingBox = /** @class */ (function (_super) {\r\n    tslib_1.__extends(BoundingBox, _super);\r\n    function BoundingBox(left, top, right, bottom, allowNegativeDimensions) {\r\n        if (allowNegativeDimensions === void 0) { allowNegativeDimensions = false; }\r\n        return _super.call(this, { left: left, top: top, right: right, bottom: bottom }, allowNegativeDimensions) || this;\r\n    }\r\n    return BoundingBox;\r\n}(Box_1.Box));\r\nexports.BoundingBox = BoundingBox;\r\n//# sourceMappingURL=BoundingBox.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/BoundingBox.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/Box.js":
/*!****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/Box.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar Point_1 = __webpack_require__(/*! ./Point */ \"./node_modules/face-api.js/build/commonjs/classes/Point.js\");\r\nvar Box = /** @class */ (function () {\r\n    function Box(_box, allowNegativeDimensions) {\r\n        if (allowNegativeDimensions === void 0) { allowNegativeDimensions = true; }\r\n        var box = (_box || {});\r\n        var isBbox = [box.left, box.top, box.right, box.bottom].every(utils_1.isValidNumber);\r\n        var isRect = [box.x, box.y, box.width, box.height].every(utils_1.isValidNumber);\r\n        if (!isRect && !isBbox) {\r\n            throw new Error(\"Box.constructor - expected box to be IBoundingBox | IRect, instead have \" + JSON.stringify(box));\r\n        }\r\n        var _a = isRect\r\n            ? [box.x, box.y, box.width, box.height]\r\n            : [box.left, box.top, box.right - box.left, box.bottom - box.top], x = _a[0], y = _a[1], width = _a[2], height = _a[3];\r\n        Box.assertIsValidBox({ x: x, y: y, width: width, height: height }, 'Box.constructor', allowNegativeDimensions);\r\n        this._x = x;\r\n        this._y = y;\r\n        this._width = width;\r\n        this._height = height;\r\n    }\r\n    Box.isRect = function (rect) {\r\n        return !!rect && [rect.x, rect.y, rect.width, rect.height].every(utils_1.isValidNumber);\r\n    };\r\n    Box.assertIsValidBox = function (box, callee, allowNegativeDimensions) {\r\n        if (allowNegativeDimensions === void 0) { allowNegativeDimensions = false; }\r\n        if (!Box.isRect(box)) {\r\n            throw new Error(callee + \" - invalid box: \" + JSON.stringify(box) + \", expected object with properties x, y, width, height\");\r\n        }\r\n        if (!allowNegativeDimensions && (box.width < 0 || box.height < 0)) {\r\n            throw new Error(callee + \" - width (\" + box.width + \") and height (\" + box.height + \") must be positive numbers\");\r\n        }\r\n    };\r\n    Object.defineProperty(Box.prototype, \"x\", {\r\n        get: function () { return this._x; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"y\", {\r\n        get: function () { return this._y; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"width\", {\r\n        get: function () { return this._width; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"height\", {\r\n        get: function () { return this._height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"left\", {\r\n        get: function () { return this.x; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"top\", {\r\n        get: function () { return this.y; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"right\", {\r\n        get: function () { return this.x + this.width; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"bottom\", {\r\n        get: function () { return this.y + this.height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"area\", {\r\n        get: function () { return this.width * this.height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"topLeft\", {\r\n        get: function () { return new Point_1.Point(this.left, this.top); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"topRight\", {\r\n        get: function () { return new Point_1.Point(this.right, this.top); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"bottomLeft\", {\r\n        get: function () { return new Point_1.Point(this.left, this.bottom); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Box.prototype, \"bottomRight\", {\r\n        get: function () { return new Point_1.Point(this.right, this.bottom); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Box.prototype.round = function () {\r\n        var _a = [this.x, this.y, this.width, this.height]\r\n            .map(function (val) { return Math.round(val); }), x = _a[0], y = _a[1], width = _a[2], height = _a[3];\r\n        return new Box({ x: x, y: y, width: width, height: height });\r\n    };\r\n    Box.prototype.floor = function () {\r\n        var _a = [this.x, this.y, this.width, this.height]\r\n            .map(function (val) { return Math.floor(val); }), x = _a[0], y = _a[1], width = _a[2], height = _a[3];\r\n        return new Box({ x: x, y: y, width: width, height: height });\r\n    };\r\n    Box.prototype.toSquare = function () {\r\n        var _a = this, x = _a.x, y = _a.y, width = _a.width, height = _a.height;\r\n        var diff = Math.abs(width - height);\r\n        if (width < height) {\r\n            x -= (diff / 2);\r\n            width += diff;\r\n        }\r\n        if (height < width) {\r\n            y -= (diff / 2);\r\n            height += diff;\r\n        }\r\n        return new Box({ x: x, y: y, width: width, height: height });\r\n    };\r\n    Box.prototype.rescale = function (s) {\r\n        var scaleX = utils_1.isDimensions(s) ? s.width : s;\r\n        var scaleY = utils_1.isDimensions(s) ? s.height : s;\r\n        return new Box({\r\n            x: this.x * scaleX,\r\n            y: this.y * scaleY,\r\n            width: this.width * scaleX,\r\n            height: this.height * scaleY\r\n        });\r\n    };\r\n    Box.prototype.pad = function (padX, padY) {\r\n        var _a = [\r\n            this.x - (padX / 2),\r\n            this.y - (padY / 2),\r\n            this.width + padX,\r\n            this.height + padY\r\n        ], x = _a[0], y = _a[1], width = _a[2], height = _a[3];\r\n        return new Box({ x: x, y: y, width: width, height: height });\r\n    };\r\n    Box.prototype.clipAtImageBorders = function (imgWidth, imgHeight) {\r\n        var _a = this, x = _a.x, y = _a.y, right = _a.right, bottom = _a.bottom;\r\n        var clippedX = Math.max(x, 0);\r\n        var clippedY = Math.max(y, 0);\r\n        var newWidth = right - clippedX;\r\n        var newHeight = bottom - clippedY;\r\n        var clippedWidth = Math.min(newWidth, imgWidth - clippedX);\r\n        var clippedHeight = Math.min(newHeight, imgHeight - clippedY);\r\n        return (new Box({ x: clippedX, y: clippedY, width: clippedWidth, height: clippedHeight })).floor();\r\n    };\r\n    Box.prototype.shift = function (sx, sy) {\r\n        var _a = this, width = _a.width, height = _a.height;\r\n        var x = this.x + sx;\r\n        var y = this.y + sy;\r\n        return new Box({ x: x, y: y, width: width, height: height });\r\n    };\r\n    Box.prototype.padAtBorders = function (imageHeight, imageWidth) {\r\n        var w = this.width + 1;\r\n        var h = this.height + 1;\r\n        var dx = 1;\r\n        var dy = 1;\r\n        var edx = w;\r\n        var edy = h;\r\n        var x = this.left;\r\n        var y = this.top;\r\n        var ex = this.right;\r\n        var ey = this.bottom;\r\n        if (ex > imageWidth) {\r\n            edx = -ex + imageWidth + w;\r\n            ex = imageWidth;\r\n        }\r\n        if (ey > imageHeight) {\r\n            edy = -ey + imageHeight + h;\r\n            ey = imageHeight;\r\n        }\r\n        if (x < 1) {\r\n            edy = 2 - x;\r\n            x = 1;\r\n        }\r\n        if (y < 1) {\r\n            edy = 2 - y;\r\n            y = 1;\r\n        }\r\n        return { dy: dy, edy: edy, dx: dx, edx: edx, y: y, ey: ey, x: x, ex: ex, w: w, h: h };\r\n    };\r\n    Box.prototype.calibrate = function (region) {\r\n        return new Box({\r\n            left: this.left + (region.left * this.width),\r\n            top: this.top + (region.top * this.height),\r\n            right: this.right + (region.right * this.width),\r\n            bottom: this.bottom + (region.bottom * this.height)\r\n        }).toSquare().round();\r\n    };\r\n    return Box;\r\n}());\r\nexports.Box = Box;\r\n//# sourceMappingURL=Box.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/Box.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/Dimensions.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/Dimensions.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar Dimensions = /** @class */ (function () {\r\n    function Dimensions(width, height) {\r\n        if (!utils_1.isValidNumber(width) || !utils_1.isValidNumber(height)) {\r\n            throw new Error(\"Dimensions.constructor - expected width and height to be valid numbers, instead have \" + JSON.stringify({ width: width, height: height }));\r\n        }\r\n        this._width = width;\r\n        this._height = height;\r\n    }\r\n    Object.defineProperty(Dimensions.prototype, \"width\", {\r\n        get: function () { return this._width; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Dimensions.prototype, \"height\", {\r\n        get: function () { return this._height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Dimensions.prototype.reverse = function () {\r\n        return new Dimensions(1 / this.width, 1 / this.height);\r\n    };\r\n    return Dimensions;\r\n}());\r\nexports.Dimensions = Dimensions;\r\n//# sourceMappingURL=Dimensions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/Dimensions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar ObjectDetection_1 = __webpack_require__(/*! ./ObjectDetection */ \"./node_modules/face-api.js/build/commonjs/classes/ObjectDetection.js\");\r\nvar FaceDetection = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceDetection, _super);\r\n    function FaceDetection(score, relativeBox, imageDims) {\r\n        return _super.call(this, score, score, '', relativeBox, imageDims) || this;\r\n    }\r\n    FaceDetection.prototype.forSize = function (width, height) {\r\n        var _a = _super.prototype.forSize.call(this, width, height), score = _a.score, relativeBox = _a.relativeBox, imageDims = _a.imageDims;\r\n        return new FaceDetection(score, relativeBox, imageDims);\r\n    };\r\n    return FaceDetection;\r\n}(ObjectDetection_1.ObjectDetection));\r\nexports.FaceDetection = FaceDetection;\r\n//# sourceMappingURL=FaceDetection.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar ops_1 = __webpack_require__(/*! ../ops */ \"./node_modules/face-api.js/build/commonjs/ops/index.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar Box_1 = __webpack_require__(/*! ./Box */ \"./node_modules/face-api.js/build/commonjs/classes/Box.js\");\r\nvar Dimensions_1 = __webpack_require__(/*! ./Dimensions */ \"./node_modules/face-api.js/build/commonjs/classes/Dimensions.js\");\r\nvar FaceDetection_1 = __webpack_require__(/*! ./FaceDetection */ \"./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js\");\r\nvar Point_1 = __webpack_require__(/*! ./Point */ \"./node_modules/face-api.js/build/commonjs/classes/Point.js\");\r\nvar Rect_1 = __webpack_require__(/*! ./Rect */ \"./node_modules/face-api.js/build/commonjs/classes/Rect.js\");\r\n// face alignment constants\r\nvar relX = 0.5;\r\nvar relY = 0.43;\r\nvar relScale = 0.45;\r\nvar FaceLandmarks = /** @class */ (function () {\r\n    function FaceLandmarks(relativeFaceLandmarkPositions, imgDims, shift) {\r\n        if (shift === void 0) { shift = new Point_1.Point(0, 0); }\r\n        var width = imgDims.width, height = imgDims.height;\r\n        this._imgDims = new Dimensions_1.Dimensions(width, height);\r\n        this._shift = shift;\r\n        this._positions = relativeFaceLandmarkPositions.map(function (pt) { return pt.mul(new Point_1.Point(width, height)).add(shift); });\r\n    }\r\n    Object.defineProperty(FaceLandmarks.prototype, \"shift\", {\r\n        get: function () { return new Point_1.Point(this._shift.x, this._shift.y); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceLandmarks.prototype, \"imageWidth\", {\r\n        get: function () { return this._imgDims.width; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceLandmarks.prototype, \"imageHeight\", {\r\n        get: function () { return this._imgDims.height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceLandmarks.prototype, \"positions\", {\r\n        get: function () { return this._positions; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceLandmarks.prototype, \"relativePositions\", {\r\n        get: function () {\r\n            var _this = this;\r\n            return this._positions.map(function (pt) { return pt.sub(_this._shift).div(new Point_1.Point(_this.imageWidth, _this.imageHeight)); });\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    FaceLandmarks.prototype.forSize = function (width, height) {\r\n        return new this.constructor(this.relativePositions, { width: width, height: height });\r\n    };\r\n    FaceLandmarks.prototype.shiftBy = function (x, y) {\r\n        return new this.constructor(this.relativePositions, this._imgDims, new Point_1.Point(x, y));\r\n    };\r\n    FaceLandmarks.prototype.shiftByPoint = function (pt) {\r\n        return this.shiftBy(pt.x, pt.y);\r\n    };\r\n    /**\r\n     * Aligns the face landmarks after face detection from the relative positions of the faces\r\n     * bounding box, or it's current shift. This function should be used to align the face images\r\n     * after face detection has been performed, before they are passed to the face recognition net.\r\n     * This will make the computed face descriptor more accurate.\r\n     *\r\n     * @param detection (optional) The bounding box of the face or the face detection result. If\r\n     * no argument was passed the position of the face landmarks are assumed to be relative to\r\n     * it's current shift.\r\n     * @returns The bounding box of the aligned face.\r\n     */\r\n    FaceLandmarks.prototype.align = function (detection, options) {\r\n        if (options === void 0) { options = {}; }\r\n        if (detection) {\r\n            var box = detection instanceof FaceDetection_1.FaceDetection\r\n                ? detection.box.floor()\r\n                : new Box_1.Box(detection);\r\n            return this.shiftBy(box.x, box.y).align(null, options);\r\n        }\r\n        var _a = Object.assign({}, { useDlibAlignment: false, minBoxPadding: 0.2 }, options), useDlibAlignment = _a.useDlibAlignment, minBoxPadding = _a.minBoxPadding;\r\n        if (useDlibAlignment) {\r\n            return this.alignDlib();\r\n        }\r\n        return this.alignMinBbox(minBoxPadding);\r\n    };\r\n    FaceLandmarks.prototype.alignDlib = function () {\r\n        var centers = this.getRefPointsForAlignment();\r\n        var leftEyeCenter = centers[0], rightEyeCenter = centers[1], mouthCenter = centers[2];\r\n        var distToMouth = function (pt) { return mouthCenter.sub(pt).magnitude(); };\r\n        var eyeToMouthDist = (distToMouth(leftEyeCenter) + distToMouth(rightEyeCenter)) / 2;\r\n        var size = Math.floor(eyeToMouthDist / relScale);\r\n        var refPoint = utils_1.getCenterPoint(centers);\r\n        // TODO: pad in case rectangle is out of image bounds\r\n        var x = Math.floor(Math.max(0, refPoint.x - (relX * size)));\r\n        var y = Math.floor(Math.max(0, refPoint.y - (relY * size)));\r\n        return new Rect_1.Rect(x, y, Math.min(size, this.imageWidth + x), Math.min(size, this.imageHeight + y));\r\n    };\r\n    FaceLandmarks.prototype.alignMinBbox = function (padding) {\r\n        var box = ops_1.minBbox(this.positions);\r\n        return box.pad(box.width * padding, box.height * padding);\r\n    };\r\n    FaceLandmarks.prototype.getRefPointsForAlignment = function () {\r\n        throw new Error('getRefPointsForAlignment not implemented by base class');\r\n    };\r\n    return FaceLandmarks;\r\n}());\r\nexports.FaceLandmarks = FaceLandmarks;\r\n//# sourceMappingURL=FaceLandmarks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks5.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks5.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar FaceLandmarks_1 = __webpack_require__(/*! ./FaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks.js\");\r\nvar FaceLandmarks5 = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceLandmarks5, _super);\r\n    function FaceLandmarks5() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    FaceLandmarks5.prototype.getRefPointsForAlignment = function () {\r\n        var pts = this.positions;\r\n        return [\r\n            pts[0],\r\n            pts[1],\r\n            utils_1.getCenterPoint([pts[3], pts[4]])\r\n        ];\r\n    };\r\n    return FaceLandmarks5;\r\n}(FaceLandmarks_1.FaceLandmarks));\r\nexports.FaceLandmarks5 = FaceLandmarks5;\r\n//# sourceMappingURL=FaceLandmarks5.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks5.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks68.js":
/*!****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks68.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar FaceLandmarks_1 = __webpack_require__(/*! ./FaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks.js\");\r\nvar FaceLandmarks68 = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceLandmarks68, _super);\r\n    function FaceLandmarks68() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    FaceLandmarks68.prototype.getJawOutline = function () {\r\n        return this.positions.slice(0, 17);\r\n    };\r\n    FaceLandmarks68.prototype.getLeftEyeBrow = function () {\r\n        return this.positions.slice(17, 22);\r\n    };\r\n    FaceLandmarks68.prototype.getRightEyeBrow = function () {\r\n        return this.positions.slice(22, 27);\r\n    };\r\n    FaceLandmarks68.prototype.getNose = function () {\r\n        return this.positions.slice(27, 36);\r\n    };\r\n    FaceLandmarks68.prototype.getLeftEye = function () {\r\n        return this.positions.slice(36, 42);\r\n    };\r\n    FaceLandmarks68.prototype.getRightEye = function () {\r\n        return this.positions.slice(42, 48);\r\n    };\r\n    FaceLandmarks68.prototype.getMouth = function () {\r\n        return this.positions.slice(48, 68);\r\n    };\r\n    FaceLandmarks68.prototype.getRefPointsForAlignment = function () {\r\n        return [\r\n            this.getLeftEye(),\r\n            this.getRightEye(),\r\n            this.getMouth()\r\n        ].map(utils_1.getCenterPoint);\r\n    };\r\n    return FaceLandmarks68;\r\n}(FaceLandmarks_1.FaceLandmarks));\r\nexports.FaceLandmarks68 = FaceLandmarks68;\r\n//# sourceMappingURL=FaceLandmarks68.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks68.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/FaceMatch.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/FaceMatch.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar FaceMatch = /** @class */ (function () {\r\n    function FaceMatch(label, distance) {\r\n        this._label = label;\r\n        this._distance = distance;\r\n    }\r\n    Object.defineProperty(FaceMatch.prototype, \"label\", {\r\n        get: function () { return this._label; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceMatch.prototype, \"distance\", {\r\n        get: function () { return this._distance; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    FaceMatch.prototype.toString = function (withDistance) {\r\n        if (withDistance === void 0) { withDistance = true; }\r\n        return \"\" + this.label + (withDistance ? \" (\" + utils_1.round(this.distance) + \")\" : '');\r\n    };\r\n    return FaceMatch;\r\n}());\r\nexports.FaceMatch = FaceMatch;\r\n//# sourceMappingURL=FaceMatch.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/FaceMatch.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/LabeledBox.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/LabeledBox.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar Box_1 = __webpack_require__(/*! ./Box */ \"./node_modules/face-api.js/build/commonjs/classes/Box.js\");\r\nvar LabeledBox = /** @class */ (function (_super) {\r\n    tslib_1.__extends(LabeledBox, _super);\r\n    function LabeledBox(box, label) {\r\n        var _this = _super.call(this, box) || this;\r\n        _this._label = label;\r\n        return _this;\r\n    }\r\n    LabeledBox.assertIsValidLabeledBox = function (box, callee) {\r\n        Box_1.Box.assertIsValidBox(box, callee);\r\n        if (!utils_1.isValidNumber(box.label)) {\r\n            throw new Error(callee + \" - expected property label (\" + box.label + \") to be a number\");\r\n        }\r\n    };\r\n    Object.defineProperty(LabeledBox.prototype, \"label\", {\r\n        get: function () { return this._label; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return LabeledBox;\r\n}(Box_1.Box));\r\nexports.LabeledBox = LabeledBox;\r\n//# sourceMappingURL=LabeledBox.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/LabeledBox.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/LabeledFaceDescriptors.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/LabeledFaceDescriptors.js ***!
  \***********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar LabeledFaceDescriptors = /** @class */ (function () {\r\n    function LabeledFaceDescriptors(label, descriptors) {\r\n        if (!(typeof label === 'string')) {\r\n            throw new Error('LabeledFaceDescriptors - constructor expected label to be a string');\r\n        }\r\n        if (!Array.isArray(descriptors) || descriptors.some(function (desc) { return !(desc instanceof Float32Array); })) {\r\n            throw new Error('LabeledFaceDescriptors - constructor expected descriptors to be an array of Float32Array');\r\n        }\r\n        this._label = label;\r\n        this._descriptors = descriptors;\r\n    }\r\n    Object.defineProperty(LabeledFaceDescriptors.prototype, \"label\", {\r\n        get: function () { return this._label; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(LabeledFaceDescriptors.prototype, \"descriptors\", {\r\n        get: function () { return this._descriptors; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    LabeledFaceDescriptors.prototype.toJSON = function () {\r\n        return {\r\n            label: this.label,\r\n            descriptors: this.descriptors.map(function (d) { return Array.from(d); })\r\n        };\r\n    };\r\n    LabeledFaceDescriptors.fromJSON = function (json) {\r\n        var descriptors = json.descriptors.map(function (d) {\r\n            return new Float32Array(d);\r\n        });\r\n        return new LabeledFaceDescriptors(json.label, descriptors);\r\n    };\r\n    return LabeledFaceDescriptors;\r\n}());\r\nexports.LabeledFaceDescriptors = LabeledFaceDescriptors;\r\n//# sourceMappingURL=LabeledFaceDescriptors.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/LabeledFaceDescriptors.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/ObjectDetection.js":
/*!****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/ObjectDetection.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar Box_1 = __webpack_require__(/*! ./Box */ \"./node_modules/face-api.js/build/commonjs/classes/Box.js\");\r\nvar Dimensions_1 = __webpack_require__(/*! ./Dimensions */ \"./node_modules/face-api.js/build/commonjs/classes/Dimensions.js\");\r\nvar ObjectDetection = /** @class */ (function () {\r\n    function ObjectDetection(score, classScore, className, relativeBox, imageDims) {\r\n        this._imageDims = new Dimensions_1.Dimensions(imageDims.width, imageDims.height);\r\n        this._score = score;\r\n        this._classScore = classScore;\r\n        this._className = className;\r\n        this._box = new Box_1.Box(relativeBox).rescale(this._imageDims);\r\n    }\r\n    Object.defineProperty(ObjectDetection.prototype, \"score\", {\r\n        get: function () { return this._score; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"classScore\", {\r\n        get: function () { return this._classScore; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"className\", {\r\n        get: function () { return this._className; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"box\", {\r\n        get: function () { return this._box; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"imageDims\", {\r\n        get: function () { return this._imageDims; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"imageWidth\", {\r\n        get: function () { return this.imageDims.width; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"imageHeight\", {\r\n        get: function () { return this.imageDims.height; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(ObjectDetection.prototype, \"relativeBox\", {\r\n        get: function () { return new Box_1.Box(this._box).rescale(this.imageDims.reverse()); },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    ObjectDetection.prototype.forSize = function (width, height) {\r\n        return new ObjectDetection(this.score, this.classScore, this.className, this.relativeBox, { width: width, height: height });\r\n    };\r\n    return ObjectDetection;\r\n}());\r\nexports.ObjectDetection = ObjectDetection;\r\n//# sourceMappingURL=ObjectDetection.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/ObjectDetection.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/Point.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/Point.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar Point = /** @class */ (function () {\r\n    function Point(x, y) {\r\n        this._x = x;\r\n        this._y = y;\r\n    }\r\n    Object.defineProperty(Point.prototype, \"x\", {\r\n        get: function () { return this._x; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(Point.prototype, \"y\", {\r\n        get: function () { return this._y; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Point.prototype.add = function (pt) {\r\n        return new Point(this.x + pt.x, this.y + pt.y);\r\n    };\r\n    Point.prototype.sub = function (pt) {\r\n        return new Point(this.x - pt.x, this.y - pt.y);\r\n    };\r\n    Point.prototype.mul = function (pt) {\r\n        return new Point(this.x * pt.x, this.y * pt.y);\r\n    };\r\n    Point.prototype.div = function (pt) {\r\n        return new Point(this.x / pt.x, this.y / pt.y);\r\n    };\r\n    Point.prototype.abs = function () {\r\n        return new Point(Math.abs(this.x), Math.abs(this.y));\r\n    };\r\n    Point.prototype.magnitude = function () {\r\n        return Math.sqrt(Math.pow(this.x, 2) + Math.pow(this.y, 2));\r\n    };\r\n    Point.prototype.floor = function () {\r\n        return new Point(Math.floor(this.x), Math.floor(this.y));\r\n    };\r\n    return Point;\r\n}());\r\nexports.Point = Point;\r\n//# sourceMappingURL=Point.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/Point.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/PredictedBox.js":
/*!*************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/PredictedBox.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar LabeledBox_1 = __webpack_require__(/*! ./LabeledBox */ \"./node_modules/face-api.js/build/commonjs/classes/LabeledBox.js\");\r\nvar PredictedBox = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictedBox, _super);\r\n    function PredictedBox(box, label, score, classScore) {\r\n        var _this = _super.call(this, box, label) || this;\r\n        _this._score = score;\r\n        _this._classScore = classScore;\r\n        return _this;\r\n    }\r\n    PredictedBox.assertIsValidPredictedBox = function (box, callee) {\r\n        LabeledBox_1.LabeledBox.assertIsValidLabeledBox(box, callee);\r\n        if (!utils_1.isValidProbablitiy(box.score)\r\n            || !utils_1.isValidProbablitiy(box.classScore)) {\r\n            throw new Error(callee + \" - expected properties score (\" + box.score + \") and (\" + box.classScore + \") to be a number between [0, 1]\");\r\n        }\r\n    };\r\n    Object.defineProperty(PredictedBox.prototype, \"score\", {\r\n        get: function () { return this._score; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(PredictedBox.prototype, \"classScore\", {\r\n        get: function () { return this._classScore; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return PredictedBox;\r\n}(LabeledBox_1.LabeledBox));\r\nexports.PredictedBox = PredictedBox;\r\n//# sourceMappingURL=PredictedBox.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/PredictedBox.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/Rect.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/Rect.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar Box_1 = __webpack_require__(/*! ./Box */ \"./node_modules/face-api.js/build/commonjs/classes/Box.js\");\r\nvar Rect = /** @class */ (function (_super) {\r\n    tslib_1.__extends(Rect, _super);\r\n    function Rect(x, y, width, height, allowNegativeDimensions) {\r\n        if (allowNegativeDimensions === void 0) { allowNegativeDimensions = false; }\r\n        return _super.call(this, { x: x, y: y, width: width, height: height }, allowNegativeDimensions) || this;\r\n    }\r\n    return Rect;\r\n}(Box_1.Box));\r\nexports.Rect = Rect;\r\n//# sourceMappingURL=Rect.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/Rect.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/classes/index.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/classes/index.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./BoundingBox */ \"./node_modules/face-api.js/build/commonjs/classes/BoundingBox.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./Box */ \"./node_modules/face-api.js/build/commonjs/classes/Box.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./Dimensions */ \"./node_modules/face-api.js/build/commonjs/classes/Dimensions.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceDetection */ \"./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceLandmarks5 */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks5.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceLandmarks68 */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks68.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceMatch */ \"./node_modules/face-api.js/build/commonjs/classes/FaceMatch.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./LabeledBox */ \"./node_modules/face-api.js/build/commonjs/classes/LabeledBox.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./LabeledFaceDescriptors */ \"./node_modules/face-api.js/build/commonjs/classes/LabeledFaceDescriptors.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./ObjectDetection */ \"./node_modules/face-api.js/build/commonjs/classes/ObjectDetection.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./Point */ \"./node_modules/face-api.js/build/commonjs/classes/Point.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./PredictedBox */ \"./node_modules/face-api.js/build/commonjs/classes/PredictedBox.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./Rect */ \"./node_modules/face-api.js/build/commonjs/classes/Rect.js\"), exports);\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/classes/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/convLayer.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/convLayer.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction convLayer(x, params, padding, withRelu) {\r\n    if (padding === void 0) { padding = 'same'; }\r\n    if (withRelu === void 0) { withRelu = false; }\r\n    return tf.tidy(function () {\r\n        var out = tf.add(tf.conv2d(x, params.filters, [1, 1], padding), params.bias);\r\n        return withRelu ? tf.relu(out) : out;\r\n    });\r\n}\r\nexports.convLayer = convLayer;\r\n//# sourceMappingURL=convLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/convLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/depthwiseSeparableConv.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/depthwiseSeparableConv.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction depthwiseSeparableConv(x, params, stride) {\r\n    return tf.tidy(function () {\r\n        var out = tf.separableConv2d(x, params.depthwise_filter, params.pointwise_filter, stride, 'same');\r\n        out = tf.add(out, params.bias);\r\n        return out;\r\n    });\r\n}\r\nexports.depthwiseSeparableConv = depthwiseSeparableConv;\r\n//# sourceMappingURL=depthwiseSeparableConv.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/depthwiseSeparableConv.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/disposeUnusedWeightTensors.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/disposeUnusedWeightTensors.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction disposeUnusedWeightTensors(weightMap, paramMappings) {\r\n    Object.keys(weightMap).forEach(function (path) {\r\n        if (!paramMappings.some(function (pm) { return pm.originalPath === path; })) {\r\n            weightMap[path].dispose();\r\n        }\r\n    });\r\n}\r\nexports.disposeUnusedWeightTensors = disposeUnusedWeightTensors;\r\n//# sourceMappingURL=disposeUnusedWeightTensors.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/disposeUnusedWeightTensors.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/extractConvParamsFactory.js":
/*!************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/extractConvParamsFactory.js ***!
  \************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction extractConvParamsFactory(extractWeights, paramMappings) {\r\n    return function (channelsIn, channelsOut, filterSize, mappedPrefix) {\r\n        var filters = tf.tensor4d(extractWeights(channelsIn * channelsOut * filterSize * filterSize), [filterSize, filterSize, channelsIn, channelsOut]);\r\n        var bias = tf.tensor1d(extractWeights(channelsOut));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/filters\" }, { paramPath: mappedPrefix + \"/bias\" });\r\n        return { filters: filters, bias: bias };\r\n    };\r\n}\r\nexports.extractConvParamsFactory = extractConvParamsFactory;\r\n//# sourceMappingURL=extractConvParamsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/extractConvParamsFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/extractFCParamsFactory.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/extractFCParamsFactory.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction extractFCParamsFactory(extractWeights, paramMappings) {\r\n    return function (channelsIn, channelsOut, mappedPrefix) {\r\n        var fc_weights = tf.tensor2d(extractWeights(channelsIn * channelsOut), [channelsIn, channelsOut]);\r\n        var fc_bias = tf.tensor1d(extractWeights(channelsOut));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/weights\" }, { paramPath: mappedPrefix + \"/bias\" });\r\n        return {\r\n            weights: fc_weights,\r\n            bias: fc_bias\r\n        };\r\n    };\r\n}\r\nexports.extractFCParamsFactory = extractFCParamsFactory;\r\n//# sourceMappingURL=extractFCParamsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/extractFCParamsFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/extractSeparableConvParamsFactory.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/extractSeparableConvParamsFactory.js ***!
  \*********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar types_1 = __webpack_require__(/*! ./types */ \"./node_modules/face-api.js/build/commonjs/common/types.js\");\r\nfunction extractSeparableConvParamsFactory(extractWeights, paramMappings) {\r\n    return function (channelsIn, channelsOut, mappedPrefix) {\r\n        var depthwise_filter = tf.tensor4d(extractWeights(3 * 3 * channelsIn), [3, 3, channelsIn, 1]);\r\n        var pointwise_filter = tf.tensor4d(extractWeights(channelsIn * channelsOut), [1, 1, channelsIn, channelsOut]);\r\n        var bias = tf.tensor1d(extractWeights(channelsOut));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/depthwise_filter\" }, { paramPath: mappedPrefix + \"/pointwise_filter\" }, { paramPath: mappedPrefix + \"/bias\" });\r\n        return new types_1.SeparableConvParams(depthwise_filter, pointwise_filter, bias);\r\n    };\r\n}\r\nexports.extractSeparableConvParamsFactory = extractSeparableConvParamsFactory;\r\nfunction loadSeparableConvParamsFactory(extractWeightEntry) {\r\n    return function (prefix) {\r\n        var depthwise_filter = extractWeightEntry(prefix + \"/depthwise_filter\", 4);\r\n        var pointwise_filter = extractWeightEntry(prefix + \"/pointwise_filter\", 4);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return new types_1.SeparableConvParams(depthwise_filter, pointwise_filter, bias);\r\n    };\r\n}\r\nexports.loadSeparableConvParamsFactory = loadSeparableConvParamsFactory;\r\n//# sourceMappingURL=extractSeparableConvParamsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/extractSeparableConvParamsFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/extractWeightEntryFactory.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/extractWeightEntryFactory.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nfunction extractWeightEntryFactory(weightMap, paramMappings) {\r\n    return function (originalPath, paramRank, mappedPath) {\r\n        var tensor = weightMap[originalPath];\r\n        if (!utils_1.isTensor(tensor, paramRank)) {\r\n            throw new Error(\"expected weightMap[\" + originalPath + \"] to be a Tensor\" + paramRank + \"D, instead have \" + tensor);\r\n        }\r\n        paramMappings.push({ originalPath: originalPath, paramPath: mappedPath || originalPath });\r\n        return tensor;\r\n    };\r\n}\r\nexports.extractWeightEntryFactory = extractWeightEntryFactory;\r\n//# sourceMappingURL=extractWeightEntryFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/extractWeightEntryFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/extractWeightsFactory.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/extractWeightsFactory.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction extractWeightsFactory(weights) {\r\n    var remainingWeights = weights;\r\n    function extractWeights(numWeights) {\r\n        var ret = remainingWeights.slice(0, numWeights);\r\n        remainingWeights = remainingWeights.slice(numWeights);\r\n        return ret;\r\n    }\r\n    function getRemainingWeights() {\r\n        return remainingWeights;\r\n    }\r\n    return {\r\n        extractWeights: extractWeights,\r\n        getRemainingWeights: getRemainingWeights\r\n    };\r\n}\r\nexports.extractWeightsFactory = extractWeightsFactory;\r\n//# sourceMappingURL=extractWeightsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/extractWeightsFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/fullyConnectedLayer.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/fullyConnectedLayer.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction fullyConnectedLayer(x, params) {\r\n    return tf.tidy(function () {\r\n        return tf.add(tf.matMul(x, params.weights), params.bias);\r\n    });\r\n}\r\nexports.fullyConnectedLayer = fullyConnectedLayer;\r\n//# sourceMappingURL=fullyConnectedLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/fullyConnectedLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/getModelUris.js":
/*!************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/getModelUris.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction getModelUris(uri, defaultModelName) {\r\n    var defaultManifestFilename = defaultModelName + \"-weights_manifest.json\";\r\n    if (!uri) {\r\n        return {\r\n            modelBaseUri: '',\r\n            manifestUri: defaultManifestFilename\r\n        };\r\n    }\r\n    if (uri === '/') {\r\n        return {\r\n            modelBaseUri: '/',\r\n            manifestUri: \"/\" + defaultManifestFilename\r\n        };\r\n    }\r\n    var protocol = uri.startsWith('http://') ? 'http://' : uri.startsWith('https://') ? 'https://' : '';\r\n    uri = uri.replace(protocol, '');\r\n    var parts = uri.split('/').filter(function (s) { return s; });\r\n    var manifestFile = uri.endsWith('.json')\r\n        ? parts[parts.length - 1]\r\n        : defaultManifestFilename;\r\n    var modelBaseUri = protocol + (uri.endsWith('.json') ? parts.slice(0, parts.length - 1) : parts).join('/');\r\n    modelBaseUri = uri.startsWith('/') ? \"/\" + modelBaseUri : modelBaseUri;\r\n    return {\r\n        modelBaseUri: modelBaseUri,\r\n        manifestUri: modelBaseUri === '/' ? \"/\" + manifestFile : modelBaseUri + \"/\" + manifestFile\r\n    };\r\n}\r\nexports.getModelUris = getModelUris;\r\n//# sourceMappingURL=getModelUris.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/getModelUris.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/index.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./convLayer */ \"./node_modules/face-api.js/build/commonjs/common/convLayer.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./depthwiseSeparableConv */ \"./node_modules/face-api.js/build/commonjs/common/depthwiseSeparableConv.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./disposeUnusedWeightTensors */ \"./node_modules/face-api.js/build/commonjs/common/disposeUnusedWeightTensors.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./extractConvParamsFactory */ \"./node_modules/face-api.js/build/commonjs/common/extractConvParamsFactory.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./extractFCParamsFactory */ \"./node_modules/face-api.js/build/commonjs/common/extractFCParamsFactory.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./extractSeparableConvParamsFactory */ \"./node_modules/face-api.js/build/commonjs/common/extractSeparableConvParamsFactory.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./extractWeightEntryFactory */ \"./node_modules/face-api.js/build/commonjs/common/extractWeightEntryFactory.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./extractWeightsFactory */ \"./node_modules/face-api.js/build/commonjs/common/extractWeightsFactory.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./getModelUris */ \"./node_modules/face-api.js/build/commonjs/common/getModelUris.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./types */ \"./node_modules/face-api.js/build/commonjs/common/types.js\"), exports);\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/loadConvParamsFactory.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/loadConvParamsFactory.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction loadConvParamsFactory(extractWeightEntry) {\r\n    return function (prefix) {\r\n        var filters = extractWeightEntry(prefix + \"/filters\", 4);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { filters: filters, bias: bias };\r\n    };\r\n}\r\nexports.loadConvParamsFactory = loadConvParamsFactory;\r\n//# sourceMappingURL=loadConvParamsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/loadConvParamsFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/common/types.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/common/types.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar SeparableConvParams = /** @class */ (function () {\r\n    function SeparableConvParams(depthwise_filter, pointwise_filter, bias) {\r\n        this.depthwise_filter = depthwise_filter;\r\n        this.pointwise_filter = pointwise_filter;\r\n        this.bias = bias;\r\n    }\r\n    return SeparableConvParams;\r\n}());\r\nexports.SeparableConvParams = SeparableConvParams;\r\n//# sourceMappingURL=types.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/common/types.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/NetInput.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/NetInput.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nvar padToSquare_1 = __webpack_require__(/*! ../ops/padToSquare */ \"./node_modules/face-api.js/build/commonjs/ops/padToSquare.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar createCanvas_1 = __webpack_require__(/*! ./createCanvas */ \"./node_modules/face-api.js/build/commonjs/dom/createCanvas.js\");\r\nvar imageToSquare_1 = __webpack_require__(/*! ./imageToSquare */ \"./node_modules/face-api.js/build/commonjs/dom/imageToSquare.js\");\r\nvar NetInput = /** @class */ (function () {\r\n    function NetInput(inputs, treatAsBatchInput) {\r\n        var _this = this;\r\n        if (treatAsBatchInput === void 0) { treatAsBatchInput = false; }\r\n        this._imageTensors = [];\r\n        this._canvases = [];\r\n        this._treatAsBatchInput = false;\r\n        this._inputDimensions = [];\r\n        if (!Array.isArray(inputs)) {\r\n            throw new Error(\"NetInput.constructor - expected inputs to be an Array of TResolvedNetInput or to be instanceof tf.Tensor4D, instead have \" + inputs);\r\n        }\r\n        this._treatAsBatchInput = treatAsBatchInput;\r\n        this._batchSize = inputs.length;\r\n        inputs.forEach(function (input, idx) {\r\n            if (utils_1.isTensor3D(input)) {\r\n                _this._imageTensors[idx] = input;\r\n                _this._inputDimensions[idx] = input.shape;\r\n                return;\r\n            }\r\n            if (utils_1.isTensor4D(input)) {\r\n                var batchSize = input.shape[0];\r\n                if (batchSize !== 1) {\r\n                    throw new Error(\"NetInput - tf.Tensor4D with batchSize \" + batchSize + \" passed, but not supported in input array\");\r\n                }\r\n                _this._imageTensors[idx] = input;\r\n                _this._inputDimensions[idx] = input.shape.slice(1);\r\n                return;\r\n            }\r\n            var canvas = input instanceof env_1.env.getEnv().Canvas ? input : createCanvas_1.createCanvasFromMedia(input);\r\n            _this._canvases[idx] = canvas;\r\n            _this._inputDimensions[idx] = [canvas.height, canvas.width, 3];\r\n        });\r\n    }\r\n    Object.defineProperty(NetInput.prototype, \"imageTensors\", {\r\n        get: function () {\r\n            return this._imageTensors;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"canvases\", {\r\n        get: function () {\r\n            return this._canvases;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"isBatchInput\", {\r\n        get: function () {\r\n            return this.batchSize > 1 || this._treatAsBatchInput;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"batchSize\", {\r\n        get: function () {\r\n            return this._batchSize;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"inputDimensions\", {\r\n        get: function () {\r\n            return this._inputDimensions;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"inputSize\", {\r\n        get: function () {\r\n            return this._inputSize;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(NetInput.prototype, \"reshapedInputDimensions\", {\r\n        get: function () {\r\n            var _this = this;\r\n            return utils_1.range(this.batchSize, 0, 1).map(function (_, batchIdx) { return _this.getReshapedInputDimensions(batchIdx); });\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    NetInput.prototype.getInput = function (batchIdx) {\r\n        return this.canvases[batchIdx] || this.imageTensors[batchIdx];\r\n    };\r\n    NetInput.prototype.getInputDimensions = function (batchIdx) {\r\n        return this._inputDimensions[batchIdx];\r\n    };\r\n    NetInput.prototype.getInputHeight = function (batchIdx) {\r\n        return this._inputDimensions[batchIdx][0];\r\n    };\r\n    NetInput.prototype.getInputWidth = function (batchIdx) {\r\n        return this._inputDimensions[batchIdx][1];\r\n    };\r\n    NetInput.prototype.getReshapedInputDimensions = function (batchIdx) {\r\n        if (typeof this.inputSize !== 'number') {\r\n            throw new Error('getReshapedInputDimensions - inputSize not set, toBatchTensor has not been called yet');\r\n        }\r\n        var width = this.getInputWidth(batchIdx);\r\n        var height = this.getInputHeight(batchIdx);\r\n        return utils_1.computeReshapedDimensions({ width: width, height: height }, this.inputSize);\r\n    };\r\n    /**\r\n     * Create a batch tensor from all input canvases and tensors\r\n     * with size [batchSize, inputSize, inputSize, 3].\r\n     *\r\n     * @param inputSize Height and width of the tensor.\r\n     * @param isCenterImage (optional, default: false) If true, add an equal amount of padding on\r\n     * both sides of the minor dimension oof the image.\r\n     * @returns The batch tensor.\r\n     */\r\n    NetInput.prototype.toBatchTensor = function (inputSize, isCenterInputs) {\r\n        var _this = this;\r\n        if (isCenterInputs === void 0) { isCenterInputs = true; }\r\n        this._inputSize = inputSize;\r\n        return tf.tidy(function () {\r\n            var inputTensors = utils_1.range(_this.batchSize, 0, 1).map(function (batchIdx) {\r\n                var input = _this.getInput(batchIdx);\r\n                if (input instanceof tf.Tensor) {\r\n                    var imgTensor = utils_1.isTensor4D(input) ? input : input.expandDims();\r\n                    imgTensor = padToSquare_1.padToSquare(imgTensor, isCenterInputs);\r\n                    if (imgTensor.shape[1] !== inputSize || imgTensor.shape[2] !== inputSize) {\r\n                        imgTensor = tf.image.resizeBilinear(imgTensor, [inputSize, inputSize]);\r\n                    }\r\n                    return imgTensor.as3D(inputSize, inputSize, 3);\r\n                }\r\n                if (input instanceof env_1.env.getEnv().Canvas) {\r\n                    return tf.browser.fromPixels(imageToSquare_1.imageToSquare(input, inputSize, isCenterInputs));\r\n                }\r\n                throw new Error(\"toBatchTensor - at batchIdx \" + batchIdx + \", expected input to be instanceof tf.Tensor or instanceof HTMLCanvasElement, instead have \" + input);\r\n            });\r\n            var batchTensor = tf.stack(inputTensors.map(function (t) { return t.toFloat(); })).as4D(_this.batchSize, inputSize, inputSize, 3);\r\n            return batchTensor;\r\n        });\r\n    };\r\n    return NetInput;\r\n}());\r\nexports.NetInput = NetInput;\r\n//# sourceMappingURL=NetInput.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/NetInput.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/awaitMediaLoaded.js":
/*!*************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/awaitMediaLoaded.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nvar isMediaLoaded_1 = __webpack_require__(/*! ./isMediaLoaded */ \"./node_modules/face-api.js/build/commonjs/dom/isMediaLoaded.js\");\r\nfunction awaitMediaLoaded(media) {\r\n    return new Promise(function (resolve, reject) {\r\n        if (media instanceof env_1.env.getEnv().Canvas || isMediaLoaded_1.isMediaLoaded(media)) {\r\n            return resolve();\r\n        }\r\n        function onLoad(e) {\r\n            if (!e.currentTarget)\r\n                return;\r\n            e.currentTarget.removeEventListener('load', onLoad);\r\n            e.currentTarget.removeEventListener('error', onError);\r\n            resolve(e);\r\n        }\r\n        function onError(e) {\r\n            if (!e.currentTarget)\r\n                return;\r\n            e.currentTarget.removeEventListener('load', onLoad);\r\n            e.currentTarget.removeEventListener('error', onError);\r\n            reject(e);\r\n        }\r\n        media.addEventListener('load', onLoad);\r\n        media.addEventListener('error', onError);\r\n    });\r\n}\r\nexports.awaitMediaLoaded = awaitMediaLoaded;\r\n//# sourceMappingURL=awaitMediaLoaded.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/awaitMediaLoaded.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/bufferToImage.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/bufferToImage.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nfunction bufferToImage(buf) {\r\n    return new Promise(function (resolve, reject) {\r\n        if (!(buf instanceof Blob)) {\r\n            return reject('bufferToImage - expected buf to be of type: Blob');\r\n        }\r\n        var reader = new FileReader();\r\n        reader.onload = function () {\r\n            if (typeof reader.result !== 'string') {\r\n                return reject('bufferToImage - expected reader.result to be a string, in onload');\r\n            }\r\n            var img = env_1.env.getEnv().createImageElement();\r\n            img.onload = function () { return resolve(img); };\r\n            img.onerror = reject;\r\n            img.src = reader.result;\r\n        };\r\n        reader.onerror = reject;\r\n        reader.readAsDataURL(buf);\r\n    });\r\n}\r\nexports.bufferToImage = bufferToImage;\r\n//# sourceMappingURL=bufferToImage.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/bufferToImage.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/createCanvas.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/createCanvas.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nvar getContext2dOrThrow_1 = __webpack_require__(/*! ./getContext2dOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/getContext2dOrThrow.js\");\r\nvar getMediaDimensions_1 = __webpack_require__(/*! ./getMediaDimensions */ \"./node_modules/face-api.js/build/commonjs/dom/getMediaDimensions.js\");\r\nvar isMediaLoaded_1 = __webpack_require__(/*! ./isMediaLoaded */ \"./node_modules/face-api.js/build/commonjs/dom/isMediaLoaded.js\");\r\nfunction createCanvas(_a) {\r\n    var width = _a.width, height = _a.height;\r\n    var createCanvasElement = env_1.env.getEnv().createCanvasElement;\r\n    var canvas = createCanvasElement();\r\n    canvas.width = width;\r\n    canvas.height = height;\r\n    return canvas;\r\n}\r\nexports.createCanvas = createCanvas;\r\nfunction createCanvasFromMedia(media, dims) {\r\n    var ImageData = env_1.env.getEnv().ImageData;\r\n    if (!(media instanceof ImageData) && !isMediaLoaded_1.isMediaLoaded(media)) {\r\n        throw new Error('createCanvasFromMedia - media has not finished loading yet');\r\n    }\r\n    var _a = dims || getMediaDimensions_1.getMediaDimensions(media), width = _a.width, height = _a.height;\r\n    var canvas = createCanvas({ width: width, height: height });\r\n    if (media instanceof ImageData) {\r\n        getContext2dOrThrow_1.getContext2dOrThrow(canvas).putImageData(media, 0, 0);\r\n    }\r\n    else {\r\n        getContext2dOrThrow_1.getContext2dOrThrow(canvas).drawImage(media, 0, 0, width, height);\r\n    }\r\n    return canvas;\r\n}\r\nexports.createCanvasFromMedia = createCanvasFromMedia;\r\n//# sourceMappingURL=createCanvas.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/createCanvas.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/extractFaceTensors.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/extractFaceTensors.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar FaceDetection_1 = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\n/**\r\n * Extracts the tensors of the image regions containing the detected faces.\r\n * Useful if you want to compute the face descriptors for the face images.\r\n * Using this method is faster then extracting a canvas for each face and\r\n * converting them to tensors individually.\r\n *\r\n * @param imageTensor The image tensor that face detection has been performed on.\r\n * @param detections The face detection results or face bounding boxes for that image.\r\n * @returns Tensors of the corresponding image region for each detected face.\r\n */\r\nfunction extractFaceTensors(imageTensor, detections) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        return tslib_1.__generator(this, function (_a) {\r\n            if (!utils_1.isTensor3D(imageTensor) && !utils_1.isTensor4D(imageTensor)) {\r\n                throw new Error('extractFaceTensors - expected image tensor to be 3D or 4D');\r\n            }\r\n            if (utils_1.isTensor4D(imageTensor) && imageTensor.shape[0] > 1) {\r\n                throw new Error('extractFaceTensors - batchSize > 1 not supported');\r\n            }\r\n            return [2 /*return*/, tf.tidy(function () {\r\n                    var _a = imageTensor.shape.slice(utils_1.isTensor4D(imageTensor) ? 1 : 0), imgHeight = _a[0], imgWidth = _a[1], numChannels = _a[2];\r\n                    var boxes = detections.map(function (det) { return det instanceof FaceDetection_1.FaceDetection\r\n                        ? det.forSize(imgWidth, imgHeight).box\r\n                        : det; })\r\n                        .map(function (box) { return box.clipAtImageBorders(imgWidth, imgHeight); });\r\n                    var faceTensors = boxes.map(function (_a) {\r\n                        var x = _a.x, y = _a.y, width = _a.width, height = _a.height;\r\n                        return tf.slice3d(imageTensor.as3D(imgHeight, imgWidth, numChannels), [y, x, 0], [height, width, numChannels]);\r\n                    });\r\n                    return faceTensors;\r\n                })];\r\n        });\r\n    });\r\n}\r\nexports.extractFaceTensors = extractFaceTensors;\r\n//# sourceMappingURL=extractFaceTensors.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/extractFaceTensors.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/extractFaces.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/extractFaces.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar FaceDetection_1 = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js\");\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nvar createCanvas_1 = __webpack_require__(/*! ./createCanvas */ \"./node_modules/face-api.js/build/commonjs/dom/createCanvas.js\");\r\nvar getContext2dOrThrow_1 = __webpack_require__(/*! ./getContext2dOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/getContext2dOrThrow.js\");\r\nvar imageTensorToCanvas_1 = __webpack_require__(/*! ./imageTensorToCanvas */ \"./node_modules/face-api.js/build/commonjs/dom/imageTensorToCanvas.js\");\r\nvar toNetInput_1 = __webpack_require__(/*! ./toNetInput */ \"./node_modules/face-api.js/build/commonjs/dom/toNetInput.js\");\r\n/**\r\n * Extracts the image regions containing the detected faces.\r\n *\r\n * @param input The image that face detection has been performed on.\r\n * @param detections The face detection results or face bounding boxes for that image.\r\n * @returns The Canvases of the corresponding image region for each detected face.\r\n */\r\nfunction extractFaces(input, detections) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var Canvas, canvas, netInput, tensorOrCanvas, _a, ctx, boxes;\r\n        return tslib_1.__generator(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0:\r\n                    Canvas = env_1.env.getEnv().Canvas;\r\n                    canvas = input;\r\n                    if (!!(input instanceof Canvas)) return [3 /*break*/, 5];\r\n                    return [4 /*yield*/, toNetInput_1.toNetInput(input)];\r\n                case 1:\r\n                    netInput = _b.sent();\r\n                    if (netInput.batchSize > 1) {\r\n                        throw new Error('extractFaces - batchSize > 1 not supported');\r\n                    }\r\n                    tensorOrCanvas = netInput.getInput(0);\r\n                    if (!(tensorOrCanvas instanceof Canvas)) return [3 /*break*/, 2];\r\n                    _a = tensorOrCanvas;\r\n                    return [3 /*break*/, 4];\r\n                case 2: return [4 /*yield*/, imageTensorToCanvas_1.imageTensorToCanvas(tensorOrCanvas)];\r\n                case 3:\r\n                    _a = _b.sent();\r\n                    _b.label = 4;\r\n                case 4:\r\n                    canvas = _a;\r\n                    _b.label = 5;\r\n                case 5:\r\n                    ctx = getContext2dOrThrow_1.getContext2dOrThrow(canvas);\r\n                    boxes = detections.map(function (det) { return det instanceof FaceDetection_1.FaceDetection\r\n                        ? det.forSize(canvas.width, canvas.height).box.floor()\r\n                        : det; })\r\n                        .map(function (box) { return box.clipAtImageBorders(canvas.width, canvas.height); });\r\n                    return [2 /*return*/, boxes.map(function (_a) {\r\n                            var x = _a.x, y = _a.y, width = _a.width, height = _a.height;\r\n                            var faceImg = createCanvas_1.createCanvas({ width: width, height: height });\r\n                            getContext2dOrThrow_1.getContext2dOrThrow(faceImg)\r\n                                .putImageData(ctx.getImageData(x, y, width, height), 0, 0);\r\n                            return faceImg;\r\n                        })];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.extractFaces = extractFaces;\r\n//# sourceMappingURL=extractFaces.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/extractFaces.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/fetchImage.js":
/*!*******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/fetchImage.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar bufferToImage_1 = __webpack_require__(/*! ./bufferToImage */ \"./node_modules/face-api.js/build/commonjs/dom/bufferToImage.js\");\r\nvar fetchOrThrow_1 = __webpack_require__(/*! ./fetchOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/fetchOrThrow.js\");\r\nfunction fetchImage(uri) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var res, blob;\r\n        return tslib_1.__generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0: return [4 /*yield*/, fetchOrThrow_1.fetchOrThrow(uri)];\r\n                case 1:\r\n                    res = _a.sent();\r\n                    return [4 /*yield*/, (res).blob()];\r\n                case 2:\r\n                    blob = _a.sent();\r\n                    if (!blob.type.startsWith('image/')) {\r\n                        throw new Error(\"fetchImage - expected blob type to be of type image/*, instead have: \" + blob.type + \", for url: \" + res.url);\r\n                    }\r\n                    return [2 /*return*/, bufferToImage_1.bufferToImage(blob)];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.fetchImage = fetchImage;\r\n//# sourceMappingURL=fetchImage.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/fetchImage.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/fetchJson.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/fetchJson.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar fetchOrThrow_1 = __webpack_require__(/*! ./fetchOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/fetchOrThrow.js\");\r\nfunction fetchJson(uri) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        return tslib_1.__generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0: return [4 /*yield*/, fetchOrThrow_1.fetchOrThrow(uri)];\r\n                case 1: return [2 /*return*/, (_a.sent()).json()];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.fetchJson = fetchJson;\r\n//# sourceMappingURL=fetchJson.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/fetchJson.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/fetchNetWeights.js":
/*!************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/fetchNetWeights.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar fetchOrThrow_1 = __webpack_require__(/*! ./fetchOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/fetchOrThrow.js\");\r\nfunction fetchNetWeights(uri) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var _a;\r\n        return tslib_1.__generator(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0:\r\n                    _a = Float32Array.bind;\r\n                    return [4 /*yield*/, fetchOrThrow_1.fetchOrThrow(uri)];\r\n                case 1: return [4 /*yield*/, (_b.sent()).arrayBuffer()];\r\n                case 2: return [2 /*return*/, new (_a.apply(Float32Array, [void 0, _b.sent()]))()];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.fetchNetWeights = fetchNetWeights;\r\n//# sourceMappingURL=fetchNetWeights.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/fetchNetWeights.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/fetchOrThrow.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/fetchOrThrow.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nfunction fetchOrThrow(url, init) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var fetch, res;\r\n        return tslib_1.__generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    fetch = env_1.env.getEnv().fetch;\r\n                    return [4 /*yield*/, fetch(url, init)];\r\n                case 1:\r\n                    res = _a.sent();\r\n                    if (!(res.status < 400)) {\r\n                        throw new Error(\"failed to fetch: (\" + res.status + \") \" + res.statusText + \", from url: \" + res.url);\r\n                    }\r\n                    return [2 /*return*/, res];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.fetchOrThrow = fetchOrThrow;\r\n//# sourceMappingURL=fetchOrThrow.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/fetchOrThrow.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/getContext2dOrThrow.js":
/*!****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/getContext2dOrThrow.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nvar resolveInput_1 = __webpack_require__(/*! ./resolveInput */ \"./node_modules/face-api.js/build/commonjs/dom/resolveInput.js\");\r\nfunction getContext2dOrThrow(canvasArg) {\r\n    var _a = env_1.env.getEnv(), Canvas = _a.Canvas, CanvasRenderingContext2D = _a.CanvasRenderingContext2D;\r\n    if (canvasArg instanceof CanvasRenderingContext2D) {\r\n        return canvasArg;\r\n    }\r\n    var canvas = resolveInput_1.resolveInput(canvasArg);\r\n    if (!(canvas instanceof Canvas)) {\r\n        throw new Error('resolveContext2d - expected canvas to be of instance of Canvas');\r\n    }\r\n    var ctx = canvas.getContext('2d');\r\n    if (!ctx) {\r\n        throw new Error('resolveContext2d - canvas 2d context is null');\r\n    }\r\n    return ctx;\r\n}\r\nexports.getContext2dOrThrow = getContext2dOrThrow;\r\n//# sourceMappingURL=getContext2dOrThrow.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/getContext2dOrThrow.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/getMediaDimensions.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/getMediaDimensions.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar Dimensions_1 = __webpack_require__(/*! ../classes/Dimensions */ \"./node_modules/face-api.js/build/commonjs/classes/Dimensions.js\");\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nfunction getMediaDimensions(input) {\r\n    var _a = env_1.env.getEnv(), Image = _a.Image, Video = _a.Video;\r\n    if (input instanceof Image) {\r\n        return new Dimensions_1.Dimensions(input.naturalWidth, input.naturalHeight);\r\n    }\r\n    if (input instanceof Video) {\r\n        return new Dimensions_1.Dimensions(input.videoWidth, input.videoHeight);\r\n    }\r\n    return new Dimensions_1.Dimensions(input.width, input.height);\r\n}\r\nexports.getMediaDimensions = getMediaDimensions;\r\n//# sourceMappingURL=getMediaDimensions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/getMediaDimensions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/imageTensorToCanvas.js":
/*!****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/imageTensorToCanvas.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nfunction imageTensorToCanvas(imgTensor, canvas) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var targetCanvas, _a, height, width, numChannels, imgTensor3D;\r\n        return tslib_1.__generator(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0:\r\n                    targetCanvas = canvas || env_1.env.getEnv().createCanvasElement();\r\n                    _a = imgTensor.shape.slice(utils_1.isTensor4D(imgTensor) ? 1 : 0), height = _a[0], width = _a[1], numChannels = _a[2];\r\n                    imgTensor3D = tf.tidy(function () { return imgTensor.as3D(height, width, numChannels).toInt(); });\r\n                    return [4 /*yield*/, tf.browser.toPixels(imgTensor3D, targetCanvas)];\r\n                case 1:\r\n                    _b.sent();\r\n                    imgTensor3D.dispose();\r\n                    return [2 /*return*/, targetCanvas];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.imageTensorToCanvas = imageTensorToCanvas;\r\n//# sourceMappingURL=imageTensorToCanvas.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/imageTensorToCanvas.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/imageToSquare.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/imageToSquare.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nvar createCanvas_1 = __webpack_require__(/*! ./createCanvas */ \"./node_modules/face-api.js/build/commonjs/dom/createCanvas.js\");\r\nvar getContext2dOrThrow_1 = __webpack_require__(/*! ./getContext2dOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/getContext2dOrThrow.js\");\r\nvar getMediaDimensions_1 = __webpack_require__(/*! ./getMediaDimensions */ \"./node_modules/face-api.js/build/commonjs/dom/getMediaDimensions.js\");\r\nfunction imageToSquare(input, inputSize, centerImage) {\r\n    if (centerImage === void 0) { centerImage = false; }\r\n    var _a = env_1.env.getEnv(), Image = _a.Image, Canvas = _a.Canvas;\r\n    if (!(input instanceof Image || input instanceof Canvas)) {\r\n        throw new Error('imageToSquare - expected arg0 to be HTMLImageElement | HTMLCanvasElement');\r\n    }\r\n    var dims = getMediaDimensions_1.getMediaDimensions(input);\r\n    var scale = inputSize / Math.max(dims.height, dims.width);\r\n    var width = scale * dims.width;\r\n    var height = scale * dims.height;\r\n    var targetCanvas = createCanvas_1.createCanvas({ width: inputSize, height: inputSize });\r\n    var inputCanvas = input instanceof Canvas ? input : createCanvas_1.createCanvasFromMedia(input);\r\n    var offset = Math.abs(width - height) / 2;\r\n    var dx = centerImage && width < height ? offset : 0;\r\n    var dy = centerImage && height < width ? offset : 0;\r\n    getContext2dOrThrow_1.getContext2dOrThrow(targetCanvas).drawImage(inputCanvas, dx, dy, width, height);\r\n    return targetCanvas;\r\n}\r\nexports.imageToSquare = imageToSquare;\r\n//# sourceMappingURL=imageToSquare.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/imageToSquare.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/index.js":
/*!**************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/index.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./awaitMediaLoaded */ \"./node_modules/face-api.js/build/commonjs/dom/awaitMediaLoaded.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./bufferToImage */ \"./node_modules/face-api.js/build/commonjs/dom/bufferToImage.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./createCanvas */ \"./node_modules/face-api.js/build/commonjs/dom/createCanvas.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./extractFaces */ \"./node_modules/face-api.js/build/commonjs/dom/extractFaces.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./extractFaceTensors */ \"./node_modules/face-api.js/build/commonjs/dom/extractFaceTensors.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./fetchImage */ \"./node_modules/face-api.js/build/commonjs/dom/fetchImage.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./fetchJson */ \"./node_modules/face-api.js/build/commonjs/dom/fetchJson.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./fetchNetWeights */ \"./node_modules/face-api.js/build/commonjs/dom/fetchNetWeights.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./fetchOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/fetchOrThrow.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./getContext2dOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/getContext2dOrThrow.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./getMediaDimensions */ \"./node_modules/face-api.js/build/commonjs/dom/getMediaDimensions.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./imageTensorToCanvas */ \"./node_modules/face-api.js/build/commonjs/dom/imageTensorToCanvas.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./imageToSquare */ \"./node_modules/face-api.js/build/commonjs/dom/imageToSquare.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./isMediaElement */ \"./node_modules/face-api.js/build/commonjs/dom/isMediaElement.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./isMediaLoaded */ \"./node_modules/face-api.js/build/commonjs/dom/isMediaLoaded.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./loadWeightMap */ \"./node_modules/face-api.js/build/commonjs/dom/loadWeightMap.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./matchDimensions */ \"./node_modules/face-api.js/build/commonjs/dom/matchDimensions.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./NetInput */ \"./node_modules/face-api.js/build/commonjs/dom/NetInput.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./resolveInput */ \"./node_modules/face-api.js/build/commonjs/dom/resolveInput.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./toNetInput */ \"./node_modules/face-api.js/build/commonjs/dom/toNetInput.js\"), exports);\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/isMediaElement.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/isMediaElement.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nfunction isMediaElement(input) {\r\n    var _a = env_1.env.getEnv(), Image = _a.Image, Canvas = _a.Canvas, Video = _a.Video;\r\n    return input instanceof Image\r\n        || input instanceof Canvas\r\n        || input instanceof Video;\r\n}\r\nexports.isMediaElement = isMediaElement;\r\n//# sourceMappingURL=isMediaElement.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/isMediaElement.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/isMediaLoaded.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/isMediaLoaded.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nfunction isMediaLoaded(media) {\r\n    var _a = env_1.env.getEnv(), Image = _a.Image, Video = _a.Video;\r\n    return (media instanceof Image && media.complete)\r\n        || (media instanceof Video && media.readyState >= 3);\r\n}\r\nexports.isMediaLoaded = isMediaLoaded;\r\n//# sourceMappingURL=isMediaLoaded.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/isMediaLoaded.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/loadWeightMap.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/loadWeightMap.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar getModelUris_1 = __webpack_require__(/*! ../common/getModelUris */ \"./node_modules/face-api.js/build/commonjs/common/getModelUris.js\");\r\nvar fetchJson_1 = __webpack_require__(/*! ./fetchJson */ \"./node_modules/face-api.js/build/commonjs/dom/fetchJson.js\");\r\nfunction loadWeightMap(uri, defaultModelName) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var _a, manifestUri, modelBaseUri, manifest;\r\n        return tslib_1.__generator(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0:\r\n                    _a = getModelUris_1.getModelUris(uri, defaultModelName), manifestUri = _a.manifestUri, modelBaseUri = _a.modelBaseUri;\r\n                    return [4 /*yield*/, fetchJson_1.fetchJson(manifestUri)];\r\n                case 1:\r\n                    manifest = _b.sent();\r\n                    return [2 /*return*/, tf.io.loadWeights(manifest, modelBaseUri)];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.loadWeightMap = loadWeightMap;\r\n//# sourceMappingURL=loadWeightMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/loadWeightMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/matchDimensions.js":
/*!************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/matchDimensions.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar getMediaDimensions_1 = __webpack_require__(/*! ./getMediaDimensions */ \"./node_modules/face-api.js/build/commonjs/dom/getMediaDimensions.js\");\r\nfunction matchDimensions(input, reference, useMediaDimensions) {\r\n    if (useMediaDimensions === void 0) { useMediaDimensions = false; }\r\n    var _a = useMediaDimensions\r\n        ? getMediaDimensions_1.getMediaDimensions(reference)\r\n        : reference, width = _a.width, height = _a.height;\r\n    input.width = width;\r\n    input.height = height;\r\n    return { width: width, height: height };\r\n}\r\nexports.matchDimensions = matchDimensions;\r\n//# sourceMappingURL=matchDimensions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/matchDimensions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/resolveInput.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/resolveInput.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nfunction resolveInput(arg) {\r\n    if (!env_1.env.isNodejs() && typeof arg === 'string') {\r\n        return document.getElementById(arg);\r\n    }\r\n    return arg;\r\n}\r\nexports.resolveInput = resolveInput;\r\n//# sourceMappingURL=resolveInput.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/resolveInput.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/dom/toNetInput.js":
/*!*******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/dom/toNetInput.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar awaitMediaLoaded_1 = __webpack_require__(/*! ./awaitMediaLoaded */ \"./node_modules/face-api.js/build/commonjs/dom/awaitMediaLoaded.js\");\r\nvar isMediaElement_1 = __webpack_require__(/*! ./isMediaElement */ \"./node_modules/face-api.js/build/commonjs/dom/isMediaElement.js\");\r\nvar NetInput_1 = __webpack_require__(/*! ./NetInput */ \"./node_modules/face-api.js/build/commonjs/dom/NetInput.js\");\r\nvar resolveInput_1 = __webpack_require__(/*! ./resolveInput */ \"./node_modules/face-api.js/build/commonjs/dom/resolveInput.js\");\r\n/**\r\n * Validates the input to make sure, they are valid net inputs and awaits all media elements\r\n * to be finished loading.\r\n *\r\n * @param input The input, which can be a media element or an array of different media elements.\r\n * @returns A NetInput instance, which can be passed into one of the neural networks.\r\n */\r\nfunction toNetInput(inputs) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var inputArgArray, getIdxHint, inputArray;\r\n        return tslib_1.__generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    if (inputs instanceof NetInput_1.NetInput) {\r\n                        return [2 /*return*/, inputs];\r\n                    }\r\n                    inputArgArray = Array.isArray(inputs)\r\n                        ? inputs\r\n                        : [inputs];\r\n                    if (!inputArgArray.length) {\r\n                        throw new Error('toNetInput - empty array passed as input');\r\n                    }\r\n                    getIdxHint = function (idx) { return Array.isArray(inputs) ? \" at input index \" + idx + \":\" : ''; };\r\n                    inputArray = inputArgArray.map(resolveInput_1.resolveInput);\r\n                    inputArray.forEach(function (input, i) {\r\n                        if (!isMediaElement_1.isMediaElement(input) && !utils_1.isTensor3D(input) && !utils_1.isTensor4D(input)) {\r\n                            if (typeof inputArgArray[i] === 'string') {\r\n                                throw new Error(\"toNetInput -\" + getIdxHint(i) + \" string passed, but could not resolve HTMLElement for element id \" + inputArgArray[i]);\r\n                            }\r\n                            throw new Error(\"toNetInput -\" + getIdxHint(i) + \" expected media to be of type HTMLImageElement | HTMLVideoElement | HTMLCanvasElement | tf.Tensor3D, or to be an element id\");\r\n                        }\r\n                        if (utils_1.isTensor4D(input)) {\r\n                            // if tf.Tensor4D is passed in the input array, the batch size has to be 1\r\n                            var batchSize = input.shape[0];\r\n                            if (batchSize !== 1) {\r\n                                throw new Error(\"toNetInput -\" + getIdxHint(i) + \" tf.Tensor4D with batchSize \" + batchSize + \" passed, but not supported in input array\");\r\n                            }\r\n                        }\r\n                    });\r\n                    // wait for all media elements being loaded\r\n                    return [4 /*yield*/, Promise.all(inputArray.map(function (input) { return isMediaElement_1.isMediaElement(input) && awaitMediaLoaded_1.awaitMediaLoaded(input); }))];\r\n                case 1:\r\n                    // wait for all media elements being loaded\r\n                    _a.sent();\r\n                    return [2 /*return*/, new NetInput_1.NetInput(inputArray, Array.isArray(inputs))];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.toNetInput = toNetInput;\r\n//# sourceMappingURL=toNetInput.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/dom/toNetInput.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/draw/DrawBox.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/draw/DrawBox.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar getContext2dOrThrow_1 = __webpack_require__(/*! ../dom/getContext2dOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/getContext2dOrThrow.js\");\r\nvar DrawTextField_1 = __webpack_require__(/*! ./DrawTextField */ \"./node_modules/face-api.js/build/commonjs/draw/DrawTextField.js\");\r\nvar DrawBoxOptions = /** @class */ (function () {\r\n    function DrawBoxOptions(options) {\r\n        if (options === void 0) { options = {}; }\r\n        var boxColor = options.boxColor, lineWidth = options.lineWidth, label = options.label, drawLabelOptions = options.drawLabelOptions;\r\n        this.boxColor = boxColor || 'rgba(0, 0, 255, 1)';\r\n        this.lineWidth = lineWidth || 2;\r\n        this.label = label;\r\n        var defaultDrawLabelOptions = {\r\n            anchorPosition: DrawTextField_1.AnchorPosition.BOTTOM_LEFT,\r\n            backgroundColor: this.boxColor\r\n        };\r\n        this.drawLabelOptions = new DrawTextField_1.DrawTextFieldOptions(Object.assign({}, defaultDrawLabelOptions, drawLabelOptions));\r\n    }\r\n    return DrawBoxOptions;\r\n}());\r\nexports.DrawBoxOptions = DrawBoxOptions;\r\nvar DrawBox = /** @class */ (function () {\r\n    function DrawBox(box, options) {\r\n        if (options === void 0) { options = {}; }\r\n        this.box = new classes_1.Box(box);\r\n        this.options = new DrawBoxOptions(options);\r\n    }\r\n    DrawBox.prototype.draw = function (canvasArg) {\r\n        var ctx = getContext2dOrThrow_1.getContext2dOrThrow(canvasArg);\r\n        var _a = this.options, boxColor = _a.boxColor, lineWidth = _a.lineWidth;\r\n        var _b = this.box, x = _b.x, y = _b.y, width = _b.width, height = _b.height;\r\n        ctx.strokeStyle = boxColor;\r\n        ctx.lineWidth = lineWidth;\r\n        ctx.strokeRect(x, y, width, height);\r\n        var label = this.options.label;\r\n        if (label) {\r\n            new DrawTextField_1.DrawTextField([label], { x: x - (lineWidth / 2), y: y }, this.options.drawLabelOptions).draw(canvasArg);\r\n        }\r\n    };\r\n    return DrawBox;\r\n}());\r\nexports.DrawBox = DrawBox;\r\n//# sourceMappingURL=DrawBox.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/draw/DrawBox.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/draw/DrawFaceLandmarks.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/draw/DrawFaceLandmarks.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar FaceLandmarks_1 = __webpack_require__(/*! ../classes/FaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks.js\");\r\nvar FaceLandmarks68_1 = __webpack_require__(/*! ../classes/FaceLandmarks68 */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks68.js\");\r\nvar getContext2dOrThrow_1 = __webpack_require__(/*! ../dom/getContext2dOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/getContext2dOrThrow.js\");\r\nvar WithFaceLandmarks_1 = __webpack_require__(/*! ../factories/WithFaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceLandmarks.js\");\r\nvar drawContour_1 = __webpack_require__(/*! ./drawContour */ \"./node_modules/face-api.js/build/commonjs/draw/drawContour.js\");\r\nvar DrawFaceLandmarksOptions = /** @class */ (function () {\r\n    function DrawFaceLandmarksOptions(options) {\r\n        if (options === void 0) { options = {}; }\r\n        var _a = options.drawLines, drawLines = _a === void 0 ? true : _a, _b = options.drawPoints, drawPoints = _b === void 0 ? true : _b, lineWidth = options.lineWidth, lineColor = options.lineColor, pointSize = options.pointSize, pointColor = options.pointColor;\r\n        this.drawLines = drawLines;\r\n        this.drawPoints = drawPoints;\r\n        this.lineWidth = lineWidth || 1;\r\n        this.pointSize = pointSize || 2;\r\n        this.lineColor = lineColor || 'rgba(0, 255, 255, 1)';\r\n        this.pointColor = pointColor || 'rgba(255, 0, 255, 1)';\r\n    }\r\n    return DrawFaceLandmarksOptions;\r\n}());\r\nexports.DrawFaceLandmarksOptions = DrawFaceLandmarksOptions;\r\nvar DrawFaceLandmarks = /** @class */ (function () {\r\n    function DrawFaceLandmarks(faceLandmarks, options) {\r\n        if (options === void 0) { options = {}; }\r\n        this.faceLandmarks = faceLandmarks;\r\n        this.options = new DrawFaceLandmarksOptions(options);\r\n    }\r\n    DrawFaceLandmarks.prototype.draw = function (canvasArg) {\r\n        var ctx = getContext2dOrThrow_1.getContext2dOrThrow(canvasArg);\r\n        var _a = this.options, drawLines = _a.drawLines, drawPoints = _a.drawPoints, lineWidth = _a.lineWidth, lineColor = _a.lineColor, pointSize = _a.pointSize, pointColor = _a.pointColor;\r\n        if (drawLines && this.faceLandmarks instanceof FaceLandmarks68_1.FaceLandmarks68) {\r\n            ctx.strokeStyle = lineColor;\r\n            ctx.lineWidth = lineWidth;\r\n            drawContour_1.drawContour(ctx, this.faceLandmarks.getJawOutline());\r\n            drawContour_1.drawContour(ctx, this.faceLandmarks.getLeftEyeBrow());\r\n            drawContour_1.drawContour(ctx, this.faceLandmarks.getRightEyeBrow());\r\n            drawContour_1.drawContour(ctx, this.faceLandmarks.getNose());\r\n            drawContour_1.drawContour(ctx, this.faceLandmarks.getLeftEye(), true);\r\n            drawContour_1.drawContour(ctx, this.faceLandmarks.getRightEye(), true);\r\n            drawContour_1.drawContour(ctx, this.faceLandmarks.getMouth(), true);\r\n        }\r\n        if (drawPoints) {\r\n            ctx.strokeStyle = pointColor;\r\n            ctx.fillStyle = pointColor;\r\n            var drawPoint = function (pt) {\r\n                ctx.beginPath();\r\n                ctx.arc(pt.x, pt.y, pointSize, 0, 2 * Math.PI);\r\n                ctx.fill();\r\n            };\r\n            this.faceLandmarks.positions.forEach(drawPoint);\r\n        }\r\n    };\r\n    return DrawFaceLandmarks;\r\n}());\r\nexports.DrawFaceLandmarks = DrawFaceLandmarks;\r\nfunction drawFaceLandmarks(canvasArg, faceLandmarks) {\r\n    var faceLandmarksArray = Array.isArray(faceLandmarks) ? faceLandmarks : [faceLandmarks];\r\n    faceLandmarksArray.forEach(function (f) {\r\n        var landmarks = f instanceof FaceLandmarks_1.FaceLandmarks\r\n            ? f\r\n            : (WithFaceLandmarks_1.isWithFaceLandmarks(f) ? f.landmarks : undefined);\r\n        if (!landmarks) {\r\n            throw new Error('drawFaceLandmarks - expected faceExpressions to be FaceLandmarks | WithFaceLandmarks<WithFaceDetection<{}>> or array thereof');\r\n        }\r\n        new DrawFaceLandmarks(landmarks).draw(canvasArg);\r\n    });\r\n}\r\nexports.drawFaceLandmarks = drawFaceLandmarks;\r\n//# sourceMappingURL=DrawFaceLandmarks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/draw/DrawFaceLandmarks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/draw/DrawTextField.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/draw/DrawTextField.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar getContext2dOrThrow_1 = __webpack_require__(/*! ../dom/getContext2dOrThrow */ \"./node_modules/face-api.js/build/commonjs/dom/getContext2dOrThrow.js\");\r\nvar resolveInput_1 = __webpack_require__(/*! ../dom/resolveInput */ \"./node_modules/face-api.js/build/commonjs/dom/resolveInput.js\");\r\nvar AnchorPosition;\r\n(function (AnchorPosition) {\r\n    AnchorPosition[\"TOP_LEFT\"] = \"TOP_LEFT\";\r\n    AnchorPosition[\"TOP_RIGHT\"] = \"TOP_RIGHT\";\r\n    AnchorPosition[\"BOTTOM_LEFT\"] = \"BOTTOM_LEFT\";\r\n    AnchorPosition[\"BOTTOM_RIGHT\"] = \"BOTTOM_RIGHT\";\r\n})(AnchorPosition = exports.AnchorPosition || (exports.AnchorPosition = {}));\r\nvar DrawTextFieldOptions = /** @class */ (function () {\r\n    function DrawTextFieldOptions(options) {\r\n        if (options === void 0) { options = {}; }\r\n        var anchorPosition = options.anchorPosition, backgroundColor = options.backgroundColor, fontColor = options.fontColor, fontSize = options.fontSize, fontStyle = options.fontStyle, padding = options.padding;\r\n        this.anchorPosition = anchorPosition || AnchorPosition.TOP_LEFT;\r\n        this.backgroundColor = backgroundColor || 'rgba(0, 0, 0, 0.5)';\r\n        this.fontColor = fontColor || 'rgba(255, 255, 255, 1)';\r\n        this.fontSize = fontSize || 14;\r\n        this.fontStyle = fontStyle || 'Georgia';\r\n        this.padding = padding || 4;\r\n    }\r\n    return DrawTextFieldOptions;\r\n}());\r\nexports.DrawTextFieldOptions = DrawTextFieldOptions;\r\nvar DrawTextField = /** @class */ (function () {\r\n    function DrawTextField(text, anchor, options) {\r\n        if (options === void 0) { options = {}; }\r\n        this.text = typeof text === 'string'\r\n            ? [text]\r\n            : (text instanceof DrawTextField ? text.text : text);\r\n        this.anchor = anchor;\r\n        this.options = new DrawTextFieldOptions(options);\r\n    }\r\n    DrawTextField.prototype.measureWidth = function (ctx) {\r\n        var padding = this.options.padding;\r\n        return this.text.map(function (l) { return ctx.measureText(l).width; }).reduce(function (w0, w1) { return w0 < w1 ? w1 : w0; }, 0) + (2 * padding);\r\n    };\r\n    DrawTextField.prototype.measureHeight = function () {\r\n        var _a = this.options, fontSize = _a.fontSize, padding = _a.padding;\r\n        return this.text.length * fontSize + (2 * padding);\r\n    };\r\n    DrawTextField.prototype.getUpperLeft = function (ctx, canvasDims) {\r\n        var anchorPosition = this.options.anchorPosition;\r\n        var isShiftLeft = anchorPosition === AnchorPosition.BOTTOM_RIGHT || anchorPosition === AnchorPosition.TOP_RIGHT;\r\n        var isShiftTop = anchorPosition === AnchorPosition.BOTTOM_LEFT || anchorPosition === AnchorPosition.BOTTOM_RIGHT;\r\n        var textFieldWidth = this.measureWidth(ctx);\r\n        var textFieldHeight = this.measureHeight();\r\n        var x = (isShiftLeft ? this.anchor.x - textFieldWidth : this.anchor.x);\r\n        var y = isShiftTop ? this.anchor.y - textFieldHeight : this.anchor.y;\r\n        // adjust anchor if text box exceeds canvas borders\r\n        if (canvasDims) {\r\n            var width = canvasDims.width, height = canvasDims.height;\r\n            var newX = Math.max(Math.min(x, width - textFieldWidth), 0);\r\n            var newY = Math.max(Math.min(y, height - textFieldHeight), 0);\r\n            return { x: newX, y: newY };\r\n        }\r\n        return { x: x, y: y };\r\n    };\r\n    DrawTextField.prototype.draw = function (canvasArg) {\r\n        var canvas = resolveInput_1.resolveInput(canvasArg);\r\n        var ctx = getContext2dOrThrow_1.getContext2dOrThrow(canvas);\r\n        var _a = this.options, backgroundColor = _a.backgroundColor, fontColor = _a.fontColor, fontSize = _a.fontSize, fontStyle = _a.fontStyle, padding = _a.padding;\r\n        ctx.font = fontSize + \"px \" + fontStyle;\r\n        var maxTextWidth = this.measureWidth(ctx);\r\n        var textHeight = this.measureHeight();\r\n        ctx.fillStyle = backgroundColor;\r\n        var upperLeft = this.getUpperLeft(ctx, canvas);\r\n        ctx.fillRect(upperLeft.x, upperLeft.y, maxTextWidth, textHeight);\r\n        ctx.fillStyle = fontColor;\r\n        this.text.forEach(function (textLine, i) {\r\n            var x = padding + upperLeft.x;\r\n            var y = padding + upperLeft.y + ((i + 1) * fontSize);\r\n            ctx.fillText(textLine, x, y);\r\n        });\r\n    };\r\n    return DrawTextField;\r\n}());\r\nexports.DrawTextField = DrawTextField;\r\n//# sourceMappingURL=DrawTextField.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/draw/DrawTextField.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/draw/drawContour.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/draw/drawContour.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction drawContour(ctx, points, isClosed) {\r\n    if (isClosed === void 0) { isClosed = false; }\r\n    ctx.beginPath();\r\n    points.slice(1).forEach(function (_a, prevIdx) {\r\n        var x = _a.x, y = _a.y;\r\n        var from = points[prevIdx];\r\n        ctx.moveTo(from.x, from.y);\r\n        ctx.lineTo(x, y);\r\n    });\r\n    if (isClosed) {\r\n        var from = points[points.length - 1];\r\n        var to = points[0];\r\n        if (!from || !to) {\r\n            return;\r\n        }\r\n        ctx.moveTo(from.x, from.y);\r\n        ctx.lineTo(to.x, to.y);\r\n    }\r\n    ctx.stroke();\r\n}\r\nexports.drawContour = drawContour;\r\n//# sourceMappingURL=drawContour.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/draw/drawContour.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/draw/drawDetections.js":
/*!************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/draw/drawDetections.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar FaceDetection_1 = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js\");\r\nvar WithFaceDetection_1 = __webpack_require__(/*! ../factories/WithFaceDetection */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceDetection.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar DrawBox_1 = __webpack_require__(/*! ./DrawBox */ \"./node_modules/face-api.js/build/commonjs/draw/DrawBox.js\");\r\nfunction drawDetections(canvasArg, detections) {\r\n    var detectionsArray = Array.isArray(detections) ? detections : [detections];\r\n    detectionsArray.forEach(function (det) {\r\n        var score = det instanceof FaceDetection_1.FaceDetection\r\n            ? det.score\r\n            : (WithFaceDetection_1.isWithFaceDetection(det) ? det.detection.score : undefined);\r\n        var box = det instanceof FaceDetection_1.FaceDetection\r\n            ? det.box\r\n            : (WithFaceDetection_1.isWithFaceDetection(det) ? det.detection.box : new classes_1.Box(det));\r\n        var label = score ? \"\" + utils_1.round(score) : undefined;\r\n        new DrawBox_1.DrawBox(box, { label: label }).draw(canvasArg);\r\n    });\r\n}\r\nexports.drawDetections = drawDetections;\r\n//# sourceMappingURL=drawDetections.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/draw/drawDetections.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/draw/drawFaceExpressions.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/draw/drawFaceExpressions.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar faceExpressionNet_1 = __webpack_require__(/*! ../faceExpressionNet */ \"./node_modules/face-api.js/build/commonjs/faceExpressionNet/index.js\");\r\nvar WithFaceDetection_1 = __webpack_require__(/*! ../factories/WithFaceDetection */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceDetection.js\");\r\nvar WithFaceExpressions_1 = __webpack_require__(/*! ../factories/WithFaceExpressions */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceExpressions.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar DrawTextField_1 = __webpack_require__(/*! ./DrawTextField */ \"./node_modules/face-api.js/build/commonjs/draw/DrawTextField.js\");\r\nfunction drawFaceExpressions(canvasArg, faceExpressions, minConfidence, textFieldAnchor) {\r\n    if (minConfidence === void 0) { minConfidence = 0.1; }\r\n    var faceExpressionsArray = Array.isArray(faceExpressions) ? faceExpressions : [faceExpressions];\r\n    faceExpressionsArray.forEach(function (e) {\r\n        var expr = e instanceof faceExpressionNet_1.FaceExpressions\r\n            ? e\r\n            : (WithFaceExpressions_1.isWithFaceExpressions(e) ? e.expressions : undefined);\r\n        if (!expr) {\r\n            throw new Error('drawFaceExpressions - expected faceExpressions to be FaceExpressions | WithFaceExpressions<{}> or array thereof');\r\n        }\r\n        var sorted = expr.asSortedArray();\r\n        var resultsToDisplay = sorted.filter(function (expr) { return expr.probability > minConfidence; });\r\n        var anchor = WithFaceDetection_1.isWithFaceDetection(e)\r\n            ? e.detection.box.bottomLeft\r\n            : (textFieldAnchor || new classes_1.Point(0, 0));\r\n        var drawTextField = new DrawTextField_1.DrawTextField(resultsToDisplay.map(function (expr) { return expr.expression + \" (\" + utils_1.round(expr.probability) + \")\"; }), anchor);\r\n        drawTextField.draw(canvasArg);\r\n    });\r\n}\r\nexports.drawFaceExpressions = drawFaceExpressions;\r\n//# sourceMappingURL=drawFaceExpressions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/draw/drawFaceExpressions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/draw/index.js":
/*!***************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/draw/index.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./drawContour */ \"./node_modules/face-api.js/build/commonjs/draw/drawContour.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./drawDetections */ \"./node_modules/face-api.js/build/commonjs/draw/drawDetections.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./drawFaceExpressions */ \"./node_modules/face-api.js/build/commonjs/draw/drawFaceExpressions.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./DrawBox */ \"./node_modules/face-api.js/build/commonjs/draw/DrawBox.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./DrawFaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/draw/DrawFaceLandmarks.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./DrawTextField */ \"./node_modules/face-api.js/build/commonjs/draw/DrawTextField.js\"), exports);\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/draw/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/env/createBrowserEnv.js":
/*!*************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/env/createBrowserEnv.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction createBrowserEnv() {\r\n    var fetch = window['fetch'] || function () {\r\n        throw new Error('fetch - missing fetch implementation for browser environment');\r\n    };\r\n    var readFile = function () {\r\n        throw new Error('readFile - filesystem not available for browser environment');\r\n    };\r\n    return {\r\n        Canvas: HTMLCanvasElement,\r\n        CanvasRenderingContext2D: CanvasRenderingContext2D,\r\n        Image: HTMLImageElement,\r\n        ImageData: ImageData,\r\n        Video: HTMLVideoElement,\r\n        createCanvasElement: function () { return document.createElement('canvas'); },\r\n        createImageElement: function () { return document.createElement('img'); },\r\n        fetch: fetch,\r\n        readFile: readFile\r\n    };\r\n}\r\nexports.createBrowserEnv = createBrowserEnv;\r\n//# sourceMappingURL=createBrowserEnv.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/env/createBrowserEnv.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/env/createFileSystem.js":
/*!*************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/env/createFileSystem.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction createFileSystem(fs) {\r\n    var requireFsError = '';\r\n    if (!fs) {\r\n        try {\r\n            fs = __webpack_require__(!(function webpackMissingModule() { var e = new Error(\"Cannot find module 'fs'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\r\n        }\r\n        catch (err) {\r\n            requireFsError = err.toString();\r\n        }\r\n    }\r\n    var readFile = fs\r\n        ? function (filePath) {\r\n            return new Promise(function (res, rej) {\r\n                fs.readFile(filePath, function (err, buffer) {\r\n                    return err ? rej(err) : res(buffer);\r\n                });\r\n            });\r\n        }\r\n        : function () {\r\n            throw new Error(\"readFile - failed to require fs in nodejs environment with error: \" + requireFsError);\r\n        };\r\n    return {\r\n        readFile: readFile\r\n    };\r\n}\r\nexports.createFileSystem = createFileSystem;\r\n//# sourceMappingURL=createFileSystem.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/env/createFileSystem.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/env/createNodejsEnv.js":
/*!************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/env/createNodejsEnv.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(global) {\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar createFileSystem_1 = __webpack_require__(/*! ./createFileSystem */ \"./node_modules/face-api.js/build/commonjs/env/createFileSystem.js\");\r\nfunction createNodejsEnv() {\r\n    var Canvas = global['Canvas'] || global['HTMLCanvasElement'];\r\n    var Image = global['Image'] || global['HTMLImageElement'];\r\n    var createCanvasElement = function () {\r\n        if (Canvas) {\r\n            return new Canvas();\r\n        }\r\n        throw new Error('createCanvasElement - missing Canvas implementation for nodejs environment');\r\n    };\r\n    var createImageElement = function () {\r\n        if (Image) {\r\n            return new Image();\r\n        }\r\n        throw new Error('createImageElement - missing Image implementation for nodejs environment');\r\n    };\r\n    var fetch = global['fetch'] || function () {\r\n        throw new Error('fetch - missing fetch implementation for nodejs environment');\r\n    };\r\n    var fileSystem = createFileSystem_1.createFileSystem();\r\n    return tslib_1.__assign({ Canvas: Canvas || /** @class */ (function () {\r\n            function Canvas() {\r\n            }\r\n            return Canvas;\r\n        }()), CanvasRenderingContext2D: global['CanvasRenderingContext2D'] || /** @class */ (function () {\r\n            function class_1() {\r\n            }\r\n            return class_1;\r\n        }()), Image: Image || /** @class */ (function () {\r\n            function Image() {\r\n            }\r\n            return Image;\r\n        }()), ImageData: global['ImageData'] || /** @class */ (function () {\r\n            function class_2() {\r\n            }\r\n            return class_2;\r\n        }()), Video: global['HTMLVideoElement'] || /** @class */ (function () {\r\n            function class_3() {\r\n            }\r\n            return class_3;\r\n        }()), createCanvasElement: createCanvasElement,\r\n        createImageElement: createImageElement,\r\n        fetch: fetch }, fileSystem);\r\n}\r\nexports.createNodejsEnv = createNodejsEnv;\r\n//# sourceMappingURL=createNodejsEnv.js.map\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/env/createNodejsEnv.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/env/index.js":
/*!**************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/env/index.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar createBrowserEnv_1 = __webpack_require__(/*! ./createBrowserEnv */ \"./node_modules/face-api.js/build/commonjs/env/createBrowserEnv.js\");\r\nvar createFileSystem_1 = __webpack_require__(/*! ./createFileSystem */ \"./node_modules/face-api.js/build/commonjs/env/createFileSystem.js\");\r\nvar createNodejsEnv_1 = __webpack_require__(/*! ./createNodejsEnv */ \"./node_modules/face-api.js/build/commonjs/env/createNodejsEnv.js\");\r\nvar isBrowser_1 = __webpack_require__(/*! ./isBrowser */ \"./node_modules/face-api.js/build/commonjs/env/isBrowser.js\");\r\nvar isNodejs_1 = __webpack_require__(/*! ./isNodejs */ \"./node_modules/face-api.js/build/commonjs/env/isNodejs.js\");\r\nvar environment;\r\nfunction getEnv() {\r\n    if (!environment) {\r\n        throw new Error('getEnv - environment is not defined, check isNodejs() and isBrowser()');\r\n    }\r\n    return environment;\r\n}\r\nfunction setEnv(env) {\r\n    environment = env;\r\n}\r\nfunction initialize() {\r\n    // check for isBrowser() first to prevent electron renderer process\r\n    // to be initialized with wrong environment due to isNodejs() returning true\r\n    if (isBrowser_1.isBrowser()) {\r\n        setEnv(createBrowserEnv_1.createBrowserEnv());\r\n    }\r\n    if (isNodejs_1.isNodejs()) {\r\n        setEnv(createNodejsEnv_1.createNodejsEnv());\r\n    }\r\n}\r\nfunction monkeyPatch(env) {\r\n    if (!environment) {\r\n        initialize();\r\n    }\r\n    if (!environment) {\r\n        throw new Error('monkeyPatch - environment is not defined, check isNodejs() and isBrowser()');\r\n    }\r\n    var _a = env.Canvas, Canvas = _a === void 0 ? environment.Canvas : _a, _b = env.Image, Image = _b === void 0 ? environment.Image : _b;\r\n    environment.Canvas = Canvas;\r\n    environment.Image = Image;\r\n    environment.createCanvasElement = env.createCanvasElement || (function () { return new Canvas(); });\r\n    environment.createImageElement = env.createImageElement || (function () { return new Image(); });\r\n    environment.ImageData = env.ImageData || environment.ImageData;\r\n    environment.Video = env.Video || environment.Video;\r\n    environment.fetch = env.fetch || environment.fetch;\r\n    environment.readFile = env.readFile || environment.readFile;\r\n}\r\nexports.env = {\r\n    getEnv: getEnv,\r\n    setEnv: setEnv,\r\n    initialize: initialize,\r\n    createBrowserEnv: createBrowserEnv_1.createBrowserEnv,\r\n    createFileSystem: createFileSystem_1.createFileSystem,\r\n    createNodejsEnv: createNodejsEnv_1.createNodejsEnv,\r\n    monkeyPatch: monkeyPatch,\r\n    isBrowser: isBrowser_1.isBrowser,\r\n    isNodejs: isNodejs_1.isNodejs\r\n};\r\ninitialize();\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/env/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/env/isBrowser.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/env/isBrowser.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction isBrowser() {\r\n    return typeof window === 'object'\r\n        && typeof document !== 'undefined'\r\n        && typeof HTMLImageElement !== 'undefined'\r\n        && typeof HTMLCanvasElement !== 'undefined'\r\n        && typeof HTMLVideoElement !== 'undefined'\r\n        && typeof ImageData !== 'undefined'\r\n        && typeof CanvasRenderingContext2D !== 'undefined';\r\n}\r\nexports.isBrowser = isBrowser;\r\n//# sourceMappingURL=isBrowser.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/env/isBrowser.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/env/isNodejs.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/env/isNodejs.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(global, process) {\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction isNodejs() {\r\n    return typeof global === 'object'\r\n        && \"function\" === 'function'\r\n        && typeof module !== 'undefined'\r\n        // issues with gatsby.js: module.exports is undefined\r\n        // && !!module.exports\r\n        && typeof process !== 'undefined' && !!process.version;\r\n}\r\nexports.isNodejs = isNodejs;\r\n//# sourceMappingURL=isNodejs.js.map\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\"), __webpack_require__(/*! ./../../../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/env/isNodejs.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/euclideanDistance.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/euclideanDistance.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction euclideanDistance(arr1, arr2) {\r\n    if (arr1.length !== arr2.length)\r\n        throw new Error('euclideanDistance: arr1.length !== arr2.length');\r\n    var desc1 = Array.from(arr1);\r\n    var desc2 = Array.from(arr2);\r\n    return Math.sqrt(desc1\r\n        .map(function (val, i) { return val - desc2[i]; })\r\n        .reduce(function (res, diff) { return res + Math.pow(diff, 2); }, 0));\r\n}\r\nexports.euclideanDistance = euclideanDistance;\r\n//# sourceMappingURL=euclideanDistance.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/euclideanDistance.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressionNet.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressionNet.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar FaceFeatureExtractor_1 = __webpack_require__(/*! ../faceFeatureExtractor/FaceFeatureExtractor */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/FaceFeatureExtractor.js\");\r\nvar FaceProcessor_1 = __webpack_require__(/*! ../faceProcessor/FaceProcessor */ \"./node_modules/face-api.js/build/commonjs/faceProcessor/FaceProcessor.js\");\r\nvar FaceExpressions_1 = __webpack_require__(/*! ./FaceExpressions */ \"./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressions.js\");\r\nvar FaceExpressionNet = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceExpressionNet, _super);\r\n    function FaceExpressionNet(faceFeatureExtractor) {\r\n        if (faceFeatureExtractor === void 0) { faceFeatureExtractor = new FaceFeatureExtractor_1.FaceFeatureExtractor(); }\r\n        return _super.call(this, 'FaceExpressionNet', faceFeatureExtractor) || this;\r\n    }\r\n    FaceExpressionNet.prototype.forwardInput = function (input) {\r\n        var _this = this;\r\n        return tf.tidy(function () { return tf.softmax(_this.runNet(input)); });\r\n    };\r\n    FaceExpressionNet.prototype.forward = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceExpressionNet.prototype.predictExpressions = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var netInput, out, probabilitesByBatch, predictionsByBatch;\r\n            var _this = this;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1:\r\n                        netInput = _a.sent();\r\n                        return [4 /*yield*/, this.forwardInput(netInput)];\r\n                    case 2:\r\n                        out = _a.sent();\r\n                        return [4 /*yield*/, Promise.all(tf.unstack(out).map(function (t) { return tslib_1.__awaiter(_this, void 0, void 0, function () {\r\n                                var data;\r\n                                return tslib_1.__generator(this, function (_a) {\r\n                                    switch (_a.label) {\r\n                                        case 0: return [4 /*yield*/, t.data()];\r\n                                        case 1:\r\n                                            data = _a.sent();\r\n                                            t.dispose();\r\n                                            return [2 /*return*/, data];\r\n                                    }\r\n                                });\r\n                            }); }))];\r\n                    case 3:\r\n                        probabilitesByBatch = _a.sent();\r\n                        out.dispose();\r\n                        predictionsByBatch = probabilitesByBatch\r\n                            .map(function (probabilites) { return new FaceExpressions_1.FaceExpressions(probabilites); });\r\n                        return [2 /*return*/, netInput.isBatchInput\r\n                                ? predictionsByBatch\r\n                                : predictionsByBatch[0]];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceExpressionNet.prototype.getDefaultModelName = function () {\r\n        return 'face_expression_model';\r\n    };\r\n    FaceExpressionNet.prototype.getClassifierChannelsIn = function () {\r\n        return 256;\r\n    };\r\n    FaceExpressionNet.prototype.getClassifierChannelsOut = function () {\r\n        return 7;\r\n    };\r\n    return FaceExpressionNet;\r\n}(FaceProcessor_1.FaceProcessor));\r\nexports.FaceExpressionNet = FaceExpressionNet;\r\n//# sourceMappingURL=FaceExpressionNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressionNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressions.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressions.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.FACE_EXPRESSION_LABELS = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised'];\r\nvar FaceExpressions = /** @class */ (function () {\r\n    function FaceExpressions(probabilities) {\r\n        var _this = this;\r\n        if (probabilities.length !== 7) {\r\n            throw new Error(\"FaceExpressions.constructor - expected probabilities.length to be 7, have: \" + probabilities.length);\r\n        }\r\n        exports.FACE_EXPRESSION_LABELS.forEach(function (expression, idx) {\r\n            _this[expression] = probabilities[idx];\r\n        });\r\n    }\r\n    FaceExpressions.prototype.asSortedArray = function () {\r\n        var _this = this;\r\n        return exports.FACE_EXPRESSION_LABELS\r\n            .map(function (expression) { return ({ expression: expression, probability: _this[expression] }); })\r\n            .sort(function (e0, e1) { return e1.probability - e0.probability; });\r\n    };\r\n    return FaceExpressions;\r\n}());\r\nexports.FaceExpressions = FaceExpressions;\r\n//# sourceMappingURL=FaceExpressions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceExpressionNet/index.js":
/*!****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceExpressionNet/index.js ***!
  \****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceExpressionNet */ \"./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressionNet.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceExpressions */ \"./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressions.js\"), exports);\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceExpressionNet/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/FaceFeatureExtractor.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/FaceFeatureExtractor.js ***!
  \**********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar NeuralNetwork_1 = __webpack_require__(/*! ../NeuralNetwork */ \"./node_modules/face-api.js/build/commonjs/NeuralNetwork.js\");\r\nvar ops_1 = __webpack_require__(/*! ../ops */ \"./node_modules/face-api.js/build/commonjs/ops/index.js\");\r\nvar denseBlock_1 = __webpack_require__(/*! ./denseBlock */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/denseBlock.js\");\r\nvar extractParams_1 = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParams.js\");\r\nvar extractParamsFromWeigthMap_1 = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsFromWeigthMap.js\");\r\nvar FaceFeatureExtractor = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceFeatureExtractor, _super);\r\n    function FaceFeatureExtractor() {\r\n        return _super.call(this, 'FaceFeatureExtractor') || this;\r\n    }\r\n    FaceFeatureExtractor.prototype.forwardInput = function (input) {\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('FaceFeatureExtractor - load model before inference');\r\n        }\r\n        return tf.tidy(function () {\r\n            var batchTensor = input.toBatchTensor(112, true);\r\n            var meanRgb = [122.782, 117.001, 104.298];\r\n            var normalized = ops_1.normalize(batchTensor, meanRgb).div(tf.scalar(255));\r\n            var out = denseBlock_1.denseBlock4(normalized, params.dense0, true);\r\n            out = denseBlock_1.denseBlock4(out, params.dense1);\r\n            out = denseBlock_1.denseBlock4(out, params.dense2);\r\n            out = denseBlock_1.denseBlock4(out, params.dense3);\r\n            out = tf.avgPool(out, [7, 7], [2, 2], 'valid');\r\n            return out;\r\n        });\r\n    };\r\n    FaceFeatureExtractor.prototype.forward = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceFeatureExtractor.prototype.getDefaultModelName = function () {\r\n        return 'face_feature_extractor_model';\r\n    };\r\n    FaceFeatureExtractor.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return extractParamsFromWeigthMap_1.extractParamsFromWeigthMap(weightMap);\r\n    };\r\n    FaceFeatureExtractor.prototype.extractParams = function (weights) {\r\n        return extractParams_1.extractParams(weights);\r\n    };\r\n    return FaceFeatureExtractor;\r\n}(NeuralNetwork_1.NeuralNetwork));\r\nexports.FaceFeatureExtractor = FaceFeatureExtractor;\r\n//# sourceMappingURL=FaceFeatureExtractor.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/FaceFeatureExtractor.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/TinyFaceFeatureExtractor.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/TinyFaceFeatureExtractor.js ***!
  \**************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar NeuralNetwork_1 = __webpack_require__(/*! ../NeuralNetwork */ \"./node_modules/face-api.js/build/commonjs/NeuralNetwork.js\");\r\nvar ops_1 = __webpack_require__(/*! ../ops */ \"./node_modules/face-api.js/build/commonjs/ops/index.js\");\r\nvar denseBlock_1 = __webpack_require__(/*! ./denseBlock */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/denseBlock.js\");\r\nvar extractParamsFromWeigthMapTiny_1 = __webpack_require__(/*! ./extractParamsFromWeigthMapTiny */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsFromWeigthMapTiny.js\");\r\nvar extractParamsTiny_1 = __webpack_require__(/*! ./extractParamsTiny */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsTiny.js\");\r\nvar TinyFaceFeatureExtractor = /** @class */ (function (_super) {\r\n    tslib_1.__extends(TinyFaceFeatureExtractor, _super);\r\n    function TinyFaceFeatureExtractor() {\r\n        return _super.call(this, 'TinyFaceFeatureExtractor') || this;\r\n    }\r\n    TinyFaceFeatureExtractor.prototype.forwardInput = function (input) {\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('TinyFaceFeatureExtractor - load model before inference');\r\n        }\r\n        return tf.tidy(function () {\r\n            var batchTensor = input.toBatchTensor(112, true);\r\n            var meanRgb = [122.782, 117.001, 104.298];\r\n            var normalized = ops_1.normalize(batchTensor, meanRgb).div(tf.scalar(255));\r\n            var out = denseBlock_1.denseBlock3(normalized, params.dense0, true);\r\n            out = denseBlock_1.denseBlock3(out, params.dense1);\r\n            out = denseBlock_1.denseBlock3(out, params.dense2);\r\n            out = tf.avgPool(out, [14, 14], [2, 2], 'valid');\r\n            return out;\r\n        });\r\n    };\r\n    TinyFaceFeatureExtractor.prototype.forward = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyFaceFeatureExtractor.prototype.getDefaultModelName = function () {\r\n        return 'face_feature_extractor_tiny_model';\r\n    };\r\n    TinyFaceFeatureExtractor.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return extractParamsFromWeigthMapTiny_1.extractParamsFromWeigthMapTiny(weightMap);\r\n    };\r\n    TinyFaceFeatureExtractor.prototype.extractParams = function (weights) {\r\n        return extractParamsTiny_1.extractParamsTiny(weights);\r\n    };\r\n    return TinyFaceFeatureExtractor;\r\n}(NeuralNetwork_1.NeuralNetwork));\r\nexports.TinyFaceFeatureExtractor = TinyFaceFeatureExtractor;\r\n//# sourceMappingURL=TinyFaceFeatureExtractor.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/TinyFaceFeatureExtractor.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/denseBlock.js":
/*!************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/denseBlock.js ***!
  \************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar depthwiseSeparableConv_1 = __webpack_require__(/*! ../common/depthwiseSeparableConv */ \"./node_modules/face-api.js/build/commonjs/common/depthwiseSeparableConv.js\");\r\nfunction denseBlock3(x, denseBlockParams, isFirstLayer) {\r\n    if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n    return tf.tidy(function () {\r\n        var out1 = tf.relu(isFirstLayer\r\n            ? tf.add(tf.conv2d(x, denseBlockParams.conv0.filters, [2, 2], 'same'), denseBlockParams.conv0.bias)\r\n            : depthwiseSeparableConv_1.depthwiseSeparableConv(x, denseBlockParams.conv0, [2, 2]));\r\n        var out2 = depthwiseSeparableConv_1.depthwiseSeparableConv(out1, denseBlockParams.conv1, [1, 1]);\r\n        var in3 = tf.relu(tf.add(out1, out2));\r\n        var out3 = depthwiseSeparableConv_1.depthwiseSeparableConv(in3, denseBlockParams.conv2, [1, 1]);\r\n        return tf.relu(tf.add(out1, tf.add(out2, out3)));\r\n    });\r\n}\r\nexports.denseBlock3 = denseBlock3;\r\nfunction denseBlock4(x, denseBlockParams, isFirstLayer, isScaleDown) {\r\n    if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n    if (isScaleDown === void 0) { isScaleDown = true; }\r\n    return tf.tidy(function () {\r\n        var out1 = tf.relu(isFirstLayer\r\n            ? tf.add(tf.conv2d(x, denseBlockParams.conv0.filters, isScaleDown ? [2, 2] : [1, 1], 'same'), denseBlockParams.conv0.bias)\r\n            : depthwiseSeparableConv_1.depthwiseSeparableConv(x, denseBlockParams.conv0, isScaleDown ? [2, 2] : [1, 1]));\r\n        var out2 = depthwiseSeparableConv_1.depthwiseSeparableConv(out1, denseBlockParams.conv1, [1, 1]);\r\n        var in3 = tf.relu(tf.add(out1, out2));\r\n        var out3 = depthwiseSeparableConv_1.depthwiseSeparableConv(in3, denseBlockParams.conv2, [1, 1]);\r\n        var in4 = tf.relu(tf.add(out1, tf.add(out2, out3)));\r\n        var out4 = depthwiseSeparableConv_1.depthwiseSeparableConv(in4, denseBlockParams.conv3, [1, 1]);\r\n        return tf.relu(tf.add(out1, tf.add(out2, tf.add(out3, out4))));\r\n    });\r\n}\r\nexports.denseBlock4 = denseBlock4;\r\n//# sourceMappingURL=denseBlock.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/denseBlock.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParams.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParams.js ***!
  \***************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar extractorsFactory_1 = __webpack_require__(/*! ./extractorsFactory */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractorsFactory.js\");\r\nfunction extractParams(weights) {\r\n    var paramMappings = [];\r\n    var _a = common_1.extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var extractDenseBlock4Params = extractorsFactory_1.extractorsFactory(extractWeights, paramMappings).extractDenseBlock4Params;\r\n    var dense0 = extractDenseBlock4Params(3, 32, 'dense0', true);\r\n    var dense1 = extractDenseBlock4Params(32, 64, 'dense1');\r\n    var dense2 = extractDenseBlock4Params(64, 128, 'dense2');\r\n    var dense3 = extractDenseBlock4Params(128, 256, 'dense3');\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        paramMappings: paramMappings,\r\n        params: { dense0: dense0, dense1: dense1, dense2: dense2, dense3: dense3 }\r\n    };\r\n}\r\nexports.extractParams = extractParams;\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsFromWeigthMap.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsFromWeigthMap.js ***!
  \****************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar loadParamsFactory_1 = __webpack_require__(/*! ./loadParamsFactory */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/loadParamsFactory.js\");\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var extractDenseBlock4Params = loadParamsFactory_1.loadParamsFactory(weightMap, paramMappings).extractDenseBlock4Params;\r\n    var params = {\r\n        dense0: extractDenseBlock4Params('dense0', true),\r\n        dense1: extractDenseBlock4Params('dense1'),\r\n        dense2: extractDenseBlock4Params('dense2'),\r\n        dense3: extractDenseBlock4Params('dense3')\r\n    };\r\n    common_1.disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\nexports.extractParamsFromWeigthMap = extractParamsFromWeigthMap;\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsFromWeigthMapTiny.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsFromWeigthMapTiny.js ***!
  \********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar loadParamsFactory_1 = __webpack_require__(/*! ./loadParamsFactory */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/loadParamsFactory.js\");\r\nfunction extractParamsFromWeigthMapTiny(weightMap) {\r\n    var paramMappings = [];\r\n    var extractDenseBlock3Params = loadParamsFactory_1.loadParamsFactory(weightMap, paramMappings).extractDenseBlock3Params;\r\n    var params = {\r\n        dense0: extractDenseBlock3Params('dense0', true),\r\n        dense1: extractDenseBlock3Params('dense1'),\r\n        dense2: extractDenseBlock3Params('dense2')\r\n    };\r\n    common_1.disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\nexports.extractParamsFromWeigthMapTiny = extractParamsFromWeigthMapTiny;\r\n//# sourceMappingURL=extractParamsFromWeigthMapTiny.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsFromWeigthMapTiny.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsTiny.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsTiny.js ***!
  \*******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar extractorsFactory_1 = __webpack_require__(/*! ./extractorsFactory */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractorsFactory.js\");\r\nfunction extractParamsTiny(weights) {\r\n    var paramMappings = [];\r\n    var _a = common_1.extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var extractDenseBlock3Params = extractorsFactory_1.extractorsFactory(extractWeights, paramMappings).extractDenseBlock3Params;\r\n    var dense0 = extractDenseBlock3Params(3, 32, 'dense0', true);\r\n    var dense1 = extractDenseBlock3Params(32, 64, 'dense1');\r\n    var dense2 = extractDenseBlock3Params(64, 128, 'dense2');\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        paramMappings: paramMappings,\r\n        params: { dense0: dense0, dense1: dense1, dense2: dense2 }\r\n    };\r\n}\r\nexports.extractParamsTiny = extractParamsTiny;\r\n//# sourceMappingURL=extractParamsTiny.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractParamsTiny.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractorsFactory.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractorsFactory.js ***!
  \*******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    var extractConvParams = common_1.extractConvParamsFactory(extractWeights, paramMappings);\r\n    var extractSeparableConvParams = common_1.extractSeparableConvParamsFactory(extractWeights, paramMappings);\r\n    function extractDenseBlock3Params(channelsIn, channelsOut, mappedPrefix, isFirstLayer) {\r\n        if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n        var conv0 = isFirstLayer\r\n            ? extractConvParams(channelsIn, channelsOut, 3, mappedPrefix + \"/conv0\")\r\n            : extractSeparableConvParams(channelsIn, channelsOut, mappedPrefix + \"/conv0\");\r\n        var conv1 = extractSeparableConvParams(channelsOut, channelsOut, mappedPrefix + \"/conv1\");\r\n        var conv2 = extractSeparableConvParams(channelsOut, channelsOut, mappedPrefix + \"/conv2\");\r\n        return { conv0: conv0, conv1: conv1, conv2: conv2 };\r\n    }\r\n    function extractDenseBlock4Params(channelsIn, channelsOut, mappedPrefix, isFirstLayer) {\r\n        if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n        var _a = extractDenseBlock3Params(channelsIn, channelsOut, mappedPrefix, isFirstLayer), conv0 = _a.conv0, conv1 = _a.conv1, conv2 = _a.conv2;\r\n        var conv3 = extractSeparableConvParams(channelsOut, channelsOut, mappedPrefix + \"/conv3\");\r\n        return { conv0: conv0, conv1: conv1, conv2: conv2, conv3: conv3 };\r\n    }\r\n    return {\r\n        extractDenseBlock3Params: extractDenseBlock3Params,\r\n        extractDenseBlock4Params: extractDenseBlock4Params\r\n    };\r\n}\r\nexports.extractorsFactory = extractorsFactory;\r\n//# sourceMappingURL=extractorsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/extractorsFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/loadParamsFactory.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/loadParamsFactory.js ***!
  \*******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar loadConvParamsFactory_1 = __webpack_require__(/*! ../common/loadConvParamsFactory */ \"./node_modules/face-api.js/build/commonjs/common/loadConvParamsFactory.js\");\r\nfunction loadParamsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = common_1.extractWeightEntryFactory(weightMap, paramMappings);\r\n    var extractConvParams = loadConvParamsFactory_1.loadConvParamsFactory(extractWeightEntry);\r\n    var extractSeparableConvParams = common_1.loadSeparableConvParamsFactory(extractWeightEntry);\r\n    function extractDenseBlock3Params(prefix, isFirstLayer) {\r\n        if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n        var conv0 = isFirstLayer\r\n            ? extractConvParams(prefix + \"/conv0\")\r\n            : extractSeparableConvParams(prefix + \"/conv0\");\r\n        var conv1 = extractSeparableConvParams(prefix + \"/conv1\");\r\n        var conv2 = extractSeparableConvParams(prefix + \"/conv2\");\r\n        return { conv0: conv0, conv1: conv1, conv2: conv2 };\r\n    }\r\n    function extractDenseBlock4Params(prefix, isFirstLayer) {\r\n        if (isFirstLayer === void 0) { isFirstLayer = false; }\r\n        var conv0 = isFirstLayer\r\n            ? extractConvParams(prefix + \"/conv0\")\r\n            : extractSeparableConvParams(prefix + \"/conv0\");\r\n        var conv1 = extractSeparableConvParams(prefix + \"/conv1\");\r\n        var conv2 = extractSeparableConvParams(prefix + \"/conv2\");\r\n        var conv3 = extractSeparableConvParams(prefix + \"/conv3\");\r\n        return { conv0: conv0, conv1: conv1, conv2: conv2, conv3: conv3 };\r\n    }\r\n    return {\r\n        extractDenseBlock3Params: extractDenseBlock3Params,\r\n        extractDenseBlock4Params: extractDenseBlock4Params\r\n    };\r\n}\r\nexports.loadParamsFactory = loadParamsFactory;\r\n//# sourceMappingURL=loadParamsFactory.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/loadParamsFactory.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68Net.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68Net.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar FaceFeatureExtractor_1 = __webpack_require__(/*! ../faceFeatureExtractor/FaceFeatureExtractor */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/FaceFeatureExtractor.js\");\r\nvar FaceLandmark68NetBase_1 = __webpack_require__(/*! ./FaceLandmark68NetBase */ \"./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68NetBase.js\");\r\nvar FaceLandmark68Net = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceLandmark68Net, _super);\r\n    function FaceLandmark68Net(faceFeatureExtractor) {\r\n        if (faceFeatureExtractor === void 0) { faceFeatureExtractor = new FaceFeatureExtractor_1.FaceFeatureExtractor(); }\r\n        return _super.call(this, 'FaceLandmark68Net', faceFeatureExtractor) || this;\r\n    }\r\n    FaceLandmark68Net.prototype.getDefaultModelName = function () {\r\n        return 'face_landmark_68_model';\r\n    };\r\n    FaceLandmark68Net.prototype.getClassifierChannelsIn = function () {\r\n        return 256;\r\n    };\r\n    return FaceLandmark68Net;\r\n}(FaceLandmark68NetBase_1.FaceLandmark68NetBase));\r\nexports.FaceLandmark68Net = FaceLandmark68Net;\r\n//# sourceMappingURL=FaceLandmark68Net.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68Net.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68NetBase.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68NetBase.js ***!
  \******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar FaceLandmarks68_1 = __webpack_require__(/*! ../classes/FaceLandmarks68 */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks68.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar FaceProcessor_1 = __webpack_require__(/*! ../faceProcessor/FaceProcessor */ \"./node_modules/face-api.js/build/commonjs/faceProcessor/FaceProcessor.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar FaceLandmark68NetBase = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceLandmark68NetBase, _super);\r\n    function FaceLandmark68NetBase() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    FaceLandmark68NetBase.prototype.postProcess = function (output, inputSize, originalDimensions) {\r\n        var inputDimensions = originalDimensions.map(function (_a) {\r\n            var width = _a.width, height = _a.height;\r\n            var scale = inputSize / Math.max(height, width);\r\n            return {\r\n                width: width * scale,\r\n                height: height * scale\r\n            };\r\n        });\r\n        var batchSize = inputDimensions.length;\r\n        return tf.tidy(function () {\r\n            var createInterleavedTensor = function (fillX, fillY) {\r\n                return tf.stack([\r\n                    tf.fill([68], fillX),\r\n                    tf.fill([68], fillY)\r\n                ], 1).as2D(1, 136).as1D();\r\n            };\r\n            var getPadding = function (batchIdx, cond) {\r\n                var _a = inputDimensions[batchIdx], width = _a.width, height = _a.height;\r\n                return cond(width, height) ? Math.abs(width - height) / 2 : 0;\r\n            };\r\n            var getPaddingX = function (batchIdx) { return getPadding(batchIdx, function (w, h) { return w < h; }); };\r\n            var getPaddingY = function (batchIdx) { return getPadding(batchIdx, function (w, h) { return h < w; }); };\r\n            var landmarkTensors = output\r\n                .mul(tf.fill([batchSize, 136], inputSize))\r\n                .sub(tf.stack(Array.from(Array(batchSize), function (_, batchIdx) {\r\n                return createInterleavedTensor(getPaddingX(batchIdx), getPaddingY(batchIdx));\r\n            })))\r\n                .div(tf.stack(Array.from(Array(batchSize), function (_, batchIdx) {\r\n                return createInterleavedTensor(inputDimensions[batchIdx].width, inputDimensions[batchIdx].height);\r\n            })));\r\n            return landmarkTensors;\r\n        });\r\n    };\r\n    FaceLandmark68NetBase.prototype.forwardInput = function (input) {\r\n        var _this = this;\r\n        return tf.tidy(function () {\r\n            var out = _this.runNet(input);\r\n            return _this.postProcess(out, input.inputSize, input.inputDimensions.map(function (_a) {\r\n                var height = _a[0], width = _a[1];\r\n                return ({ height: height, width: width });\r\n            }));\r\n        });\r\n    };\r\n    FaceLandmark68NetBase.prototype.forward = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceLandmark68NetBase.prototype.detectLandmarks = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var netInput, landmarkTensors, landmarksForBatch;\r\n            var _this = this;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1:\r\n                        netInput = _a.sent();\r\n                        landmarkTensors = tf.tidy(function () { return tf.unstack(_this.forwardInput(netInput)); });\r\n                        return [4 /*yield*/, Promise.all(landmarkTensors.map(function (landmarkTensor, batchIdx) { return tslib_1.__awaiter(_this, void 0, void 0, function () {\r\n                                var landmarksArray, _a, _b, xCoords, yCoords;\r\n                                return tslib_1.__generator(this, function (_c) {\r\n                                    switch (_c.label) {\r\n                                        case 0:\r\n                                            _b = (_a = Array).from;\r\n                                            return [4 /*yield*/, landmarkTensor.data()];\r\n                                        case 1:\r\n                                            landmarksArray = _b.apply(_a, [_c.sent()]);\r\n                                            xCoords = landmarksArray.filter(function (_, i) { return utils_1.isEven(i); });\r\n                                            yCoords = landmarksArray.filter(function (_, i) { return !utils_1.isEven(i); });\r\n                                            return [2 /*return*/, new FaceLandmarks68_1.FaceLandmarks68(Array(68).fill(0).map(function (_, i) { return new classes_1.Point(xCoords[i], yCoords[i]); }), {\r\n                                                    height: netInput.getInputHeight(batchIdx),\r\n                                                    width: netInput.getInputWidth(batchIdx),\r\n                                                })];\r\n                                    }\r\n                                });\r\n                            }); }))];\r\n                    case 2:\r\n                        landmarksForBatch = _a.sent();\r\n                        landmarkTensors.forEach(function (t) { return t.dispose(); });\r\n                        return [2 /*return*/, netInput.isBatchInput\r\n                                ? landmarksForBatch\r\n                                : landmarksForBatch[0]];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceLandmark68NetBase.prototype.getClassifierChannelsOut = function () {\r\n        return 136;\r\n    };\r\n    return FaceLandmark68NetBase;\r\n}(FaceProcessor_1.FaceProcessor));\r\nexports.FaceLandmark68NetBase = FaceLandmark68NetBase;\r\n//# sourceMappingURL=FaceLandmark68NetBase.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68NetBase.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68TinyNet.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68TinyNet.js ***!
  \******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar TinyFaceFeatureExtractor_1 = __webpack_require__(/*! ../faceFeatureExtractor/TinyFaceFeatureExtractor */ \"./node_modules/face-api.js/build/commonjs/faceFeatureExtractor/TinyFaceFeatureExtractor.js\");\r\nvar FaceLandmark68NetBase_1 = __webpack_require__(/*! ./FaceLandmark68NetBase */ \"./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68NetBase.js\");\r\nvar FaceLandmark68TinyNet = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceLandmark68TinyNet, _super);\r\n    function FaceLandmark68TinyNet(faceFeatureExtractor) {\r\n        if (faceFeatureExtractor === void 0) { faceFeatureExtractor = new TinyFaceFeatureExtractor_1.TinyFaceFeatureExtractor(); }\r\n        return _super.call(this, 'FaceLandmark68TinyNet', faceFeatureExtractor) || this;\r\n    }\r\n    FaceLandmark68TinyNet.prototype.getDefaultModelName = function () {\r\n        return 'face_landmark_68_tiny_model';\r\n    };\r\n    FaceLandmark68TinyNet.prototype.getClassifierChannelsIn = function () {\r\n        return 128;\r\n    };\r\n    return FaceLandmark68TinyNet;\r\n}(FaceLandmark68NetBase_1.FaceLandmark68NetBase));\r\nexports.FaceLandmark68TinyNet = FaceLandmark68TinyNet;\r\n//# sourceMappingURL=FaceLandmark68TinyNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68TinyNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceLandmarkNet/index.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceLandmarkNet/index.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar FaceLandmark68Net_1 = __webpack_require__(/*! ./FaceLandmark68Net */ \"./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68Net.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceLandmark68Net */ \"./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68Net.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceLandmark68TinyNet */ \"./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68TinyNet.js\"), exports);\r\nvar FaceLandmarkNet = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceLandmarkNet, _super);\r\n    function FaceLandmarkNet() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    return FaceLandmarkNet;\r\n}(FaceLandmark68Net_1.FaceLandmark68Net));\r\nexports.FaceLandmarkNet = FaceLandmarkNet;\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceLandmarkNet/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceProcessor/FaceProcessor.js":
/*!********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceProcessor/FaceProcessor.js ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar fullyConnectedLayer_1 = __webpack_require__(/*! ../common/fullyConnectedLayer */ \"./node_modules/face-api.js/build/commonjs/common/fullyConnectedLayer.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar NeuralNetwork_1 = __webpack_require__(/*! ../NeuralNetwork */ \"./node_modules/face-api.js/build/commonjs/NeuralNetwork.js\");\r\nvar extractParams_1 = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/commonjs/faceProcessor/extractParams.js\");\r\nvar extractParamsFromWeigthMap_1 = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/commonjs/faceProcessor/extractParamsFromWeigthMap.js\");\r\nvar util_1 = __webpack_require__(/*! ./util */ \"./node_modules/face-api.js/build/commonjs/faceProcessor/util.js\");\r\nvar FaceProcessor = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceProcessor, _super);\r\n    function FaceProcessor(_name, faceFeatureExtractor) {\r\n        var _this = _super.call(this, _name) || this;\r\n        _this._faceFeatureExtractor = faceFeatureExtractor;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(FaceProcessor.prototype, \"faceFeatureExtractor\", {\r\n        get: function () {\r\n            return this._faceFeatureExtractor;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    FaceProcessor.prototype.runNet = function (input) {\r\n        var _this = this;\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error(this._name + \" - load model before inference\");\r\n        }\r\n        return tf.tidy(function () {\r\n            var bottleneckFeatures = input instanceof dom_1.NetInput\r\n                ? _this.faceFeatureExtractor.forwardInput(input)\r\n                : input;\r\n            return fullyConnectedLayer_1.fullyConnectedLayer(bottleneckFeatures.as2D(bottleneckFeatures.shape[0], -1), params.fc);\r\n        });\r\n    };\r\n    FaceProcessor.prototype.dispose = function (throwOnRedispose) {\r\n        if (throwOnRedispose === void 0) { throwOnRedispose = true; }\r\n        this.faceFeatureExtractor.dispose(throwOnRedispose);\r\n        _super.prototype.dispose.call(this, throwOnRedispose);\r\n    };\r\n    FaceProcessor.prototype.loadClassifierParams = function (weights) {\r\n        var _a = this.extractClassifierParams(weights), params = _a.params, paramMappings = _a.paramMappings;\r\n        this._params = params;\r\n        this._paramMappings = paramMappings;\r\n    };\r\n    FaceProcessor.prototype.extractClassifierParams = function (weights) {\r\n        return extractParams_1.extractParams(weights, this.getClassifierChannelsIn(), this.getClassifierChannelsOut());\r\n    };\r\n    FaceProcessor.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        var _a = util_1.seperateWeightMaps(weightMap), featureExtractorMap = _a.featureExtractorMap, classifierMap = _a.classifierMap;\r\n        this.faceFeatureExtractor.loadFromWeightMap(featureExtractorMap);\r\n        return extractParamsFromWeigthMap_1.extractParamsFromWeigthMap(classifierMap);\r\n    };\r\n    FaceProcessor.prototype.extractParams = function (weights) {\r\n        var cIn = this.getClassifierChannelsIn();\r\n        var cOut = this.getClassifierChannelsOut();\r\n        var classifierWeightSize = (cOut * cIn) + cOut;\r\n        var featureExtractorWeights = weights.slice(0, weights.length - classifierWeightSize);\r\n        var classifierWeights = weights.slice(weights.length - classifierWeightSize);\r\n        this.faceFeatureExtractor.extractWeights(featureExtractorWeights);\r\n        return this.extractClassifierParams(classifierWeights);\r\n    };\r\n    return FaceProcessor;\r\n}(NeuralNetwork_1.NeuralNetwork));\r\nexports.FaceProcessor = FaceProcessor;\r\n//# sourceMappingURL=FaceProcessor.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceProcessor/FaceProcessor.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceProcessor/extractParams.js":
/*!********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceProcessor/extractParams.js ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nfunction extractParams(weights, channelsIn, channelsOut) {\r\n    var paramMappings = [];\r\n    var _a = common_1.extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var extractFCParams = common_1.extractFCParamsFactory(extractWeights, paramMappings);\r\n    var fc = extractFCParams(channelsIn, channelsOut, 'fc');\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        paramMappings: paramMappings,\r\n        params: { fc: fc }\r\n    };\r\n}\r\nexports.extractParams = extractParams;\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceProcessor/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceProcessor/extractParamsFromWeigthMap.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceProcessor/extractParamsFromWeigthMap.js ***!
  \*********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var extractWeightEntry = common_1.extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractFcParams(prefix) {\r\n        var weights = extractWeightEntry(prefix + \"/weights\", 2);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { weights: weights, bias: bias };\r\n    }\r\n    var params = {\r\n        fc: extractFcParams('fc')\r\n    };\r\n    common_1.disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\nexports.extractParamsFromWeigthMap = extractParamsFromWeigthMap;\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceProcessor/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceProcessor/util.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceProcessor/util.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction seperateWeightMaps(weightMap) {\r\n    var featureExtractorMap = {};\r\n    var classifierMap = {};\r\n    Object.keys(weightMap).forEach(function (key) {\r\n        var map = key.startsWith('fc') ? classifierMap : featureExtractorMap;\r\n        map[key] = weightMap[key];\r\n    });\r\n    return { featureExtractorMap: featureExtractorMap, classifierMap: classifierMap };\r\n}\r\nexports.seperateWeightMaps = seperateWeightMaps;\r\n//# sourceMappingURL=util.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceProcessor/util.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceRecognitionNet/FaceRecognitionNet.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceRecognitionNet/FaceRecognitionNet.js ***!
  \******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar NeuralNetwork_1 = __webpack_require__(/*! ../NeuralNetwork */ \"./node_modules/face-api.js/build/commonjs/NeuralNetwork.js\");\r\nvar ops_1 = __webpack_require__(/*! ../ops */ \"./node_modules/face-api.js/build/commonjs/ops/index.js\");\r\nvar convLayer_1 = __webpack_require__(/*! ./convLayer */ \"./node_modules/face-api.js/build/commonjs/faceRecognitionNet/convLayer.js\");\r\nvar extractParams_1 = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/commonjs/faceRecognitionNet/extractParams.js\");\r\nvar extractParamsFromWeigthMap_1 = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/commonjs/faceRecognitionNet/extractParamsFromWeigthMap.js\");\r\nvar residualLayer_1 = __webpack_require__(/*! ./residualLayer */ \"./node_modules/face-api.js/build/commonjs/faceRecognitionNet/residualLayer.js\");\r\nvar FaceRecognitionNet = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceRecognitionNet, _super);\r\n    function FaceRecognitionNet() {\r\n        return _super.call(this, 'FaceRecognitionNet') || this;\r\n    }\r\n    FaceRecognitionNet.prototype.forwardInput = function (input) {\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('FaceRecognitionNet - load model before inference');\r\n        }\r\n        return tf.tidy(function () {\r\n            var batchTensor = input.toBatchTensor(150, true).toFloat();\r\n            var meanRgb = [122.782, 117.001, 104.298];\r\n            var normalized = ops_1.normalize(batchTensor, meanRgb).div(tf.scalar(256));\r\n            var out = convLayer_1.convDown(normalized, params.conv32_down);\r\n            out = tf.maxPool(out, 3, 2, 'valid');\r\n            out = residualLayer_1.residual(out, params.conv32_1);\r\n            out = residualLayer_1.residual(out, params.conv32_2);\r\n            out = residualLayer_1.residual(out, params.conv32_3);\r\n            out = residualLayer_1.residualDown(out, params.conv64_down);\r\n            out = residualLayer_1.residual(out, params.conv64_1);\r\n            out = residualLayer_1.residual(out, params.conv64_2);\r\n            out = residualLayer_1.residual(out, params.conv64_3);\r\n            out = residualLayer_1.residualDown(out, params.conv128_down);\r\n            out = residualLayer_1.residual(out, params.conv128_1);\r\n            out = residualLayer_1.residual(out, params.conv128_2);\r\n            out = residualLayer_1.residualDown(out, params.conv256_down);\r\n            out = residualLayer_1.residual(out, params.conv256_1);\r\n            out = residualLayer_1.residual(out, params.conv256_2);\r\n            out = residualLayer_1.residualDown(out, params.conv256_down_out);\r\n            var globalAvg = out.mean([1, 2]);\r\n            var fullyConnected = tf.matMul(globalAvg, params.fc);\r\n            return fullyConnected;\r\n        });\r\n    };\r\n    FaceRecognitionNet.prototype.forward = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceRecognitionNet.prototype.computeFaceDescriptor = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var netInput, faceDescriptorTensors, faceDescriptorsForBatch;\r\n            var _this = this;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1:\r\n                        netInput = _a.sent();\r\n                        faceDescriptorTensors = tf.tidy(function () { return tf.unstack(_this.forwardInput(netInput)); });\r\n                        return [4 /*yield*/, Promise.all(faceDescriptorTensors.map(function (t) { return t.data(); }))];\r\n                    case 2:\r\n                        faceDescriptorsForBatch = _a.sent();\r\n                        faceDescriptorTensors.forEach(function (t) { return t.dispose(); });\r\n                        return [2 /*return*/, netInput.isBatchInput\r\n                                ? faceDescriptorsForBatch\r\n                                : faceDescriptorsForBatch[0]];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    FaceRecognitionNet.prototype.getDefaultModelName = function () {\r\n        return 'face_recognition_model';\r\n    };\r\n    FaceRecognitionNet.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return extractParamsFromWeigthMap_1.extractParamsFromWeigthMap(weightMap);\r\n    };\r\n    FaceRecognitionNet.prototype.extractParams = function (weights) {\r\n        return extractParams_1.extractParams(weights);\r\n    };\r\n    return FaceRecognitionNet;\r\n}(NeuralNetwork_1.NeuralNetwork));\r\nexports.FaceRecognitionNet = FaceRecognitionNet;\r\n//# sourceMappingURL=FaceRecognitionNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceRecognitionNet/FaceRecognitionNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceRecognitionNet/convLayer.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceRecognitionNet/convLayer.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar scaleLayer_1 = __webpack_require__(/*! ./scaleLayer */ \"./node_modules/face-api.js/build/commonjs/faceRecognitionNet/scaleLayer.js\");\r\nfunction convLayer(x, params, strides, withRelu, padding) {\r\n    if (padding === void 0) { padding = 'same'; }\r\n    var _a = params.conv, filters = _a.filters, bias = _a.bias;\r\n    var out = tf.conv2d(x, filters, strides, padding);\r\n    out = tf.add(out, bias);\r\n    out = scaleLayer_1.scale(out, params.scale);\r\n    return withRelu ? tf.relu(out) : out;\r\n}\r\nfunction conv(x, params) {\r\n    return convLayer(x, params, [1, 1], true);\r\n}\r\nexports.conv = conv;\r\nfunction convNoRelu(x, params) {\r\n    return convLayer(x, params, [1, 1], false);\r\n}\r\nexports.convNoRelu = convNoRelu;\r\nfunction convDown(x, params) {\r\n    return convLayer(x, params, [2, 2], true, 'valid');\r\n}\r\nexports.convDown = convDown;\r\n//# sourceMappingURL=convLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceRecognitionNet/convLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceRecognitionNet/extractParams.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceRecognitionNet/extractParams.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    function extractFilterValues(numFilterValues, numFilters, filterSize) {\r\n        var weights = extractWeights(numFilterValues);\r\n        var depth = weights.length / (numFilters * filterSize * filterSize);\r\n        if (utils_1.isFloat(depth)) {\r\n            throw new Error(\"depth has to be an integer: \" + depth + \", weights.length: \" + weights.length + \", numFilters: \" + numFilters + \", filterSize: \" + filterSize);\r\n        }\r\n        return tf.tidy(function () { return tf.transpose(tf.tensor4d(weights, [numFilters, depth, filterSize, filterSize]), [2, 3, 1, 0]); });\r\n    }\r\n    function extractConvParams(numFilterValues, numFilters, filterSize, mappedPrefix) {\r\n        var filters = extractFilterValues(numFilterValues, numFilters, filterSize);\r\n        var bias = tf.tensor1d(extractWeights(numFilters));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/filters\" }, { paramPath: mappedPrefix + \"/bias\" });\r\n        return { filters: filters, bias: bias };\r\n    }\r\n    function extractScaleLayerParams(numWeights, mappedPrefix) {\r\n        var weights = tf.tensor1d(extractWeights(numWeights));\r\n        var biases = tf.tensor1d(extractWeights(numWeights));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/weights\" }, { paramPath: mappedPrefix + \"/biases\" });\r\n        return {\r\n            weights: weights,\r\n            biases: biases\r\n        };\r\n    }\r\n    function extractConvLayerParams(numFilterValues, numFilters, filterSize, mappedPrefix) {\r\n        var conv = extractConvParams(numFilterValues, numFilters, filterSize, mappedPrefix + \"/conv\");\r\n        var scale = extractScaleLayerParams(numFilters, mappedPrefix + \"/scale\");\r\n        return { conv: conv, scale: scale };\r\n    }\r\n    function extractResidualLayerParams(numFilterValues, numFilters, filterSize, mappedPrefix, isDown) {\r\n        if (isDown === void 0) { isDown = false; }\r\n        var conv1 = extractConvLayerParams((isDown ? 0.5 : 1) * numFilterValues, numFilters, filterSize, mappedPrefix + \"/conv1\");\r\n        var conv2 = extractConvLayerParams(numFilterValues, numFilters, filterSize, mappedPrefix + \"/conv2\");\r\n        return { conv1: conv1, conv2: conv2 };\r\n    }\r\n    return {\r\n        extractConvLayerParams: extractConvLayerParams,\r\n        extractResidualLayerParams: extractResidualLayerParams\r\n    };\r\n}\r\nfunction extractParams(weights) {\r\n    var _a = common_1.extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var paramMappings = [];\r\n    var _b = extractorsFactory(extractWeights, paramMappings), extractConvLayerParams = _b.extractConvLayerParams, extractResidualLayerParams = _b.extractResidualLayerParams;\r\n    var conv32_down = extractConvLayerParams(4704, 32, 7, 'conv32_down');\r\n    var conv32_1 = extractResidualLayerParams(9216, 32, 3, 'conv32_1');\r\n    var conv32_2 = extractResidualLayerParams(9216, 32, 3, 'conv32_2');\r\n    var conv32_3 = extractResidualLayerParams(9216, 32, 3, 'conv32_3');\r\n    var conv64_down = extractResidualLayerParams(36864, 64, 3, 'conv64_down', true);\r\n    var conv64_1 = extractResidualLayerParams(36864, 64, 3, 'conv64_1');\r\n    var conv64_2 = extractResidualLayerParams(36864, 64, 3, 'conv64_2');\r\n    var conv64_3 = extractResidualLayerParams(36864, 64, 3, 'conv64_3');\r\n    var conv128_down = extractResidualLayerParams(147456, 128, 3, 'conv128_down', true);\r\n    var conv128_1 = extractResidualLayerParams(147456, 128, 3, 'conv128_1');\r\n    var conv128_2 = extractResidualLayerParams(147456, 128, 3, 'conv128_2');\r\n    var conv256_down = extractResidualLayerParams(589824, 256, 3, 'conv256_down', true);\r\n    var conv256_1 = extractResidualLayerParams(589824, 256, 3, 'conv256_1');\r\n    var conv256_2 = extractResidualLayerParams(589824, 256, 3, 'conv256_2');\r\n    var conv256_down_out = extractResidualLayerParams(589824, 256, 3, 'conv256_down_out');\r\n    var fc = tf.tidy(function () { return tf.transpose(tf.tensor2d(extractWeights(256 * 128), [128, 256]), [1, 0]); });\r\n    paramMappings.push({ paramPath: \"fc\" });\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    var params = {\r\n        conv32_down: conv32_down,\r\n        conv32_1: conv32_1,\r\n        conv32_2: conv32_2,\r\n        conv32_3: conv32_3,\r\n        conv64_down: conv64_down,\r\n        conv64_1: conv64_1,\r\n        conv64_2: conv64_2,\r\n        conv64_3: conv64_3,\r\n        conv128_down: conv128_down,\r\n        conv128_1: conv128_1,\r\n        conv128_2: conv128_2,\r\n        conv256_down: conv256_down,\r\n        conv256_1: conv256_1,\r\n        conv256_2: conv256_2,\r\n        conv256_down_out: conv256_down_out,\r\n        fc: fc\r\n    };\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\nexports.extractParams = extractParams;\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceRecognitionNet/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceRecognitionNet/extractParamsFromWeigthMap.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceRecognitionNet/extractParamsFromWeigthMap.js ***!
  \**************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nfunction extractorsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = common_1.extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractScaleLayerParams(prefix) {\r\n        var weights = extractWeightEntry(prefix + \"/scale/weights\", 1);\r\n        var biases = extractWeightEntry(prefix + \"/scale/biases\", 1);\r\n        return { weights: weights, biases: biases };\r\n    }\r\n    function extractConvLayerParams(prefix) {\r\n        var filters = extractWeightEntry(prefix + \"/conv/filters\", 4);\r\n        var bias = extractWeightEntry(prefix + \"/conv/bias\", 1);\r\n        var scale = extractScaleLayerParams(prefix);\r\n        return { conv: { filters: filters, bias: bias }, scale: scale };\r\n    }\r\n    function extractResidualLayerParams(prefix) {\r\n        return {\r\n            conv1: extractConvLayerParams(prefix + \"/conv1\"),\r\n            conv2: extractConvLayerParams(prefix + \"/conv2\")\r\n        };\r\n    }\r\n    return {\r\n        extractConvLayerParams: extractConvLayerParams,\r\n        extractResidualLayerParams: extractResidualLayerParams\r\n    };\r\n}\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var _a = extractorsFactory(weightMap, paramMappings), extractConvLayerParams = _a.extractConvLayerParams, extractResidualLayerParams = _a.extractResidualLayerParams;\r\n    var conv32_down = extractConvLayerParams('conv32_down');\r\n    var conv32_1 = extractResidualLayerParams('conv32_1');\r\n    var conv32_2 = extractResidualLayerParams('conv32_2');\r\n    var conv32_3 = extractResidualLayerParams('conv32_3');\r\n    var conv64_down = extractResidualLayerParams('conv64_down');\r\n    var conv64_1 = extractResidualLayerParams('conv64_1');\r\n    var conv64_2 = extractResidualLayerParams('conv64_2');\r\n    var conv64_3 = extractResidualLayerParams('conv64_3');\r\n    var conv128_down = extractResidualLayerParams('conv128_down');\r\n    var conv128_1 = extractResidualLayerParams('conv128_1');\r\n    var conv128_2 = extractResidualLayerParams('conv128_2');\r\n    var conv256_down = extractResidualLayerParams('conv256_down');\r\n    var conv256_1 = extractResidualLayerParams('conv256_1');\r\n    var conv256_2 = extractResidualLayerParams('conv256_2');\r\n    var conv256_down_out = extractResidualLayerParams('conv256_down_out');\r\n    var fc = weightMap['fc'];\r\n    paramMappings.push({ originalPath: 'fc', paramPath: 'fc' });\r\n    if (!utils_1.isTensor2D(fc)) {\r\n        throw new Error(\"expected weightMap[fc] to be a Tensor2D, instead have \" + fc);\r\n    }\r\n    var params = {\r\n        conv32_down: conv32_down,\r\n        conv32_1: conv32_1,\r\n        conv32_2: conv32_2,\r\n        conv32_3: conv32_3,\r\n        conv64_down: conv64_down,\r\n        conv64_1: conv64_1,\r\n        conv64_2: conv64_2,\r\n        conv64_3: conv64_3,\r\n        conv128_down: conv128_down,\r\n        conv128_1: conv128_1,\r\n        conv128_2: conv128_2,\r\n        conv256_down: conv256_down,\r\n        conv256_1: conv256_1,\r\n        conv256_2: conv256_2,\r\n        conv256_down_out: conv256_down_out,\r\n        fc: fc\r\n    };\r\n    common_1.disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\nexports.extractParamsFromWeigthMap = extractParamsFromWeigthMap;\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceRecognitionNet/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceRecognitionNet/index.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceRecognitionNet/index.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar FaceRecognitionNet_1 = __webpack_require__(/*! ./FaceRecognitionNet */ \"./node_modules/face-api.js/build/commonjs/faceRecognitionNet/FaceRecognitionNet.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceRecognitionNet */ \"./node_modules/face-api.js/build/commonjs/faceRecognitionNet/FaceRecognitionNet.js\"), exports);\r\nfunction createFaceRecognitionNet(weights) {\r\n    var net = new FaceRecognitionNet_1.FaceRecognitionNet();\r\n    net.extractWeights(weights);\r\n    return net;\r\n}\r\nexports.createFaceRecognitionNet = createFaceRecognitionNet;\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceRecognitionNet/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceRecognitionNet/residualLayer.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceRecognitionNet/residualLayer.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar convLayer_1 = __webpack_require__(/*! ./convLayer */ \"./node_modules/face-api.js/build/commonjs/faceRecognitionNet/convLayer.js\");\r\nfunction residual(x, params) {\r\n    var out = convLayer_1.conv(x, params.conv1);\r\n    out = convLayer_1.convNoRelu(out, params.conv2);\r\n    out = tf.add(out, x);\r\n    out = tf.relu(out);\r\n    return out;\r\n}\r\nexports.residual = residual;\r\nfunction residualDown(x, params) {\r\n    var out = convLayer_1.convDown(x, params.conv1);\r\n    out = convLayer_1.convNoRelu(out, params.conv2);\r\n    var pooled = tf.avgPool(x, 2, 2, 'valid');\r\n    var zeros = tf.zeros(pooled.shape);\r\n    var isPad = pooled.shape[3] !== out.shape[3];\r\n    var isAdjustShape = pooled.shape[1] !== out.shape[1] || pooled.shape[2] !== out.shape[2];\r\n    if (isAdjustShape) {\r\n        var padShapeX = tslib_1.__spreadArrays(out.shape);\r\n        padShapeX[1] = 1;\r\n        var zerosW = tf.zeros(padShapeX);\r\n        out = tf.concat([out, zerosW], 1);\r\n        var padShapeY = tslib_1.__spreadArrays(out.shape);\r\n        padShapeY[2] = 1;\r\n        var zerosH = tf.zeros(padShapeY);\r\n        out = tf.concat([out, zerosH], 2);\r\n    }\r\n    pooled = isPad ? tf.concat([pooled, zeros], 3) : pooled;\r\n    out = tf.add(pooled, out);\r\n    out = tf.relu(out);\r\n    return out;\r\n}\r\nexports.residualDown = residualDown;\r\n//# sourceMappingURL=residualLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceRecognitionNet/residualLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/faceRecognitionNet/scaleLayer.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/faceRecognitionNet/scaleLayer.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction scale(x, params) {\r\n    return tf.add(tf.mul(x, params.weights), params.biases);\r\n}\r\nexports.scale = scale;\r\n//# sourceMappingURL=scaleLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/faceRecognitionNet/scaleLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/factories/WithAge.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/factories/WithAge.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction isWithAge(obj) {\r\n    return typeof obj['age'] === 'number';\r\n}\r\nexports.isWithAge = isWithAge;\r\nfunction extendWithAge(sourceObj, age) {\r\n    var extension = { age: age };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\nexports.extendWithAge = extendWithAge;\r\n//# sourceMappingURL=WithAge.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/factories/WithAge.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/factories/WithFaceDescriptor.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/factories/WithFaceDescriptor.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction extendWithFaceDescriptor(sourceObj, descriptor) {\r\n    var extension = { descriptor: descriptor };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\nexports.extendWithFaceDescriptor = extendWithFaceDescriptor;\r\n//# sourceMappingURL=WithFaceDescriptor.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/factories/WithFaceDescriptor.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/factories/WithFaceDetection.js":
/*!********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/factories/WithFaceDetection.js ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar FaceDetection_1 = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js\");\r\nfunction isWithFaceDetection(obj) {\r\n    return obj['detection'] instanceof FaceDetection_1.FaceDetection;\r\n}\r\nexports.isWithFaceDetection = isWithFaceDetection;\r\nfunction extendWithFaceDetection(sourceObj, detection) {\r\n    var extension = { detection: detection };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\nexports.extendWithFaceDetection = extendWithFaceDetection;\r\n//# sourceMappingURL=WithFaceDetection.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/factories/WithFaceDetection.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/factories/WithFaceExpressions.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/factories/WithFaceExpressions.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar FaceExpressions_1 = __webpack_require__(/*! ../faceExpressionNet/FaceExpressions */ \"./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressions.js\");\r\nfunction isWithFaceExpressions(obj) {\r\n    return obj['expressions'] instanceof FaceExpressions_1.FaceExpressions;\r\n}\r\nexports.isWithFaceExpressions = isWithFaceExpressions;\r\nfunction extendWithFaceExpressions(sourceObj, expressions) {\r\n    var extension = { expressions: expressions };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\nexports.extendWithFaceExpressions = extendWithFaceExpressions;\r\n//# sourceMappingURL=WithFaceExpressions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/factories/WithFaceExpressions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/factories/WithFaceLandmarks.js":
/*!********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/factories/WithFaceLandmarks.js ***!
  \********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar FaceDetection_1 = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js\");\r\nvar FaceLandmarks_1 = __webpack_require__(/*! ../classes/FaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks.js\");\r\nvar WithFaceDetection_1 = __webpack_require__(/*! ./WithFaceDetection */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceDetection.js\");\r\nfunction isWithFaceLandmarks(obj) {\r\n    return WithFaceDetection_1.isWithFaceDetection(obj)\r\n        && obj['landmarks'] instanceof FaceLandmarks_1.FaceLandmarks\r\n        && obj['unshiftedLandmarks'] instanceof FaceLandmarks_1.FaceLandmarks\r\n        && obj['alignedRect'] instanceof FaceDetection_1.FaceDetection;\r\n}\r\nexports.isWithFaceLandmarks = isWithFaceLandmarks;\r\nfunction extendWithFaceLandmarks(sourceObj, unshiftedLandmarks) {\r\n    var shift = sourceObj.detection.box;\r\n    var landmarks = unshiftedLandmarks.shiftBy(shift.x, shift.y);\r\n    var rect = landmarks.align();\r\n    var imageDims = sourceObj.detection.imageDims;\r\n    var alignedRect = new FaceDetection_1.FaceDetection(sourceObj.detection.score, rect.rescale(imageDims.reverse()), imageDims);\r\n    var extension = {\r\n        landmarks: landmarks,\r\n        unshiftedLandmarks: unshiftedLandmarks,\r\n        alignedRect: alignedRect\r\n    };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\nexports.extendWithFaceLandmarks = extendWithFaceLandmarks;\r\n//# sourceMappingURL=WithFaceLandmarks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/factories/WithFaceLandmarks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/factories/WithGender.js":
/*!*************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/factories/WithGender.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar types_1 = __webpack_require__(/*! ../ageGenderNet/types */ \"./node_modules/face-api.js/build/commonjs/ageGenderNet/types.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nfunction isWithGender(obj) {\r\n    return (obj['gender'] === types_1.Gender.MALE || obj['gender'] === types_1.Gender.FEMALE)\r\n        && utils_1.isValidProbablitiy(obj['genderProbability']);\r\n}\r\nexports.isWithGender = isWithGender;\r\nfunction extendWithGender(sourceObj, gender, genderProbability) {\r\n    var extension = { gender: gender, genderProbability: genderProbability };\r\n    return Object.assign({}, sourceObj, extension);\r\n}\r\nexports.extendWithGender = extendWithGender;\r\n//# sourceMappingURL=WithGender.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/factories/WithGender.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/factories/index.js":
/*!********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/factories/index.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./WithFaceDescriptor */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceDescriptor.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./WithFaceDetection */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceDetection.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./WithFaceExpressions */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceExpressions.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./WithFaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceLandmarks.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./WithAge */ \"./node_modules/face-api.js/build/commonjs/factories/WithAge.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./WithGender */ \"./node_modules/face-api.js/build/commonjs/factories/WithGender.js\"), exports);\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/factories/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/ComposableTask.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/ComposableTask.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar ComposableTask = /** @class */ (function () {\r\n    function ComposableTask() {\r\n    }\r\n    ComposableTask.prototype.then = function (onfulfilled) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = onfulfilled;\r\n                        return [4 /*yield*/, this.run()];\r\n                    case 1: return [2 /*return*/, _a.apply(void 0, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    ComposableTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            return tslib_1.__generator(this, function (_a) {\r\n                throw new Error('ComposableTask - run is not implemented');\r\n            });\r\n        });\r\n    };\r\n    return ComposableTask;\r\n}());\r\nexports.ComposableTask = ComposableTask;\r\n//# sourceMappingURL=ComposableTask.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/ComposableTask.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/ComputeFaceDescriptorsTasks.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/ComputeFaceDescriptorsTasks.js ***!
  \******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar WithFaceDescriptor_1 = __webpack_require__(/*! ../factories/WithFaceDescriptor */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceDescriptor.js\");\r\nvar ComposableTask_1 = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/ComposableTask.js\");\r\nvar extractFacesAndComputeResults_1 = __webpack_require__(/*! ./extractFacesAndComputeResults */ \"./node_modules/face-api.js/build/commonjs/globalApi/extractFacesAndComputeResults.js\");\r\nvar nets_1 = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/commonjs/globalApi/nets.js\");\r\nvar PredictAgeAndGenderTask_1 = __webpack_require__(/*! ./PredictAgeAndGenderTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/PredictAgeAndGenderTask.js\");\r\nvar PredictFaceExpressionsTask_1 = __webpack_require__(/*! ./PredictFaceExpressionsTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/PredictFaceExpressionsTask.js\");\r\nvar ComputeFaceDescriptorsTaskBase = /** @class */ (function (_super) {\r\n    tslib_1.__extends(ComputeFaceDescriptorsTaskBase, _super);\r\n    function ComputeFaceDescriptorsTaskBase(parentTask, input) {\r\n        var _this = _super.call(this) || this;\r\n        _this.parentTask = parentTask;\r\n        _this.input = input;\r\n        return _this;\r\n    }\r\n    return ComputeFaceDescriptorsTaskBase;\r\n}(ComposableTask_1.ComposableTask));\r\nexports.ComputeFaceDescriptorsTaskBase = ComputeFaceDescriptorsTaskBase;\r\nvar ComputeAllFaceDescriptorsTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(ComputeAllFaceDescriptorsTask, _super);\r\n    function ComputeAllFaceDescriptorsTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    ComputeAllFaceDescriptorsTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var parentResults, descriptors;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResults = _a.sent();\r\n                        return [4 /*yield*/, extractFacesAndComputeResults_1.extractAllFacesAndComputeResults(parentResults, this.input, function (faces) { return Promise.all(faces.map(function (face) {\r\n                                return nets_1.nets.faceRecognitionNet.computeFaceDescriptor(face);\r\n                            })); }, null, function (parentResult) { return parentResult.landmarks.align(null, { useDlibAlignment: true }); })];\r\n                    case 2:\r\n                        descriptors = _a.sent();\r\n                        return [2 /*return*/, descriptors.map(function (descriptor, i) { return WithFaceDescriptor_1.extendWithFaceDescriptor(parentResults[i], descriptor); })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    ComputeAllFaceDescriptorsTask.prototype.withFaceExpressions = function () {\r\n        return new PredictFaceExpressionsTask_1.PredictAllFaceExpressionsWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    ComputeAllFaceDescriptorsTask.prototype.withAgeAndGender = function () {\r\n        return new PredictAgeAndGenderTask_1.PredictAllAgeAndGenderWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    return ComputeAllFaceDescriptorsTask;\r\n}(ComputeFaceDescriptorsTaskBase));\r\nexports.ComputeAllFaceDescriptorsTask = ComputeAllFaceDescriptorsTask;\r\nvar ComputeSingleFaceDescriptorTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(ComputeSingleFaceDescriptorTask, _super);\r\n    function ComputeSingleFaceDescriptorTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    ComputeSingleFaceDescriptorTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var parentResult, descriptor;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResult = _a.sent();\r\n                        if (!parentResult) {\r\n                            return [2 /*return*/];\r\n                        }\r\n                        return [4 /*yield*/, extractFacesAndComputeResults_1.extractSingleFaceAndComputeResult(parentResult, this.input, function (face) { return nets_1.nets.faceRecognitionNet.computeFaceDescriptor(face); }, null, function (parentResult) { return parentResult.landmarks.align(null, { useDlibAlignment: true }); })];\r\n                    case 2:\r\n                        descriptor = _a.sent();\r\n                        return [2 /*return*/, WithFaceDescriptor_1.extendWithFaceDescriptor(parentResult, descriptor)];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    ComputeSingleFaceDescriptorTask.prototype.withFaceExpressions = function () {\r\n        return new PredictFaceExpressionsTask_1.PredictSingleFaceExpressionsWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    ComputeSingleFaceDescriptorTask.prototype.withAgeAndGender = function () {\r\n        return new PredictAgeAndGenderTask_1.PredictSingleAgeAndGenderWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    return ComputeSingleFaceDescriptorTask;\r\n}(ComputeFaceDescriptorsTaskBase));\r\nexports.ComputeSingleFaceDescriptorTask = ComputeSingleFaceDescriptorTask;\r\n//# sourceMappingURL=ComputeFaceDescriptorsTasks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/ComputeFaceDescriptorsTasks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/DetectFaceLandmarksTasks.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/DetectFaceLandmarksTasks.js ***!
  \***************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar WithFaceLandmarks_1 = __webpack_require__(/*! ../factories/WithFaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceLandmarks.js\");\r\nvar ComposableTask_1 = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/ComposableTask.js\");\r\nvar ComputeFaceDescriptorsTasks_1 = __webpack_require__(/*! ./ComputeFaceDescriptorsTasks */ \"./node_modules/face-api.js/build/commonjs/globalApi/ComputeFaceDescriptorsTasks.js\");\r\nvar nets_1 = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/commonjs/globalApi/nets.js\");\r\nvar PredictAgeAndGenderTask_1 = __webpack_require__(/*! ./PredictAgeAndGenderTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/PredictAgeAndGenderTask.js\");\r\nvar PredictFaceExpressionsTask_1 = __webpack_require__(/*! ./PredictFaceExpressionsTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/PredictFaceExpressionsTask.js\");\r\nvar DetectFaceLandmarksTaskBase = /** @class */ (function (_super) {\r\n    tslib_1.__extends(DetectFaceLandmarksTaskBase, _super);\r\n    function DetectFaceLandmarksTaskBase(parentTask, input, useTinyLandmarkNet) {\r\n        var _this = _super.call(this) || this;\r\n        _this.parentTask = parentTask;\r\n        _this.input = input;\r\n        _this.useTinyLandmarkNet = useTinyLandmarkNet;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(DetectFaceLandmarksTaskBase.prototype, \"landmarkNet\", {\r\n        get: function () {\r\n            return this.useTinyLandmarkNet\r\n                ? nets_1.nets.faceLandmark68TinyNet\r\n                : nets_1.nets.faceLandmark68Net;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return DetectFaceLandmarksTaskBase;\r\n}(ComposableTask_1.ComposableTask));\r\nexports.DetectFaceLandmarksTaskBase = DetectFaceLandmarksTaskBase;\r\nvar DetectAllFaceLandmarksTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(DetectAllFaceLandmarksTask, _super);\r\n    function DetectAllFaceLandmarksTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    DetectAllFaceLandmarksTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var parentResults, detections, faces, _a, faceLandmarksByFace;\r\n            var _this = this;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResults = _b.sent();\r\n                        detections = parentResults.map(function (res) { return res.detection; });\r\n                        if (!(this.input instanceof tf.Tensor)) return [3 /*break*/, 3];\r\n                        return [4 /*yield*/, dom_1.extractFaceTensors(this.input, detections)];\r\n                    case 2:\r\n                        _a = _b.sent();\r\n                        return [3 /*break*/, 5];\r\n                    case 3: return [4 /*yield*/, dom_1.extractFaces(this.input, detections)];\r\n                    case 4:\r\n                        _a = _b.sent();\r\n                        _b.label = 5;\r\n                    case 5:\r\n                        faces = _a;\r\n                        return [4 /*yield*/, Promise.all(faces.map(function (face) { return _this.landmarkNet.detectLandmarks(face); }))];\r\n                    case 6:\r\n                        faceLandmarksByFace = _b.sent();\r\n                        faces.forEach(function (f) { return f instanceof tf.Tensor && f.dispose(); });\r\n                        return [2 /*return*/, parentResults.map(function (parentResult, i) {\r\n                                return WithFaceLandmarks_1.extendWithFaceLandmarks(parentResult, faceLandmarksByFace[i]);\r\n                            })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    DetectAllFaceLandmarksTask.prototype.withFaceExpressions = function () {\r\n        return new PredictFaceExpressionsTask_1.PredictAllFaceExpressionsWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    DetectAllFaceLandmarksTask.prototype.withAgeAndGender = function () {\r\n        return new PredictAgeAndGenderTask_1.PredictAllAgeAndGenderWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    DetectAllFaceLandmarksTask.prototype.withFaceDescriptors = function () {\r\n        return new ComputeFaceDescriptorsTasks_1.ComputeAllFaceDescriptorsTask(this, this.input);\r\n    };\r\n    return DetectAllFaceLandmarksTask;\r\n}(DetectFaceLandmarksTaskBase));\r\nexports.DetectAllFaceLandmarksTask = DetectAllFaceLandmarksTask;\r\nvar DetectSingleFaceLandmarksTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(DetectSingleFaceLandmarksTask, _super);\r\n    function DetectSingleFaceLandmarksTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    DetectSingleFaceLandmarksTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var parentResult, detection, faces, _a, landmarks;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResult = _b.sent();\r\n                        if (!parentResult) {\r\n                            return [2 /*return*/];\r\n                        }\r\n                        detection = parentResult.detection;\r\n                        if (!(this.input instanceof tf.Tensor)) return [3 /*break*/, 3];\r\n                        return [4 /*yield*/, dom_1.extractFaceTensors(this.input, [detection])];\r\n                    case 2:\r\n                        _a = _b.sent();\r\n                        return [3 /*break*/, 5];\r\n                    case 3: return [4 /*yield*/, dom_1.extractFaces(this.input, [detection])];\r\n                    case 4:\r\n                        _a = _b.sent();\r\n                        _b.label = 5;\r\n                    case 5:\r\n                        faces = _a;\r\n                        return [4 /*yield*/, this.landmarkNet.detectLandmarks(faces[0])];\r\n                    case 6:\r\n                        landmarks = _b.sent();\r\n                        faces.forEach(function (f) { return f instanceof tf.Tensor && f.dispose(); });\r\n                        return [2 /*return*/, WithFaceLandmarks_1.extendWithFaceLandmarks(parentResult, landmarks)];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    DetectSingleFaceLandmarksTask.prototype.withFaceExpressions = function () {\r\n        return new PredictFaceExpressionsTask_1.PredictSingleFaceExpressionsWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    DetectSingleFaceLandmarksTask.prototype.withAgeAndGender = function () {\r\n        return new PredictAgeAndGenderTask_1.PredictSingleAgeAndGenderWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    DetectSingleFaceLandmarksTask.prototype.withFaceDescriptor = function () {\r\n        return new ComputeFaceDescriptorsTasks_1.ComputeSingleFaceDescriptorTask(this, this.input);\r\n    };\r\n    return DetectSingleFaceLandmarksTask;\r\n}(DetectFaceLandmarksTaskBase));\r\nexports.DetectSingleFaceLandmarksTask = DetectSingleFaceLandmarksTask;\r\n//# sourceMappingURL=DetectFaceLandmarksTasks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/DetectFaceLandmarksTasks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/DetectFacesTasks.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/DetectFacesTasks.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar WithFaceDetection_1 = __webpack_require__(/*! ../factories/WithFaceDetection */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceDetection.js\");\r\nvar MtcnnOptions_1 = __webpack_require__(/*! ../mtcnn/MtcnnOptions */ \"./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnOptions.js\");\r\nvar SsdMobilenetv1Options_1 = __webpack_require__(/*! ../ssdMobilenetv1/SsdMobilenetv1Options */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1Options.js\");\r\nvar TinyFaceDetectorOptions_1 = __webpack_require__(/*! ../tinyFaceDetector/TinyFaceDetectorOptions */ \"./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetectorOptions.js\");\r\nvar tinyYolov2_1 = __webpack_require__(/*! ../tinyYolov2 */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/index.js\");\r\nvar ComposableTask_1 = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/ComposableTask.js\");\r\nvar DetectFaceLandmarksTasks_1 = __webpack_require__(/*! ./DetectFaceLandmarksTasks */ \"./node_modules/face-api.js/build/commonjs/globalApi/DetectFaceLandmarksTasks.js\");\r\nvar nets_1 = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/commonjs/globalApi/nets.js\");\r\nvar PredictAgeAndGenderTask_1 = __webpack_require__(/*! ./PredictAgeAndGenderTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/PredictAgeAndGenderTask.js\");\r\nvar PredictFaceExpressionsTask_1 = __webpack_require__(/*! ./PredictFaceExpressionsTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/PredictFaceExpressionsTask.js\");\r\nvar DetectFacesTaskBase = /** @class */ (function (_super) {\r\n    tslib_1.__extends(DetectFacesTaskBase, _super);\r\n    function DetectFacesTaskBase(input, options) {\r\n        if (options === void 0) { options = new SsdMobilenetv1Options_1.SsdMobilenetv1Options(); }\r\n        var _this = _super.call(this) || this;\r\n        _this.input = input;\r\n        _this.options = options;\r\n        return _this;\r\n    }\r\n    return DetectFacesTaskBase;\r\n}(ComposableTask_1.ComposableTask));\r\nexports.DetectFacesTaskBase = DetectFacesTaskBase;\r\nvar DetectAllFacesTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(DetectAllFacesTask, _super);\r\n    function DetectAllFacesTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    DetectAllFacesTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a, input, options, faceDetectionFunction;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this, input = _a.input, options = _a.options;\r\n                        if (!(options instanceof MtcnnOptions_1.MtcnnOptions)) return [3 /*break*/, 2];\r\n                        return [4 /*yield*/, nets_1.nets.mtcnn.forward(input, options)];\r\n                    case 1: return [2 /*return*/, (_b.sent())\r\n                            .map(function (result) { return result.detection; })];\r\n                    case 2:\r\n                        faceDetectionFunction = options instanceof TinyFaceDetectorOptions_1.TinyFaceDetectorOptions\r\n                            ? function (input) { return nets_1.nets.tinyFaceDetector.locateFaces(input, options); }\r\n                            : (options instanceof SsdMobilenetv1Options_1.SsdMobilenetv1Options\r\n                                ? function (input) { return nets_1.nets.ssdMobilenetv1.locateFaces(input, options); }\r\n                                : (options instanceof tinyYolov2_1.TinyYolov2Options\r\n                                    ? function (input) { return nets_1.nets.tinyYolov2.locateFaces(input, options); }\r\n                                    : null));\r\n                        if (!faceDetectionFunction) {\r\n                            throw new Error('detectFaces - expected options to be instance of TinyFaceDetectorOptions | SsdMobilenetv1Options | MtcnnOptions | TinyYolov2Options');\r\n                        }\r\n                        return [2 /*return*/, faceDetectionFunction(input)];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    DetectAllFacesTask.prototype.runAndExtendWithFaceDetections = function () {\r\n        var _this = this;\r\n        return new Promise(function (res) { return tslib_1.__awaiter(_this, void 0, void 0, function () {\r\n            var detections;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.run()];\r\n                    case 1:\r\n                        detections = _a.sent();\r\n                        return [2 /*return*/, res(detections.map(function (detection) { return WithFaceDetection_1.extendWithFaceDetection({}, detection); }))];\r\n                }\r\n            });\r\n        }); });\r\n    };\r\n    DetectAllFacesTask.prototype.withFaceLandmarks = function (useTinyLandmarkNet) {\r\n        if (useTinyLandmarkNet === void 0) { useTinyLandmarkNet = false; }\r\n        return new DetectFaceLandmarksTasks_1.DetectAllFaceLandmarksTask(this.runAndExtendWithFaceDetections(), this.input, useTinyLandmarkNet);\r\n    };\r\n    DetectAllFacesTask.prototype.withFaceExpressions = function () {\r\n        return new PredictFaceExpressionsTask_1.PredictAllFaceExpressionsTask(this.runAndExtendWithFaceDetections(), this.input);\r\n    };\r\n    DetectAllFacesTask.prototype.withAgeAndGender = function () {\r\n        return new PredictAgeAndGenderTask_1.PredictAllAgeAndGenderTask(this.runAndExtendWithFaceDetections(), this.input);\r\n    };\r\n    return DetectAllFacesTask;\r\n}(DetectFacesTaskBase));\r\nexports.DetectAllFacesTask = DetectAllFacesTask;\r\nvar DetectSingleFaceTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(DetectSingleFaceTask, _super);\r\n    function DetectSingleFaceTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    DetectSingleFaceTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var faceDetections, faceDetectionWithHighestScore;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, new DetectAllFacesTask(this.input, this.options)];\r\n                    case 1:\r\n                        faceDetections = _a.sent();\r\n                        faceDetectionWithHighestScore = faceDetections[0];\r\n                        faceDetections.forEach(function (faceDetection) {\r\n                            if (faceDetection.score > faceDetectionWithHighestScore.score) {\r\n                                faceDetectionWithHighestScore = faceDetection;\r\n                            }\r\n                        });\r\n                        return [2 /*return*/, faceDetectionWithHighestScore];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    DetectSingleFaceTask.prototype.runAndExtendWithFaceDetection = function () {\r\n        var _this = this;\r\n        return new Promise(function (res) { return tslib_1.__awaiter(_this, void 0, void 0, function () {\r\n            var detection;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.run()];\r\n                    case 1:\r\n                        detection = _a.sent();\r\n                        return [2 /*return*/, res(detection ? WithFaceDetection_1.extendWithFaceDetection({}, detection) : undefined)];\r\n                }\r\n            });\r\n        }); });\r\n    };\r\n    DetectSingleFaceTask.prototype.withFaceLandmarks = function (useTinyLandmarkNet) {\r\n        if (useTinyLandmarkNet === void 0) { useTinyLandmarkNet = false; }\r\n        return new DetectFaceLandmarksTasks_1.DetectSingleFaceLandmarksTask(this.runAndExtendWithFaceDetection(), this.input, useTinyLandmarkNet);\r\n    };\r\n    DetectSingleFaceTask.prototype.withFaceExpressions = function () {\r\n        return new PredictFaceExpressionsTask_1.PredictSingleFaceExpressionsTask(this.runAndExtendWithFaceDetection(), this.input);\r\n    };\r\n    DetectSingleFaceTask.prototype.withAgeAndGender = function () {\r\n        return new PredictAgeAndGenderTask_1.PredictSingleAgeAndGenderTask(this.runAndExtendWithFaceDetection(), this.input);\r\n    };\r\n    return DetectSingleFaceTask;\r\n}(DetectFacesTaskBase));\r\nexports.DetectSingleFaceTask = DetectSingleFaceTask;\r\n//# sourceMappingURL=DetectFacesTasks.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/DetectFacesTasks.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/FaceMatcher.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/FaceMatcher.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar FaceMatch_1 = __webpack_require__(/*! ../classes/FaceMatch */ \"./node_modules/face-api.js/build/commonjs/classes/FaceMatch.js\");\r\nvar LabeledFaceDescriptors_1 = __webpack_require__(/*! ../classes/LabeledFaceDescriptors */ \"./node_modules/face-api.js/build/commonjs/classes/LabeledFaceDescriptors.js\");\r\nvar euclideanDistance_1 = __webpack_require__(/*! ../euclideanDistance */ \"./node_modules/face-api.js/build/commonjs/euclideanDistance.js\");\r\nvar FaceMatcher = /** @class */ (function () {\r\n    function FaceMatcher(inputs, distanceThreshold) {\r\n        if (distanceThreshold === void 0) { distanceThreshold = 0.6; }\r\n        this._distanceThreshold = distanceThreshold;\r\n        var inputArray = Array.isArray(inputs) ? inputs : [inputs];\r\n        if (!inputArray.length) {\r\n            throw new Error(\"FaceRecognizer.constructor - expected atleast one input\");\r\n        }\r\n        var count = 1;\r\n        var createUniqueLabel = function () { return \"person \" + count++; };\r\n        this._labeledDescriptors = inputArray.map(function (desc) {\r\n            if (desc instanceof LabeledFaceDescriptors_1.LabeledFaceDescriptors) {\r\n                return desc;\r\n            }\r\n            if (desc instanceof Float32Array) {\r\n                return new LabeledFaceDescriptors_1.LabeledFaceDescriptors(createUniqueLabel(), [desc]);\r\n            }\r\n            if (desc.descriptor && desc.descriptor instanceof Float32Array) {\r\n                return new LabeledFaceDescriptors_1.LabeledFaceDescriptors(createUniqueLabel(), [desc.descriptor]);\r\n            }\r\n            throw new Error(\"FaceRecognizer.constructor - expected inputs to be of type LabeledFaceDescriptors | WithFaceDescriptor<any> | Float32Array | Array<LabeledFaceDescriptors | WithFaceDescriptor<any> | Float32Array>\");\r\n        });\r\n    }\r\n    Object.defineProperty(FaceMatcher.prototype, \"labeledDescriptors\", {\r\n        get: function () { return this._labeledDescriptors; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(FaceMatcher.prototype, \"distanceThreshold\", {\r\n        get: function () { return this._distanceThreshold; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    FaceMatcher.prototype.computeMeanDistance = function (queryDescriptor, descriptors) {\r\n        return descriptors\r\n            .map(function (d) { return euclideanDistance_1.euclideanDistance(d, queryDescriptor); })\r\n            .reduce(function (d1, d2) { return d1 + d2; }, 0)\r\n            / (descriptors.length || 1);\r\n    };\r\n    FaceMatcher.prototype.matchDescriptor = function (queryDescriptor) {\r\n        var _this = this;\r\n        return this.labeledDescriptors\r\n            .map(function (_a) {\r\n            var descriptors = _a.descriptors, label = _a.label;\r\n            return new FaceMatch_1.FaceMatch(label, _this.computeMeanDistance(queryDescriptor, descriptors));\r\n        })\r\n            .reduce(function (best, curr) { return best.distance < curr.distance ? best : curr; });\r\n    };\r\n    FaceMatcher.prototype.findBestMatch = function (queryDescriptor) {\r\n        var bestMatch = this.matchDescriptor(queryDescriptor);\r\n        return bestMatch.distance < this.distanceThreshold\r\n            ? bestMatch\r\n            : new FaceMatch_1.FaceMatch('unknown', bestMatch.distance);\r\n    };\r\n    FaceMatcher.prototype.toJSON = function () {\r\n        return {\r\n            distanceThreshold: this.distanceThreshold,\r\n            labeledDescriptors: this.labeledDescriptors.map(function (ld) { return ld.toJSON(); })\r\n        };\r\n    };\r\n    FaceMatcher.fromJSON = function (json) {\r\n        var labeledDescriptors = json.labeledDescriptors\r\n            .map(function (ld) { return LabeledFaceDescriptors_1.LabeledFaceDescriptors.fromJSON(ld); });\r\n        return new FaceMatcher(labeledDescriptors, json.distanceThreshold);\r\n    };\r\n    return FaceMatcher;\r\n}());\r\nexports.FaceMatcher = FaceMatcher;\r\n//# sourceMappingURL=FaceMatcher.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/FaceMatcher.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/PredictAgeAndGenderTask.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/PredictAgeAndGenderTask.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar WithAge_1 = __webpack_require__(/*! ../factories/WithAge */ \"./node_modules/face-api.js/build/commonjs/factories/WithAge.js\");\r\nvar WithGender_1 = __webpack_require__(/*! ../factories/WithGender */ \"./node_modules/face-api.js/build/commonjs/factories/WithGender.js\");\r\nvar ComposableTask_1 = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/ComposableTask.js\");\r\nvar ComputeFaceDescriptorsTasks_1 = __webpack_require__(/*! ./ComputeFaceDescriptorsTasks */ \"./node_modules/face-api.js/build/commonjs/globalApi/ComputeFaceDescriptorsTasks.js\");\r\nvar extractFacesAndComputeResults_1 = __webpack_require__(/*! ./extractFacesAndComputeResults */ \"./node_modules/face-api.js/build/commonjs/globalApi/extractFacesAndComputeResults.js\");\r\nvar nets_1 = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/commonjs/globalApi/nets.js\");\r\nvar PredictFaceExpressionsTask_1 = __webpack_require__(/*! ./PredictFaceExpressionsTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/PredictFaceExpressionsTask.js\");\r\nvar PredictAgeAndGenderTaskBase = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictAgeAndGenderTaskBase, _super);\r\n    function PredictAgeAndGenderTaskBase(parentTask, input, extractedFaces) {\r\n        var _this = _super.call(this) || this;\r\n        _this.parentTask = parentTask;\r\n        _this.input = input;\r\n        _this.extractedFaces = extractedFaces;\r\n        return _this;\r\n    }\r\n    return PredictAgeAndGenderTaskBase;\r\n}(ComposableTask_1.ComposableTask));\r\nexports.PredictAgeAndGenderTaskBase = PredictAgeAndGenderTaskBase;\r\nvar PredictAllAgeAndGenderTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictAllAgeAndGenderTask, _super);\r\n    function PredictAllAgeAndGenderTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictAllAgeAndGenderTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var parentResults, ageAndGenderByFace;\r\n            var _this = this;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResults = _a.sent();\r\n                        return [4 /*yield*/, extractFacesAndComputeResults_1.extractAllFacesAndComputeResults(parentResults, this.input, function (faces) { return tslib_1.__awaiter(_this, void 0, void 0, function () {\r\n                                return tslib_1.__generator(this, function (_a) {\r\n                                    switch (_a.label) {\r\n                                        case 0: return [4 /*yield*/, Promise.all(faces.map(function (face) { return nets_1.nets.ageGenderNet.predictAgeAndGender(face); }))];\r\n                                        case 1: return [2 /*return*/, _a.sent()];\r\n                                    }\r\n                                });\r\n                            }); }, this.extractedFaces)];\r\n                    case 2:\r\n                        ageAndGenderByFace = _a.sent();\r\n                        return [2 /*return*/, parentResults.map(function (parentResult, i) {\r\n                                var _a = ageAndGenderByFace[i], age = _a.age, gender = _a.gender, genderProbability = _a.genderProbability;\r\n                                return WithAge_1.extendWithAge(WithGender_1.extendWithGender(parentResult, gender, genderProbability), age);\r\n                            })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    PredictAllAgeAndGenderTask.prototype.withFaceExpressions = function () {\r\n        return new PredictFaceExpressionsTask_1.PredictAllFaceExpressionsTask(this, this.input);\r\n    };\r\n    return PredictAllAgeAndGenderTask;\r\n}(PredictAgeAndGenderTaskBase));\r\nexports.PredictAllAgeAndGenderTask = PredictAllAgeAndGenderTask;\r\nvar PredictSingleAgeAndGenderTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictSingleAgeAndGenderTask, _super);\r\n    function PredictSingleAgeAndGenderTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictSingleAgeAndGenderTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var parentResult, _a, age, gender, genderProbability;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResult = _b.sent();\r\n                        if (!parentResult) {\r\n                            return [2 /*return*/];\r\n                        }\r\n                        return [4 /*yield*/, extractFacesAndComputeResults_1.extractSingleFaceAndComputeResult(parentResult, this.input, function (face) { return nets_1.nets.ageGenderNet.predictAgeAndGender(face); }, this.extractedFaces)];\r\n                    case 2:\r\n                        _a = _b.sent(), age = _a.age, gender = _a.gender, genderProbability = _a.genderProbability;\r\n                        return [2 /*return*/, WithAge_1.extendWithAge(WithGender_1.extendWithGender(parentResult, gender, genderProbability), age)];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    PredictSingleAgeAndGenderTask.prototype.withFaceExpressions = function () {\r\n        return new PredictFaceExpressionsTask_1.PredictSingleFaceExpressionsTask(this, this.input);\r\n    };\r\n    return PredictSingleAgeAndGenderTask;\r\n}(PredictAgeAndGenderTaskBase));\r\nexports.PredictSingleAgeAndGenderTask = PredictSingleAgeAndGenderTask;\r\nvar PredictAllAgeAndGenderWithFaceAlignmentTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictAllAgeAndGenderWithFaceAlignmentTask, _super);\r\n    function PredictAllAgeAndGenderWithFaceAlignmentTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictAllAgeAndGenderWithFaceAlignmentTask.prototype.withFaceExpressions = function () {\r\n        return new PredictFaceExpressionsTask_1.PredictAllFaceExpressionsWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    PredictAllAgeAndGenderWithFaceAlignmentTask.prototype.withFaceDescriptors = function () {\r\n        return new ComputeFaceDescriptorsTasks_1.ComputeAllFaceDescriptorsTask(this, this.input);\r\n    };\r\n    return PredictAllAgeAndGenderWithFaceAlignmentTask;\r\n}(PredictAllAgeAndGenderTask));\r\nexports.PredictAllAgeAndGenderWithFaceAlignmentTask = PredictAllAgeAndGenderWithFaceAlignmentTask;\r\nvar PredictSingleAgeAndGenderWithFaceAlignmentTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictSingleAgeAndGenderWithFaceAlignmentTask, _super);\r\n    function PredictSingleAgeAndGenderWithFaceAlignmentTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictSingleAgeAndGenderWithFaceAlignmentTask.prototype.withFaceExpressions = function () {\r\n        return new PredictFaceExpressionsTask_1.PredictSingleFaceExpressionsWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    PredictSingleAgeAndGenderWithFaceAlignmentTask.prototype.withFaceDescriptor = function () {\r\n        return new ComputeFaceDescriptorsTasks_1.ComputeSingleFaceDescriptorTask(this, this.input);\r\n    };\r\n    return PredictSingleAgeAndGenderWithFaceAlignmentTask;\r\n}(PredictSingleAgeAndGenderTask));\r\nexports.PredictSingleAgeAndGenderWithFaceAlignmentTask = PredictSingleAgeAndGenderWithFaceAlignmentTask;\r\n//# sourceMappingURL=PredictAgeAndGenderTask.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/PredictAgeAndGenderTask.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/PredictFaceExpressionsTask.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/PredictFaceExpressionsTask.js ***!
  \*****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar WithFaceExpressions_1 = __webpack_require__(/*! ../factories/WithFaceExpressions */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceExpressions.js\");\r\nvar ComposableTask_1 = __webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/ComposableTask.js\");\r\nvar ComputeFaceDescriptorsTasks_1 = __webpack_require__(/*! ./ComputeFaceDescriptorsTasks */ \"./node_modules/face-api.js/build/commonjs/globalApi/ComputeFaceDescriptorsTasks.js\");\r\nvar extractFacesAndComputeResults_1 = __webpack_require__(/*! ./extractFacesAndComputeResults */ \"./node_modules/face-api.js/build/commonjs/globalApi/extractFacesAndComputeResults.js\");\r\nvar nets_1 = __webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/commonjs/globalApi/nets.js\");\r\nvar PredictAgeAndGenderTask_1 = __webpack_require__(/*! ./PredictAgeAndGenderTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/PredictAgeAndGenderTask.js\");\r\nvar PredictFaceExpressionsTaskBase = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictFaceExpressionsTaskBase, _super);\r\n    function PredictFaceExpressionsTaskBase(parentTask, input, extractedFaces) {\r\n        var _this = _super.call(this) || this;\r\n        _this.parentTask = parentTask;\r\n        _this.input = input;\r\n        _this.extractedFaces = extractedFaces;\r\n        return _this;\r\n    }\r\n    return PredictFaceExpressionsTaskBase;\r\n}(ComposableTask_1.ComposableTask));\r\nexports.PredictFaceExpressionsTaskBase = PredictFaceExpressionsTaskBase;\r\nvar PredictAllFaceExpressionsTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictAllFaceExpressionsTask, _super);\r\n    function PredictAllFaceExpressionsTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictAllFaceExpressionsTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var parentResults, faceExpressionsByFace;\r\n            var _this = this;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResults = _a.sent();\r\n                        return [4 /*yield*/, extractFacesAndComputeResults_1.extractAllFacesAndComputeResults(parentResults, this.input, function (faces) { return tslib_1.__awaiter(_this, void 0, void 0, function () {\r\n                                return tslib_1.__generator(this, function (_a) {\r\n                                    switch (_a.label) {\r\n                                        case 0: return [4 /*yield*/, Promise.all(faces.map(function (face) { return nets_1.nets.faceExpressionNet.predictExpressions(face); }))];\r\n                                        case 1: return [2 /*return*/, _a.sent()];\r\n                                    }\r\n                                });\r\n                            }); }, this.extractedFaces)];\r\n                    case 2:\r\n                        faceExpressionsByFace = _a.sent();\r\n                        return [2 /*return*/, parentResults.map(function (parentResult, i) { return WithFaceExpressions_1.extendWithFaceExpressions(parentResult, faceExpressionsByFace[i]); })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    PredictAllFaceExpressionsTask.prototype.withAgeAndGender = function () {\r\n        return new PredictAgeAndGenderTask_1.PredictAllAgeAndGenderTask(this, this.input);\r\n    };\r\n    return PredictAllFaceExpressionsTask;\r\n}(PredictFaceExpressionsTaskBase));\r\nexports.PredictAllFaceExpressionsTask = PredictAllFaceExpressionsTask;\r\nvar PredictSingleFaceExpressionsTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictSingleFaceExpressionsTask, _super);\r\n    function PredictSingleFaceExpressionsTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictSingleFaceExpressionsTask.prototype.run = function () {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var parentResult, faceExpressions;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.parentTask];\r\n                    case 1:\r\n                        parentResult = _a.sent();\r\n                        if (!parentResult) {\r\n                            return [2 /*return*/];\r\n                        }\r\n                        return [4 /*yield*/, extractFacesAndComputeResults_1.extractSingleFaceAndComputeResult(parentResult, this.input, function (face) { return nets_1.nets.faceExpressionNet.predictExpressions(face); }, this.extractedFaces)];\r\n                    case 2:\r\n                        faceExpressions = _a.sent();\r\n                        return [2 /*return*/, WithFaceExpressions_1.extendWithFaceExpressions(parentResult, faceExpressions)];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    PredictSingleFaceExpressionsTask.prototype.withAgeAndGender = function () {\r\n        return new PredictAgeAndGenderTask_1.PredictSingleAgeAndGenderTask(this, this.input);\r\n    };\r\n    return PredictSingleFaceExpressionsTask;\r\n}(PredictFaceExpressionsTaskBase));\r\nexports.PredictSingleFaceExpressionsTask = PredictSingleFaceExpressionsTask;\r\nvar PredictAllFaceExpressionsWithFaceAlignmentTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictAllFaceExpressionsWithFaceAlignmentTask, _super);\r\n    function PredictAllFaceExpressionsWithFaceAlignmentTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictAllFaceExpressionsWithFaceAlignmentTask.prototype.withAgeAndGender = function () {\r\n        return new PredictAgeAndGenderTask_1.PredictAllAgeAndGenderWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    PredictAllFaceExpressionsWithFaceAlignmentTask.prototype.withFaceDescriptors = function () {\r\n        return new ComputeFaceDescriptorsTasks_1.ComputeAllFaceDescriptorsTask(this, this.input);\r\n    };\r\n    return PredictAllFaceExpressionsWithFaceAlignmentTask;\r\n}(PredictAllFaceExpressionsTask));\r\nexports.PredictAllFaceExpressionsWithFaceAlignmentTask = PredictAllFaceExpressionsWithFaceAlignmentTask;\r\nvar PredictSingleFaceExpressionsWithFaceAlignmentTask = /** @class */ (function (_super) {\r\n    tslib_1.__extends(PredictSingleFaceExpressionsWithFaceAlignmentTask, _super);\r\n    function PredictSingleFaceExpressionsWithFaceAlignmentTask() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    PredictSingleFaceExpressionsWithFaceAlignmentTask.prototype.withAgeAndGender = function () {\r\n        return new PredictAgeAndGenderTask_1.PredictSingleAgeAndGenderWithFaceAlignmentTask(this, this.input);\r\n    };\r\n    PredictSingleFaceExpressionsWithFaceAlignmentTask.prototype.withFaceDescriptor = function () {\r\n        return new ComputeFaceDescriptorsTasks_1.ComputeSingleFaceDescriptorTask(this, this.input);\r\n    };\r\n    return PredictSingleFaceExpressionsWithFaceAlignmentTask;\r\n}(PredictSingleFaceExpressionsTask));\r\nexports.PredictSingleFaceExpressionsWithFaceAlignmentTask = PredictSingleFaceExpressionsWithFaceAlignmentTask;\r\n//# sourceMappingURL=PredictFaceExpressionsTask.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/PredictFaceExpressionsTask.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/allFaces.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/allFaces.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar MtcnnOptions_1 = __webpack_require__(/*! ../mtcnn/MtcnnOptions */ \"./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnOptions.js\");\r\nvar ssdMobilenetv1_1 = __webpack_require__(/*! ../ssdMobilenetv1 */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/index.js\");\r\nvar tinyYolov2_1 = __webpack_require__(/*! ../tinyYolov2 */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/index.js\");\r\nvar detectFaces_1 = __webpack_require__(/*! ./detectFaces */ \"./node_modules/face-api.js/build/commonjs/globalApi/detectFaces.js\");\r\n// export allFaces API for backward compatibility\r\nfunction allFacesSsdMobilenetv1(input, minConfidence) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        return tslib_1.__generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    console.warn('allFacesSsdMobilenetv1 is deprecated and will be removed soon, use the high level api instead');\r\n                    return [4 /*yield*/, detectFaces_1.detectAllFaces(input, new ssdMobilenetv1_1.SsdMobilenetv1Options(minConfidence ? { minConfidence: minConfidence } : {}))\r\n                            .withFaceLandmarks()\r\n                            .withFaceDescriptors()];\r\n                case 1: return [2 /*return*/, _a.sent()];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.allFacesSsdMobilenetv1 = allFacesSsdMobilenetv1;\r\nfunction allFacesTinyYolov2(input, forwardParams) {\r\n    if (forwardParams === void 0) { forwardParams = {}; }\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        return tslib_1.__generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    console.warn('allFacesTinyYolov2 is deprecated and will be removed soon, use the high level api instead');\r\n                    return [4 /*yield*/, detectFaces_1.detectAllFaces(input, new tinyYolov2_1.TinyYolov2Options(forwardParams))\r\n                            .withFaceLandmarks()\r\n                            .withFaceDescriptors()];\r\n                case 1: return [2 /*return*/, _a.sent()];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.allFacesTinyYolov2 = allFacesTinyYolov2;\r\nfunction allFacesMtcnn(input, forwardParams) {\r\n    if (forwardParams === void 0) { forwardParams = {}; }\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        return tslib_1.__generator(this, function (_a) {\r\n            switch (_a.label) {\r\n                case 0:\r\n                    console.warn('allFacesMtcnn is deprecated and will be removed soon, use the high level api instead');\r\n                    return [4 /*yield*/, detectFaces_1.detectAllFaces(input, new MtcnnOptions_1.MtcnnOptions(forwardParams))\r\n                            .withFaceLandmarks()\r\n                            .withFaceDescriptors()];\r\n                case 1: return [2 /*return*/, _a.sent()];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.allFacesMtcnn = allFacesMtcnn;\r\nexports.allFaces = allFacesSsdMobilenetv1;\r\n//# sourceMappingURL=allFaces.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/allFaces.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/detectFaces.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/detectFaces.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar SsdMobilenetv1Options_1 = __webpack_require__(/*! ../ssdMobilenetv1/SsdMobilenetv1Options */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1Options.js\");\r\nvar DetectFacesTasks_1 = __webpack_require__(/*! ./DetectFacesTasks */ \"./node_modules/face-api.js/build/commonjs/globalApi/DetectFacesTasks.js\");\r\nfunction detectSingleFace(input, options) {\r\n    if (options === void 0) { options = new SsdMobilenetv1Options_1.SsdMobilenetv1Options(); }\r\n    return new DetectFacesTasks_1.DetectSingleFaceTask(input, options);\r\n}\r\nexports.detectSingleFace = detectSingleFace;\r\nfunction detectAllFaces(input, options) {\r\n    if (options === void 0) { options = new SsdMobilenetv1Options_1.SsdMobilenetv1Options(); }\r\n    return new DetectFacesTasks_1.DetectAllFacesTask(input, options);\r\n}\r\nexports.detectAllFaces = detectAllFaces;\r\n//# sourceMappingURL=detectFaces.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/detectFaces.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/extractFacesAndComputeResults.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/extractFacesAndComputeResults.js ***!
  \********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar WithFaceLandmarks_1 = __webpack_require__(/*! ../factories/WithFaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceLandmarks.js\");\r\nfunction extractAllFacesAndComputeResults(parentResults, input, computeResults, extractedFaces, getRectForAlignment) {\r\n    if (getRectForAlignment === void 0) { getRectForAlignment = function (_a) {\r\n        var alignedRect = _a.alignedRect;\r\n        return alignedRect;\r\n    }; }\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var faceBoxes, faces, _a, _b, results;\r\n        return tslib_1.__generator(this, function (_c) {\r\n            switch (_c.label) {\r\n                case 0:\r\n                    faceBoxes = parentResults.map(function (parentResult) {\r\n                        return WithFaceLandmarks_1.isWithFaceLandmarks(parentResult)\r\n                            ? getRectForAlignment(parentResult)\r\n                            : parentResult.detection;\r\n                    });\r\n                    _a = extractedFaces;\r\n                    if (_a) return [3 /*break*/, 5];\r\n                    if (!(input instanceof tf.Tensor)) return [3 /*break*/, 2];\r\n                    return [4 /*yield*/, dom_1.extractFaceTensors(input, faceBoxes)];\r\n                case 1:\r\n                    _b = _c.sent();\r\n                    return [3 /*break*/, 4];\r\n                case 2: return [4 /*yield*/, dom_1.extractFaces(input, faceBoxes)];\r\n                case 3:\r\n                    _b = _c.sent();\r\n                    _c.label = 4;\r\n                case 4:\r\n                    _a = (_b);\r\n                    _c.label = 5;\r\n                case 5:\r\n                    faces = _a;\r\n                    return [4 /*yield*/, computeResults(faces)];\r\n                case 6:\r\n                    results = _c.sent();\r\n                    faces.forEach(function (f) { return f instanceof tf.Tensor && f.dispose(); });\r\n                    return [2 /*return*/, results];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.extractAllFacesAndComputeResults = extractAllFacesAndComputeResults;\r\nfunction extractSingleFaceAndComputeResult(parentResult, input, computeResult, extractedFaces, getRectForAlignment) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var _this = this;\r\n        return tslib_1.__generator(this, function (_a) {\r\n            return [2 /*return*/, extractAllFacesAndComputeResults([parentResult], input, function (faces) { return tslib_1.__awaiter(_this, void 0, void 0, function () { return tslib_1.__generator(this, function (_a) {\r\n                    return [2 /*return*/, computeResult(faces[0])];\r\n                }); }); }, extractedFaces, getRectForAlignment)];\r\n        });\r\n    });\r\n}\r\nexports.extractSingleFaceAndComputeResult = extractSingleFaceAndComputeResult;\r\n//# sourceMappingURL=extractFacesAndComputeResults.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/extractFacesAndComputeResults.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/index.js":
/*!********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/index.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./allFaces */ \"./node_modules/face-api.js/build/commonjs/globalApi/allFaces.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./ComposableTask */ \"./node_modules/face-api.js/build/commonjs/globalApi/ComposableTask.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./ComputeFaceDescriptorsTasks */ \"./node_modules/face-api.js/build/commonjs/globalApi/ComputeFaceDescriptorsTasks.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./detectFaces */ \"./node_modules/face-api.js/build/commonjs/globalApi/detectFaces.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./DetectFacesTasks */ \"./node_modules/face-api.js/build/commonjs/globalApi/DetectFacesTasks.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./DetectFaceLandmarksTasks */ \"./node_modules/face-api.js/build/commonjs/globalApi/DetectFaceLandmarksTasks.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./FaceMatcher */ \"./node_modules/face-api.js/build/commonjs/globalApi/FaceMatcher.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./nets */ \"./node_modules/face-api.js/build/commonjs/globalApi/nets.js\"), exports);\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/globalApi/nets.js":
/*!*******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/globalApi/nets.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar AgeGenderNet_1 = __webpack_require__(/*! ../ageGenderNet/AgeGenderNet */ \"./node_modules/face-api.js/build/commonjs/ageGenderNet/AgeGenderNet.js\");\r\nvar FaceExpressionNet_1 = __webpack_require__(/*! ../faceExpressionNet/FaceExpressionNet */ \"./node_modules/face-api.js/build/commonjs/faceExpressionNet/FaceExpressionNet.js\");\r\nvar FaceLandmark68Net_1 = __webpack_require__(/*! ../faceLandmarkNet/FaceLandmark68Net */ \"./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68Net.js\");\r\nvar FaceLandmark68TinyNet_1 = __webpack_require__(/*! ../faceLandmarkNet/FaceLandmark68TinyNet */ \"./node_modules/face-api.js/build/commonjs/faceLandmarkNet/FaceLandmark68TinyNet.js\");\r\nvar FaceRecognitionNet_1 = __webpack_require__(/*! ../faceRecognitionNet/FaceRecognitionNet */ \"./node_modules/face-api.js/build/commonjs/faceRecognitionNet/FaceRecognitionNet.js\");\r\nvar Mtcnn_1 = __webpack_require__(/*! ../mtcnn/Mtcnn */ \"./node_modules/face-api.js/build/commonjs/mtcnn/Mtcnn.js\");\r\nvar SsdMobilenetv1_1 = __webpack_require__(/*! ../ssdMobilenetv1/SsdMobilenetv1 */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1.js\");\r\nvar TinyFaceDetector_1 = __webpack_require__(/*! ../tinyFaceDetector/TinyFaceDetector */ \"./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetector.js\");\r\nvar tinyYolov2_1 = __webpack_require__(/*! ../tinyYolov2 */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/index.js\");\r\nexports.nets = {\r\n    ssdMobilenetv1: new SsdMobilenetv1_1.SsdMobilenetv1(),\r\n    tinyFaceDetector: new TinyFaceDetector_1.TinyFaceDetector(),\r\n    tinyYolov2: new tinyYolov2_1.TinyYolov2(),\r\n    mtcnn: new Mtcnn_1.Mtcnn(),\r\n    faceLandmark68Net: new FaceLandmark68Net_1.FaceLandmark68Net(),\r\n    faceLandmark68TinyNet: new FaceLandmark68TinyNet_1.FaceLandmark68TinyNet(),\r\n    faceRecognitionNet: new FaceRecognitionNet_1.FaceRecognitionNet(),\r\n    faceExpressionNet: new FaceExpressionNet_1.FaceExpressionNet(),\r\n    ageGenderNet: new AgeGenderNet_1.AgeGenderNet()\r\n};\r\n/**\r\n * Attempts to detect all faces in an image using SSD Mobilenetv1 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see SsdMobilenetv1Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\r\nexports.ssdMobilenetv1 = function (input, options) {\r\n    return exports.nets.ssdMobilenetv1.locateFaces(input, options);\r\n};\r\n/**\r\n * Attempts to detect all faces in an image using the Tiny Face Detector.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyFaceDetectorOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\r\nexports.tinyFaceDetector = function (input, options) {\r\n    return exports.nets.tinyFaceDetector.locateFaces(input, options);\r\n};\r\n/**\r\n * Attempts to detect all faces in an image using the Tiny Yolov2 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyYolov2Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\r\nexports.tinyYolov2 = function (input, options) {\r\n    return exports.nets.tinyYolov2.locateFaces(input, options);\r\n};\r\n/**\r\n * Attempts to detect all faces in an image and the 5 point face landmarks\r\n * of each detected face using the MTCNN Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see MtcnnOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score and 5 point face landmarks.\r\n */\r\nexports.mtcnn = function (input, options) {\r\n    return exports.nets.mtcnn.forward(input, options);\r\n};\r\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\r\nexports.detectFaceLandmarks = function (input) {\r\n    return exports.nets.faceLandmark68Net.detectLandmarks(input);\r\n};\r\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image\r\n * using a tinier version of the 68 point face landmark model, which is slightly\r\n * faster at inference, but also slightly less accurate.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\r\nexports.detectFaceLandmarksTiny = function (input) {\r\n    return exports.nets.faceLandmark68TinyNet.detectLandmarks(input);\r\n};\r\n/**\r\n * Computes a 128 entry vector (face descriptor / face embeddings) from the face shown in an image,\r\n * which uniquely represents the features of that persons face. The computed face descriptor can\r\n * be used to measure the similarity between faces, by computing the euclidean distance of two\r\n * face descriptors.\r\n *\r\n * @param inputs The face image extracted from the aligned bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Face descriptor with 128 entries or array thereof in case of batch input.\r\n */\r\nexports.computeFaceDescriptor = function (input) {\r\n    return exports.nets.faceRecognitionNet.computeFaceDescriptor(input);\r\n};\r\n/**\r\n * Recognizes the facial expressions from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Facial expressions with corresponding probabilities or array thereof in case of batch input.\r\n */\r\nexports.recognizeFaceExpressions = function (input) {\r\n    return exports.nets.faceExpressionNet.predictExpressions(input);\r\n};\r\n/**\r\n * Predicts age and gender from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Predictions with age, gender and gender probability or array thereof in case of batch input.\r\n */\r\nexports.predictAgeAndGender = function (input) {\r\n    return exports.nets.ageGenderNet.predictAgeAndGender(input);\r\n};\r\nexports.loadSsdMobilenetv1Model = function (url) { return exports.nets.ssdMobilenetv1.load(url); };\r\nexports.loadTinyFaceDetectorModel = function (url) { return exports.nets.tinyFaceDetector.load(url); };\r\nexports.loadMtcnnModel = function (url) { return exports.nets.mtcnn.load(url); };\r\nexports.loadTinyYolov2Model = function (url) { return exports.nets.tinyYolov2.load(url); };\r\nexports.loadFaceLandmarkModel = function (url) { return exports.nets.faceLandmark68Net.load(url); };\r\nexports.loadFaceLandmarkTinyModel = function (url) { return exports.nets.faceLandmark68TinyNet.load(url); };\r\nexports.loadFaceRecognitionModel = function (url) { return exports.nets.faceRecognitionNet.load(url); };\r\nexports.loadFaceExpressionModel = function (url) { return exports.nets.faceExpressionNet.load(url); };\r\nexports.loadAgeGenderModel = function (url) { return exports.nets.ageGenderNet.load(url); };\r\n// backward compatibility\r\nexports.loadFaceDetectionModel = exports.loadSsdMobilenetv1Model;\r\nexports.locateFaces = exports.ssdMobilenetv1;\r\nexports.detectLandmarks = exports.detectFaceLandmarks;\r\n//# sourceMappingURL=nets.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/globalApi/nets.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/index.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nexports.tf = tf;\r\nvar draw = __webpack_require__(/*! ./draw */ \"./node_modules/face-api.js/build/commonjs/draw/index.js\");\r\nexports.draw = draw;\r\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nexports.utils = utils;\r\ntslib_1.__exportStar(__webpack_require__(/*! ./ageGenderNet/index */ \"./node_modules/face-api.js/build/commonjs/ageGenderNet/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./classes/index */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./dom/index */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./env/index */ \"./node_modules/face-api.js/build/commonjs/env/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./faceExpressionNet/index */ \"./node_modules/face-api.js/build/commonjs/faceExpressionNet/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./faceLandmarkNet/index */ \"./node_modules/face-api.js/build/commonjs/faceLandmarkNet/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./faceRecognitionNet/index */ \"./node_modules/face-api.js/build/commonjs/faceRecognitionNet/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./factories/index */ \"./node_modules/face-api.js/build/commonjs/factories/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./globalApi/index */ \"./node_modules/face-api.js/build/commonjs/globalApi/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./mtcnn/index */ \"./node_modules/face-api.js/build/commonjs/mtcnn/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./ops/index */ \"./node_modules/face-api.js/build/commonjs/ops/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./ssdMobilenetv1/index */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./tinyFaceDetector/index */ \"./node_modules/face-api.js/build/commonjs/tinyFaceDetector/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./tinyYolov2/index */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/index.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./euclideanDistance */ \"./node_modules/face-api.js/build/commonjs/euclideanDistance.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./NeuralNetwork */ \"./node_modules/face-api.js/build/commonjs/NeuralNetwork.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./resizeResults */ \"./node_modules/face-api.js/build/commonjs/resizeResults.js\"), exports);\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/Mtcnn.js":
/*!****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/Mtcnn.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar FaceDetection_1 = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js\");\r\nvar FaceLandmarks5_1 = __webpack_require__(/*! ../classes/FaceLandmarks5 */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks5.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar factories_1 = __webpack_require__(/*! ../factories */ \"./node_modules/face-api.js/build/commonjs/factories/index.js\");\r\nvar NeuralNetwork_1 = __webpack_require__(/*! ../NeuralNetwork */ \"./node_modules/face-api.js/build/commonjs/NeuralNetwork.js\");\r\nvar bgrToRgbTensor_1 = __webpack_require__(/*! ./bgrToRgbTensor */ \"./node_modules/face-api.js/build/commonjs/mtcnn/bgrToRgbTensor.js\");\r\nvar config_1 = __webpack_require__(/*! ./config */ \"./node_modules/face-api.js/build/commonjs/mtcnn/config.js\");\r\nvar extractParams_1 = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/commonjs/mtcnn/extractParams.js\");\r\nvar extractParamsFromWeigthMap_1 = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/commonjs/mtcnn/extractParamsFromWeigthMap.js\");\r\nvar getSizesForScale_1 = __webpack_require__(/*! ./getSizesForScale */ \"./node_modules/face-api.js/build/commonjs/mtcnn/getSizesForScale.js\");\r\nvar MtcnnOptions_1 = __webpack_require__(/*! ./MtcnnOptions */ \"./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnOptions.js\");\r\nvar pyramidDown_1 = __webpack_require__(/*! ./pyramidDown */ \"./node_modules/face-api.js/build/commonjs/mtcnn/pyramidDown.js\");\r\nvar stage1_1 = __webpack_require__(/*! ./stage1 */ \"./node_modules/face-api.js/build/commonjs/mtcnn/stage1.js\");\r\nvar stage2_1 = __webpack_require__(/*! ./stage2 */ \"./node_modules/face-api.js/build/commonjs/mtcnn/stage2.js\");\r\nvar stage3_1 = __webpack_require__(/*! ./stage3 */ \"./node_modules/face-api.js/build/commonjs/mtcnn/stage3.js\");\r\nvar Mtcnn = /** @class */ (function (_super) {\r\n    tslib_1.__extends(Mtcnn, _super);\r\n    function Mtcnn() {\r\n        return _super.call(this, 'Mtcnn') || this;\r\n    }\r\n    Mtcnn.prototype.load = function (weightsOrUrl) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            return tslib_1.__generator(this, function (_a) {\r\n                console.warn('mtcnn is deprecated and will be removed soon');\r\n                return [2 /*return*/, _super.prototype.load.call(this, weightsOrUrl)];\r\n            });\r\n        });\r\n    };\r\n    Mtcnn.prototype.loadFromDisk = function (filePath) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            return tslib_1.__generator(this, function (_a) {\r\n                console.warn('mtcnn is deprecated and will be removed soon');\r\n                return [2 /*return*/, _super.prototype.loadFromDisk.call(this, filePath)];\r\n            });\r\n        });\r\n    };\r\n    Mtcnn.prototype.forwardInput = function (input, forwardParams) {\r\n        if (forwardParams === void 0) { forwardParams = {}; }\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var params, inputCanvas, stats, tsTotal, imgTensor, onReturn, _a, height, width, _b, minFaceSize, scaleFactor, maxNumScales, scoreThresholds, scaleSteps, scales, ts, out1, out2, out3, results;\r\n            return tslib_1.__generator(this, function (_c) {\r\n                switch (_c.label) {\r\n                    case 0:\r\n                        params = this.params;\r\n                        if (!params) {\r\n                            throw new Error('Mtcnn - load model before inference');\r\n                        }\r\n                        inputCanvas = input.canvases[0];\r\n                        if (!inputCanvas) {\r\n                            throw new Error('Mtcnn - inputCanvas is not defined, note that passing tensors into Mtcnn.forwardInput is not supported yet.');\r\n                        }\r\n                        stats = {};\r\n                        tsTotal = Date.now();\r\n                        imgTensor = tf.tidy(function () {\r\n                            return bgrToRgbTensor_1.bgrToRgbTensor(tf.expandDims(tf.browser.fromPixels(inputCanvas)).toFloat());\r\n                        });\r\n                        onReturn = function (results) {\r\n                            // dispose tensors on return\r\n                            imgTensor.dispose();\r\n                            stats.total = Date.now() - tsTotal;\r\n                            return results;\r\n                        };\r\n                        _a = imgTensor.shape.slice(1), height = _a[0], width = _a[1];\r\n                        _b = new MtcnnOptions_1.MtcnnOptions(forwardParams), minFaceSize = _b.minFaceSize, scaleFactor = _b.scaleFactor, maxNumScales = _b.maxNumScales, scoreThresholds = _b.scoreThresholds, scaleSteps = _b.scaleSteps;\r\n                        scales = (scaleSteps || pyramidDown_1.pyramidDown(minFaceSize, scaleFactor, [height, width]))\r\n                            .filter(function (scale) {\r\n                            var sizes = getSizesForScale_1.getSizesForScale(scale, [height, width]);\r\n                            return Math.min(sizes.width, sizes.height) > config_1.CELL_SIZE;\r\n                        })\r\n                            .slice(0, maxNumScales);\r\n                        stats.scales = scales;\r\n                        stats.pyramid = scales.map(function (scale) { return getSizesForScale_1.getSizesForScale(scale, [height, width]); });\r\n                        ts = Date.now();\r\n                        return [4 /*yield*/, stage1_1.stage1(imgTensor, scales, scoreThresholds[0], params.pnet, stats)];\r\n                    case 1:\r\n                        out1 = _c.sent();\r\n                        stats.total_stage1 = Date.now() - ts;\r\n                        if (!out1.boxes.length) {\r\n                            return [2 /*return*/, onReturn({ results: [], stats: stats })];\r\n                        }\r\n                        stats.stage2_numInputBoxes = out1.boxes.length;\r\n                        // using the inputCanvas to extract and resize the image patches, since it is faster\r\n                        // than doing this on the gpu\r\n                        ts = Date.now();\r\n                        return [4 /*yield*/, stage2_1.stage2(inputCanvas, out1.boxes, scoreThresholds[1], params.rnet, stats)];\r\n                    case 2:\r\n                        out2 = _c.sent();\r\n                        stats.total_stage2 = Date.now() - ts;\r\n                        if (!out2.boxes.length) {\r\n                            return [2 /*return*/, onReturn({ results: [], stats: stats })];\r\n                        }\r\n                        stats.stage3_numInputBoxes = out2.boxes.length;\r\n                        ts = Date.now();\r\n                        return [4 /*yield*/, stage3_1.stage3(inputCanvas, out2.boxes, scoreThresholds[2], params.onet, stats)];\r\n                    case 3:\r\n                        out3 = _c.sent();\r\n                        stats.total_stage3 = Date.now() - ts;\r\n                        results = out3.boxes.map(function (box, idx) { return factories_1.extendWithFaceLandmarks(factories_1.extendWithFaceDetection({}, new FaceDetection_1.FaceDetection(out3.scores[idx], new classes_1.Rect(box.left / width, box.top / height, box.width / width, box.height / height), {\r\n                            height: height,\r\n                            width: width\r\n                        })), new FaceLandmarks5_1.FaceLandmarks5(out3.points[idx].map(function (pt) { return pt.sub(new classes_1.Point(box.left, box.top)).div(new classes_1.Point(box.width, box.height)); }), { width: box.width, height: box.height })); });\r\n                        return [2 /*return*/, onReturn({ results: results, stats: stats })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    Mtcnn.prototype.forward = function (input, forwardParams) {\r\n        if (forwardParams === void 0) { forwardParams = {}; }\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [4 /*yield*/, _a.apply(this, [_b.sent(),\r\n                            forwardParams])];\r\n                    case 2: return [2 /*return*/, (_b.sent()).results];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    Mtcnn.prototype.forwardWithStats = function (input, forwardParams) {\r\n        if (forwardParams === void 0) { forwardParams = {}; }\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent(),\r\n                            forwardParams])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    Mtcnn.prototype.getDefaultModelName = function () {\r\n        return 'mtcnn_model';\r\n    };\r\n    Mtcnn.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return extractParamsFromWeigthMap_1.extractParamsFromWeigthMap(weightMap);\r\n    };\r\n    Mtcnn.prototype.extractParams = function (weights) {\r\n        return extractParams_1.extractParams(weights);\r\n    };\r\n    return Mtcnn;\r\n}(NeuralNetwork_1.NeuralNetwork));\r\nexports.Mtcnn = Mtcnn;\r\n//# sourceMappingURL=Mtcnn.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/Mtcnn.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnBox.js":
/*!*******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnBox.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar MtcnnBox = /** @class */ (function (_super) {\r\n    tslib_1.__extends(MtcnnBox, _super);\r\n    function MtcnnBox(left, top, right, bottom) {\r\n        return _super.call(this, { left: left, top: top, right: right, bottom: bottom }, true) || this;\r\n    }\r\n    return MtcnnBox;\r\n}(classes_1.Box));\r\nexports.MtcnnBox = MtcnnBox;\r\n//# sourceMappingURL=MtcnnBox.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnBox.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnOptions.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnOptions.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar MtcnnOptions = /** @class */ (function () {\r\n    function MtcnnOptions(_a) {\r\n        var _b = _a === void 0 ? {} : _a, minFaceSize = _b.minFaceSize, scaleFactor = _b.scaleFactor, maxNumScales = _b.maxNumScales, scoreThresholds = _b.scoreThresholds, scaleSteps = _b.scaleSteps;\r\n        this._name = 'MtcnnOptions';\r\n        this._minFaceSize = minFaceSize || 20;\r\n        this._scaleFactor = scaleFactor || 0.709;\r\n        this._maxNumScales = maxNumScales || 10;\r\n        this._scoreThresholds = scoreThresholds || [0.6, 0.7, 0.7];\r\n        this._scaleSteps = scaleSteps;\r\n        if (typeof this._minFaceSize !== 'number' || this._minFaceSize < 0) {\r\n            throw new Error(this._name + \" - expected minFaceSize to be a number > 0\");\r\n        }\r\n        if (typeof this._scaleFactor !== 'number' || this._scaleFactor <= 0 || this._scaleFactor >= 1) {\r\n            throw new Error(this._name + \" - expected scaleFactor to be a number between 0 and 1\");\r\n        }\r\n        if (typeof this._maxNumScales !== 'number' || this._maxNumScales < 0) {\r\n            throw new Error(this._name + \" - expected maxNumScales to be a number > 0\");\r\n        }\r\n        if (!Array.isArray(this._scoreThresholds)\r\n            || this._scoreThresholds.length !== 3\r\n            || this._scoreThresholds.some(function (th) { return typeof th !== 'number'; })) {\r\n            throw new Error(this._name + \" - expected scoreThresholds to be an array of numbers of length 3\");\r\n        }\r\n        if (this._scaleSteps\r\n            && (!Array.isArray(this._scaleSteps) || this._scaleSteps.some(function (th) { return typeof th !== 'number'; }))) {\r\n            throw new Error(this._name + \" - expected scaleSteps to be an array of numbers\");\r\n        }\r\n    }\r\n    Object.defineProperty(MtcnnOptions.prototype, \"minFaceSize\", {\r\n        get: function () { return this._minFaceSize; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(MtcnnOptions.prototype, \"scaleFactor\", {\r\n        get: function () { return this._scaleFactor; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(MtcnnOptions.prototype, \"maxNumScales\", {\r\n        get: function () { return this._maxNumScales; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(MtcnnOptions.prototype, \"scoreThresholds\", {\r\n        get: function () { return this._scoreThresholds; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(MtcnnOptions.prototype, \"scaleSteps\", {\r\n        get: function () { return this._scaleSteps; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return MtcnnOptions;\r\n}());\r\nexports.MtcnnOptions = MtcnnOptions;\r\n//# sourceMappingURL=MtcnnOptions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnOptions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/ONet.js":
/*!***************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/ONet.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar fullyConnectedLayer_1 = __webpack_require__(/*! ../common/fullyConnectedLayer */ \"./node_modules/face-api.js/build/commonjs/common/fullyConnectedLayer.js\");\r\nvar prelu_1 = __webpack_require__(/*! ./prelu */ \"./node_modules/face-api.js/build/commonjs/mtcnn/prelu.js\");\r\nvar sharedLayers_1 = __webpack_require__(/*! ./sharedLayers */ \"./node_modules/face-api.js/build/commonjs/mtcnn/sharedLayers.js\");\r\nfunction ONet(x, params) {\r\n    return tf.tidy(function () {\r\n        var out = sharedLayers_1.sharedLayer(x, params);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = common_1.convLayer(out, params.conv4, 'valid');\r\n        out = prelu_1.prelu(out, params.prelu4_alpha);\r\n        var vectorized = tf.reshape(out, [out.shape[0], params.fc1.weights.shape[0]]);\r\n        var fc1 = fullyConnectedLayer_1.fullyConnectedLayer(vectorized, params.fc1);\r\n        var prelu5 = prelu_1.prelu(fc1, params.prelu5_alpha);\r\n        var fc2_1 = fullyConnectedLayer_1.fullyConnectedLayer(prelu5, params.fc2_1);\r\n        var max = tf.expandDims(tf.max(fc2_1, 1), 1);\r\n        var prob = tf.softmax(tf.sub(fc2_1, max), 1);\r\n        var regions = fullyConnectedLayer_1.fullyConnectedLayer(prelu5, params.fc2_2);\r\n        var points = fullyConnectedLayer_1.fullyConnectedLayer(prelu5, params.fc2_3);\r\n        var scores = tf.unstack(prob, 1)[1];\r\n        return { scores: scores, regions: regions, points: points };\r\n    });\r\n}\r\nexports.ONet = ONet;\r\n//# sourceMappingURL=ONet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/ONet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/PNet.js":
/*!***************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/PNet.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar sharedLayers_1 = __webpack_require__(/*! ./sharedLayers */ \"./node_modules/face-api.js/build/commonjs/mtcnn/sharedLayers.js\");\r\nfunction PNet(x, params) {\r\n    return tf.tidy(function () {\r\n        var out = sharedLayers_1.sharedLayer(x, params, true);\r\n        var conv = common_1.convLayer(out, params.conv4_1, 'valid');\r\n        var max = tf.expandDims(tf.max(conv, 3), 3);\r\n        var prob = tf.softmax(tf.sub(conv, max), 3);\r\n        var regions = common_1.convLayer(out, params.conv4_2, 'valid');\r\n        return { prob: prob, regions: regions };\r\n    });\r\n}\r\nexports.PNet = PNet;\r\n//# sourceMappingURL=PNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/PNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/RNet.js":
/*!***************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/RNet.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar fullyConnectedLayer_1 = __webpack_require__(/*! ../common/fullyConnectedLayer */ \"./node_modules/face-api.js/build/commonjs/common/fullyConnectedLayer.js\");\r\nvar prelu_1 = __webpack_require__(/*! ./prelu */ \"./node_modules/face-api.js/build/commonjs/mtcnn/prelu.js\");\r\nvar sharedLayers_1 = __webpack_require__(/*! ./sharedLayers */ \"./node_modules/face-api.js/build/commonjs/mtcnn/sharedLayers.js\");\r\nfunction RNet(x, params) {\r\n    return tf.tidy(function () {\r\n        var convOut = sharedLayers_1.sharedLayer(x, params);\r\n        var vectorized = tf.reshape(convOut, [convOut.shape[0], params.fc1.weights.shape[0]]);\r\n        var fc1 = fullyConnectedLayer_1.fullyConnectedLayer(vectorized, params.fc1);\r\n        var prelu4 = prelu_1.prelu(fc1, params.prelu4_alpha);\r\n        var fc2_1 = fullyConnectedLayer_1.fullyConnectedLayer(prelu4, params.fc2_1);\r\n        var max = tf.expandDims(tf.max(fc2_1, 1), 1);\r\n        var prob = tf.softmax(tf.sub(fc2_1, max), 1);\r\n        var regions = fullyConnectedLayer_1.fullyConnectedLayer(prelu4, params.fc2_2);\r\n        var scores = tf.unstack(prob, 1)[1];\r\n        return { scores: scores, regions: regions };\r\n    });\r\n}\r\nexports.RNet = RNet;\r\n//# sourceMappingURL=RNet.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/RNet.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/bgrToRgbTensor.js":
/*!*************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/bgrToRgbTensor.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction bgrToRgbTensor(tensor) {\r\n    return tf.tidy(function () { return tf.stack(tf.unstack(tensor, 3).reverse(), 3); });\r\n}\r\nexports.bgrToRgbTensor = bgrToRgbTensor;\r\n//# sourceMappingURL=bgrToRgbTensor.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/bgrToRgbTensor.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/config.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/config.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nexports.CELL_STRIDE = 2;\r\nexports.CELL_SIZE = 12;\r\n//# sourceMappingURL=config.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/config.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/extractImagePatches.js":
/*!******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/extractImagePatches.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar env_1 = __webpack_require__(/*! ../env */ \"./node_modules/face-api.js/build/commonjs/env/index.js\");\r\nvar normalize_1 = __webpack_require__(/*! ./normalize */ \"./node_modules/face-api.js/build/commonjs/mtcnn/normalize.js\");\r\nfunction extractImagePatches(img, boxes, _a) {\r\n    var width = _a.width, height = _a.height;\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var imgCtx, bitmaps, imagePatchesDatas;\r\n        var _this = this;\r\n        return tslib_1.__generator(this, function (_b) {\r\n            switch (_b.label) {\r\n                case 0:\r\n                    imgCtx = dom_1.getContext2dOrThrow(img);\r\n                    return [4 /*yield*/, Promise.all(boxes.map(function (box) { return tslib_1.__awaiter(_this, void 0, void 0, function () {\r\n                            var _a, y, ey, x, ex, fromX, fromY, imgData;\r\n                            return tslib_1.__generator(this, function (_b) {\r\n                                _a = box.padAtBorders(img.height, img.width), y = _a.y, ey = _a.ey, x = _a.x, ex = _a.ex;\r\n                                fromX = x - 1;\r\n                                fromY = y - 1;\r\n                                imgData = imgCtx.getImageData(fromX, fromY, (ex - fromX), (ey - fromY));\r\n                                return [2 /*return*/, env_1.env.isNodejs() ? dom_1.createCanvasFromMedia(imgData) : createImageBitmap(imgData)];\r\n                            });\r\n                        }); }))];\r\n                case 1:\r\n                    bitmaps = _b.sent();\r\n                    imagePatchesDatas = [];\r\n                    bitmaps.forEach(function (bmp) {\r\n                        var patch = dom_1.createCanvas({ width: width, height: height });\r\n                        var patchCtx = dom_1.getContext2dOrThrow(patch);\r\n                        patchCtx.drawImage(bmp, 0, 0, width, height);\r\n                        var data = patchCtx.getImageData(0, 0, width, height).data;\r\n                        var currData = [];\r\n                        // RGBA -> BGR\r\n                        for (var i = 0; i < data.length; i += 4) {\r\n                            currData.push(data[i + 2]);\r\n                            currData.push(data[i + 1]);\r\n                            currData.push(data[i]);\r\n                        }\r\n                        imagePatchesDatas.push(currData);\r\n                    });\r\n                    return [2 /*return*/, imagePatchesDatas.map(function (data) {\r\n                            var t = tf.tidy(function () {\r\n                                var imagePatchTensor = tf.transpose(tf.tensor4d(data, [1, width, height, 3]), [0, 2, 1, 3]).toFloat();\r\n                                return normalize_1.normalize(imagePatchTensor);\r\n                            });\r\n                            return t;\r\n                        })];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.extractImagePatches = extractImagePatches;\r\n//# sourceMappingURL=extractImagePatches.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/extractImagePatches.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/extractParams.js":
/*!************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/extractParams.js ***!
  \************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    var extractConvParams = common_1.extractConvParamsFactory(extractWeights, paramMappings);\r\n    var extractFCParams = common_1.extractFCParamsFactory(extractWeights, paramMappings);\r\n    function extractPReluParams(size, paramPath) {\r\n        var alpha = tf.tensor1d(extractWeights(size));\r\n        paramMappings.push({ paramPath: paramPath });\r\n        return alpha;\r\n    }\r\n    function extractSharedParams(numFilters, mappedPrefix, isRnet) {\r\n        if (isRnet === void 0) { isRnet = false; }\r\n        var conv1 = extractConvParams(numFilters[0], numFilters[1], 3, mappedPrefix + \"/conv1\");\r\n        var prelu1_alpha = extractPReluParams(numFilters[1], mappedPrefix + \"/prelu1_alpha\");\r\n        var conv2 = extractConvParams(numFilters[1], numFilters[2], 3, mappedPrefix + \"/conv2\");\r\n        var prelu2_alpha = extractPReluParams(numFilters[2], mappedPrefix + \"/prelu2_alpha\");\r\n        var conv3 = extractConvParams(numFilters[2], numFilters[3], isRnet ? 2 : 3, mappedPrefix + \"/conv3\");\r\n        var prelu3_alpha = extractPReluParams(numFilters[3], mappedPrefix + \"/prelu3_alpha\");\r\n        return { conv1: conv1, prelu1_alpha: prelu1_alpha, conv2: conv2, prelu2_alpha: prelu2_alpha, conv3: conv3, prelu3_alpha: prelu3_alpha };\r\n    }\r\n    function extractPNetParams() {\r\n        var sharedParams = extractSharedParams([3, 10, 16, 32], 'pnet');\r\n        var conv4_1 = extractConvParams(32, 2, 1, 'pnet/conv4_1');\r\n        var conv4_2 = extractConvParams(32, 4, 1, 'pnet/conv4_2');\r\n        return tslib_1.__assign(tslib_1.__assign({}, sharedParams), { conv4_1: conv4_1, conv4_2: conv4_2 });\r\n    }\r\n    function extractRNetParams() {\r\n        var sharedParams = extractSharedParams([3, 28, 48, 64], 'rnet', true);\r\n        var fc1 = extractFCParams(576, 128, 'rnet/fc1');\r\n        var prelu4_alpha = extractPReluParams(128, 'rnet/prelu4_alpha');\r\n        var fc2_1 = extractFCParams(128, 2, 'rnet/fc2_1');\r\n        var fc2_2 = extractFCParams(128, 4, 'rnet/fc2_2');\r\n        return tslib_1.__assign(tslib_1.__assign({}, sharedParams), { fc1: fc1, prelu4_alpha: prelu4_alpha, fc2_1: fc2_1, fc2_2: fc2_2 });\r\n    }\r\n    function extractONetParams() {\r\n        var sharedParams = extractSharedParams([3, 32, 64, 64], 'onet');\r\n        var conv4 = extractConvParams(64, 128, 2, 'onet/conv4');\r\n        var prelu4_alpha = extractPReluParams(128, 'onet/prelu4_alpha');\r\n        var fc1 = extractFCParams(1152, 256, 'onet/fc1');\r\n        var prelu5_alpha = extractPReluParams(256, 'onet/prelu5_alpha');\r\n        var fc2_1 = extractFCParams(256, 2, 'onet/fc2_1');\r\n        var fc2_2 = extractFCParams(256, 4, 'onet/fc2_2');\r\n        var fc2_3 = extractFCParams(256, 10, 'onet/fc2_3');\r\n        return tslib_1.__assign(tslib_1.__assign({}, sharedParams), { conv4: conv4, prelu4_alpha: prelu4_alpha, fc1: fc1, prelu5_alpha: prelu5_alpha, fc2_1: fc2_1, fc2_2: fc2_2, fc2_3: fc2_3 });\r\n    }\r\n    return {\r\n        extractPNetParams: extractPNetParams,\r\n        extractRNetParams: extractRNetParams,\r\n        extractONetParams: extractONetParams\r\n    };\r\n}\r\nfunction extractParams(weights) {\r\n    var _a = common_1.extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var paramMappings = [];\r\n    var _b = extractorsFactory(extractWeights, paramMappings), extractPNetParams = _b.extractPNetParams, extractRNetParams = _b.extractRNetParams, extractONetParams = _b.extractONetParams;\r\n    var pnet = extractPNetParams();\r\n    var rnet = extractRNetParams();\r\n    var onet = extractONetParams();\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return { params: { pnet: pnet, rnet: rnet, onet: onet }, paramMappings: paramMappings };\r\n}\r\nexports.extractParams = extractParams;\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/extractParamsFromWeigthMap.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/extractParamsFromWeigthMap.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nfunction extractorsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = common_1.extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractConvParams(prefix) {\r\n        var filters = extractWeightEntry(prefix + \"/weights\", 4, prefix + \"/filters\");\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { filters: filters, bias: bias };\r\n    }\r\n    function extractFCParams(prefix) {\r\n        var weights = extractWeightEntry(prefix + \"/weights\", 2);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { weights: weights, bias: bias };\r\n    }\r\n    function extractPReluParams(paramPath) {\r\n        return extractWeightEntry(paramPath, 1);\r\n    }\r\n    function extractSharedParams(prefix) {\r\n        var conv1 = extractConvParams(prefix + \"/conv1\");\r\n        var prelu1_alpha = extractPReluParams(prefix + \"/prelu1_alpha\");\r\n        var conv2 = extractConvParams(prefix + \"/conv2\");\r\n        var prelu2_alpha = extractPReluParams(prefix + \"/prelu2_alpha\");\r\n        var conv3 = extractConvParams(prefix + \"/conv3\");\r\n        var prelu3_alpha = extractPReluParams(prefix + \"/prelu3_alpha\");\r\n        return { conv1: conv1, prelu1_alpha: prelu1_alpha, conv2: conv2, prelu2_alpha: prelu2_alpha, conv3: conv3, prelu3_alpha: prelu3_alpha };\r\n    }\r\n    function extractPNetParams() {\r\n        var sharedParams = extractSharedParams('pnet');\r\n        var conv4_1 = extractConvParams('pnet/conv4_1');\r\n        var conv4_2 = extractConvParams('pnet/conv4_2');\r\n        return tslib_1.__assign(tslib_1.__assign({}, sharedParams), { conv4_1: conv4_1, conv4_2: conv4_2 });\r\n    }\r\n    function extractRNetParams() {\r\n        var sharedParams = extractSharedParams('rnet');\r\n        var fc1 = extractFCParams('rnet/fc1');\r\n        var prelu4_alpha = extractPReluParams('rnet/prelu4_alpha');\r\n        var fc2_1 = extractFCParams('rnet/fc2_1');\r\n        var fc2_2 = extractFCParams('rnet/fc2_2');\r\n        return tslib_1.__assign(tslib_1.__assign({}, sharedParams), { fc1: fc1, prelu4_alpha: prelu4_alpha, fc2_1: fc2_1, fc2_2: fc2_2 });\r\n    }\r\n    function extractONetParams() {\r\n        var sharedParams = extractSharedParams('onet');\r\n        var conv4 = extractConvParams('onet/conv4');\r\n        var prelu4_alpha = extractPReluParams('onet/prelu4_alpha');\r\n        var fc1 = extractFCParams('onet/fc1');\r\n        var prelu5_alpha = extractPReluParams('onet/prelu5_alpha');\r\n        var fc2_1 = extractFCParams('onet/fc2_1');\r\n        var fc2_2 = extractFCParams('onet/fc2_2');\r\n        var fc2_3 = extractFCParams('onet/fc2_3');\r\n        return tslib_1.__assign(tslib_1.__assign({}, sharedParams), { conv4: conv4, prelu4_alpha: prelu4_alpha, fc1: fc1, prelu5_alpha: prelu5_alpha, fc2_1: fc2_1, fc2_2: fc2_2, fc2_3: fc2_3 });\r\n    }\r\n    return {\r\n        extractPNetParams: extractPNetParams,\r\n        extractRNetParams: extractRNetParams,\r\n        extractONetParams: extractONetParams\r\n    };\r\n}\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var _a = extractorsFactory(weightMap, paramMappings), extractPNetParams = _a.extractPNetParams, extractRNetParams = _a.extractRNetParams, extractONetParams = _a.extractONetParams;\r\n    var pnet = extractPNetParams();\r\n    var rnet = extractRNetParams();\r\n    var onet = extractONetParams();\r\n    common_1.disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: { pnet: pnet, rnet: rnet, onet: onet }, paramMappings: paramMappings };\r\n}\r\nexports.extractParamsFromWeigthMap = extractParamsFromWeigthMap;\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/getSizesForScale.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/getSizesForScale.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction getSizesForScale(scale, _a) {\r\n    var height = _a[0], width = _a[1];\r\n    return {\r\n        height: Math.floor(height * scale),\r\n        width: Math.floor(width * scale)\r\n    };\r\n}\r\nexports.getSizesForScale = getSizesForScale;\r\n//# sourceMappingURL=getSizesForScale.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/getSizesForScale.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/index.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar Mtcnn_1 = __webpack_require__(/*! ./Mtcnn */ \"./node_modules/face-api.js/build/commonjs/mtcnn/Mtcnn.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./Mtcnn */ \"./node_modules/face-api.js/build/commonjs/mtcnn/Mtcnn.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./MtcnnOptions */ \"./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnOptions.js\"), exports);\r\nfunction createMtcnn(weights) {\r\n    var net = new Mtcnn_1.Mtcnn();\r\n    net.extractWeights(weights);\r\n    return net;\r\n}\r\nexports.createMtcnn = createMtcnn;\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/normalize.js":
/*!********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/normalize.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction normalize(x) {\r\n    return tf.tidy(function () { return tf.mul(tf.sub(x, tf.scalar(127.5)), tf.scalar(0.0078125)); });\r\n}\r\nexports.normalize = normalize;\r\n//# sourceMappingURL=normalize.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/normalize.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/prelu.js":
/*!****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/prelu.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction prelu(x, alpha) {\r\n    return tf.tidy(function () {\r\n        return tf.add(tf.relu(x), tf.mul(alpha, tf.neg(tf.relu(tf.neg(x)))));\r\n    });\r\n}\r\nexports.prelu = prelu;\r\n//# sourceMappingURL=prelu.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/prelu.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/pyramidDown.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/pyramidDown.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar config_1 = __webpack_require__(/*! ./config */ \"./node_modules/face-api.js/build/commonjs/mtcnn/config.js\");\r\nfunction pyramidDown(minFaceSize, scaleFactor, dims) {\r\n    var height = dims[0], width = dims[1];\r\n    var m = config_1.CELL_SIZE / minFaceSize;\r\n    var scales = [];\r\n    var minLayer = Math.min(height, width) * m;\r\n    var exp = 0;\r\n    while (minLayer >= 12) {\r\n        scales.push(m * Math.pow(scaleFactor, exp));\r\n        minLayer = minLayer * scaleFactor;\r\n        exp += 1;\r\n    }\r\n    return scales;\r\n}\r\nexports.pyramidDown = pyramidDown;\r\n//# sourceMappingURL=pyramidDown.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/pyramidDown.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/sharedLayers.js":
/*!***********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/sharedLayers.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar prelu_1 = __webpack_require__(/*! ./prelu */ \"./node_modules/face-api.js/build/commonjs/mtcnn/prelu.js\");\r\nfunction sharedLayer(x, params, isPnet) {\r\n    if (isPnet === void 0) { isPnet = false; }\r\n    return tf.tidy(function () {\r\n        var out = common_1.convLayer(x, params.conv1, 'valid');\r\n        out = prelu_1.prelu(out, params.prelu1_alpha);\r\n        out = tf.maxPool(out, isPnet ? [2, 2] : [3, 3], [2, 2], 'same');\r\n        out = common_1.convLayer(out, params.conv2, 'valid');\r\n        out = prelu_1.prelu(out, params.prelu2_alpha);\r\n        out = isPnet ? out : tf.maxPool(out, [3, 3], [2, 2], 'valid');\r\n        out = common_1.convLayer(out, params.conv3, 'valid');\r\n        out = prelu_1.prelu(out, params.prelu3_alpha);\r\n        return out;\r\n    });\r\n}\r\nexports.sharedLayer = sharedLayer;\r\n//# sourceMappingURL=sharedLayers.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/sharedLayers.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/stage1.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/stage1.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar ops_1 = __webpack_require__(/*! ../ops */ \"./node_modules/face-api.js/build/commonjs/ops/index.js\");\r\nvar config_1 = __webpack_require__(/*! ./config */ \"./node_modules/face-api.js/build/commonjs/mtcnn/config.js\");\r\nvar getSizesForScale_1 = __webpack_require__(/*! ./getSizesForScale */ \"./node_modules/face-api.js/build/commonjs/mtcnn/getSizesForScale.js\");\r\nvar MtcnnBox_1 = __webpack_require__(/*! ./MtcnnBox */ \"./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnBox.js\");\r\nvar normalize_1 = __webpack_require__(/*! ./normalize */ \"./node_modules/face-api.js/build/commonjs/mtcnn/normalize.js\");\r\nvar PNet_1 = __webpack_require__(/*! ./PNet */ \"./node_modules/face-api.js/build/commonjs/mtcnn/PNet.js\");\r\nfunction rescaleAndNormalize(x, scale) {\r\n    return tf.tidy(function () {\r\n        var _a = getSizesForScale_1.getSizesForScale(scale, x.shape.slice(1)), height = _a.height, width = _a.width;\r\n        var resized = tf.image.resizeBilinear(x, [height, width]);\r\n        var normalized = normalize_1.normalize(resized);\r\n        return tf.transpose(normalized, [0, 2, 1, 3]);\r\n    });\r\n}\r\nfunction extractBoundingBoxes(scoresTensor, regionsTensor, scale, scoreThreshold) {\r\n    // TODO: fix this!, maybe better to use tf.gather here\r\n    var indices = [];\r\n    var scoresData = scoresTensor.arraySync();\r\n    for (var y = 0; y < scoresTensor.shape[0]; y++) {\r\n        for (var x = 0; x < scoresTensor.shape[1]; x++) {\r\n            if (scoresData[y][x] >= scoreThreshold) {\r\n                indices.push(new classes_1.Point(x, y));\r\n            }\r\n        }\r\n    }\r\n    var boundingBoxes = indices.map(function (idx) {\r\n        var cell = new classes_1.BoundingBox(Math.round((idx.y * config_1.CELL_STRIDE + 1) / scale), Math.round((idx.x * config_1.CELL_STRIDE + 1) / scale), Math.round((idx.y * config_1.CELL_STRIDE + config_1.CELL_SIZE) / scale), Math.round((idx.x * config_1.CELL_STRIDE + config_1.CELL_SIZE) / scale));\r\n        var score = scoresData[idx.y][idx.x];\r\n        var regionsData = regionsTensor.arraySync();\r\n        var region = new MtcnnBox_1.MtcnnBox(regionsData[idx.y][idx.x][0], regionsData[idx.y][idx.x][1], regionsData[idx.y][idx.x][2], regionsData[idx.y][idx.x][3]);\r\n        return {\r\n            cell: cell,\r\n            score: score,\r\n            region: region\r\n        };\r\n    });\r\n    return boundingBoxes;\r\n}\r\nfunction stage1(imgTensor, scales, scoreThreshold, params, stats) {\r\n    stats.stage1 = [];\r\n    var pnetOutputs = scales.map(function (scale) { return tf.tidy(function () {\r\n        var statsForScale = { scale: scale };\r\n        var resized = rescaleAndNormalize(imgTensor, scale);\r\n        var ts = Date.now();\r\n        var _a = PNet_1.PNet(resized, params), prob = _a.prob, regions = _a.regions;\r\n        statsForScale.pnet = Date.now() - ts;\r\n        var scoresTensor = tf.unstack(tf.unstack(prob, 3)[1])[0];\r\n        var regionsTensor = tf.unstack(regions)[0];\r\n        return {\r\n            scoresTensor: scoresTensor,\r\n            regionsTensor: regionsTensor,\r\n            scale: scale,\r\n            statsForScale: statsForScale\r\n        };\r\n    }); });\r\n    var boxesForScale = pnetOutputs.map(function (_a) {\r\n        var scoresTensor = _a.scoresTensor, regionsTensor = _a.regionsTensor, scale = _a.scale, statsForScale = _a.statsForScale;\r\n        var boundingBoxes = extractBoundingBoxes(scoresTensor, regionsTensor, scale, scoreThreshold);\r\n        scoresTensor.dispose();\r\n        regionsTensor.dispose();\r\n        if (!boundingBoxes.length) {\r\n            stats.stage1.push(statsForScale);\r\n            return [];\r\n        }\r\n        var ts = Date.now();\r\n        var indices = ops_1.nonMaxSuppression(boundingBoxes.map(function (bbox) { return bbox.cell; }), boundingBoxes.map(function (bbox) { return bbox.score; }), 0.5);\r\n        statsForScale.nms = Date.now() - ts;\r\n        statsForScale.numBoxes = indices.length;\r\n        stats.stage1.push(statsForScale);\r\n        return indices.map(function (boxIdx) { return boundingBoxes[boxIdx]; });\r\n    });\r\n    var allBoxes = boxesForScale.reduce(function (all, boxes) { return all.concat(boxes); }, []);\r\n    var finalBoxes = [];\r\n    var finalScores = [];\r\n    if (allBoxes.length > 0) {\r\n        var ts = Date.now();\r\n        var indices = ops_1.nonMaxSuppression(allBoxes.map(function (bbox) { return bbox.cell; }), allBoxes.map(function (bbox) { return bbox.score; }), 0.7);\r\n        stats.stage1_nms = Date.now() - ts;\r\n        finalScores = indices.map(function (idx) { return allBoxes[idx].score; });\r\n        finalBoxes = indices\r\n            .map(function (idx) { return allBoxes[idx]; })\r\n            .map(function (_a) {\r\n            var cell = _a.cell, region = _a.region;\r\n            return new classes_1.BoundingBox(cell.left + (region.left * cell.width), cell.top + (region.top * cell.height), cell.right + (region.right * cell.width), cell.bottom + (region.bottom * cell.height)).toSquare().round();\r\n        });\r\n    }\r\n    return {\r\n        boxes: finalBoxes,\r\n        scores: finalScores\r\n    };\r\n}\r\nexports.stage1 = stage1;\r\n//# sourceMappingURL=stage1.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/stage1.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/stage2.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/stage2.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar ops_1 = __webpack_require__(/*! ../ops */ \"./node_modules/face-api.js/build/commonjs/ops/index.js\");\r\nvar extractImagePatches_1 = __webpack_require__(/*! ./extractImagePatches */ \"./node_modules/face-api.js/build/commonjs/mtcnn/extractImagePatches.js\");\r\nvar MtcnnBox_1 = __webpack_require__(/*! ./MtcnnBox */ \"./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnBox.js\");\r\nvar RNet_1 = __webpack_require__(/*! ./RNet */ \"./node_modules/face-api.js/build/commonjs/mtcnn/RNet.js\");\r\nfunction stage2(img, inputBoxes, scoreThreshold, params, stats) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var ts, rnetInputs, rnetOuts, scoresTensor, scores, _a, _b, indices, filteredBoxes, filteredScores, finalBoxes, finalScores, indicesNms, regions_1;\r\n        return tslib_1.__generator(this, function (_c) {\r\n            switch (_c.label) {\r\n                case 0:\r\n                    ts = Date.now();\r\n                    return [4 /*yield*/, extractImagePatches_1.extractImagePatches(img, inputBoxes, { width: 24, height: 24 })];\r\n                case 1:\r\n                    rnetInputs = _c.sent();\r\n                    stats.stage2_extractImagePatches = Date.now() - ts;\r\n                    ts = Date.now();\r\n                    rnetOuts = rnetInputs.map(function (rnetInput) {\r\n                        var out = RNet_1.RNet(rnetInput, params);\r\n                        rnetInput.dispose();\r\n                        return out;\r\n                    });\r\n                    stats.stage2_rnet = Date.now() - ts;\r\n                    scoresTensor = rnetOuts.length > 1\r\n                        ? tf.concat(rnetOuts.map(function (out) { return out.scores; }))\r\n                        : rnetOuts[0].scores;\r\n                    _b = (_a = Array).from;\r\n                    return [4 /*yield*/, scoresTensor.data()];\r\n                case 2:\r\n                    scores = _b.apply(_a, [_c.sent()]);\r\n                    scoresTensor.dispose();\r\n                    indices = scores\r\n                        .map(function (score, idx) { return ({ score: score, idx: idx }); })\r\n                        .filter(function (c) { return c.score > scoreThreshold; })\r\n                        .map(function (_a) {\r\n                        var idx = _a.idx;\r\n                        return idx;\r\n                    });\r\n                    filteredBoxes = indices.map(function (idx) { return inputBoxes[idx]; });\r\n                    filteredScores = indices.map(function (idx) { return scores[idx]; });\r\n                    finalBoxes = [];\r\n                    finalScores = [];\r\n                    if (filteredBoxes.length > 0) {\r\n                        ts = Date.now();\r\n                        indicesNms = ops_1.nonMaxSuppression(filteredBoxes, filteredScores, 0.7);\r\n                        stats.stage2_nms = Date.now() - ts;\r\n                        regions_1 = indicesNms.map(function (idx) {\r\n                            var regionsData = rnetOuts[indices[idx]].regions.arraySync();\r\n                            return new MtcnnBox_1.MtcnnBox(regionsData[0][0], regionsData[0][1], regionsData[0][2], regionsData[0][3]);\r\n                        });\r\n                        finalScores = indicesNms.map(function (idx) { return filteredScores[idx]; });\r\n                        finalBoxes = indicesNms.map(function (idx, i) { return filteredBoxes[idx].calibrate(regions_1[i]); });\r\n                    }\r\n                    rnetOuts.forEach(function (t) {\r\n                        t.regions.dispose();\r\n                        t.scores.dispose();\r\n                    });\r\n                    return [2 /*return*/, {\r\n                            boxes: finalBoxes,\r\n                            scores: finalScores\r\n                        }];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.stage2 = stage2;\r\n//# sourceMappingURL=stage2.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/stage2.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/mtcnn/stage3.js":
/*!*****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/mtcnn/stage3.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar ops_1 = __webpack_require__(/*! ../ops */ \"./node_modules/face-api.js/build/commonjs/ops/index.js\");\r\nvar extractImagePatches_1 = __webpack_require__(/*! ./extractImagePatches */ \"./node_modules/face-api.js/build/commonjs/mtcnn/extractImagePatches.js\");\r\nvar MtcnnBox_1 = __webpack_require__(/*! ./MtcnnBox */ \"./node_modules/face-api.js/build/commonjs/mtcnn/MtcnnBox.js\");\r\nvar ONet_1 = __webpack_require__(/*! ./ONet */ \"./node_modules/face-api.js/build/commonjs/mtcnn/ONet.js\");\r\nfunction stage3(img, inputBoxes, scoreThreshold, params, stats) {\r\n    return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n        var ts, onetInputs, onetOuts, scoresTensor, scores, _a, _b, indices, filteredRegions, filteredBoxes, filteredScores, finalBoxes, finalScores, points, indicesNms;\r\n        return tslib_1.__generator(this, function (_c) {\r\n            switch (_c.label) {\r\n                case 0:\r\n                    ts = Date.now();\r\n                    return [4 /*yield*/, extractImagePatches_1.extractImagePatches(img, inputBoxes, { width: 48, height: 48 })];\r\n                case 1:\r\n                    onetInputs = _c.sent();\r\n                    stats.stage3_extractImagePatches = Date.now() - ts;\r\n                    ts = Date.now();\r\n                    onetOuts = onetInputs.map(function (onetInput) {\r\n                        var out = ONet_1.ONet(onetInput, params);\r\n                        onetInput.dispose();\r\n                        return out;\r\n                    });\r\n                    stats.stage3_onet = Date.now() - ts;\r\n                    scoresTensor = onetOuts.length > 1\r\n                        ? tf.concat(onetOuts.map(function (out) { return out.scores; }))\r\n                        : onetOuts[0].scores;\r\n                    _b = (_a = Array).from;\r\n                    return [4 /*yield*/, scoresTensor.data()];\r\n                case 2:\r\n                    scores = _b.apply(_a, [_c.sent()]);\r\n                    scoresTensor.dispose();\r\n                    indices = scores\r\n                        .map(function (score, idx) { return ({ score: score, idx: idx }); })\r\n                        .filter(function (c) { return c.score > scoreThreshold; })\r\n                        .map(function (_a) {\r\n                        var idx = _a.idx;\r\n                        return idx;\r\n                    });\r\n                    filteredRegions = indices.map(function (idx) {\r\n                        var regionsData = onetOuts[idx].regions.arraySync();\r\n                        return new MtcnnBox_1.MtcnnBox(regionsData[0][0], regionsData[0][1], regionsData[0][2], regionsData[0][3]);\r\n                    });\r\n                    filteredBoxes = indices\r\n                        .map(function (idx, i) { return inputBoxes[idx].calibrate(filteredRegions[i]); });\r\n                    filteredScores = indices.map(function (idx) { return scores[idx]; });\r\n                    finalBoxes = [];\r\n                    finalScores = [];\r\n                    points = [];\r\n                    if (filteredBoxes.length > 0) {\r\n                        ts = Date.now();\r\n                        indicesNms = ops_1.nonMaxSuppression(filteredBoxes, filteredScores, 0.7, false);\r\n                        stats.stage3_nms = Date.now() - ts;\r\n                        finalBoxes = indicesNms.map(function (idx) { return filteredBoxes[idx]; });\r\n                        finalScores = indicesNms.map(function (idx) { return filteredScores[idx]; });\r\n                        points = indicesNms.map(function (idx, i) {\r\n                            return Array(5).fill(0).map(function (_, ptIdx) {\r\n                                var pointsData = onetOuts[idx].points.arraySync();\r\n                                return new classes_1.Point(((pointsData[0][ptIdx] * (finalBoxes[i].width + 1)) + finalBoxes[i].left), ((pointsData[0][ptIdx + 5] * (finalBoxes[i].height + 1)) + finalBoxes[i].top));\r\n                            });\r\n                        });\r\n                    }\r\n                    onetOuts.forEach(function (t) {\r\n                        t.regions.dispose();\r\n                        t.scores.dispose();\r\n                        t.points.dispose();\r\n                    });\r\n                    return [2 /*return*/, {\r\n                            boxes: finalBoxes,\r\n                            scores: finalScores,\r\n                            points: points\r\n                        }];\r\n            }\r\n        });\r\n    });\r\n}\r\nexports.stage3 = stage3;\r\n//# sourceMappingURL=stage3.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/mtcnn/stage3.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ops/index.js":
/*!**************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ops/index.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./iou */ \"./node_modules/face-api.js/build/commonjs/ops/iou.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./minBbox */ \"./node_modules/face-api.js/build/commonjs/ops/minBbox.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./nonMaxSuppression */ \"./node_modules/face-api.js/build/commonjs/ops/nonMaxSuppression.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./normalize */ \"./node_modules/face-api.js/build/commonjs/ops/normalize.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./padToSquare */ \"./node_modules/face-api.js/build/commonjs/ops/padToSquare.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./shuffleArray */ \"./node_modules/face-api.js/build/commonjs/ops/shuffleArray.js\"), exports);\r\nfunction sigmoid(x) {\r\n    return 1 / (1 + Math.exp(-x));\r\n}\r\nexports.sigmoid = sigmoid;\r\nfunction inverseSigmoid(x) {\r\n    return Math.log(x / (1 - x));\r\n}\r\nexports.inverseSigmoid = inverseSigmoid;\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ops/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ops/iou.js":
/*!************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ops/iou.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction iou(box1, box2, isIOU) {\r\n    if (isIOU === void 0) { isIOU = true; }\r\n    var width = Math.max(0.0, Math.min(box1.right, box2.right) - Math.max(box1.left, box2.left));\r\n    var height = Math.max(0.0, Math.min(box1.bottom, box2.bottom) - Math.max(box1.top, box2.top));\r\n    var interSection = width * height;\r\n    return isIOU\r\n        ? interSection / (box1.area + box2.area - interSection)\r\n        : interSection / Math.min(box1.area, box2.area);\r\n}\r\nexports.iou = iou;\r\n//# sourceMappingURL=iou.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ops/iou.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ops/minBbox.js":
/*!****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ops/minBbox.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nfunction minBbox(pts) {\r\n    var xs = pts.map(function (pt) { return pt.x; });\r\n    var ys = pts.map(function (pt) { return pt.y; });\r\n    var minX = xs.reduce(function (min, x) { return x < min ? x : min; }, Infinity);\r\n    var minY = ys.reduce(function (min, y) { return y < min ? y : min; }, Infinity);\r\n    var maxX = xs.reduce(function (max, x) { return max < x ? x : max; }, 0);\r\n    var maxY = ys.reduce(function (max, y) { return max < y ? y : max; }, 0);\r\n    return new classes_1.BoundingBox(minX, minY, maxX, maxY);\r\n}\r\nexports.minBbox = minBbox;\r\n//# sourceMappingURL=minBbox.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ops/minBbox.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ops/nonMaxSuppression.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ops/nonMaxSuppression.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar iou_1 = __webpack_require__(/*! ./iou */ \"./node_modules/face-api.js/build/commonjs/ops/iou.js\");\r\nfunction nonMaxSuppression(boxes, scores, iouThreshold, isIOU) {\r\n    if (isIOU === void 0) { isIOU = true; }\r\n    var indicesSortedByScore = scores\r\n        .map(function (score, boxIndex) { return ({ score: score, boxIndex: boxIndex }); })\r\n        .sort(function (c1, c2) { return c1.score - c2.score; })\r\n        .map(function (c) { return c.boxIndex; });\r\n    var pick = [];\r\n    var _loop_1 = function () {\r\n        var curr = indicesSortedByScore.pop();\r\n        pick.push(curr);\r\n        var indices = indicesSortedByScore;\r\n        var outputs = [];\r\n        for (var i = 0; i < indices.length; i++) {\r\n            var idx = indices[i];\r\n            var currBox = boxes[curr];\r\n            var idxBox = boxes[idx];\r\n            outputs.push(iou_1.iou(currBox, idxBox, isIOU));\r\n        }\r\n        indicesSortedByScore = indicesSortedByScore.filter(function (_, j) { return outputs[j] <= iouThreshold; });\r\n    };\r\n    while (indicesSortedByScore.length > 0) {\r\n        _loop_1();\r\n    }\r\n    return pick;\r\n}\r\nexports.nonMaxSuppression = nonMaxSuppression;\r\n//# sourceMappingURL=nonMaxSuppression.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ops/nonMaxSuppression.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ops/normalize.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ops/normalize.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction normalize(x, meanRgb) {\r\n    return tf.tidy(function () {\r\n        var r = meanRgb[0], g = meanRgb[1], b = meanRgb[2];\r\n        var avg_r = tf.fill(tslib_1.__spreadArrays(x.shape.slice(0, 3), [1]), r);\r\n        var avg_g = tf.fill(tslib_1.__spreadArrays(x.shape.slice(0, 3), [1]), g);\r\n        var avg_b = tf.fill(tslib_1.__spreadArrays(x.shape.slice(0, 3), [1]), b);\r\n        var avg_rgb = tf.concat([avg_r, avg_g, avg_b], 3);\r\n        return tf.sub(x, avg_rgb);\r\n    });\r\n}\r\nexports.normalize = normalize;\r\n//# sourceMappingURL=normalize.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ops/normalize.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ops/padToSquare.js":
/*!********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ops/padToSquare.js ***!
  \********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\n/**\r\n * Pads the smaller dimension of an image tensor with zeros, such that width === height.\r\n *\r\n * @param imgTensor The image tensor.\r\n * @param isCenterImage (optional, default: false) If true, add an equal amount of padding on\r\n * both sides of the minor dimension oof the image.\r\n * @returns The padded tensor with width === height.\r\n */\r\nfunction padToSquare(imgTensor, isCenterImage) {\r\n    if (isCenterImage === void 0) { isCenterImage = false; }\r\n    return tf.tidy(function () {\r\n        var _a = imgTensor.shape.slice(1), height = _a[0], width = _a[1];\r\n        if (height === width) {\r\n            return imgTensor;\r\n        }\r\n        var dimDiff = Math.abs(height - width);\r\n        var paddingAmount = Math.round(dimDiff * (isCenterImage ? 0.5 : 1));\r\n        var paddingAxis = height > width ? 2 : 1;\r\n        var createPaddingTensor = function (paddingAmount) {\r\n            var paddingTensorShape = imgTensor.shape.slice();\r\n            paddingTensorShape[paddingAxis] = paddingAmount;\r\n            return tf.fill(paddingTensorShape, 0);\r\n        };\r\n        var paddingTensorAppend = createPaddingTensor(paddingAmount);\r\n        var remainingPaddingAmount = dimDiff - paddingTensorAppend.shape[paddingAxis];\r\n        var paddingTensorPrepend = isCenterImage && remainingPaddingAmount\r\n            ? createPaddingTensor(remainingPaddingAmount)\r\n            : null;\r\n        var tensorsToStack = [\r\n            paddingTensorPrepend,\r\n            imgTensor,\r\n            paddingTensorAppend\r\n        ]\r\n            .filter(function (t) { return !!t; })\r\n            .map(function (t) { return t.toFloat(); });\r\n        return tf.concat(tensorsToStack, paddingAxis);\r\n    });\r\n}\r\nexports.padToSquare = padToSquare;\r\n//# sourceMappingURL=padToSquare.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ops/padToSquare.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ops/shuffleArray.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ops/shuffleArray.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction shuffleArray(inputArray) {\r\n    var array = inputArray.slice();\r\n    for (var i = array.length - 1; i > 0; i--) {\r\n        var j = Math.floor(Math.random() * (i + 1));\r\n        var x = array[i];\r\n        array[i] = array[j];\r\n        array[j] = x;\r\n    }\r\n    return array;\r\n}\r\nexports.shuffleArray = shuffleArray;\r\n//# sourceMappingURL=shuffleArray.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ops/shuffleArray.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/resizeResults.js":
/*!******************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/resizeResults.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar classes_1 = __webpack_require__(/*! ./classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar FaceDetection_1 = __webpack_require__(/*! ./classes/FaceDetection */ \"./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js\");\r\nvar FaceLandmarks_1 = __webpack_require__(/*! ./classes/FaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/classes/FaceLandmarks.js\");\r\nvar WithFaceDetection_1 = __webpack_require__(/*! ./factories/WithFaceDetection */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceDetection.js\");\r\nvar WithFaceLandmarks_1 = __webpack_require__(/*! ./factories/WithFaceLandmarks */ \"./node_modules/face-api.js/build/commonjs/factories/WithFaceLandmarks.js\");\r\nfunction resizeResults(results, dimensions) {\r\n    var _a = new classes_1.Dimensions(dimensions.width, dimensions.height), width = _a.width, height = _a.height;\r\n    if (width <= 0 || height <= 0) {\r\n        throw new Error(\"resizeResults - invalid dimensions: \" + JSON.stringify({ width: width, height: height }));\r\n    }\r\n    if (Array.isArray(results)) {\r\n        return results.map(function (obj) { return resizeResults(obj, { width: width, height: height }); });\r\n    }\r\n    if (WithFaceLandmarks_1.isWithFaceLandmarks(results)) {\r\n        var resizedDetection = results.detection.forSize(width, height);\r\n        var resizedLandmarks = results.unshiftedLandmarks.forSize(resizedDetection.box.width, resizedDetection.box.height);\r\n        return WithFaceLandmarks_1.extendWithFaceLandmarks(WithFaceDetection_1.extendWithFaceDetection(results, resizedDetection), resizedLandmarks);\r\n    }\r\n    if (WithFaceDetection_1.isWithFaceDetection(results)) {\r\n        return WithFaceDetection_1.extendWithFaceDetection(results, results.detection.forSize(width, height));\r\n    }\r\n    if (results instanceof FaceLandmarks_1.FaceLandmarks || results instanceof FaceDetection_1.FaceDetection) {\r\n        return results.forSize(width, height);\r\n    }\r\n    return results;\r\n}\r\nexports.resizeResults = resizeResults;\r\n//# sourceMappingURL=resizeResults.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/resizeResults.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1.js ***!
  \**********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar FaceDetection_1 = __webpack_require__(/*! ../classes/FaceDetection */ \"./node_modules/face-api.js/build/commonjs/classes/FaceDetection.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar NeuralNetwork_1 = __webpack_require__(/*! ../NeuralNetwork */ \"./node_modules/face-api.js/build/commonjs/NeuralNetwork.js\");\r\nvar extractParams_1 = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/extractParams.js\");\r\nvar extractParamsFromWeigthMap_1 = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/extractParamsFromWeigthMap.js\");\r\nvar mobileNetV1_1 = __webpack_require__(/*! ./mobileNetV1 */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/mobileNetV1.js\");\r\nvar nonMaxSuppression_1 = __webpack_require__(/*! ./nonMaxSuppression */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/nonMaxSuppression.js\");\r\nvar outputLayer_1 = __webpack_require__(/*! ./outputLayer */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/outputLayer.js\");\r\nvar predictionLayer_1 = __webpack_require__(/*! ./predictionLayer */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/predictionLayer.js\");\r\nvar SsdMobilenetv1Options_1 = __webpack_require__(/*! ./SsdMobilenetv1Options */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1Options.js\");\r\nvar SsdMobilenetv1 = /** @class */ (function (_super) {\r\n    tslib_1.__extends(SsdMobilenetv1, _super);\r\n    function SsdMobilenetv1() {\r\n        return _super.call(this, 'SsdMobilenetv1') || this;\r\n    }\r\n    SsdMobilenetv1.prototype.forwardInput = function (input) {\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('SsdMobilenetv1 - load model before inference');\r\n        }\r\n        return tf.tidy(function () {\r\n            var batchTensor = input.toBatchTensor(512, false).toFloat();\r\n            var x = tf.sub(tf.mul(batchTensor, tf.scalar(0.007843137718737125)), tf.scalar(1));\r\n            var features = mobileNetV1_1.mobileNetV1(x, params.mobilenetv1);\r\n            var _a = predictionLayer_1.predictionLayer(features.out, features.conv11, params.prediction_layer), boxPredictions = _a.boxPredictions, classPredictions = _a.classPredictions;\r\n            return outputLayer_1.outputLayer(boxPredictions, classPredictions, params.output_layer);\r\n        });\r\n    };\r\n    SsdMobilenetv1.prototype.forward = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    SsdMobilenetv1.prototype.locateFaces = function (input, options) {\r\n        if (options === void 0) { options = {}; }\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a, maxResults, minConfidence, netInput, _b, _boxes, _scores, boxes, scores, i, scoresData, _c, _d, iouThreshold, indices, reshapedDims, inputSize, padX, padY, boxesData, results;\r\n            return tslib_1.__generator(this, function (_e) {\r\n                switch (_e.label) {\r\n                    case 0:\r\n                        _a = new SsdMobilenetv1Options_1.SsdMobilenetv1Options(options), maxResults = _a.maxResults, minConfidence = _a.minConfidence;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1:\r\n                        netInput = _e.sent();\r\n                        _b = this.forwardInput(netInput), _boxes = _b.boxes, _scores = _b.scores;\r\n                        boxes = _boxes[0];\r\n                        scores = _scores[0];\r\n                        for (i = 1; i < _boxes.length; i++) {\r\n                            _boxes[i].dispose();\r\n                            _scores[i].dispose();\r\n                        }\r\n                        _d = (_c = Array).from;\r\n                        return [4 /*yield*/, scores.data()];\r\n                    case 2:\r\n                        scoresData = _d.apply(_c, [_e.sent()]);\r\n                        iouThreshold = 0.5;\r\n                        indices = nonMaxSuppression_1.nonMaxSuppression(boxes, scoresData, maxResults, iouThreshold, minConfidence);\r\n                        reshapedDims = netInput.getReshapedInputDimensions(0);\r\n                        inputSize = netInput.inputSize;\r\n                        padX = inputSize / reshapedDims.width;\r\n                        padY = inputSize / reshapedDims.height;\r\n                        boxesData = boxes.arraySync();\r\n                        results = indices\r\n                            .map(function (idx) {\r\n                            var _a = [\r\n                                Math.max(0, boxesData[idx][0]),\r\n                                Math.min(1.0, boxesData[idx][2])\r\n                            ].map(function (val) { return val * padY; }), top = _a[0], bottom = _a[1];\r\n                            var _b = [\r\n                                Math.max(0, boxesData[idx][1]),\r\n                                Math.min(1.0, boxesData[idx][3])\r\n                            ].map(function (val) { return val * padX; }), left = _b[0], right = _b[1];\r\n                            return new FaceDetection_1.FaceDetection(scoresData[idx], new classes_1.Rect(left, top, right - left, bottom - top), {\r\n                                height: netInput.getInputHeight(0),\r\n                                width: netInput.getInputWidth(0)\r\n                            });\r\n                        });\r\n                        boxes.dispose();\r\n                        scores.dispose();\r\n                        return [2 /*return*/, results];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    SsdMobilenetv1.prototype.getDefaultModelName = function () {\r\n        return 'ssd_mobilenetv1_model';\r\n    };\r\n    SsdMobilenetv1.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return extractParamsFromWeigthMap_1.extractParamsFromWeigthMap(weightMap);\r\n    };\r\n    SsdMobilenetv1.prototype.extractParams = function (weights) {\r\n        return extractParams_1.extractParams(weights);\r\n    };\r\n    return SsdMobilenetv1;\r\n}(NeuralNetwork_1.NeuralNetwork));\r\nexports.SsdMobilenetv1 = SsdMobilenetv1;\r\n//# sourceMappingURL=SsdMobilenetv1.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1Options.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1Options.js ***!
  \*****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar SsdMobilenetv1Options = /** @class */ (function () {\r\n    function SsdMobilenetv1Options(_a) {\r\n        var _b = _a === void 0 ? {} : _a, minConfidence = _b.minConfidence, maxResults = _b.maxResults;\r\n        this._name = 'SsdMobilenetv1Options';\r\n        this._minConfidence = minConfidence || 0.5;\r\n        this._maxResults = maxResults || 100;\r\n        if (typeof this._minConfidence !== 'number' || this._minConfidence <= 0 || this._minConfidence >= 1) {\r\n            throw new Error(this._name + \" - expected minConfidence to be a number between 0 and 1\");\r\n        }\r\n        if (typeof this._maxResults !== 'number') {\r\n            throw new Error(this._name + \" - expected maxResults to be a number\");\r\n        }\r\n    }\r\n    Object.defineProperty(SsdMobilenetv1Options.prototype, \"minConfidence\", {\r\n        get: function () { return this._minConfidence; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(SsdMobilenetv1Options.prototype, \"maxResults\", {\r\n        get: function () { return this._maxResults; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return SsdMobilenetv1Options;\r\n}());\r\nexports.SsdMobilenetv1Options = SsdMobilenetv1Options;\r\n//# sourceMappingURL=SsdMobilenetv1Options.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1Options.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/boxPredictionLayer.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/boxPredictionLayer.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nfunction boxPredictionLayer(x, params) {\r\n    return tf.tidy(function () {\r\n        var batchSize = x.shape[0];\r\n        var boxPredictionEncoding = tf.reshape(common_1.convLayer(x, params.box_encoding_predictor), [batchSize, -1, 1, 4]);\r\n        var classPrediction = tf.reshape(common_1.convLayer(x, params.class_predictor), [batchSize, -1, 3]);\r\n        return {\r\n            boxPredictionEncoding: boxPredictionEncoding,\r\n            classPrediction: classPrediction\r\n        };\r\n    });\r\n}\r\nexports.boxPredictionLayer = boxPredictionLayer;\r\n//# sourceMappingURL=boxPredictionLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/boxPredictionLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/extractParams.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/extractParams.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    function extractDepthwiseConvParams(numChannels, mappedPrefix) {\r\n        var filters = tf.tensor4d(extractWeights(3 * 3 * numChannels), [3, 3, numChannels, 1]);\r\n        var batch_norm_scale = tf.tensor1d(extractWeights(numChannels));\r\n        var batch_norm_offset = tf.tensor1d(extractWeights(numChannels));\r\n        var batch_norm_mean = tf.tensor1d(extractWeights(numChannels));\r\n        var batch_norm_variance = tf.tensor1d(extractWeights(numChannels));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/filters\" }, { paramPath: mappedPrefix + \"/batch_norm_scale\" }, { paramPath: mappedPrefix + \"/batch_norm_offset\" }, { paramPath: mappedPrefix + \"/batch_norm_mean\" }, { paramPath: mappedPrefix + \"/batch_norm_variance\" });\r\n        return {\r\n            filters: filters,\r\n            batch_norm_scale: batch_norm_scale,\r\n            batch_norm_offset: batch_norm_offset,\r\n            batch_norm_mean: batch_norm_mean,\r\n            batch_norm_variance: batch_norm_variance\r\n        };\r\n    }\r\n    function extractConvParams(channelsIn, channelsOut, filterSize, mappedPrefix, isPointwiseConv) {\r\n        var filters = tf.tensor4d(extractWeights(channelsIn * channelsOut * filterSize * filterSize), [filterSize, filterSize, channelsIn, channelsOut]);\r\n        var bias = tf.tensor1d(extractWeights(channelsOut));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/filters\" }, { paramPath: mappedPrefix + \"/\" + (isPointwiseConv ? 'batch_norm_offset' : 'bias') });\r\n        return { filters: filters, bias: bias };\r\n    }\r\n    function extractPointwiseConvParams(channelsIn, channelsOut, filterSize, mappedPrefix) {\r\n        var _a = extractConvParams(channelsIn, channelsOut, filterSize, mappedPrefix, true), filters = _a.filters, bias = _a.bias;\r\n        return {\r\n            filters: filters,\r\n            batch_norm_offset: bias\r\n        };\r\n    }\r\n    function extractConvPairParams(channelsIn, channelsOut, mappedPrefix) {\r\n        var depthwise_conv = extractDepthwiseConvParams(channelsIn, mappedPrefix + \"/depthwise_conv\");\r\n        var pointwise_conv = extractPointwiseConvParams(channelsIn, channelsOut, 1, mappedPrefix + \"/pointwise_conv\");\r\n        return { depthwise_conv: depthwise_conv, pointwise_conv: pointwise_conv };\r\n    }\r\n    function extractMobilenetV1Params() {\r\n        var conv_0 = extractPointwiseConvParams(3, 32, 3, 'mobilenetv1/conv_0');\r\n        var conv_1 = extractConvPairParams(32, 64, 'mobilenetv1/conv_1');\r\n        var conv_2 = extractConvPairParams(64, 128, 'mobilenetv1/conv_2');\r\n        var conv_3 = extractConvPairParams(128, 128, 'mobilenetv1/conv_3');\r\n        var conv_4 = extractConvPairParams(128, 256, 'mobilenetv1/conv_4');\r\n        var conv_5 = extractConvPairParams(256, 256, 'mobilenetv1/conv_5');\r\n        var conv_6 = extractConvPairParams(256, 512, 'mobilenetv1/conv_6');\r\n        var conv_7 = extractConvPairParams(512, 512, 'mobilenetv1/conv_7');\r\n        var conv_8 = extractConvPairParams(512, 512, 'mobilenetv1/conv_8');\r\n        var conv_9 = extractConvPairParams(512, 512, 'mobilenetv1/conv_9');\r\n        var conv_10 = extractConvPairParams(512, 512, 'mobilenetv1/conv_10');\r\n        var conv_11 = extractConvPairParams(512, 512, 'mobilenetv1/conv_11');\r\n        var conv_12 = extractConvPairParams(512, 1024, 'mobilenetv1/conv_12');\r\n        var conv_13 = extractConvPairParams(1024, 1024, 'mobilenetv1/conv_13');\r\n        return {\r\n            conv_0: conv_0,\r\n            conv_1: conv_1,\r\n            conv_2: conv_2,\r\n            conv_3: conv_3,\r\n            conv_4: conv_4,\r\n            conv_5: conv_5,\r\n            conv_6: conv_6,\r\n            conv_7: conv_7,\r\n            conv_8: conv_8,\r\n            conv_9: conv_9,\r\n            conv_10: conv_10,\r\n            conv_11: conv_11,\r\n            conv_12: conv_12,\r\n            conv_13: conv_13\r\n        };\r\n    }\r\n    function extractPredictionLayerParams() {\r\n        var conv_0 = extractPointwiseConvParams(1024, 256, 1, 'prediction_layer/conv_0');\r\n        var conv_1 = extractPointwiseConvParams(256, 512, 3, 'prediction_layer/conv_1');\r\n        var conv_2 = extractPointwiseConvParams(512, 128, 1, 'prediction_layer/conv_2');\r\n        var conv_3 = extractPointwiseConvParams(128, 256, 3, 'prediction_layer/conv_3');\r\n        var conv_4 = extractPointwiseConvParams(256, 128, 1, 'prediction_layer/conv_4');\r\n        var conv_5 = extractPointwiseConvParams(128, 256, 3, 'prediction_layer/conv_5');\r\n        var conv_6 = extractPointwiseConvParams(256, 64, 1, 'prediction_layer/conv_6');\r\n        var conv_7 = extractPointwiseConvParams(64, 128, 3, 'prediction_layer/conv_7');\r\n        var box_encoding_0_predictor = extractConvParams(512, 12, 1, 'prediction_layer/box_predictor_0/box_encoding_predictor');\r\n        var class_predictor_0 = extractConvParams(512, 9, 1, 'prediction_layer/box_predictor_0/class_predictor');\r\n        var box_encoding_1_predictor = extractConvParams(1024, 24, 1, 'prediction_layer/box_predictor_1/box_encoding_predictor');\r\n        var class_predictor_1 = extractConvParams(1024, 18, 1, 'prediction_layer/box_predictor_1/class_predictor');\r\n        var box_encoding_2_predictor = extractConvParams(512, 24, 1, 'prediction_layer/box_predictor_2/box_encoding_predictor');\r\n        var class_predictor_2 = extractConvParams(512, 18, 1, 'prediction_layer/box_predictor_2/class_predictor');\r\n        var box_encoding_3_predictor = extractConvParams(256, 24, 1, 'prediction_layer/box_predictor_3/box_encoding_predictor');\r\n        var class_predictor_3 = extractConvParams(256, 18, 1, 'prediction_layer/box_predictor_3/class_predictor');\r\n        var box_encoding_4_predictor = extractConvParams(256, 24, 1, 'prediction_layer/box_predictor_4/box_encoding_predictor');\r\n        var class_predictor_4 = extractConvParams(256, 18, 1, 'prediction_layer/box_predictor_4/class_predictor');\r\n        var box_encoding_5_predictor = extractConvParams(128, 24, 1, 'prediction_layer/box_predictor_5/box_encoding_predictor');\r\n        var class_predictor_5 = extractConvParams(128, 18, 1, 'prediction_layer/box_predictor_5/class_predictor');\r\n        var box_predictor_0 = {\r\n            box_encoding_predictor: box_encoding_0_predictor,\r\n            class_predictor: class_predictor_0\r\n        };\r\n        var box_predictor_1 = {\r\n            box_encoding_predictor: box_encoding_1_predictor,\r\n            class_predictor: class_predictor_1\r\n        };\r\n        var box_predictor_2 = {\r\n            box_encoding_predictor: box_encoding_2_predictor,\r\n            class_predictor: class_predictor_2\r\n        };\r\n        var box_predictor_3 = {\r\n            box_encoding_predictor: box_encoding_3_predictor,\r\n            class_predictor: class_predictor_3\r\n        };\r\n        var box_predictor_4 = {\r\n            box_encoding_predictor: box_encoding_4_predictor,\r\n            class_predictor: class_predictor_4\r\n        };\r\n        var box_predictor_5 = {\r\n            box_encoding_predictor: box_encoding_5_predictor,\r\n            class_predictor: class_predictor_5\r\n        };\r\n        return {\r\n            conv_0: conv_0,\r\n            conv_1: conv_1,\r\n            conv_2: conv_2,\r\n            conv_3: conv_3,\r\n            conv_4: conv_4,\r\n            conv_5: conv_5,\r\n            conv_6: conv_6,\r\n            conv_7: conv_7,\r\n            box_predictor_0: box_predictor_0,\r\n            box_predictor_1: box_predictor_1,\r\n            box_predictor_2: box_predictor_2,\r\n            box_predictor_3: box_predictor_3,\r\n            box_predictor_4: box_predictor_4,\r\n            box_predictor_5: box_predictor_5\r\n        };\r\n    }\r\n    return {\r\n        extractMobilenetV1Params: extractMobilenetV1Params,\r\n        extractPredictionLayerParams: extractPredictionLayerParams\r\n    };\r\n}\r\nfunction extractParams(weights) {\r\n    var paramMappings = [];\r\n    var _a = common_1.extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var _b = extractorsFactory(extractWeights, paramMappings), extractMobilenetV1Params = _b.extractMobilenetV1Params, extractPredictionLayerParams = _b.extractPredictionLayerParams;\r\n    var mobilenetv1 = extractMobilenetV1Params();\r\n    var prediction_layer = extractPredictionLayerParams();\r\n    var extra_dim = tf.tensor3d(extractWeights(5118 * 4), [1, 5118, 4]);\r\n    var output_layer = {\r\n        extra_dim: extra_dim\r\n    };\r\n    paramMappings.push({ paramPath: 'output_layer/extra_dim' });\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        params: {\r\n            mobilenetv1: mobilenetv1,\r\n            prediction_layer: prediction_layer,\r\n            output_layer: output_layer\r\n        },\r\n        paramMappings: paramMappings\r\n    };\r\n}\r\nexports.extractParams = extractParams;\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/extractParamsFromWeigthMap.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/extractParamsFromWeigthMap.js ***!
  \**********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nfunction extractorsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = common_1.extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractPointwiseConvParams(prefix, idx, mappedPrefix) {\r\n        var filters = extractWeightEntry(prefix + \"/Conv2d_\" + idx + \"_pointwise/weights\", 4, mappedPrefix + \"/filters\");\r\n        var batch_norm_offset = extractWeightEntry(prefix + \"/Conv2d_\" + idx + \"_pointwise/convolution_bn_offset\", 1, mappedPrefix + \"/batch_norm_offset\");\r\n        return { filters: filters, batch_norm_offset: batch_norm_offset };\r\n    }\r\n    function extractConvPairParams(idx) {\r\n        var mappedPrefix = \"mobilenetv1/conv_\" + idx;\r\n        var prefixDepthwiseConv = \"MobilenetV1/Conv2d_\" + idx + \"_depthwise\";\r\n        var mappedPrefixDepthwiseConv = mappedPrefix + \"/depthwise_conv\";\r\n        var mappedPrefixPointwiseConv = mappedPrefix + \"/pointwise_conv\";\r\n        var filters = extractWeightEntry(prefixDepthwiseConv + \"/depthwise_weights\", 4, mappedPrefixDepthwiseConv + \"/filters\");\r\n        var batch_norm_scale = extractWeightEntry(prefixDepthwiseConv + \"/BatchNorm/gamma\", 1, mappedPrefixDepthwiseConv + \"/batch_norm_scale\");\r\n        var batch_norm_offset = extractWeightEntry(prefixDepthwiseConv + \"/BatchNorm/beta\", 1, mappedPrefixDepthwiseConv + \"/batch_norm_offset\");\r\n        var batch_norm_mean = extractWeightEntry(prefixDepthwiseConv + \"/BatchNorm/moving_mean\", 1, mappedPrefixDepthwiseConv + \"/batch_norm_mean\");\r\n        var batch_norm_variance = extractWeightEntry(prefixDepthwiseConv + \"/BatchNorm/moving_variance\", 1, mappedPrefixDepthwiseConv + \"/batch_norm_variance\");\r\n        return {\r\n            depthwise_conv: {\r\n                filters: filters,\r\n                batch_norm_scale: batch_norm_scale,\r\n                batch_norm_offset: batch_norm_offset,\r\n                batch_norm_mean: batch_norm_mean,\r\n                batch_norm_variance: batch_norm_variance\r\n            },\r\n            pointwise_conv: extractPointwiseConvParams('MobilenetV1', idx, mappedPrefixPointwiseConv)\r\n        };\r\n    }\r\n    function extractMobilenetV1Params() {\r\n        return {\r\n            conv_0: extractPointwiseConvParams('MobilenetV1', 0, 'mobilenetv1/conv_0'),\r\n            conv_1: extractConvPairParams(1),\r\n            conv_2: extractConvPairParams(2),\r\n            conv_3: extractConvPairParams(3),\r\n            conv_4: extractConvPairParams(4),\r\n            conv_5: extractConvPairParams(5),\r\n            conv_6: extractConvPairParams(6),\r\n            conv_7: extractConvPairParams(7),\r\n            conv_8: extractConvPairParams(8),\r\n            conv_9: extractConvPairParams(9),\r\n            conv_10: extractConvPairParams(10),\r\n            conv_11: extractConvPairParams(11),\r\n            conv_12: extractConvPairParams(12),\r\n            conv_13: extractConvPairParams(13)\r\n        };\r\n    }\r\n    function extractConvParams(prefix, mappedPrefix) {\r\n        var filters = extractWeightEntry(prefix + \"/weights\", 4, mappedPrefix + \"/filters\");\r\n        var bias = extractWeightEntry(prefix + \"/biases\", 1, mappedPrefix + \"/bias\");\r\n        return { filters: filters, bias: bias };\r\n    }\r\n    function extractBoxPredictorParams(idx) {\r\n        var box_encoding_predictor = extractConvParams(\"Prediction/BoxPredictor_\" + idx + \"/BoxEncodingPredictor\", \"prediction_layer/box_predictor_\" + idx + \"/box_encoding_predictor\");\r\n        var class_predictor = extractConvParams(\"Prediction/BoxPredictor_\" + idx + \"/ClassPredictor\", \"prediction_layer/box_predictor_\" + idx + \"/class_predictor\");\r\n        return { box_encoding_predictor: box_encoding_predictor, class_predictor: class_predictor };\r\n    }\r\n    function extractPredictionLayerParams() {\r\n        return {\r\n            conv_0: extractPointwiseConvParams('Prediction', 0, 'prediction_layer/conv_0'),\r\n            conv_1: extractPointwiseConvParams('Prediction', 1, 'prediction_layer/conv_1'),\r\n            conv_2: extractPointwiseConvParams('Prediction', 2, 'prediction_layer/conv_2'),\r\n            conv_3: extractPointwiseConvParams('Prediction', 3, 'prediction_layer/conv_3'),\r\n            conv_4: extractPointwiseConvParams('Prediction', 4, 'prediction_layer/conv_4'),\r\n            conv_5: extractPointwiseConvParams('Prediction', 5, 'prediction_layer/conv_5'),\r\n            conv_6: extractPointwiseConvParams('Prediction', 6, 'prediction_layer/conv_6'),\r\n            conv_7: extractPointwiseConvParams('Prediction', 7, 'prediction_layer/conv_7'),\r\n            box_predictor_0: extractBoxPredictorParams(0),\r\n            box_predictor_1: extractBoxPredictorParams(1),\r\n            box_predictor_2: extractBoxPredictorParams(2),\r\n            box_predictor_3: extractBoxPredictorParams(3),\r\n            box_predictor_4: extractBoxPredictorParams(4),\r\n            box_predictor_5: extractBoxPredictorParams(5)\r\n        };\r\n    }\r\n    return {\r\n        extractMobilenetV1Params: extractMobilenetV1Params,\r\n        extractPredictionLayerParams: extractPredictionLayerParams\r\n    };\r\n}\r\nfunction extractParamsFromWeigthMap(weightMap) {\r\n    var paramMappings = [];\r\n    var _a = extractorsFactory(weightMap, paramMappings), extractMobilenetV1Params = _a.extractMobilenetV1Params, extractPredictionLayerParams = _a.extractPredictionLayerParams;\r\n    var extra_dim = weightMap['Output/extra_dim'];\r\n    paramMappings.push({ originalPath: 'Output/extra_dim', paramPath: 'output_layer/extra_dim' });\r\n    if (!utils_1.isTensor3D(extra_dim)) {\r\n        throw new Error(\"expected weightMap['Output/extra_dim'] to be a Tensor3D, instead have \" + extra_dim);\r\n    }\r\n    var params = {\r\n        mobilenetv1: extractMobilenetV1Params(),\r\n        prediction_layer: extractPredictionLayerParams(),\r\n        output_layer: {\r\n            extra_dim: extra_dim\r\n        }\r\n    };\r\n    common_1.disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\nexports.extractParamsFromWeigthMap = extractParamsFromWeigthMap;\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/index.js":
/*!*************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/index.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar SsdMobilenetv1_1 = __webpack_require__(/*! ./SsdMobilenetv1 */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./SsdMobilenetv1 */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./SsdMobilenetv1Options */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/SsdMobilenetv1Options.js\"), exports);\r\nfunction createSsdMobilenetv1(weights) {\r\n    var net = new SsdMobilenetv1_1.SsdMobilenetv1();\r\n    net.extractWeights(weights);\r\n    return net;\r\n}\r\nexports.createSsdMobilenetv1 = createSsdMobilenetv1;\r\nfunction createFaceDetectionNet(weights) {\r\n    return createSsdMobilenetv1(weights);\r\n}\r\nexports.createFaceDetectionNet = createFaceDetectionNet;\r\n// alias for backward compatibily\r\nvar FaceDetectionNet = /** @class */ (function (_super) {\r\n    tslib_1.__extends(FaceDetectionNet, _super);\r\n    function FaceDetectionNet() {\r\n        return _super !== null && _super.apply(this, arguments) || this;\r\n    }\r\n    return FaceDetectionNet;\r\n}(SsdMobilenetv1_1.SsdMobilenetv1));\r\nexports.FaceDetectionNet = FaceDetectionNet;\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/mobileNetV1.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/mobileNetV1.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar pointwiseConvLayer_1 = __webpack_require__(/*! ./pointwiseConvLayer */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/pointwiseConvLayer.js\");\r\nvar epsilon = 0.0010000000474974513;\r\nfunction depthwiseConvLayer(x, params, strides) {\r\n    return tf.tidy(function () {\r\n        var out = tf.depthwiseConv2d(x, params.filters, strides, 'same');\r\n        out = tf.batchNorm(out, params.batch_norm_mean, params.batch_norm_variance, params.batch_norm_offset, params.batch_norm_scale, epsilon);\r\n        return tf.clipByValue(out, 0, 6);\r\n    });\r\n}\r\nfunction getStridesForLayerIdx(layerIdx) {\r\n    return [2, 4, 6, 12].some(function (idx) { return idx === layerIdx; }) ? [2, 2] : [1, 1];\r\n}\r\nfunction mobileNetV1(x, params) {\r\n    return tf.tidy(function () {\r\n        var conv11 = null;\r\n        var out = pointwiseConvLayer_1.pointwiseConvLayer(x, params.conv_0, [2, 2]);\r\n        var convPairParams = [\r\n            params.conv_1,\r\n            params.conv_2,\r\n            params.conv_3,\r\n            params.conv_4,\r\n            params.conv_5,\r\n            params.conv_6,\r\n            params.conv_7,\r\n            params.conv_8,\r\n            params.conv_9,\r\n            params.conv_10,\r\n            params.conv_11,\r\n            params.conv_12,\r\n            params.conv_13\r\n        ];\r\n        convPairParams.forEach(function (param, i) {\r\n            var layerIdx = i + 1;\r\n            var depthwiseConvStrides = getStridesForLayerIdx(layerIdx);\r\n            out = depthwiseConvLayer(out, param.depthwise_conv, depthwiseConvStrides);\r\n            out = pointwiseConvLayer_1.pointwiseConvLayer(out, param.pointwise_conv, [1, 1]);\r\n            if (layerIdx === 11) {\r\n                conv11 = out;\r\n            }\r\n        });\r\n        if (conv11 === null) {\r\n            throw new Error('mobileNetV1 - output of conv layer 11 is null');\r\n        }\r\n        return {\r\n            out: out,\r\n            conv11: conv11\r\n        };\r\n    });\r\n}\r\nexports.mobileNetV1 = mobileNetV1;\r\n//# sourceMappingURL=mobileNetV1.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/mobileNetV1.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/nonMaxSuppression.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/nonMaxSuppression.js ***!
  \*************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nfunction nonMaxSuppression(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {\r\n    var numBoxes = boxes.shape[0];\r\n    var outputSize = Math.min(maxOutputSize, numBoxes);\r\n    var candidates = scores\r\n        .map(function (score, boxIndex) { return ({ score: score, boxIndex: boxIndex }); })\r\n        .filter(function (c) { return c.score > scoreThreshold; })\r\n        .sort(function (c1, c2) { return c2.score - c1.score; });\r\n    var suppressFunc = function (x) { return x <= iouThreshold ? 1 : 0; };\r\n    var selected = [];\r\n    candidates.forEach(function (c) {\r\n        if (selected.length >= outputSize) {\r\n            return;\r\n        }\r\n        var originalScore = c.score;\r\n        for (var j = selected.length - 1; j >= 0; --j) {\r\n            var iou = IOU(boxes, c.boxIndex, selected[j]);\r\n            if (iou === 0.0) {\r\n                continue;\r\n            }\r\n            c.score *= suppressFunc(iou);\r\n            if (c.score <= scoreThreshold) {\r\n                break;\r\n            }\r\n        }\r\n        if (originalScore === c.score) {\r\n            selected.push(c.boxIndex);\r\n        }\r\n    });\r\n    return selected;\r\n}\r\nexports.nonMaxSuppression = nonMaxSuppression;\r\nfunction IOU(boxes, i, j) {\r\n    var boxesData = boxes.arraySync();\r\n    var yminI = Math.min(boxesData[i][0], boxesData[i][2]);\r\n    var xminI = Math.min(boxesData[i][1], boxesData[i][3]);\r\n    var ymaxI = Math.max(boxesData[i][0], boxesData[i][2]);\r\n    var xmaxI = Math.max(boxesData[i][1], boxesData[i][3]);\r\n    var yminJ = Math.min(boxesData[j][0], boxesData[j][2]);\r\n    var xminJ = Math.min(boxesData[j][1], boxesData[j][3]);\r\n    var ymaxJ = Math.max(boxesData[j][0], boxesData[j][2]);\r\n    var xmaxJ = Math.max(boxesData[j][1], boxesData[j][3]);\r\n    var areaI = (ymaxI - yminI) * (xmaxI - xminI);\r\n    var areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);\r\n    if (areaI <= 0 || areaJ <= 0) {\r\n        return 0.0;\r\n    }\r\n    var intersectionYmin = Math.max(yminI, yminJ);\r\n    var intersectionXmin = Math.max(xminI, xminJ);\r\n    var intersectionYmax = Math.min(ymaxI, ymaxJ);\r\n    var intersectionXmax = Math.min(xmaxI, xmaxJ);\r\n    var intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0.0) *\r\n        Math.max(intersectionXmax - intersectionXmin, 0.0);\r\n    return intersectionArea / (areaI + areaJ - intersectionArea);\r\n}\r\n//# sourceMappingURL=nonMaxSuppression.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/nonMaxSuppression.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/outputLayer.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/outputLayer.js ***!
  \*******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction getCenterCoordinatesAndSizesLayer(x) {\r\n    var vec = tf.unstack(tf.transpose(x, [1, 0]));\r\n    var sizes = [\r\n        tf.sub(vec[2], vec[0]),\r\n        tf.sub(vec[3], vec[1])\r\n    ];\r\n    var centers = [\r\n        tf.add(vec[0], tf.div(sizes[0], tf.scalar(2))),\r\n        tf.add(vec[1], tf.div(sizes[1], tf.scalar(2)))\r\n    ];\r\n    return {\r\n        sizes: sizes,\r\n        centers: centers\r\n    };\r\n}\r\nfunction decodeBoxesLayer(x0, x1) {\r\n    var _a = getCenterCoordinatesAndSizesLayer(x0), sizes = _a.sizes, centers = _a.centers;\r\n    var vec = tf.unstack(tf.transpose(x1, [1, 0]));\r\n    var div0_out = tf.div(tf.mul(tf.exp(tf.div(vec[2], tf.scalar(5))), sizes[0]), tf.scalar(2));\r\n    var add0_out = tf.add(tf.mul(tf.div(vec[0], tf.scalar(10)), sizes[0]), centers[0]);\r\n    var div1_out = tf.div(tf.mul(tf.exp(tf.div(vec[3], tf.scalar(5))), sizes[1]), tf.scalar(2));\r\n    var add1_out = tf.add(tf.mul(tf.div(vec[1], tf.scalar(10)), sizes[1]), centers[1]);\r\n    return tf.transpose(tf.stack([\r\n        tf.sub(add0_out, div0_out),\r\n        tf.sub(add1_out, div1_out),\r\n        tf.add(add0_out, div0_out),\r\n        tf.add(add1_out, div1_out)\r\n    ]), [1, 0]);\r\n}\r\nfunction outputLayer(boxPredictions, classPredictions, params) {\r\n    return tf.tidy(function () {\r\n        var batchSize = boxPredictions.shape[0];\r\n        var boxes = decodeBoxesLayer(tf.reshape(tf.tile(params.extra_dim, [batchSize, 1, 1]), [-1, 4]), tf.reshape(boxPredictions, [-1, 4]));\r\n        boxes = tf.reshape(boxes, [batchSize, (boxes.shape[0] / batchSize), 4]);\r\n        var scoresAndClasses = tf.sigmoid(tf.slice(classPredictions, [0, 0, 1], [-1, -1, -1]));\r\n        var scores = tf.slice(scoresAndClasses, [0, 0, 0], [-1, -1, 1]);\r\n        scores = tf.reshape(scores, [batchSize, scores.shape[1]]);\r\n        var boxesByBatch = tf.unstack(boxes);\r\n        var scoresByBatch = tf.unstack(scores);\r\n        return {\r\n            boxes: boxesByBatch,\r\n            scores: scoresByBatch\r\n        };\r\n    });\r\n}\r\nexports.outputLayer = outputLayer;\r\n//# sourceMappingURL=outputLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/outputLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/pointwiseConvLayer.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/pointwiseConvLayer.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction pointwiseConvLayer(x, params, strides) {\r\n    return tf.tidy(function () {\r\n        var out = tf.conv2d(x, params.filters, strides, 'same');\r\n        out = tf.add(out, params.batch_norm_offset);\r\n        return tf.clipByValue(out, 0, 6);\r\n    });\r\n}\r\nexports.pointwiseConvLayer = pointwiseConvLayer;\r\n//# sourceMappingURL=pointwiseConvLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/pointwiseConvLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/predictionLayer.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/predictionLayer.js ***!
  \***********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar boxPredictionLayer_1 = __webpack_require__(/*! ./boxPredictionLayer */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/boxPredictionLayer.js\");\r\nvar pointwiseConvLayer_1 = __webpack_require__(/*! ./pointwiseConvLayer */ \"./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/pointwiseConvLayer.js\");\r\nfunction predictionLayer(x, conv11, params) {\r\n    return tf.tidy(function () {\r\n        var conv0 = pointwiseConvLayer_1.pointwiseConvLayer(x, params.conv_0, [1, 1]);\r\n        var conv1 = pointwiseConvLayer_1.pointwiseConvLayer(conv0, params.conv_1, [2, 2]);\r\n        var conv2 = pointwiseConvLayer_1.pointwiseConvLayer(conv1, params.conv_2, [1, 1]);\r\n        var conv3 = pointwiseConvLayer_1.pointwiseConvLayer(conv2, params.conv_3, [2, 2]);\r\n        var conv4 = pointwiseConvLayer_1.pointwiseConvLayer(conv3, params.conv_4, [1, 1]);\r\n        var conv5 = pointwiseConvLayer_1.pointwiseConvLayer(conv4, params.conv_5, [2, 2]);\r\n        var conv6 = pointwiseConvLayer_1.pointwiseConvLayer(conv5, params.conv_6, [1, 1]);\r\n        var conv7 = pointwiseConvLayer_1.pointwiseConvLayer(conv6, params.conv_7, [2, 2]);\r\n        var boxPrediction0 = boxPredictionLayer_1.boxPredictionLayer(conv11, params.box_predictor_0);\r\n        var boxPrediction1 = boxPredictionLayer_1.boxPredictionLayer(x, params.box_predictor_1);\r\n        var boxPrediction2 = boxPredictionLayer_1.boxPredictionLayer(conv1, params.box_predictor_2);\r\n        var boxPrediction3 = boxPredictionLayer_1.boxPredictionLayer(conv3, params.box_predictor_3);\r\n        var boxPrediction4 = boxPredictionLayer_1.boxPredictionLayer(conv5, params.box_predictor_4);\r\n        var boxPrediction5 = boxPredictionLayer_1.boxPredictionLayer(conv7, params.box_predictor_5);\r\n        var boxPredictions = tf.concat([\r\n            boxPrediction0.boxPredictionEncoding,\r\n            boxPrediction1.boxPredictionEncoding,\r\n            boxPrediction2.boxPredictionEncoding,\r\n            boxPrediction3.boxPredictionEncoding,\r\n            boxPrediction4.boxPredictionEncoding,\r\n            boxPrediction5.boxPredictionEncoding\r\n        ], 1);\r\n        var classPredictions = tf.concat([\r\n            boxPrediction0.classPrediction,\r\n            boxPrediction1.classPrediction,\r\n            boxPrediction2.classPrediction,\r\n            boxPrediction3.classPrediction,\r\n            boxPrediction4.classPrediction,\r\n            boxPrediction5.classPrediction\r\n        ], 1);\r\n        return {\r\n            boxPredictions: boxPredictions,\r\n            classPredictions: classPredictions\r\n        };\r\n    });\r\n}\r\nexports.predictionLayer = predictionLayer;\r\n//# sourceMappingURL=predictionLayer.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/ssdMobilenetv1/predictionLayer.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetector.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetector.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar TinyYolov2Base_1 = __webpack_require__(/*! ../tinyYolov2/TinyYolov2Base */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2Base.js\");\r\nvar const_1 = __webpack_require__(/*! ./const */ \"./node_modules/face-api.js/build/commonjs/tinyFaceDetector/const.js\");\r\nvar TinyFaceDetector = /** @class */ (function (_super) {\r\n    tslib_1.__extends(TinyFaceDetector, _super);\r\n    function TinyFaceDetector() {\r\n        var _this = this;\r\n        var config = {\r\n            withSeparableConvs: true,\r\n            iouThreshold: const_1.IOU_THRESHOLD,\r\n            classes: ['face'],\r\n            anchors: const_1.BOX_ANCHORS,\r\n            meanRgb: const_1.MEAN_RGB,\r\n            isFirstLayerConv2d: true,\r\n            filterSizes: [3, 16, 32, 64, 128, 256, 512]\r\n        };\r\n        _this = _super.call(this, config) || this;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(TinyFaceDetector.prototype, \"anchors\", {\r\n        get: function () {\r\n            return this.config.anchors;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    TinyFaceDetector.prototype.locateFaces = function (input, forwardParams) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var objectDetections;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.detect(input, forwardParams)];\r\n                    case 1:\r\n                        objectDetections = _a.sent();\r\n                        return [2 /*return*/, objectDetections.map(function (det) { return new classes_1.FaceDetection(det.score, det.relativeBox, { width: det.imageWidth, height: det.imageHeight }); })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyFaceDetector.prototype.getDefaultModelName = function () {\r\n        return 'tiny_face_detector_model';\r\n    };\r\n    TinyFaceDetector.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return _super.prototype.extractParamsFromWeigthMap.call(this, weightMap);\r\n    };\r\n    return TinyFaceDetector;\r\n}(TinyYolov2Base_1.TinyYolov2Base));\r\nexports.TinyFaceDetector = TinyFaceDetector;\r\n//# sourceMappingURL=TinyFaceDetector.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetector.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetectorOptions.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetectorOptions.js ***!
  \*********************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tinyYolov2_1 = __webpack_require__(/*! ../tinyYolov2 */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/index.js\");\r\nvar TinyFaceDetectorOptions = /** @class */ (function (_super) {\r\n    tslib_1.__extends(TinyFaceDetectorOptions, _super);\r\n    function TinyFaceDetectorOptions() {\r\n        var _this = _super !== null && _super.apply(this, arguments) || this;\r\n        _this._name = 'TinyFaceDetectorOptions';\r\n        return _this;\r\n    }\r\n    return TinyFaceDetectorOptions;\r\n}(tinyYolov2_1.TinyYolov2Options));\r\nexports.TinyFaceDetectorOptions = TinyFaceDetectorOptions;\r\n//# sourceMappingURL=TinyFaceDetectorOptions.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetectorOptions.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyFaceDetector/const.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyFaceDetector/const.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nexports.IOU_THRESHOLD = 0.4;\r\nexports.BOX_ANCHORS = [\r\n    new classes_1.Point(1.603231, 2.094468),\r\n    new classes_1.Point(6.041143, 7.080126),\r\n    new classes_1.Point(2.882459, 3.518061),\r\n    new classes_1.Point(4.266906, 5.178857),\r\n    new classes_1.Point(9.041765, 10.66308)\r\n];\r\nexports.MEAN_RGB = [117.001, 114.697, 97.404];\r\n//# sourceMappingURL=const.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyFaceDetector/const.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyFaceDetector/index.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyFaceDetector/index.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar TinyFaceDetector_1 = __webpack_require__(/*! ./TinyFaceDetector */ \"./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetector.js\");\r\ntslib_1.__exportStar(__webpack_require__(/*! ./TinyFaceDetector */ \"./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetector.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./TinyFaceDetectorOptions */ \"./node_modules/face-api.js/build/commonjs/tinyFaceDetector/TinyFaceDetectorOptions.js\"), exports);\r\nfunction createTinyFaceDetector(weights) {\r\n    var net = new TinyFaceDetector_1.TinyFaceDetector();\r\n    net.extractWeights(weights);\r\n    return net;\r\n}\r\nexports.createTinyFaceDetector = createTinyFaceDetector;\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyFaceDetector/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar const_1 = __webpack_require__(/*! ./const */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/const.js\");\r\nvar TinyYolov2Base_1 = __webpack_require__(/*! ./TinyYolov2Base */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2Base.js\");\r\nvar TinyYolov2 = /** @class */ (function (_super) {\r\n    tslib_1.__extends(TinyYolov2, _super);\r\n    function TinyYolov2(withSeparableConvs) {\r\n        if (withSeparableConvs === void 0) { withSeparableConvs = true; }\r\n        var _this = this;\r\n        var config = Object.assign({}, {\r\n            withSeparableConvs: withSeparableConvs,\r\n            iouThreshold: const_1.IOU_THRESHOLD,\r\n            classes: ['face']\r\n        }, withSeparableConvs\r\n            ? {\r\n                anchors: const_1.BOX_ANCHORS_SEPARABLE,\r\n                meanRgb: const_1.MEAN_RGB_SEPARABLE\r\n            }\r\n            : {\r\n                anchors: const_1.BOX_ANCHORS,\r\n                withClassScores: true\r\n            });\r\n        _this = _super.call(this, config) || this;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(TinyYolov2.prototype, \"withSeparableConvs\", {\r\n        get: function () {\r\n            return this.config.withSeparableConvs;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(TinyYolov2.prototype, \"anchors\", {\r\n        get: function () {\r\n            return this.config.anchors;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    TinyYolov2.prototype.locateFaces = function (input, forwardParams) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var objectDetections;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0: return [4 /*yield*/, this.detect(input, forwardParams)];\r\n                    case 1:\r\n                        objectDetections = _a.sent();\r\n                        return [2 /*return*/, objectDetections.map(function (det) { return new classes_1.FaceDetection(det.score, det.relativeBox, { width: det.imageWidth, height: det.imageHeight }); })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyYolov2.prototype.getDefaultModelName = function () {\r\n        return this.withSeparableConvs ? const_1.DEFAULT_MODEL_NAME_SEPARABLE_CONV : const_1.DEFAULT_MODEL_NAME;\r\n    };\r\n    TinyYolov2.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return _super.prototype.extractParamsFromWeigthMap.call(this, weightMap);\r\n    };\r\n    return TinyYolov2;\r\n}(TinyYolov2Base_1.TinyYolov2Base));\r\nexports.TinyYolov2 = TinyYolov2;\r\n//# sourceMappingURL=TinyYolov2.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2Base.js":
/*!******************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2Base.js ***!
  \******************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar BoundingBox_1 = __webpack_require__(/*! ../classes/BoundingBox */ \"./node_modules/face-api.js/build/commonjs/classes/BoundingBox.js\");\r\nvar ObjectDetection_1 = __webpack_require__(/*! ../classes/ObjectDetection */ \"./node_modules/face-api.js/build/commonjs/classes/ObjectDetection.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar NeuralNetwork_1 = __webpack_require__(/*! ../NeuralNetwork */ \"./node_modules/face-api.js/build/commonjs/NeuralNetwork.js\");\r\nvar ops_1 = __webpack_require__(/*! ../ops */ \"./node_modules/face-api.js/build/commonjs/ops/index.js\");\r\nvar nonMaxSuppression_1 = __webpack_require__(/*! ../ops/nonMaxSuppression */ \"./node_modules/face-api.js/build/commonjs/ops/nonMaxSuppression.js\");\r\nvar normalize_1 = __webpack_require__(/*! ../ops/normalize */ \"./node_modules/face-api.js/build/commonjs/ops/normalize.js\");\r\nvar config_1 = __webpack_require__(/*! ./config */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/config.js\");\r\nvar convWithBatchNorm_1 = __webpack_require__(/*! ./convWithBatchNorm */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/convWithBatchNorm.js\");\r\nvar depthwiseSeparableConv_1 = __webpack_require__(/*! ./depthwiseSeparableConv */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/depthwiseSeparableConv.js\");\r\nvar extractParams_1 = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/extractParams.js\");\r\nvar extractParamsFromWeigthMap_1 = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/extractParamsFromWeigthMap.js\");\r\nvar leaky_1 = __webpack_require__(/*! ./leaky */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/leaky.js\");\r\nvar TinyYolov2Options_1 = __webpack_require__(/*! ./TinyYolov2Options */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2Options.js\");\r\nvar TinyYolov2Base = /** @class */ (function (_super) {\r\n    tslib_1.__extends(TinyYolov2Base, _super);\r\n    function TinyYolov2Base(config) {\r\n        var _this = _super.call(this, 'TinyYolov2') || this;\r\n        config_1.validateConfig(config);\r\n        _this._config = config;\r\n        return _this;\r\n    }\r\n    Object.defineProperty(TinyYolov2Base.prototype, \"config\", {\r\n        get: function () {\r\n            return this._config;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(TinyYolov2Base.prototype, \"withClassScores\", {\r\n        get: function () {\r\n            return this.config.withClassScores || this.config.classes.length > 1;\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(TinyYolov2Base.prototype, \"boxEncodingSize\", {\r\n        get: function () {\r\n            return 5 + (this.withClassScores ? this.config.classes.length : 0);\r\n        },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    TinyYolov2Base.prototype.runTinyYolov2 = function (x, params) {\r\n        var out = convWithBatchNorm_1.convWithBatchNorm(x, params.conv0);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = convWithBatchNorm_1.convWithBatchNorm(out, params.conv1);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = convWithBatchNorm_1.convWithBatchNorm(out, params.conv2);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = convWithBatchNorm_1.convWithBatchNorm(out, params.conv3);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = convWithBatchNorm_1.convWithBatchNorm(out, params.conv4);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = convWithBatchNorm_1.convWithBatchNorm(out, params.conv5);\r\n        out = tf.maxPool(out, [2, 2], [1, 1], 'same');\r\n        out = convWithBatchNorm_1.convWithBatchNorm(out, params.conv6);\r\n        out = convWithBatchNorm_1.convWithBatchNorm(out, params.conv7);\r\n        return common_1.convLayer(out, params.conv8, 'valid', false);\r\n    };\r\n    TinyYolov2Base.prototype.runMobilenet = function (x, params) {\r\n        var out = this.config.isFirstLayerConv2d\r\n            ? leaky_1.leaky(common_1.convLayer(x, params.conv0, 'valid', false))\r\n            : depthwiseSeparableConv_1.depthwiseSeparableConv(x, params.conv0);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = depthwiseSeparableConv_1.depthwiseSeparableConv(out, params.conv1);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = depthwiseSeparableConv_1.depthwiseSeparableConv(out, params.conv2);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = depthwiseSeparableConv_1.depthwiseSeparableConv(out, params.conv3);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = depthwiseSeparableConv_1.depthwiseSeparableConv(out, params.conv4);\r\n        out = tf.maxPool(out, [2, 2], [2, 2], 'same');\r\n        out = depthwiseSeparableConv_1.depthwiseSeparableConv(out, params.conv5);\r\n        out = tf.maxPool(out, [2, 2], [1, 1], 'same');\r\n        out = params.conv6 ? depthwiseSeparableConv_1.depthwiseSeparableConv(out, params.conv6) : out;\r\n        out = params.conv7 ? depthwiseSeparableConv_1.depthwiseSeparableConv(out, params.conv7) : out;\r\n        return common_1.convLayer(out, params.conv8, 'valid', false);\r\n    };\r\n    TinyYolov2Base.prototype.forwardInput = function (input, inputSize) {\r\n        var _this = this;\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('TinyYolov2 - load model before inference');\r\n        }\r\n        return tf.tidy(function () {\r\n            var batchTensor = input.toBatchTensor(inputSize, false).toFloat();\r\n            batchTensor = _this.config.meanRgb\r\n                ? normalize_1.normalize(batchTensor, _this.config.meanRgb)\r\n                : batchTensor;\r\n            batchTensor = batchTensor.div(tf.scalar(256));\r\n            return _this.config.withSeparableConvs\r\n                ? _this.runMobilenet(batchTensor, params)\r\n                : _this.runTinyYolov2(batchTensor, params);\r\n        });\r\n    };\r\n    TinyYolov2Base.prototype.forward = function (input, inputSize) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [4 /*yield*/, _a.apply(this, [_b.sent(), inputSize])];\r\n                    case 2: return [2 /*return*/, _b.sent()];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyYolov2Base.prototype.detect = function (input, forwardParams) {\r\n        if (forwardParams === void 0) { forwardParams = {}; }\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a, inputSize, scoreThreshold, netInput, out, out0, inputDimensions, results, boxes, scores, classScores, classNames, indices, detections;\r\n            var _this = this;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = new TinyYolov2Options_1.TinyYolov2Options(forwardParams), inputSize = _a.inputSize, scoreThreshold = _a.scoreThreshold;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1:\r\n                        netInput = _b.sent();\r\n                        return [4 /*yield*/, this.forwardInput(netInput, inputSize)];\r\n                    case 2:\r\n                        out = _b.sent();\r\n                        out0 = tf.tidy(function () { return tf.unstack(out)[0].expandDims(); });\r\n                        inputDimensions = {\r\n                            width: netInput.getInputWidth(0),\r\n                            height: netInput.getInputHeight(0)\r\n                        };\r\n                        return [4 /*yield*/, this.extractBoxes(out0, netInput.getReshapedInputDimensions(0), scoreThreshold)];\r\n                    case 3:\r\n                        results = _b.sent();\r\n                        out.dispose();\r\n                        out0.dispose();\r\n                        boxes = results.map(function (res) { return res.box; });\r\n                        scores = results.map(function (res) { return res.score; });\r\n                        classScores = results.map(function (res) { return res.classScore; });\r\n                        classNames = results.map(function (res) { return _this.config.classes[res.label]; });\r\n                        indices = nonMaxSuppression_1.nonMaxSuppression(boxes.map(function (box) { return box.rescale(inputSize); }), scores, this.config.iouThreshold, true);\r\n                        detections = indices.map(function (idx) {\r\n                            return new ObjectDetection_1.ObjectDetection(scores[idx], classScores[idx], classNames[idx], boxes[idx], inputDimensions);\r\n                        });\r\n                        return [2 /*return*/, detections];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyYolov2Base.prototype.getDefaultModelName = function () {\r\n        return '';\r\n    };\r\n    TinyYolov2Base.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return extractParamsFromWeigthMap_1.extractParamsFromWeigthMap(weightMap, this.config);\r\n    };\r\n    TinyYolov2Base.prototype.extractParams = function (weights) {\r\n        var filterSizes = this.config.filterSizes || TinyYolov2Base.DEFAULT_FILTER_SIZES;\r\n        var numFilters = filterSizes ? filterSizes.length : undefined;\r\n        if (numFilters !== 7 && numFilters !== 8 && numFilters !== 9) {\r\n            throw new Error(\"TinyYolov2 - expected 7 | 8 | 9 convolutional filters, but found \" + numFilters + \" filterSizes in config\");\r\n        }\r\n        return extractParams_1.extractParams(weights, this.config, this.boxEncodingSize, filterSizes);\r\n    };\r\n    TinyYolov2Base.prototype.extractBoxes = function (outputTensor, inputBlobDimensions, scoreThreshold) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var width, height, inputSize, correctionFactorX, correctionFactorY, numCells, numBoxes, _a, boxesTensor, scoresTensor, classScoresTensor, results, scoresData, boxesData, row, col, anchor, score, ctX, ctY, width_1, height_1, x, y, pos, _b, classScore, label, _c;\r\n            var _this = this;\r\n            return tslib_1.__generator(this, function (_d) {\r\n                switch (_d.label) {\r\n                    case 0:\r\n                        width = inputBlobDimensions.width, height = inputBlobDimensions.height;\r\n                        inputSize = Math.max(width, height);\r\n                        correctionFactorX = inputSize / width;\r\n                        correctionFactorY = inputSize / height;\r\n                        numCells = outputTensor.shape[1];\r\n                        numBoxes = this.config.anchors.length;\r\n                        _a = tf.tidy(function () {\r\n                            var reshaped = outputTensor.reshape([numCells, numCells, numBoxes, _this.boxEncodingSize]);\r\n                            var boxes = reshaped.slice([0, 0, 0, 0], [numCells, numCells, numBoxes, 4]);\r\n                            var scores = reshaped.slice([0, 0, 0, 4], [numCells, numCells, numBoxes, 1]);\r\n                            var classScores = _this.withClassScores\r\n                                ? tf.softmax(reshaped.slice([0, 0, 0, 5], [numCells, numCells, numBoxes, _this.config.classes.length]), 3)\r\n                                : tf.scalar(0);\r\n                            return [boxes, scores, classScores];\r\n                        }), boxesTensor = _a[0], scoresTensor = _a[1], classScoresTensor = _a[2];\r\n                        results = [];\r\n                        return [4 /*yield*/, scoresTensor.array()];\r\n                    case 1:\r\n                        scoresData = _d.sent();\r\n                        return [4 /*yield*/, boxesTensor.array()];\r\n                    case 2:\r\n                        boxesData = _d.sent();\r\n                        row = 0;\r\n                        _d.label = 3;\r\n                    case 3:\r\n                        if (!(row < numCells)) return [3 /*break*/, 12];\r\n                        col = 0;\r\n                        _d.label = 4;\r\n                    case 4:\r\n                        if (!(col < numCells)) return [3 /*break*/, 11];\r\n                        anchor = 0;\r\n                        _d.label = 5;\r\n                    case 5:\r\n                        if (!(anchor < numBoxes)) return [3 /*break*/, 10];\r\n                        score = ops_1.sigmoid(scoresData[row][col][anchor][0]);\r\n                        if (!(!scoreThreshold || score > scoreThreshold)) return [3 /*break*/, 9];\r\n                        ctX = ((col + ops_1.sigmoid(boxesData[row][col][anchor][0])) / numCells) * correctionFactorX;\r\n                        ctY = ((row + ops_1.sigmoid(boxesData[row][col][anchor][1])) / numCells) * correctionFactorY;\r\n                        width_1 = ((Math.exp(boxesData[row][col][anchor][2]) * this.config.anchors[anchor].x) / numCells) * correctionFactorX;\r\n                        height_1 = ((Math.exp(boxesData[row][col][anchor][3]) * this.config.anchors[anchor].y) / numCells) * correctionFactorY;\r\n                        x = (ctX - (width_1 / 2));\r\n                        y = (ctY - (height_1 / 2));\r\n                        pos = { row: row, col: col, anchor: anchor };\r\n                        if (!this.withClassScores) return [3 /*break*/, 7];\r\n                        return [4 /*yield*/, this.extractPredictedClass(classScoresTensor, pos)];\r\n                    case 6:\r\n                        _c = _d.sent();\r\n                        return [3 /*break*/, 8];\r\n                    case 7:\r\n                        _c = { classScore: 1, label: 0 };\r\n                        _d.label = 8;\r\n                    case 8:\r\n                        _b = _c, classScore = _b.classScore, label = _b.label;\r\n                        results.push(tslib_1.__assign({ box: new BoundingBox_1.BoundingBox(x, y, x + width_1, y + height_1), score: score, classScore: score * classScore, label: label }, pos));\r\n                        _d.label = 9;\r\n                    case 9:\r\n                        anchor++;\r\n                        return [3 /*break*/, 5];\r\n                    case 10:\r\n                        col++;\r\n                        return [3 /*break*/, 4];\r\n                    case 11:\r\n                        row++;\r\n                        return [3 /*break*/, 3];\r\n                    case 12:\r\n                        boxesTensor.dispose();\r\n                        scoresTensor.dispose();\r\n                        classScoresTensor.dispose();\r\n                        return [2 /*return*/, results];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyYolov2Base.prototype.extractPredictedClass = function (classesTensor, pos) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var row, col, anchor, classesData;\r\n            return tslib_1.__generator(this, function (_a) {\r\n                switch (_a.label) {\r\n                    case 0:\r\n                        row = pos.row, col = pos.col, anchor = pos.anchor;\r\n                        return [4 /*yield*/, classesTensor.array()];\r\n                    case 1:\r\n                        classesData = _a.sent();\r\n                        return [2 /*return*/, Array(this.config.classes.length).fill(0)\r\n                                .map(function (_, i) { return classesData[row][col][anchor][i]; })\r\n                                .map(function (classScore, label) { return ({\r\n                                classScore: classScore,\r\n                                label: label\r\n                            }); })\r\n                                .reduce(function (max, curr) { return max.classScore > curr.classScore ? max : curr; })];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyYolov2Base.DEFAULT_FILTER_SIZES = [\r\n        3, 16, 32, 64, 128, 256, 512, 1024, 1024\r\n    ];\r\n    return TinyYolov2Base;\r\n}(NeuralNetwork_1.NeuralNetwork));\r\nexports.TinyYolov2Base = TinyYolov2Base;\r\n//# sourceMappingURL=TinyYolov2Base.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2Base.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2Options.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2Options.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar TinyYolov2SizeType;\r\n(function (TinyYolov2SizeType) {\r\n    TinyYolov2SizeType[TinyYolov2SizeType[\"XS\"] = 224] = \"XS\";\r\n    TinyYolov2SizeType[TinyYolov2SizeType[\"SM\"] = 320] = \"SM\";\r\n    TinyYolov2SizeType[TinyYolov2SizeType[\"MD\"] = 416] = \"MD\";\r\n    TinyYolov2SizeType[TinyYolov2SizeType[\"LG\"] = 608] = \"LG\";\r\n})(TinyYolov2SizeType = exports.TinyYolov2SizeType || (exports.TinyYolov2SizeType = {}));\r\nvar TinyYolov2Options = /** @class */ (function () {\r\n    function TinyYolov2Options(_a) {\r\n        var _b = _a === void 0 ? {} : _a, inputSize = _b.inputSize, scoreThreshold = _b.scoreThreshold;\r\n        this._name = 'TinyYolov2Options';\r\n        this._inputSize = inputSize || 416;\r\n        this._scoreThreshold = scoreThreshold || 0.5;\r\n        if (typeof this._inputSize !== 'number' || this._inputSize % 32 !== 0) {\r\n            throw new Error(this._name + \" - expected inputSize to be a number divisible by 32\");\r\n        }\r\n        if (typeof this._scoreThreshold !== 'number' || this._scoreThreshold <= 0 || this._scoreThreshold >= 1) {\r\n            throw new Error(this._name + \" - expected scoreThreshold to be a number between 0 and 1\");\r\n        }\r\n    }\r\n    Object.defineProperty(TinyYolov2Options.prototype, \"inputSize\", {\r\n        get: function () { return this._inputSize; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    Object.defineProperty(TinyYolov2Options.prototype, \"scoreThreshold\", {\r\n        get: function () { return this._scoreThreshold; },\r\n        enumerable: true,\r\n        configurable: true\r\n    });\r\n    return TinyYolov2Options;\r\n}());\r\nexports.TinyYolov2Options = TinyYolov2Options;\r\n//# sourceMappingURL=TinyYolov2Options.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2Options.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/config.js":
/*!**********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/config.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar isNumber = function (arg) { return typeof arg === 'number'; };\r\nfunction validateConfig(config) {\r\n    if (!config) {\r\n        throw new Error(\"invalid config: \" + config);\r\n    }\r\n    if (typeof config.withSeparableConvs !== 'boolean') {\r\n        throw new Error(\"config.withSeparableConvs has to be a boolean, have: \" + config.withSeparableConvs);\r\n    }\r\n    if (!isNumber(config.iouThreshold) || config.iouThreshold < 0 || config.iouThreshold > 1.0) {\r\n        throw new Error(\"config.iouThreshold has to be a number between [0, 1], have: \" + config.iouThreshold);\r\n    }\r\n    if (!Array.isArray(config.classes)\r\n        || !config.classes.length\r\n        || !config.classes.every(function (c) { return typeof c === 'string'; })) {\r\n        throw new Error(\"config.classes has to be an array class names: string[], have: \" + JSON.stringify(config.classes));\r\n    }\r\n    if (!Array.isArray(config.anchors)\r\n        || !config.anchors.length\r\n        || !config.anchors.map(function (a) { return a || {}; }).every(function (a) { return isNumber(a.x) && isNumber(a.y); })) {\r\n        throw new Error(\"config.anchors has to be an array of { x: number, y: number }, have: \" + JSON.stringify(config.anchors));\r\n    }\r\n    if (config.meanRgb && (!Array.isArray(config.meanRgb)\r\n        || config.meanRgb.length !== 3\r\n        || !config.meanRgb.every(isNumber))) {\r\n        throw new Error(\"config.meanRgb has to be an array of shape [number, number, number], have: \" + JSON.stringify(config.meanRgb));\r\n    }\r\n}\r\nexports.validateConfig = validateConfig;\r\n//# sourceMappingURL=config.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/config.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/const.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/const.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nexports.IOU_THRESHOLD = 0.4;\r\nexports.BOX_ANCHORS = [\r\n    new classes_1.Point(0.738768, 0.874946),\r\n    new classes_1.Point(2.42204, 2.65704),\r\n    new classes_1.Point(4.30971, 7.04493),\r\n    new classes_1.Point(10.246, 4.59428),\r\n    new classes_1.Point(12.6868, 11.8741)\r\n];\r\nexports.BOX_ANCHORS_SEPARABLE = [\r\n    new classes_1.Point(1.603231, 2.094468),\r\n    new classes_1.Point(6.041143, 7.080126),\r\n    new classes_1.Point(2.882459, 3.518061),\r\n    new classes_1.Point(4.266906, 5.178857),\r\n    new classes_1.Point(9.041765, 10.66308)\r\n];\r\nexports.MEAN_RGB_SEPARABLE = [117.001, 114.697, 97.404];\r\nexports.DEFAULT_MODEL_NAME = 'tiny_yolov2_model';\r\nexports.DEFAULT_MODEL_NAME_SEPARABLE_CONV = 'tiny_yolov2_separable_conv_model';\r\n//# sourceMappingURL=const.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/const.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/convWithBatchNorm.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/convWithBatchNorm.js ***!
  \*********************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar leaky_1 = __webpack_require__(/*! ./leaky */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/leaky.js\");\r\nfunction convWithBatchNorm(x, params) {\r\n    return tf.tidy(function () {\r\n        var out = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]]);\r\n        out = tf.conv2d(out, params.conv.filters, [1, 1], 'valid');\r\n        out = tf.sub(out, params.bn.sub);\r\n        out = tf.mul(out, params.bn.truediv);\r\n        out = tf.add(out, params.conv.bias);\r\n        return leaky_1.leaky(out);\r\n    });\r\n}\r\nexports.convWithBatchNorm = convWithBatchNorm;\r\n//# sourceMappingURL=convWithBatchNorm.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/convWithBatchNorm.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/depthwiseSeparableConv.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/depthwiseSeparableConv.js ***!
  \**************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar leaky_1 = __webpack_require__(/*! ./leaky */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/leaky.js\");\r\nfunction depthwiseSeparableConv(x, params) {\r\n    return tf.tidy(function () {\r\n        var out = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]]);\r\n        out = tf.separableConv2d(out, params.depthwise_filter, params.pointwise_filter, [1, 1], 'valid');\r\n        out = tf.add(out, params.bias);\r\n        return leaky_1.leaky(out);\r\n    });\r\n}\r\nexports.depthwiseSeparableConv = depthwiseSeparableConv;\r\n//# sourceMappingURL=depthwiseSeparableConv.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/depthwiseSeparableConv.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/extractParams.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/extractParams.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar extractSeparableConvParamsFactory_1 = __webpack_require__(/*! ../common/extractSeparableConvParamsFactory */ \"./node_modules/face-api.js/build/commonjs/common/extractSeparableConvParamsFactory.js\");\r\nvar extractWeightsFactory_1 = __webpack_require__(/*! ../common/extractWeightsFactory */ \"./node_modules/face-api.js/build/commonjs/common/extractWeightsFactory.js\");\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    var extractConvParams = common_1.extractConvParamsFactory(extractWeights, paramMappings);\r\n    function extractBatchNormParams(size, mappedPrefix) {\r\n        var sub = tf.tensor1d(extractWeights(size));\r\n        var truediv = tf.tensor1d(extractWeights(size));\r\n        paramMappings.push({ paramPath: mappedPrefix + \"/sub\" }, { paramPath: mappedPrefix + \"/truediv\" });\r\n        return { sub: sub, truediv: truediv };\r\n    }\r\n    function extractConvWithBatchNormParams(channelsIn, channelsOut, mappedPrefix) {\r\n        var conv = extractConvParams(channelsIn, channelsOut, 3, mappedPrefix + \"/conv\");\r\n        var bn = extractBatchNormParams(channelsOut, mappedPrefix + \"/bn\");\r\n        return { conv: conv, bn: bn };\r\n    }\r\n    var extractSeparableConvParams = extractSeparableConvParamsFactory_1.extractSeparableConvParamsFactory(extractWeights, paramMappings);\r\n    return {\r\n        extractConvParams: extractConvParams,\r\n        extractConvWithBatchNormParams: extractConvWithBatchNormParams,\r\n        extractSeparableConvParams: extractSeparableConvParams\r\n    };\r\n}\r\nfunction extractParams(weights, config, boxEncodingSize, filterSizes) {\r\n    var _a = extractWeightsFactory_1.extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var paramMappings = [];\r\n    var _b = extractorsFactory(extractWeights, paramMappings), extractConvParams = _b.extractConvParams, extractConvWithBatchNormParams = _b.extractConvWithBatchNormParams, extractSeparableConvParams = _b.extractSeparableConvParams;\r\n    var params;\r\n    if (config.withSeparableConvs) {\r\n        var s0 = filterSizes[0], s1 = filterSizes[1], s2 = filterSizes[2], s3 = filterSizes[3], s4 = filterSizes[4], s5 = filterSizes[5], s6 = filterSizes[6], s7 = filterSizes[7], s8 = filterSizes[8];\r\n        var conv0 = config.isFirstLayerConv2d\r\n            ? extractConvParams(s0, s1, 3, 'conv0')\r\n            : extractSeparableConvParams(s0, s1, 'conv0');\r\n        var conv1 = extractSeparableConvParams(s1, s2, 'conv1');\r\n        var conv2 = extractSeparableConvParams(s2, s3, 'conv2');\r\n        var conv3 = extractSeparableConvParams(s3, s4, 'conv3');\r\n        var conv4 = extractSeparableConvParams(s4, s5, 'conv4');\r\n        var conv5 = extractSeparableConvParams(s5, s6, 'conv5');\r\n        var conv6 = s7 ? extractSeparableConvParams(s6, s7, 'conv6') : undefined;\r\n        var conv7 = s8 ? extractSeparableConvParams(s7, s8, 'conv7') : undefined;\r\n        var conv8 = extractConvParams(s8 || s7 || s6, 5 * boxEncodingSize, 1, 'conv8');\r\n        params = { conv0: conv0, conv1: conv1, conv2: conv2, conv3: conv3, conv4: conv4, conv5: conv5, conv6: conv6, conv7: conv7, conv8: conv8 };\r\n    }\r\n    else {\r\n        var s0 = filterSizes[0], s1 = filterSizes[1], s2 = filterSizes[2], s3 = filterSizes[3], s4 = filterSizes[4], s5 = filterSizes[5], s6 = filterSizes[6], s7 = filterSizes[7], s8 = filterSizes[8];\r\n        var conv0 = extractConvWithBatchNormParams(s0, s1, 'conv0');\r\n        var conv1 = extractConvWithBatchNormParams(s1, s2, 'conv1');\r\n        var conv2 = extractConvWithBatchNormParams(s2, s3, 'conv2');\r\n        var conv3 = extractConvWithBatchNormParams(s3, s4, 'conv3');\r\n        var conv4 = extractConvWithBatchNormParams(s4, s5, 'conv4');\r\n        var conv5 = extractConvWithBatchNormParams(s5, s6, 'conv5');\r\n        var conv6 = extractConvWithBatchNormParams(s6, s7, 'conv6');\r\n        var conv7 = extractConvWithBatchNormParams(s7, s8, 'conv7');\r\n        var conv8 = extractConvParams(s8, 5 * boxEncodingSize, 1, 'conv8');\r\n        params = { conv0: conv0, conv1: conv1, conv2: conv2, conv3: conv3, conv4: conv4, conv5: conv5, conv6: conv6, conv7: conv7, conv8: conv8 };\r\n    }\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\nexports.extractParams = extractParams;\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/extractParamsFromWeigthMap.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/extractParamsFromWeigthMap.js ***!
  \******************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar disposeUnusedWeightTensors_1 = __webpack_require__(/*! ../common/disposeUnusedWeightTensors */ \"./node_modules/face-api.js/build/commonjs/common/disposeUnusedWeightTensors.js\");\r\nvar extractSeparableConvParamsFactory_1 = __webpack_require__(/*! ../common/extractSeparableConvParamsFactory */ \"./node_modules/face-api.js/build/commonjs/common/extractSeparableConvParamsFactory.js\");\r\nvar extractWeightEntryFactory_1 = __webpack_require__(/*! ../common/extractWeightEntryFactory */ \"./node_modules/face-api.js/build/commonjs/common/extractWeightEntryFactory.js\");\r\nfunction extractorsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = extractWeightEntryFactory_1.extractWeightEntryFactory(weightMap, paramMappings);\r\n    function extractBatchNormParams(prefix) {\r\n        var sub = extractWeightEntry(prefix + \"/sub\", 1);\r\n        var truediv = extractWeightEntry(prefix + \"/truediv\", 1);\r\n        return { sub: sub, truediv: truediv };\r\n    }\r\n    function extractConvParams(prefix) {\r\n        var filters = extractWeightEntry(prefix + \"/filters\", 4);\r\n        var bias = extractWeightEntry(prefix + \"/bias\", 1);\r\n        return { filters: filters, bias: bias };\r\n    }\r\n    function extractConvWithBatchNormParams(prefix) {\r\n        var conv = extractConvParams(prefix + \"/conv\");\r\n        var bn = extractBatchNormParams(prefix + \"/bn\");\r\n        return { conv: conv, bn: bn };\r\n    }\r\n    var extractSeparableConvParams = extractSeparableConvParamsFactory_1.loadSeparableConvParamsFactory(extractWeightEntry);\r\n    return {\r\n        extractConvParams: extractConvParams,\r\n        extractConvWithBatchNormParams: extractConvWithBatchNormParams,\r\n        extractSeparableConvParams: extractSeparableConvParams\r\n    };\r\n}\r\nfunction extractParamsFromWeigthMap(weightMap, config) {\r\n    var paramMappings = [];\r\n    var _a = extractorsFactory(weightMap, paramMappings), extractConvParams = _a.extractConvParams, extractConvWithBatchNormParams = _a.extractConvWithBatchNormParams, extractSeparableConvParams = _a.extractSeparableConvParams;\r\n    var params;\r\n    if (config.withSeparableConvs) {\r\n        var numFilters = (config.filterSizes && config.filterSizes.length || 9);\r\n        params = {\r\n            conv0: config.isFirstLayerConv2d ? extractConvParams('conv0') : extractSeparableConvParams('conv0'),\r\n            conv1: extractSeparableConvParams('conv1'),\r\n            conv2: extractSeparableConvParams('conv2'),\r\n            conv3: extractSeparableConvParams('conv3'),\r\n            conv4: extractSeparableConvParams('conv4'),\r\n            conv5: extractSeparableConvParams('conv5'),\r\n            conv6: numFilters > 7 ? extractSeparableConvParams('conv6') : undefined,\r\n            conv7: numFilters > 8 ? extractSeparableConvParams('conv7') : undefined,\r\n            conv8: extractConvParams('conv8')\r\n        };\r\n    }\r\n    else {\r\n        params = {\r\n            conv0: extractConvWithBatchNormParams('conv0'),\r\n            conv1: extractConvWithBatchNormParams('conv1'),\r\n            conv2: extractConvWithBatchNormParams('conv2'),\r\n            conv3: extractConvWithBatchNormParams('conv3'),\r\n            conv4: extractConvWithBatchNormParams('conv4'),\r\n            conv5: extractConvWithBatchNormParams('conv5'),\r\n            conv6: extractConvWithBatchNormParams('conv6'),\r\n            conv7: extractConvWithBatchNormParams('conv7'),\r\n            conv8: extractConvParams('conv8')\r\n        };\r\n    }\r\n    disposeUnusedWeightTensors_1.disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: params, paramMappings: paramMappings };\r\n}\r\nexports.extractParamsFromWeigthMap = extractParamsFromWeigthMap;\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/index.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/index.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar TinyYolov2_1 = __webpack_require__(/*! ./TinyYolov2 */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2.js\");\r\nexports.TinyYolov2 = TinyYolov2_1.TinyYolov2;\r\ntslib_1.__exportStar(__webpack_require__(/*! ./TinyYolov2Options */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/TinyYolov2Options.js\"), exports);\r\ntslib_1.__exportStar(__webpack_require__(/*! ./config */ \"./node_modules/face-api.js/build/commonjs/tinyYolov2/config.js\"), exports);\r\nfunction createTinyYolov2(weights, withSeparableConvs) {\r\n    if (withSeparableConvs === void 0) { withSeparableConvs = true; }\r\n    var net = new TinyYolov2_1.TinyYolov2(withSeparableConvs);\r\n    net.extractWeights(weights);\r\n    return net;\r\n}\r\nexports.createTinyYolov2 = createTinyYolov2;\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/tinyYolov2/leaky.js":
/*!*********************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/tinyYolov2/leaky.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nfunction leaky(x) {\r\n    return tf.tidy(function () {\r\n        var min = tf.mul(x, tf.scalar(0.10000000149011612));\r\n        return tf.add(tf.relu(tf.sub(x, min)), min);\r\n        //return tf.maximum(x, min)\r\n    });\r\n}\r\nexports.leaky = leaky;\r\n//# sourceMappingURL=leaky.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/tinyYolov2/leaky.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/utils/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/utils/index.js ***!
  \****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar classes_1 = __webpack_require__(/*! ../classes */ \"./node_modules/face-api.js/build/commonjs/classes/index.js\");\r\nvar Dimensions_1 = __webpack_require__(/*! ../classes/Dimensions */ \"./node_modules/face-api.js/build/commonjs/classes/Dimensions.js\");\r\nfunction isTensor(tensor, dim) {\r\n    return tensor instanceof tf.Tensor && tensor.shape.length === dim;\r\n}\r\nexports.isTensor = isTensor;\r\nfunction isTensor1D(tensor) {\r\n    return isTensor(tensor, 1);\r\n}\r\nexports.isTensor1D = isTensor1D;\r\nfunction isTensor2D(tensor) {\r\n    return isTensor(tensor, 2);\r\n}\r\nexports.isTensor2D = isTensor2D;\r\nfunction isTensor3D(tensor) {\r\n    return isTensor(tensor, 3);\r\n}\r\nexports.isTensor3D = isTensor3D;\r\nfunction isTensor4D(tensor) {\r\n    return isTensor(tensor, 4);\r\n}\r\nexports.isTensor4D = isTensor4D;\r\nfunction isFloat(num) {\r\n    return num % 1 !== 0;\r\n}\r\nexports.isFloat = isFloat;\r\nfunction isEven(num) {\r\n    return num % 2 === 0;\r\n}\r\nexports.isEven = isEven;\r\nfunction round(num, prec) {\r\n    if (prec === void 0) { prec = 2; }\r\n    var f = Math.pow(10, prec);\r\n    return Math.floor(num * f) / f;\r\n}\r\nexports.round = round;\r\nfunction isDimensions(obj) {\r\n    return obj && obj.width && obj.height;\r\n}\r\nexports.isDimensions = isDimensions;\r\nfunction computeReshapedDimensions(_a, inputSize) {\r\n    var width = _a.width, height = _a.height;\r\n    var scale = inputSize / Math.max(height, width);\r\n    return new Dimensions_1.Dimensions(Math.round(width * scale), Math.round(height * scale));\r\n}\r\nexports.computeReshapedDimensions = computeReshapedDimensions;\r\nfunction getCenterPoint(pts) {\r\n    return pts.reduce(function (sum, pt) { return sum.add(pt); }, new classes_1.Point(0, 0))\r\n        .div(new classes_1.Point(pts.length, pts.length));\r\n}\r\nexports.getCenterPoint = getCenterPoint;\r\nfunction range(num, start, step) {\r\n    return Array(num).fill(0).map(function (_, i) { return start + (i * step); });\r\n}\r\nexports.range = range;\r\nfunction isValidNumber(num) {\r\n    return !!num && num !== Infinity && num !== -Infinity && !isNaN(num) || num === 0;\r\n}\r\nexports.isValidNumber = isValidNumber;\r\nfunction isValidProbablitiy(num) {\r\n    return isValidNumber(num) && 0 <= num && num <= 1.0;\r\n}\r\nexports.isValidProbablitiy = isValidProbablitiy;\r\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/utils/index.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/xception/TinyXception.js":
/*!**************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/xception/TinyXception.js ***!
  \**************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar tslib_1 = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.js\");\r\nvar tf = __webpack_require__(/*! @tensorflow/tfjs-core */ \"./node_modules/@tensorflow/tfjs-core/dist/index.js\");\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar dom_1 = __webpack_require__(/*! ../dom */ \"./node_modules/face-api.js/build/commonjs/dom/index.js\");\r\nvar NeuralNetwork_1 = __webpack_require__(/*! ../NeuralNetwork */ \"./node_modules/face-api.js/build/commonjs/NeuralNetwork.js\");\r\nvar ops_1 = __webpack_require__(/*! ../ops */ \"./node_modules/face-api.js/build/commonjs/ops/index.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nvar extractParams_1 = __webpack_require__(/*! ./extractParams */ \"./node_modules/face-api.js/build/commonjs/xception/extractParams.js\");\r\nvar extractParamsFromWeigthMap_1 = __webpack_require__(/*! ./extractParamsFromWeigthMap */ \"./node_modules/face-api.js/build/commonjs/xception/extractParamsFromWeigthMap.js\");\r\nfunction conv(x, params, stride) {\r\n    return tf.add(tf.conv2d(x, params.filters, stride, 'same'), params.bias);\r\n}\r\nfunction reductionBlock(x, params, isActivateInput) {\r\n    if (isActivateInput === void 0) { isActivateInput = true; }\r\n    var out = isActivateInput ? tf.relu(x) : x;\r\n    out = common_1.depthwiseSeparableConv(out, params.separable_conv0, [1, 1]);\r\n    out = common_1.depthwiseSeparableConv(tf.relu(out), params.separable_conv1, [1, 1]);\r\n    out = tf.maxPool(out, [3, 3], [2, 2], 'same');\r\n    out = tf.add(out, conv(x, params.expansion_conv, [2, 2]));\r\n    return out;\r\n}\r\nfunction mainBlock(x, params) {\r\n    var out = common_1.depthwiseSeparableConv(tf.relu(x), params.separable_conv0, [1, 1]);\r\n    out = common_1.depthwiseSeparableConv(tf.relu(out), params.separable_conv1, [1, 1]);\r\n    out = common_1.depthwiseSeparableConv(tf.relu(out), params.separable_conv2, [1, 1]);\r\n    out = tf.add(out, x);\r\n    return out;\r\n}\r\nvar TinyXception = /** @class */ (function (_super) {\r\n    tslib_1.__extends(TinyXception, _super);\r\n    function TinyXception(numMainBlocks) {\r\n        var _this = _super.call(this, 'TinyXception') || this;\r\n        _this._numMainBlocks = numMainBlocks;\r\n        return _this;\r\n    }\r\n    TinyXception.prototype.forwardInput = function (input) {\r\n        var _this = this;\r\n        var params = this.params;\r\n        if (!params) {\r\n            throw new Error('TinyXception - load model before inference');\r\n        }\r\n        return tf.tidy(function () {\r\n            var batchTensor = input.toBatchTensor(112, true);\r\n            var meanRgb = [122.782, 117.001, 104.298];\r\n            var normalized = ops_1.normalize(batchTensor, meanRgb).div(tf.scalar(256));\r\n            var out = tf.relu(conv(normalized, params.entry_flow.conv_in, [2, 2]));\r\n            out = reductionBlock(out, params.entry_flow.reduction_block_0, false);\r\n            out = reductionBlock(out, params.entry_flow.reduction_block_1);\r\n            utils_1.range(_this._numMainBlocks, 0, 1).forEach(function (idx) {\r\n                out = mainBlock(out, params.middle_flow[\"main_block_\" + idx]);\r\n            });\r\n            out = reductionBlock(out, params.exit_flow.reduction_block);\r\n            out = tf.relu(common_1.depthwiseSeparableConv(out, params.exit_flow.separable_conv, [1, 1]));\r\n            return out;\r\n        });\r\n    };\r\n    TinyXception.prototype.forward = function (input) {\r\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\r\n            var _a;\r\n            return tslib_1.__generator(this, function (_b) {\r\n                switch (_b.label) {\r\n                    case 0:\r\n                        _a = this.forwardInput;\r\n                        return [4 /*yield*/, dom_1.toNetInput(input)];\r\n                    case 1: return [2 /*return*/, _a.apply(this, [_b.sent()])];\r\n                }\r\n            });\r\n        });\r\n    };\r\n    TinyXception.prototype.getDefaultModelName = function () {\r\n        return 'tiny_xception_model';\r\n    };\r\n    TinyXception.prototype.extractParamsFromWeigthMap = function (weightMap) {\r\n        return extractParamsFromWeigthMap_1.extractParamsFromWeigthMap(weightMap, this._numMainBlocks);\r\n    };\r\n    TinyXception.prototype.extractParams = function (weights) {\r\n        return extractParams_1.extractParams(weights, this._numMainBlocks);\r\n    };\r\n    return TinyXception;\r\n}(NeuralNetwork_1.NeuralNetwork));\r\nexports.TinyXception = TinyXception;\r\n//# sourceMappingURL=TinyXception.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/xception/TinyXception.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/xception/extractParams.js":
/*!***************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/xception/extractParams.js ***!
  \***************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nfunction extractorsFactory(extractWeights, paramMappings) {\r\n    var extractConvParams = common_1.extractConvParamsFactory(extractWeights, paramMappings);\r\n    var extractSeparableConvParams = common_1.extractSeparableConvParamsFactory(extractWeights, paramMappings);\r\n    function extractReductionBlockParams(channelsIn, channelsOut, mappedPrefix) {\r\n        var separable_conv0 = extractSeparableConvParams(channelsIn, channelsOut, mappedPrefix + \"/separable_conv0\");\r\n        var separable_conv1 = extractSeparableConvParams(channelsOut, channelsOut, mappedPrefix + \"/separable_conv1\");\r\n        var expansion_conv = extractConvParams(channelsIn, channelsOut, 1, mappedPrefix + \"/expansion_conv\");\r\n        return { separable_conv0: separable_conv0, separable_conv1: separable_conv1, expansion_conv: expansion_conv };\r\n    }\r\n    function extractMainBlockParams(channels, mappedPrefix) {\r\n        var separable_conv0 = extractSeparableConvParams(channels, channels, mappedPrefix + \"/separable_conv0\");\r\n        var separable_conv1 = extractSeparableConvParams(channels, channels, mappedPrefix + \"/separable_conv1\");\r\n        var separable_conv2 = extractSeparableConvParams(channels, channels, mappedPrefix + \"/separable_conv2\");\r\n        return { separable_conv0: separable_conv0, separable_conv1: separable_conv1, separable_conv2: separable_conv2 };\r\n    }\r\n    return {\r\n        extractConvParams: extractConvParams,\r\n        extractSeparableConvParams: extractSeparableConvParams,\r\n        extractReductionBlockParams: extractReductionBlockParams,\r\n        extractMainBlockParams: extractMainBlockParams\r\n    };\r\n}\r\nfunction extractParams(weights, numMainBlocks) {\r\n    var paramMappings = [];\r\n    var _a = common_1.extractWeightsFactory(weights), extractWeights = _a.extractWeights, getRemainingWeights = _a.getRemainingWeights;\r\n    var _b = extractorsFactory(extractWeights, paramMappings), extractConvParams = _b.extractConvParams, extractSeparableConvParams = _b.extractSeparableConvParams, extractReductionBlockParams = _b.extractReductionBlockParams, extractMainBlockParams = _b.extractMainBlockParams;\r\n    var entry_flow_conv_in = extractConvParams(3, 32, 3, 'entry_flow/conv_in');\r\n    var entry_flow_reduction_block_0 = extractReductionBlockParams(32, 64, 'entry_flow/reduction_block_0');\r\n    var entry_flow_reduction_block_1 = extractReductionBlockParams(64, 128, 'entry_flow/reduction_block_1');\r\n    var entry_flow = {\r\n        conv_in: entry_flow_conv_in,\r\n        reduction_block_0: entry_flow_reduction_block_0,\r\n        reduction_block_1: entry_flow_reduction_block_1\r\n    };\r\n    var middle_flow = {};\r\n    utils_1.range(numMainBlocks, 0, 1).forEach(function (idx) {\r\n        middle_flow[\"main_block_\" + idx] = extractMainBlockParams(128, \"middle_flow/main_block_\" + idx);\r\n    });\r\n    var exit_flow_reduction_block = extractReductionBlockParams(128, 256, 'exit_flow/reduction_block');\r\n    var exit_flow_separable_conv = extractSeparableConvParams(256, 512, 'exit_flow/separable_conv');\r\n    var exit_flow = {\r\n        reduction_block: exit_flow_reduction_block,\r\n        separable_conv: exit_flow_separable_conv\r\n    };\r\n    if (getRemainingWeights().length !== 0) {\r\n        throw new Error(\"weights remaing after extract: \" + getRemainingWeights().length);\r\n    }\r\n    return {\r\n        paramMappings: paramMappings,\r\n        params: { entry_flow: entry_flow, middle_flow: middle_flow, exit_flow: exit_flow }\r\n    };\r\n}\r\nexports.extractParams = extractParams;\r\n//# sourceMappingURL=extractParams.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/xception/extractParams.js?");

/***/ }),

/***/ "./node_modules/face-api.js/build/commonjs/xception/extractParamsFromWeigthMap.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/face-api.js/build/commonjs/xception/extractParamsFromWeigthMap.js ***!
  \****************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nvar common_1 = __webpack_require__(/*! ../common */ \"./node_modules/face-api.js/build/commonjs/common/index.js\");\r\nvar loadConvParamsFactory_1 = __webpack_require__(/*! ../common/loadConvParamsFactory */ \"./node_modules/face-api.js/build/commonjs/common/loadConvParamsFactory.js\");\r\nvar utils_1 = __webpack_require__(/*! ../utils */ \"./node_modules/face-api.js/build/commonjs/utils/index.js\");\r\nfunction loadParamsFactory(weightMap, paramMappings) {\r\n    var extractWeightEntry = common_1.extractWeightEntryFactory(weightMap, paramMappings);\r\n    var extractConvParams = loadConvParamsFactory_1.loadConvParamsFactory(extractWeightEntry);\r\n    var extractSeparableConvParams = common_1.loadSeparableConvParamsFactory(extractWeightEntry);\r\n    function extractReductionBlockParams(mappedPrefix) {\r\n        var separable_conv0 = extractSeparableConvParams(mappedPrefix + \"/separable_conv0\");\r\n        var separable_conv1 = extractSeparableConvParams(mappedPrefix + \"/separable_conv1\");\r\n        var expansion_conv = extractConvParams(mappedPrefix + \"/expansion_conv\");\r\n        return { separable_conv0: separable_conv0, separable_conv1: separable_conv1, expansion_conv: expansion_conv };\r\n    }\r\n    function extractMainBlockParams(mappedPrefix) {\r\n        var separable_conv0 = extractSeparableConvParams(mappedPrefix + \"/separable_conv0\");\r\n        var separable_conv1 = extractSeparableConvParams(mappedPrefix + \"/separable_conv1\");\r\n        var separable_conv2 = extractSeparableConvParams(mappedPrefix + \"/separable_conv2\");\r\n        return { separable_conv0: separable_conv0, separable_conv1: separable_conv1, separable_conv2: separable_conv2 };\r\n    }\r\n    return {\r\n        extractConvParams: extractConvParams,\r\n        extractSeparableConvParams: extractSeparableConvParams,\r\n        extractReductionBlockParams: extractReductionBlockParams,\r\n        extractMainBlockParams: extractMainBlockParams\r\n    };\r\n}\r\nfunction extractParamsFromWeigthMap(weightMap, numMainBlocks) {\r\n    var paramMappings = [];\r\n    var _a = loadParamsFactory(weightMap, paramMappings), extractConvParams = _a.extractConvParams, extractSeparableConvParams = _a.extractSeparableConvParams, extractReductionBlockParams = _a.extractReductionBlockParams, extractMainBlockParams = _a.extractMainBlockParams;\r\n    var entry_flow_conv_in = extractConvParams('entry_flow/conv_in');\r\n    var entry_flow_reduction_block_0 = extractReductionBlockParams('entry_flow/reduction_block_0');\r\n    var entry_flow_reduction_block_1 = extractReductionBlockParams('entry_flow/reduction_block_1');\r\n    var entry_flow = {\r\n        conv_in: entry_flow_conv_in,\r\n        reduction_block_0: entry_flow_reduction_block_0,\r\n        reduction_block_1: entry_flow_reduction_block_1\r\n    };\r\n    var middle_flow = {};\r\n    utils_1.range(numMainBlocks, 0, 1).forEach(function (idx) {\r\n        middle_flow[\"main_block_\" + idx] = extractMainBlockParams(\"middle_flow/main_block_\" + idx);\r\n    });\r\n    var exit_flow_reduction_block = extractReductionBlockParams('exit_flow/reduction_block');\r\n    var exit_flow_separable_conv = extractSeparableConvParams('exit_flow/separable_conv');\r\n    var exit_flow = {\r\n        reduction_block: exit_flow_reduction_block,\r\n        separable_conv: exit_flow_separable_conv\r\n    };\r\n    common_1.disposeUnusedWeightTensors(weightMap, paramMappings);\r\n    return { params: { entry_flow: entry_flow, middle_flow: middle_flow, exit_flow: exit_flow }, paramMappings: paramMappings };\r\n}\r\nexports.extractParamsFromWeigthMap = extractParamsFromWeigthMap;\r\n//# sourceMappingURL=extractParamsFromWeigthMap.js.map\n\n//# sourceURL=webpack:///./node_modules/face-api.js/build/commonjs/xception/extractParamsFromWeigthMap.js?");

/***/ }),

/***/ "./node_modules/https-browserify/index.js":
/*!************************************************!*\
  !*** ./node_modules/https-browserify/index.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var http = __webpack_require__(/*! http */ \"./node_modules/stream-http/index.js\")\nvar url = __webpack_require__(/*! url */ \"./node_modules/url/url.js\")\n\nvar https = module.exports\n\nfor (var key in http) {\n  if (http.hasOwnProperty(key)) https[key] = http[key]\n}\n\nhttps.request = function (params, cb) {\n  params = validateParams(params)\n  return http.request.call(this, params, cb)\n}\n\nhttps.get = function (params, cb) {\n  params = validateParams(params)\n  return http.get.call(this, params, cb)\n}\n\nfunction validateParams (params) {\n  if (typeof params === 'string') {\n    params = url.parse(params)\n  }\n  if (!params.protocol) {\n    params.protocol = 'https:'\n  }\n  if (params.protocol !== 'https:') {\n    throw new Error('Protocol \"' + params.protocol + '\" not supported. Expected \"https:\"')\n  }\n  return params\n}\n\n\n//# sourceURL=webpack:///./node_modules/https-browserify/index.js?");

/***/ }),

/***/ "./node_modules/ieee754/index.js":
/*!***************************************!*\
  !*** ./node_modules/ieee754/index.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("exports.read = function (buffer, offset, isLE, mLen, nBytes) {\n  var e, m\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var nBits = -7\n  var i = isLE ? (nBytes - 1) : 0\n  var d = isLE ? -1 : 1\n  var s = buffer[offset + i]\n\n  i += d\n\n  e = s & ((1 << (-nBits)) - 1)\n  s >>= (-nBits)\n  nBits += eLen\n  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  m = e & ((1 << (-nBits)) - 1)\n  e >>= (-nBits)\n  nBits += mLen\n  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  if (e === 0) {\n    e = 1 - eBias\n  } else if (e === eMax) {\n    return m ? NaN : ((s ? -1 : 1) * Infinity)\n  } else {\n    m = m + Math.pow(2, mLen)\n    e = e - eBias\n  }\n  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)\n}\n\nexports.write = function (buffer, value, offset, isLE, mLen, nBytes) {\n  var e, m, c\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)\n  var i = isLE ? 0 : (nBytes - 1)\n  var d = isLE ? 1 : -1\n  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0\n\n  value = Math.abs(value)\n\n  if (isNaN(value) || value === Infinity) {\n    m = isNaN(value) ? 1 : 0\n    e = eMax\n  } else {\n    e = Math.floor(Math.log(value) / Math.LN2)\n    if (value * (c = Math.pow(2, -e)) < 1) {\n      e--\n      c *= 2\n    }\n    if (e + eBias >= 1) {\n      value += rt / c\n    } else {\n      value += rt * Math.pow(2, 1 - eBias)\n    }\n    if (value * c >= 2) {\n      e++\n      c /= 2\n    }\n\n    if (e + eBias >= eMax) {\n      m = 0\n      e = eMax\n    } else if (e + eBias >= 1) {\n      m = ((value * c) - 1) * Math.pow(2, mLen)\n      e = e + eBias\n    } else {\n      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)\n      e = 0\n    }\n  }\n\n  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}\n\n  e = (e << mLen) | m\n  eLen += mLen\n  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}\n\n  buffer[offset + i - d] |= s * 128\n}\n\n\n//# sourceURL=webpack:///./node_modules/ieee754/index.js?");

/***/ }),

/***/ "./node_modules/inherits/inherits.js":
/*!*******************************************!*\
  !*** ./node_modules/inherits/inherits.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("try {\n  var util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\");\n  /* istanbul ignore next */\n  if (typeof util.inherits !== 'function') throw '';\n  module.exports = util.inherits;\n} catch (e) {\n  /* istanbul ignore next */\n  module.exports = __webpack_require__(/*! ./inherits_browser.js */ \"./node_modules/inherits/inherits_browser.js\");\n}\n\n\n//# sourceURL=webpack:///./node_modules/inherits/inherits.js?");

/***/ }),

/***/ "./node_modules/inherits/inherits_browser.js":
/*!***************************************************!*\
  !*** ./node_modules/inherits/inherits_browser.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n\n\n//# sourceURL=webpack:///./node_modules/inherits/inherits_browser.js?");

/***/ }),

/***/ "./node_modules/isarray/index.js":
/*!***************************************!*\
  !*** ./node_modules/isarray/index.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("var toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n\n\n//# sourceURL=webpack:///./node_modules/isarray/index.js?");

/***/ }),

/***/ "./node_modules/node-fetch/lib/index.js":
/*!**********************************************!*\
  !*** ./node_modules/node-fetch/lib/index.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(Buffer, global) {\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\n// Based on https://github.com/tmpvar/jsdom/blob/aa85b2abf07766ff7bf5c1f6daafb3726f2f2db5/lib/jsdom/living/blob.js\n// (MIT licensed)\n\nconst BUFFER = Symbol('buffer');\nconst TYPE = Symbol('type');\n\nclass Blob {\n\tconstructor() {\n\t\tthis[TYPE] = '';\n\n\t\tconst blobParts = arguments[0];\n\t\tconst options = arguments[1];\n\n\t\tconst buffers = [];\n\n\t\tif (blobParts) {\n\t\t\tconst a = blobParts;\n\t\t\tconst length = Number(a.length);\n\t\t\tfor (let i = 0; i < length; i++) {\n\t\t\t\tconst element = a[i];\n\t\t\t\tlet buffer;\n\t\t\t\tif (element instanceof Buffer) {\n\t\t\t\t\tbuffer = element;\n\t\t\t\t} else if (ArrayBuffer.isView(element)) {\n\t\t\t\t\tbuffer = Buffer.from(element.buffer, element.byteOffset, element.byteLength);\n\t\t\t\t} else if (element instanceof ArrayBuffer) {\n\t\t\t\t\tbuffer = Buffer.from(element);\n\t\t\t\t} else if (element instanceof Blob) {\n\t\t\t\t\tbuffer = element[BUFFER];\n\t\t\t\t} else {\n\t\t\t\t\tbuffer = Buffer.from(typeof element === 'string' ? element : String(element));\n\t\t\t\t}\n\t\t\t\tbuffers.push(buffer);\n\t\t\t}\n\t\t}\n\n\t\tthis[BUFFER] = Buffer.concat(buffers);\n\n\t\tlet type = options && options.type !== undefined && String(options.type).toLowerCase();\n\t\tif (type && !/[^\\u0020-\\u007E]/.test(type)) {\n\t\t\tthis[TYPE] = type;\n\t\t}\n\t}\n\tget size() {\n\t\treturn this[BUFFER].length;\n\t}\n\tget type() {\n\t\treturn this[TYPE];\n\t}\n\tslice() {\n\t\tconst size = this.size;\n\n\t\tconst start = arguments[0];\n\t\tconst end = arguments[1];\n\t\tlet relativeStart, relativeEnd;\n\t\tif (start === undefined) {\n\t\t\trelativeStart = 0;\n\t\t} else if (start < 0) {\n\t\t\trelativeStart = Math.max(size + start, 0);\n\t\t} else {\n\t\t\trelativeStart = Math.min(start, size);\n\t\t}\n\t\tif (end === undefined) {\n\t\t\trelativeEnd = size;\n\t\t} else if (end < 0) {\n\t\t\trelativeEnd = Math.max(size + end, 0);\n\t\t} else {\n\t\t\trelativeEnd = Math.min(end, size);\n\t\t}\n\t\tconst span = Math.max(relativeEnd - relativeStart, 0);\n\n\t\tconst buffer = this[BUFFER];\n\t\tconst slicedBuffer = buffer.slice(relativeStart, relativeStart + span);\n\t\tconst blob = new Blob([], { type: arguments[2] });\n\t\tblob[BUFFER] = slicedBuffer;\n\t\treturn blob;\n\t}\n}\n\nObject.defineProperties(Blob.prototype, {\n\tsize: { enumerable: true },\n\ttype: { enumerable: true },\n\tslice: { enumerable: true }\n});\n\nObject.defineProperty(Blob.prototype, Symbol.toStringTag, {\n\tvalue: 'Blob',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\n/**\n * fetch-error.js\n *\n * FetchError interface for operational errors\n */\n\n/**\n * Create FetchError instance\n *\n * @param   String      message      Error message for human\n * @param   String      type         Error type for machine\n * @param   String      systemError  For Node.js system error\n * @return  FetchError\n */\nfunction FetchError(message, type, systemError) {\n  Error.call(this, message);\n\n  this.message = message;\n  this.type = type;\n\n  // when err.type is `system`, err.code contains system error code\n  if (systemError) {\n    this.code = this.errno = systemError.code;\n  }\n\n  // hide custom error implementation details from end-users\n  Error.captureStackTrace(this, this.constructor);\n}\n\nFetchError.prototype = Object.create(Error.prototype);\nFetchError.prototype.constructor = FetchError;\nFetchError.prototype.name = 'FetchError';\n\n/**\n * body.js\n *\n * Body interface provides common methods for Request and Response\n */\n\nconst Stream = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\");\n\nvar _require = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\");\n\nconst PassThrough = _require.PassThrough;\n\n\nlet convert;\ntry {\n\tconvert = __webpack_require__(!(function webpackMissingModule() { var e = new Error(\"Cannot find module 'encoding'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())).convert;\n} catch (e) {}\n\nconst INTERNALS = Symbol('Body internals');\n\n/**\n * Body mixin\n *\n * Ref: https://fetch.spec.whatwg.org/#body\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nfunction Body(body) {\n\tvar _this = this;\n\n\tvar _ref = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {},\n\t    _ref$size = _ref.size;\n\n\tlet size = _ref$size === undefined ? 0 : _ref$size;\n\tvar _ref$timeout = _ref.timeout;\n\tlet timeout = _ref$timeout === undefined ? 0 : _ref$timeout;\n\n\tif (body == null) {\n\t\t// body is undefined or null\n\t\tbody = null;\n\t} else if (typeof body === 'string') {\n\t\t// body is string\n\t} else if (isURLSearchParams(body)) {\n\t\t// body is a URLSearchParams\n\t} else if (body instanceof Blob) {\n\t\t// body is blob\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// body is buffer\n\t} else if (Object.prototype.toString.call(body) === '[object ArrayBuffer]') {\n\t\t// body is array buffer\n\t} else if (body instanceof Stream) {\n\t\t// body is stream\n\t} else {\n\t\t// none of the above\n\t\t// coerce to string\n\t\tbody = String(body);\n\t}\n\tthis[INTERNALS] = {\n\t\tbody,\n\t\tdisturbed: false,\n\t\terror: null\n\t};\n\tthis.size = size;\n\tthis.timeout = timeout;\n\n\tif (body instanceof Stream) {\n\t\tbody.on('error', function (err) {\n\t\t\t_this[INTERNALS].error = new FetchError(`Invalid response body while trying to fetch ${_this.url}: ${err.message}`, 'system', err);\n\t\t});\n\t}\n}\n\nBody.prototype = {\n\tget body() {\n\t\treturn this[INTERNALS].body;\n\t},\n\n\tget bodyUsed() {\n\t\treturn this[INTERNALS].disturbed;\n\t},\n\n\t/**\n  * Decode response as ArrayBuffer\n  *\n  * @return  Promise\n  */\n\tarrayBuffer() {\n\t\treturn consumeBody.call(this).then(function (buf) {\n\t\t\treturn buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n\t\t});\n\t},\n\n\t/**\n  * Return raw response as Blob\n  *\n  * @return Promise\n  */\n\tblob() {\n\t\tlet ct = this.headers && this.headers.get('content-type') || '';\n\t\treturn consumeBody.call(this).then(function (buf) {\n\t\t\treturn Object.assign(\n\t\t\t// Prevent copying\n\t\t\tnew Blob([], {\n\t\t\t\ttype: ct.toLowerCase()\n\t\t\t}), {\n\t\t\t\t[BUFFER]: buf\n\t\t\t});\n\t\t});\n\t},\n\n\t/**\n  * Decode response as json\n  *\n  * @return  Promise\n  */\n\tjson() {\n\t\tvar _this2 = this;\n\n\t\treturn consumeBody.call(this).then(function (buffer) {\n\t\t\ttry {\n\t\t\t\treturn JSON.parse(buffer.toString());\n\t\t\t} catch (err) {\n\t\t\t\treturn Body.Promise.reject(new FetchError(`invalid json response body at ${_this2.url} reason: ${err.message}`, 'invalid-json'));\n\t\t\t}\n\t\t});\n\t},\n\n\t/**\n  * Decode response as text\n  *\n  * @return  Promise\n  */\n\ttext() {\n\t\treturn consumeBody.call(this).then(function (buffer) {\n\t\t\treturn buffer.toString();\n\t\t});\n\t},\n\n\t/**\n  * Decode response as buffer (non-spec api)\n  *\n  * @return  Promise\n  */\n\tbuffer() {\n\t\treturn consumeBody.call(this);\n\t},\n\n\t/**\n  * Decode response as text, while automatically detecting the encoding and\n  * trying to decode to UTF-8 (non-spec api)\n  *\n  * @return  Promise\n  */\n\ttextConverted() {\n\t\tvar _this3 = this;\n\n\t\treturn consumeBody.call(this).then(function (buffer) {\n\t\t\treturn convertBody(buffer, _this3.headers);\n\t\t});\n\t}\n\n};\n\n// In browsers, all properties are enumerable.\nObject.defineProperties(Body.prototype, {\n\tbody: { enumerable: true },\n\tbodyUsed: { enumerable: true },\n\tarrayBuffer: { enumerable: true },\n\tblob: { enumerable: true },\n\tjson: { enumerable: true },\n\ttext: { enumerable: true }\n});\n\nBody.mixIn = function (proto) {\n\tfor (const name of Object.getOwnPropertyNames(Body.prototype)) {\n\t\t// istanbul ignore else: future proof\n\t\tif (!(name in proto)) {\n\t\t\tconst desc = Object.getOwnPropertyDescriptor(Body.prototype, name);\n\t\t\tObject.defineProperty(proto, name, desc);\n\t\t}\n\t}\n};\n\n/**\n * Consume and convert an entire Body to a Buffer.\n *\n * Ref: https://fetch.spec.whatwg.org/#concept-body-consume-body\n *\n * @return  Promise\n */\nfunction consumeBody() {\n\tvar _this4 = this;\n\n\tif (this[INTERNALS].disturbed) {\n\t\treturn Body.Promise.reject(new TypeError(`body used already for: ${this.url}`));\n\t}\n\n\tthis[INTERNALS].disturbed = true;\n\n\tif (this[INTERNALS].error) {\n\t\treturn Body.Promise.reject(this[INTERNALS].error);\n\t}\n\n\t// body is null\n\tif (this.body === null) {\n\t\treturn Body.Promise.resolve(Buffer.alloc(0));\n\t}\n\n\t// body is string\n\tif (typeof this.body === 'string') {\n\t\treturn Body.Promise.resolve(Buffer.from(this.body));\n\t}\n\n\t// body is blob\n\tif (this.body instanceof Blob) {\n\t\treturn Body.Promise.resolve(this.body[BUFFER]);\n\t}\n\n\t// body is buffer\n\tif (Buffer.isBuffer(this.body)) {\n\t\treturn Body.Promise.resolve(this.body);\n\t}\n\n\t// body is buffer\n\tif (Object.prototype.toString.call(this.body) === '[object ArrayBuffer]') {\n\t\treturn Body.Promise.resolve(Buffer.from(this.body));\n\t}\n\n\t// istanbul ignore if: should never happen\n\tif (!(this.body instanceof Stream)) {\n\t\treturn Body.Promise.resolve(Buffer.alloc(0));\n\t}\n\n\t// body is stream\n\t// get ready to actually consume the body\n\tlet accum = [];\n\tlet accumBytes = 0;\n\tlet abort = false;\n\n\treturn new Body.Promise(function (resolve, reject) {\n\t\tlet resTimeout;\n\n\t\t// allow timeout on slow response body\n\t\tif (_this4.timeout) {\n\t\t\tresTimeout = setTimeout(function () {\n\t\t\t\tabort = true;\n\t\t\t\treject(new FetchError(`Response timeout while trying to fetch ${_this4.url} (over ${_this4.timeout}ms)`, 'body-timeout'));\n\t\t\t}, _this4.timeout);\n\t\t}\n\n\t\t// handle stream error, such as incorrect content-encoding\n\t\t_this4.body.on('error', function (err) {\n\t\t\treject(new FetchError(`Invalid response body while trying to fetch ${_this4.url}: ${err.message}`, 'system', err));\n\t\t});\n\n\t\t_this4.body.on('data', function (chunk) {\n\t\t\tif (abort || chunk === null) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (_this4.size && accumBytes + chunk.length > _this4.size) {\n\t\t\t\tabort = true;\n\t\t\t\treject(new FetchError(`content size at ${_this4.url} over limit: ${_this4.size}`, 'max-size'));\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\taccumBytes += chunk.length;\n\t\t\taccum.push(chunk);\n\t\t});\n\n\t\t_this4.body.on('end', function () {\n\t\t\tif (abort) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tclearTimeout(resTimeout);\n\n\t\t\ttry {\n\t\t\t\tresolve(Buffer.concat(accum));\n\t\t\t} catch (err) {\n\t\t\t\t// handle streams that have accumulated too much data (issue #414)\n\t\t\t\treject(new FetchError(`Could not create Buffer from response body for ${_this4.url}: ${err.message}`, 'system', err));\n\t\t\t}\n\t\t});\n\t});\n}\n\n/**\n * Detect buffer encoding and convert to target encoding\n * ref: http://www.w3.org/TR/2011/WD-html5-20110113/parsing.html#determining-the-character-encoding\n *\n * @param   Buffer  buffer    Incoming buffer\n * @param   String  encoding  Target encoding\n * @return  String\n */\nfunction convertBody(buffer, headers) {\n\tif (typeof convert !== 'function') {\n\t\tthrow new Error('The package `encoding` must be installed to use the textConverted() function');\n\t}\n\n\tconst ct = headers.get('content-type');\n\tlet charset = 'utf-8';\n\tlet res, str;\n\n\t// header\n\tif (ct) {\n\t\tres = /charset=([^;]*)/i.exec(ct);\n\t}\n\n\t// no charset in content type, peek at response body for at most 1024 bytes\n\tstr = buffer.slice(0, 1024).toString();\n\n\t// html5\n\tif (!res && str) {\n\t\tres = /<meta.+?charset=(['\"])(.+?)\\1/i.exec(str);\n\t}\n\n\t// html4\n\tif (!res && str) {\n\t\tres = /<meta[\\s]+?http-equiv=(['\"])content-type\\1[\\s]+?content=(['\"])(.+?)\\2/i.exec(str);\n\n\t\tif (res) {\n\t\t\tres = /charset=(.*)/i.exec(res.pop());\n\t\t}\n\t}\n\n\t// xml\n\tif (!res && str) {\n\t\tres = /<\\?xml.+?encoding=(['\"])(.+?)\\1/i.exec(str);\n\t}\n\n\t// found charset\n\tif (res) {\n\t\tcharset = res.pop();\n\n\t\t// prevent decode issues when sites use incorrect encoding\n\t\t// ref: https://hsivonen.fi/encoding-menu/\n\t\tif (charset === 'gb2312' || charset === 'gbk') {\n\t\t\tcharset = 'gb18030';\n\t\t}\n\t}\n\n\t// turn raw buffers into a single utf-8 buffer\n\treturn convert(buffer, 'UTF-8', charset).toString();\n}\n\n/**\n * Detect a URLSearchParams object\n * ref: https://github.com/bitinn/node-fetch/issues/296#issuecomment-307598143\n *\n * @param   Object  obj     Object to detect by type or brand\n * @return  String\n */\nfunction isURLSearchParams(obj) {\n\t// Duck-typing as a necessary condition.\n\tif (typeof obj !== 'object' || typeof obj.append !== 'function' || typeof obj.delete !== 'function' || typeof obj.get !== 'function' || typeof obj.getAll !== 'function' || typeof obj.has !== 'function' || typeof obj.set !== 'function') {\n\t\treturn false;\n\t}\n\n\t// Brand-checking and more duck-typing as optional condition.\n\treturn obj.constructor.name === 'URLSearchParams' || Object.prototype.toString.call(obj) === '[object URLSearchParams]' || typeof obj.sort === 'function';\n}\n\n/**\n * Clone body given Res/Req instance\n *\n * @param   Mixed  instance  Response or Request instance\n * @return  Mixed\n */\nfunction clone(instance) {\n\tlet p1, p2;\n\tlet body = instance.body;\n\n\t// don't allow cloning a used body\n\tif (instance.bodyUsed) {\n\t\tthrow new Error('cannot clone body after it is used');\n\t}\n\n\t// check that body is a stream and not form-data object\n\t// note: we can't clone the form-data object without having it as a dependency\n\tif (body instanceof Stream && typeof body.getBoundary !== 'function') {\n\t\t// tee instance body\n\t\tp1 = new PassThrough();\n\t\tp2 = new PassThrough();\n\t\tbody.pipe(p1);\n\t\tbody.pipe(p2);\n\t\t// set instance body to teed body and return the other teed body\n\t\tinstance[INTERNALS].body = p1;\n\t\tbody = p2;\n\t}\n\n\treturn body;\n}\n\n/**\n * Performs the operation \"extract a `Content-Type` value from |object|\" as\n * specified in the specification:\n * https://fetch.spec.whatwg.org/#concept-bodyinit-extract\n *\n * This function assumes that instance.body is present.\n *\n * @param   Mixed  instance  Response or Request instance\n */\nfunction extractContentType(instance) {\n\tconst body = instance.body;\n\n\t// istanbul ignore if: Currently, because of a guard in Request, body\n\t// can never be null. Included here for completeness.\n\n\tif (body === null) {\n\t\t// body is null\n\t\treturn null;\n\t} else if (typeof body === 'string') {\n\t\t// body is string\n\t\treturn 'text/plain;charset=UTF-8';\n\t} else if (isURLSearchParams(body)) {\n\t\t// body is a URLSearchParams\n\t\treturn 'application/x-www-form-urlencoded;charset=UTF-8';\n\t} else if (body instanceof Blob) {\n\t\t// body is blob\n\t\treturn body.type || null;\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// body is buffer\n\t\treturn null;\n\t} else if (Object.prototype.toString.call(body) === '[object ArrayBuffer]') {\n\t\t// body is array buffer\n\t\treturn null;\n\t} else if (typeof body.getBoundary === 'function') {\n\t\t// detect form data input from form-data module\n\t\treturn `multipart/form-data;boundary=${body.getBoundary()}`;\n\t} else {\n\t\t// body is stream\n\t\t// can't really do much about this\n\t\treturn null;\n\t}\n}\n\n/**\n * The Fetch Standard treats this as if \"total bytes\" is a property on the body.\n * For us, we have to explicitly get it with a function.\n *\n * ref: https://fetch.spec.whatwg.org/#concept-body-total-bytes\n *\n * @param   Body    instance   Instance of Body\n * @return  Number?            Number of bytes, or null if not possible\n */\nfunction getTotalBytes(instance) {\n\tconst body = instance.body;\n\n\t// istanbul ignore if: included for completion\n\n\tif (body === null) {\n\t\t// body is null\n\t\treturn 0;\n\t} else if (typeof body === 'string') {\n\t\t// body is string\n\t\treturn Buffer.byteLength(body);\n\t} else if (isURLSearchParams(body)) {\n\t\t// body is URLSearchParams\n\t\treturn Buffer.byteLength(String(body));\n\t} else if (body instanceof Blob) {\n\t\t// body is blob\n\t\treturn body.size;\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// body is buffer\n\t\treturn body.length;\n\t} else if (Object.prototype.toString.call(body) === '[object ArrayBuffer]') {\n\t\t// body is array buffer\n\t\treturn body.byteLength;\n\t} else if (body && typeof body.getLengthSync === 'function') {\n\t\t// detect form data input from form-data module\n\t\tif (body._lengthRetrievers && body._lengthRetrievers.length == 0 || // 1.x\n\t\tbody.hasKnownLength && body.hasKnownLength()) {\n\t\t\t// 2.x\n\t\t\treturn body.getLengthSync();\n\t\t}\n\t\treturn null;\n\t} else {\n\t\t// body is stream\n\t\t// can't really do much about this\n\t\treturn null;\n\t}\n}\n\n/**\n * Write a Body to a Node.js WritableStream (e.g. http.Request) object.\n *\n * @param   Body    instance   Instance of Body\n * @return  Void\n */\nfunction writeToStream(dest, instance) {\n\tconst body = instance.body;\n\n\n\tif (body === null) {\n\t\t// body is null\n\t\tdest.end();\n\t} else if (typeof body === 'string') {\n\t\t// body is string\n\t\tdest.write(body);\n\t\tdest.end();\n\t} else if (isURLSearchParams(body)) {\n\t\t// body is URLSearchParams\n\t\tdest.write(Buffer.from(String(body)));\n\t\tdest.end();\n\t} else if (body instanceof Blob) {\n\t\t// body is blob\n\t\tdest.write(body[BUFFER]);\n\t\tdest.end();\n\t} else if (Buffer.isBuffer(body)) {\n\t\t// body is buffer\n\t\tdest.write(body);\n\t\tdest.end();\n\t} else if (Object.prototype.toString.call(body) === '[object ArrayBuffer]') {\n\t\t// body is array buffer\n\t\tdest.write(Buffer.from(body));\n\t\tdest.end();\n\t} else {\n\t\t// body is stream\n\t\tbody.pipe(dest);\n\t}\n}\n\n// expose Promise\nBody.Promise = global.Promise;\n\n/**\n * headers.js\n *\n * Headers class offers convenient helpers\n */\n\nconst invalidTokenRegex = /[^\\^_`a-zA-Z\\-0-9!#$%&'*+.|~]/;\nconst invalidHeaderCharRegex = /[^\\t\\x20-\\x7e\\x80-\\xff]/;\n\nfunction validateName(name) {\n\tname = `${name}`;\n\tif (invalidTokenRegex.test(name)) {\n\t\tthrow new TypeError(`${name} is not a legal HTTP header name`);\n\t}\n}\n\nfunction validateValue(value) {\n\tvalue = `${value}`;\n\tif (invalidHeaderCharRegex.test(value)) {\n\t\tthrow new TypeError(`${value} is not a legal HTTP header value`);\n\t}\n}\n\n/**\n * Find the key in the map object given a header name.\n *\n * Returns undefined if not found.\n *\n * @param   String  name  Header name\n * @return  String|Undefined\n */\nfunction find(map, name) {\n\tname = name.toLowerCase();\n\tfor (const key in map) {\n\t\tif (key.toLowerCase() === name) {\n\t\t\treturn key;\n\t\t}\n\t}\n\treturn undefined;\n}\n\nconst MAP = Symbol('map');\nclass Headers {\n\t/**\n  * Headers class\n  *\n  * @param   Object  headers  Response headers\n  * @return  Void\n  */\n\tconstructor() {\n\t\tlet init = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : undefined;\n\n\t\tthis[MAP] = Object.create(null);\n\n\t\tif (init instanceof Headers) {\n\t\t\tconst rawHeaders = init.raw();\n\t\t\tconst headerNames = Object.keys(rawHeaders);\n\n\t\t\tfor (const headerName of headerNames) {\n\t\t\t\tfor (const value of rawHeaders[headerName]) {\n\t\t\t\t\tthis.append(headerName, value);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn;\n\t\t}\n\n\t\t// We don't worry about converting prop to ByteString here as append()\n\t\t// will handle it.\n\t\tif (init == null) {\n\t\t\t// no op\n\t\t} else if (typeof init === 'object') {\n\t\t\tconst method = init[Symbol.iterator];\n\t\t\tif (method != null) {\n\t\t\t\tif (typeof method !== 'function') {\n\t\t\t\t\tthrow new TypeError('Header pairs must be iterable');\n\t\t\t\t}\n\n\t\t\t\t// sequence<sequence<ByteString>>\n\t\t\t\t// Note: per spec we have to first exhaust the lists then process them\n\t\t\t\tconst pairs = [];\n\t\t\t\tfor (const pair of init) {\n\t\t\t\t\tif (typeof pair !== 'object' || typeof pair[Symbol.iterator] !== 'function') {\n\t\t\t\t\t\tthrow new TypeError('Each header pair must be iterable');\n\t\t\t\t\t}\n\t\t\t\t\tpairs.push(Array.from(pair));\n\t\t\t\t}\n\n\t\t\t\tfor (const pair of pairs) {\n\t\t\t\t\tif (pair.length !== 2) {\n\t\t\t\t\t\tthrow new TypeError('Each header pair must be a name/value tuple');\n\t\t\t\t\t}\n\t\t\t\t\tthis.append(pair[0], pair[1]);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// record<ByteString, ByteString>\n\t\t\t\tfor (const key of Object.keys(init)) {\n\t\t\t\t\tconst value = init[key];\n\t\t\t\t\tthis.append(key, value);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tthrow new TypeError('Provided initializer must be an object');\n\t\t}\n\t}\n\n\t/**\n  * Return combined header value given name\n  *\n  * @param   String  name  Header name\n  * @return  Mixed\n  */\n\tget(name) {\n\t\tname = `${name}`;\n\t\tvalidateName(name);\n\t\tconst key = find(this[MAP], name);\n\t\tif (key === undefined) {\n\t\t\treturn null;\n\t\t}\n\n\t\treturn this[MAP][key].join(', ');\n\t}\n\n\t/**\n  * Iterate over all headers\n  *\n  * @param   Function  callback  Executed for each item with parameters (value, name, thisArg)\n  * @param   Boolean   thisArg   `this` context for callback function\n  * @return  Void\n  */\n\tforEach(callback) {\n\t\tlet thisArg = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : undefined;\n\n\t\tlet pairs = getHeaders(this);\n\t\tlet i = 0;\n\t\twhile (i < pairs.length) {\n\t\t\tvar _pairs$i = pairs[i];\n\t\t\tconst name = _pairs$i[0],\n\t\t\t      value = _pairs$i[1];\n\n\t\t\tcallback.call(thisArg, value, name, this);\n\t\t\tpairs = getHeaders(this);\n\t\t\ti++;\n\t\t}\n\t}\n\n\t/**\n  * Overwrite header values given name\n  *\n  * @param   String  name   Header name\n  * @param   String  value  Header value\n  * @return  Void\n  */\n\tset(name, value) {\n\t\tname = `${name}`;\n\t\tvalue = `${value}`;\n\t\tvalidateName(name);\n\t\tvalidateValue(value);\n\t\tconst key = find(this[MAP], name);\n\t\tthis[MAP][key !== undefined ? key : name] = [value];\n\t}\n\n\t/**\n  * Append a value onto existing header\n  *\n  * @param   String  name   Header name\n  * @param   String  value  Header value\n  * @return  Void\n  */\n\tappend(name, value) {\n\t\tname = `${name}`;\n\t\tvalue = `${value}`;\n\t\tvalidateName(name);\n\t\tvalidateValue(value);\n\t\tconst key = find(this[MAP], name);\n\t\tif (key !== undefined) {\n\t\t\tthis[MAP][key].push(value);\n\t\t} else {\n\t\t\tthis[MAP][name] = [value];\n\t\t}\n\t}\n\n\t/**\n  * Check for header name existence\n  *\n  * @param   String   name  Header name\n  * @return  Boolean\n  */\n\thas(name) {\n\t\tname = `${name}`;\n\t\tvalidateName(name);\n\t\treturn find(this[MAP], name) !== undefined;\n\t}\n\n\t/**\n  * Delete all header values given name\n  *\n  * @param   String  name  Header name\n  * @return  Void\n  */\n\tdelete(name) {\n\t\tname = `${name}`;\n\t\tvalidateName(name);\n\t\tconst key = find(this[MAP], name);\n\t\tif (key !== undefined) {\n\t\t\tdelete this[MAP][key];\n\t\t}\n\t}\n\n\t/**\n  * Return raw headers (non-spec api)\n  *\n  * @return  Object\n  */\n\traw() {\n\t\treturn this[MAP];\n\t}\n\n\t/**\n  * Get an iterator on keys.\n  *\n  * @return  Iterator\n  */\n\tkeys() {\n\t\treturn createHeadersIterator(this, 'key');\n\t}\n\n\t/**\n  * Get an iterator on values.\n  *\n  * @return  Iterator\n  */\n\tvalues() {\n\t\treturn createHeadersIterator(this, 'value');\n\t}\n\n\t/**\n  * Get an iterator on entries.\n  *\n  * This is the default iterator of the Headers object.\n  *\n  * @return  Iterator\n  */\n\t[Symbol.iterator]() {\n\t\treturn createHeadersIterator(this, 'key+value');\n\t}\n}\nHeaders.prototype.entries = Headers.prototype[Symbol.iterator];\n\nObject.defineProperty(Headers.prototype, Symbol.toStringTag, {\n\tvalue: 'Headers',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\nObject.defineProperties(Headers.prototype, {\n\tget: { enumerable: true },\n\tforEach: { enumerable: true },\n\tset: { enumerable: true },\n\tappend: { enumerable: true },\n\thas: { enumerable: true },\n\tdelete: { enumerable: true },\n\tkeys: { enumerable: true },\n\tvalues: { enumerable: true },\n\tentries: { enumerable: true }\n});\n\nfunction getHeaders(headers) {\n\tlet kind = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 'key+value';\n\n\tconst keys = Object.keys(headers[MAP]).sort();\n\treturn keys.map(kind === 'key' ? function (k) {\n\t\treturn k.toLowerCase();\n\t} : kind === 'value' ? function (k) {\n\t\treturn headers[MAP][k].join(', ');\n\t} : function (k) {\n\t\treturn [k.toLowerCase(), headers[MAP][k].join(', ')];\n\t});\n}\n\nconst INTERNAL = Symbol('internal');\n\nfunction createHeadersIterator(target, kind) {\n\tconst iterator = Object.create(HeadersIteratorPrototype);\n\titerator[INTERNAL] = {\n\t\ttarget,\n\t\tkind,\n\t\tindex: 0\n\t};\n\treturn iterator;\n}\n\nconst HeadersIteratorPrototype = Object.setPrototypeOf({\n\tnext() {\n\t\t// istanbul ignore if\n\t\tif (!this || Object.getPrototypeOf(this) !== HeadersIteratorPrototype) {\n\t\t\tthrow new TypeError('Value of `this` is not a HeadersIterator');\n\t\t}\n\n\t\tvar _INTERNAL = this[INTERNAL];\n\t\tconst target = _INTERNAL.target,\n\t\t      kind = _INTERNAL.kind,\n\t\t      index = _INTERNAL.index;\n\n\t\tconst values = getHeaders(target, kind);\n\t\tconst len = values.length;\n\t\tif (index >= len) {\n\t\t\treturn {\n\t\t\t\tvalue: undefined,\n\t\t\t\tdone: true\n\t\t\t};\n\t\t}\n\n\t\tthis[INTERNAL].index = index + 1;\n\n\t\treturn {\n\t\t\tvalue: values[index],\n\t\t\tdone: false\n\t\t};\n\t}\n}, Object.getPrototypeOf(Object.getPrototypeOf([][Symbol.iterator]())));\n\nObject.defineProperty(HeadersIteratorPrototype, Symbol.toStringTag, {\n\tvalue: 'HeadersIterator',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\n/**\n * Export the Headers object in a form that Node.js can consume.\n *\n * @param   Headers  headers\n * @return  Object\n */\nfunction exportNodeCompatibleHeaders(headers) {\n\tconst obj = Object.assign({ __proto__: null }, headers[MAP]);\n\n\t// http.request() only supports string as Host header. This hack makes\n\t// specifying custom Host header possible.\n\tconst hostHeaderKey = find(headers[MAP], 'Host');\n\tif (hostHeaderKey !== undefined) {\n\t\tobj[hostHeaderKey] = obj[hostHeaderKey][0];\n\t}\n\n\treturn obj;\n}\n\n/**\n * Create a Headers object from an object of headers, ignoring those that do\n * not conform to HTTP grammar productions.\n *\n * @param   Object  obj  Object of headers\n * @return  Headers\n */\nfunction createHeadersLenient(obj) {\n\tconst headers = new Headers();\n\tfor (const name of Object.keys(obj)) {\n\t\tif (invalidTokenRegex.test(name)) {\n\t\t\tcontinue;\n\t\t}\n\t\tif (Array.isArray(obj[name])) {\n\t\t\tfor (const val of obj[name]) {\n\t\t\t\tif (invalidHeaderCharRegex.test(val)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (headers[MAP][name] === undefined) {\n\t\t\t\t\theaders[MAP][name] = [val];\n\t\t\t\t} else {\n\t\t\t\t\theaders[MAP][name].push(val);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (!invalidHeaderCharRegex.test(obj[name])) {\n\t\t\theaders[MAP][name] = [obj[name]];\n\t\t}\n\t}\n\treturn headers;\n}\n\n/**\n * response.js\n *\n * Response class provides content decoding\n */\n\nvar _require$1 = __webpack_require__(/*! http */ \"./node_modules/stream-http/index.js\");\n\nconst STATUS_CODES = _require$1.STATUS_CODES;\n\n\nconst INTERNALS$1 = Symbol('Response internals');\n\n/**\n * Response class\n *\n * @param   Stream  body  Readable stream\n * @param   Object  opts  Response options\n * @return  Void\n */\nclass Response {\n\tconstructor() {\n\t\tlet body = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n\t\tlet opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n\t\tBody.call(this, body, opts);\n\n\t\tconst status = opts.status || 200;\n\n\t\tthis[INTERNALS$1] = {\n\t\t\turl: opts.url,\n\t\t\tstatus,\n\t\t\tstatusText: opts.statusText || STATUS_CODES[status],\n\t\t\theaders: new Headers(opts.headers)\n\t\t};\n\t}\n\n\tget url() {\n\t\treturn this[INTERNALS$1].url;\n\t}\n\n\tget status() {\n\t\treturn this[INTERNALS$1].status;\n\t}\n\n\t/**\n  * Convenience property representing if the request ended normally\n  */\n\tget ok() {\n\t\treturn this[INTERNALS$1].status >= 200 && this[INTERNALS$1].status < 300;\n\t}\n\n\tget statusText() {\n\t\treturn this[INTERNALS$1].statusText;\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS$1].headers;\n\t}\n\n\t/**\n  * Clone this response\n  *\n  * @return  Response\n  */\n\tclone() {\n\t\treturn new Response(clone(this), {\n\t\t\turl: this.url,\n\t\t\tstatus: this.status,\n\t\t\tstatusText: this.statusText,\n\t\t\theaders: this.headers,\n\t\t\tok: this.ok\n\t\t});\n\t}\n}\n\nBody.mixIn(Response.prototype);\n\nObject.defineProperties(Response.prototype, {\n\turl: { enumerable: true },\n\tstatus: { enumerable: true },\n\tok: { enumerable: true },\n\tstatusText: { enumerable: true },\n\theaders: { enumerable: true },\n\tclone: { enumerable: true }\n});\n\nObject.defineProperty(Response.prototype, Symbol.toStringTag, {\n\tvalue: 'Response',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\n/**\n * request.js\n *\n * Request class contains server only options\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\nvar _require$2 = __webpack_require__(/*! url */ \"./node_modules/url/url.js\");\n\nconst format_url = _require$2.format;\nconst parse_url = _require$2.parse;\n\n\nconst INTERNALS$2 = Symbol('Request internals');\n\n/**\n * Check if a value is an instance of Request.\n *\n * @param   Mixed   input\n * @return  Boolean\n */\nfunction isRequest(input) {\n\treturn typeof input === 'object' && typeof input[INTERNALS$2] === 'object';\n}\n\n/**\n * Request class\n *\n * @param   Mixed   input  Url or Request instance\n * @param   Object  init   Custom options\n * @return  Void\n */\nclass Request {\n\tconstructor(input) {\n\t\tlet init = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n\t\tlet parsedURL;\n\n\t\t// normalize input\n\t\tif (!isRequest(input)) {\n\t\t\tif (input && input.href) {\n\t\t\t\t// in order to support Node.js' Url objects; though WHATWG's URL objects\n\t\t\t\t// will fall into this branch also (since their `toString()` will return\n\t\t\t\t// `href` property anyway)\n\t\t\t\tparsedURL = parse_url(input.href);\n\t\t\t} else {\n\t\t\t\t// coerce input to a string before attempting to parse\n\t\t\t\tparsedURL = parse_url(`${input}`);\n\t\t\t}\n\t\t\tinput = {};\n\t\t} else {\n\t\t\tparsedURL = parse_url(input.url);\n\t\t}\n\n\t\tlet method = init.method || input.method || 'GET';\n\t\tmethod = method.toUpperCase();\n\n\t\tif ((init.body != null || isRequest(input) && input.body !== null) && (method === 'GET' || method === 'HEAD')) {\n\t\t\tthrow new TypeError('Request with GET/HEAD method cannot have body');\n\t\t}\n\n\t\tlet inputBody = init.body != null ? init.body : isRequest(input) && input.body !== null ? clone(input) : null;\n\n\t\tBody.call(this, inputBody, {\n\t\t\ttimeout: init.timeout || input.timeout || 0,\n\t\t\tsize: init.size || input.size || 0\n\t\t});\n\n\t\tconst headers = new Headers(init.headers || input.headers || {});\n\n\t\tif (init.body != null) {\n\t\t\tconst contentType = extractContentType(this);\n\t\t\tif (contentType !== null && !headers.has('Content-Type')) {\n\t\t\t\theaders.append('Content-Type', contentType);\n\t\t\t}\n\t\t}\n\n\t\tthis[INTERNALS$2] = {\n\t\t\tmethod,\n\t\t\tredirect: init.redirect || input.redirect || 'follow',\n\t\t\theaders,\n\t\t\tparsedURL\n\t\t};\n\n\t\t// node-fetch-only options\n\t\tthis.follow = init.follow !== undefined ? init.follow : input.follow !== undefined ? input.follow : 20;\n\t\tthis.compress = init.compress !== undefined ? init.compress : input.compress !== undefined ? input.compress : true;\n\t\tthis.counter = init.counter || input.counter || 0;\n\t\tthis.agent = init.agent || input.agent;\n\t}\n\n\tget method() {\n\t\treturn this[INTERNALS$2].method;\n\t}\n\n\tget url() {\n\t\treturn format_url(this[INTERNALS$2].parsedURL);\n\t}\n\n\tget headers() {\n\t\treturn this[INTERNALS$2].headers;\n\t}\n\n\tget redirect() {\n\t\treturn this[INTERNALS$2].redirect;\n\t}\n\n\t/**\n  * Clone this request\n  *\n  * @return  Request\n  */\n\tclone() {\n\t\treturn new Request(this);\n\t}\n}\n\nBody.mixIn(Request.prototype);\n\nObject.defineProperty(Request.prototype, Symbol.toStringTag, {\n\tvalue: 'Request',\n\twritable: false,\n\tenumerable: false,\n\tconfigurable: true\n});\n\nObject.defineProperties(Request.prototype, {\n\tmethod: { enumerable: true },\n\turl: { enumerable: true },\n\theaders: { enumerable: true },\n\tredirect: { enumerable: true },\n\tclone: { enumerable: true }\n});\n\n/**\n * Convert a Request to Node.js http request options.\n *\n * @param   Request  A Request instance\n * @return  Object   The options object to be passed to http.request\n */\nfunction getNodeRequestOptions(request) {\n\tconst parsedURL = request[INTERNALS$2].parsedURL;\n\tconst headers = new Headers(request[INTERNALS$2].headers);\n\n\t// fetch step 1.3\n\tif (!headers.has('Accept')) {\n\t\theaders.set('Accept', '*/*');\n\t}\n\n\t// Basic fetch\n\tif (!parsedURL.protocol || !parsedURL.hostname) {\n\t\tthrow new TypeError('Only absolute URLs are supported');\n\t}\n\n\tif (!/^https?:$/.test(parsedURL.protocol)) {\n\t\tthrow new TypeError('Only HTTP(S) protocols are supported');\n\t}\n\n\t// HTTP-network-or-cache fetch steps 2.4-2.7\n\tlet contentLengthValue = null;\n\tif (request.body == null && /^(POST|PUT)$/i.test(request.method)) {\n\t\tcontentLengthValue = '0';\n\t}\n\tif (request.body != null) {\n\t\tconst totalBytes = getTotalBytes(request);\n\t\tif (typeof totalBytes === 'number') {\n\t\t\tcontentLengthValue = String(totalBytes);\n\t\t}\n\t}\n\tif (contentLengthValue) {\n\t\theaders.set('Content-Length', contentLengthValue);\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.11\n\tif (!headers.has('User-Agent')) {\n\t\theaders.set('User-Agent', 'node-fetch/1.0 (+https://github.com/bitinn/node-fetch)');\n\t}\n\n\t// HTTP-network-or-cache fetch step 2.15\n\tif (request.compress) {\n\t\theaders.set('Accept-Encoding', 'gzip,deflate');\n\t}\n\tif (!headers.has('Connection') && !request.agent) {\n\t\theaders.set('Connection', 'close');\n\t}\n\n\t// HTTP-network fetch step 4.2\n\t// chunked encoding is handled by Node.js\n\n\treturn Object.assign({}, parsedURL, {\n\t\tmethod: request.method,\n\t\theaders: exportNodeCompatibleHeaders(headers),\n\t\tagent: request.agent\n\t});\n}\n\n/**\n * index.js\n *\n * a request API compatible with window.fetch\n *\n * All spec algorithm step numbers are based on https://fetch.spec.whatwg.org/commit-snapshots/ae716822cb3a61843226cd090eefc6589446c1d2/.\n */\n\nconst http = __webpack_require__(/*! http */ \"./node_modules/stream-http/index.js\");\nconst https = __webpack_require__(/*! https */ \"./node_modules/https-browserify/index.js\");\n\nvar _require$3 = __webpack_require__(/*! stream */ \"./node_modules/stream-browserify/index.js\");\n\nconst PassThrough$1 = _require$3.PassThrough;\n\nvar _require2 = __webpack_require__(/*! url */ \"./node_modules/url/url.js\");\n\nconst resolve_url = _require2.resolve;\n\nconst zlib = __webpack_require__(/*! zlib */ \"./node_modules/browserify-zlib/lib/index.js\");\n\n/**\n * Fetch function\n *\n * @param   Mixed    url   Absolute url or Request instance\n * @param   Object   opts  Fetch options\n * @return  Promise\n */\nfunction fetch(url, opts) {\n\n\t// allow custom promise\n\tif (!fetch.Promise) {\n\t\tthrow new Error('native promise missing, set fetch.Promise to your favorite alternative');\n\t}\n\n\tBody.Promise = fetch.Promise;\n\n\t// wrap http.request into fetch\n\treturn new fetch.Promise(function (resolve, reject) {\n\t\t// build request object\n\t\tconst request = new Request(url, opts);\n\t\tconst options = getNodeRequestOptions(request);\n\n\t\tconst send = (options.protocol === 'https:' ? https : http).request;\n\n\t\t// send request\n\t\tconst req = send(options);\n\t\tlet reqTimeout;\n\n\t\tfunction finalize() {\n\t\t\treq.abort();\n\t\t\tclearTimeout(reqTimeout);\n\t\t}\n\n\t\tif (request.timeout) {\n\t\t\treq.once('socket', function (socket) {\n\t\t\t\treqTimeout = setTimeout(function () {\n\t\t\t\t\treject(new FetchError(`network timeout at: ${request.url}`, 'request-timeout'));\n\t\t\t\t\tfinalize();\n\t\t\t\t}, request.timeout);\n\t\t\t});\n\t\t}\n\n\t\treq.on('error', function (err) {\n\t\t\treject(new FetchError(`request to ${request.url} failed, reason: ${err.message}`, 'system', err));\n\t\t\tfinalize();\n\t\t});\n\n\t\treq.on('response', function (res) {\n\t\t\tclearTimeout(reqTimeout);\n\n\t\t\tconst headers = createHeadersLenient(res.headers);\n\n\t\t\t// HTTP fetch step 5\n\t\t\tif (fetch.isRedirect(res.statusCode)) {\n\t\t\t\t// HTTP fetch step 5.2\n\t\t\t\tconst location = headers.get('Location');\n\n\t\t\t\t// HTTP fetch step 5.3\n\t\t\t\tconst locationURL = location === null ? null : resolve_url(request.url, location);\n\n\t\t\t\t// HTTP fetch step 5.5\n\t\t\t\tswitch (request.redirect) {\n\t\t\t\t\tcase 'error':\n\t\t\t\t\t\treject(new FetchError(`redirect mode is set to error: ${request.url}`, 'no-redirect'));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t\tcase 'manual':\n\t\t\t\t\t\t// node-fetch-specific step: make manual redirect a bit easier to use by setting the Location header value to the resolved URL.\n\t\t\t\t\t\tif (locationURL !== null) {\n\t\t\t\t\t\t\theaders.set('Location', locationURL);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'follow':\n\t\t\t\t\t\t// HTTP-redirect fetch step 2\n\t\t\t\t\t\tif (locationURL === null) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 5\n\t\t\t\t\t\tif (request.counter >= request.follow) {\n\t\t\t\t\t\t\treject(new FetchError(`maximum redirect reached at: ${request.url}`, 'max-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 6 (counter increment)\n\t\t\t\t\t\t// Create a new Request object.\n\t\t\t\t\t\tconst requestOpts = {\n\t\t\t\t\t\t\theaders: new Headers(request.headers),\n\t\t\t\t\t\t\tfollow: request.follow,\n\t\t\t\t\t\t\tcounter: request.counter + 1,\n\t\t\t\t\t\t\tagent: request.agent,\n\t\t\t\t\t\t\tcompress: request.compress,\n\t\t\t\t\t\t\tmethod: request.method,\n\t\t\t\t\t\t\tbody: request.body\n\t\t\t\t\t\t};\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 9\n\t\t\t\t\t\tif (res.statusCode !== 303 && request.body && getTotalBytes(request) === null) {\n\t\t\t\t\t\t\treject(new FetchError('Cannot follow redirect with body being a readable stream', 'unsupported-redirect'));\n\t\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 11\n\t\t\t\t\t\tif (res.statusCode === 303 || (res.statusCode === 301 || res.statusCode === 302) && request.method === 'POST') {\n\t\t\t\t\t\t\trequestOpts.method = 'GET';\n\t\t\t\t\t\t\trequestOpts.body = undefined;\n\t\t\t\t\t\t\trequestOpts.headers.delete('content-length');\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// HTTP-redirect fetch step 15\n\t\t\t\t\t\tresolve(fetch(new Request(locationURL, requestOpts)));\n\t\t\t\t\t\tfinalize();\n\t\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// prepare response\n\t\t\tlet body = res.pipe(new PassThrough$1());\n\t\t\tconst response_options = {\n\t\t\t\turl: request.url,\n\t\t\t\tstatus: res.statusCode,\n\t\t\t\tstatusText: res.statusMessage,\n\t\t\t\theaders: headers,\n\t\t\t\tsize: request.size,\n\t\t\t\ttimeout: request.timeout\n\t\t\t};\n\n\t\t\t// HTTP-network fetch step 12.1.1.3\n\t\t\tconst codings = headers.get('Content-Encoding');\n\n\t\t\t// HTTP-network fetch step 12.1.1.4: handle content codings\n\n\t\t\t// in following scenarios we ignore compression support\n\t\t\t// 1. compression support is disabled\n\t\t\t// 2. HEAD request\n\t\t\t// 3. no Content-Encoding header\n\t\t\t// 4. no content response (204)\n\t\t\t// 5. content not modified response (304)\n\t\t\tif (!request.compress || request.method === 'HEAD' || codings === null || res.statusCode === 204 || res.statusCode === 304) {\n\t\t\t\tresolve(new Response(body, response_options));\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// For Node v6+\n\t\t\t// Be less strict when decoding compressed responses, since sometimes\n\t\t\t// servers send slightly invalid responses that are still accepted\n\t\t\t// by common browsers.\n\t\t\t// Always using Z_SYNC_FLUSH is what cURL does.\n\t\t\tconst zlibOptions = {\n\t\t\t\tflush: zlib.Z_SYNC_FLUSH,\n\t\t\t\tfinishFlush: zlib.Z_SYNC_FLUSH\n\t\t\t};\n\n\t\t\t// for gzip\n\t\t\tif (codings == 'gzip' || codings == 'x-gzip') {\n\t\t\t\tbody = body.pipe(zlib.createGunzip(zlibOptions));\n\t\t\t\tresolve(new Response(body, response_options));\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// for deflate\n\t\t\tif (codings == 'deflate' || codings == 'x-deflate') {\n\t\t\t\t// handle the infamous raw deflate response from old servers\n\t\t\t\t// a hack for old IIS and Apache servers\n\t\t\t\tconst raw = res.pipe(new PassThrough$1());\n\t\t\t\traw.once('data', function (chunk) {\n\t\t\t\t\t// see http://stackoverflow.com/questions/37519828\n\t\t\t\t\tif ((chunk[0] & 0x0F) === 0x08) {\n\t\t\t\t\t\tbody = body.pipe(zlib.createInflate());\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbody = body.pipe(zlib.createInflateRaw());\n\t\t\t\t\t}\n\t\t\t\t\tresolve(new Response(body, response_options));\n\t\t\t\t});\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// otherwise, use response as-is\n\t\t\tresolve(new Response(body, response_options));\n\t\t});\n\n\t\twriteToStream(req, request);\n\t});\n}\n\n/**\n * Redirect code matching\n *\n * @param   Number   code  Status code\n * @return  Boolean\n */\nfetch.isRedirect = function (code) {\n\treturn code === 301 || code === 302 || code === 303 || code === 307 || code === 308;\n};\n\n// Needed for TypeScript.\nfetch.default = fetch;\n\n// expose Promise\nfetch.Promise = global.Promise;\n\nmodule.exports = exports = fetch;\nexports.Headers = Headers;\nexports.Request = Request;\nexports.Response = Response;\nexports.FetchError = FetchError;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer, __webpack_require__(/*! ./../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/node-fetch/lib/index.js?");

/***/ }),

/***/ "./node_modules/object-assign/index.js":
/*!*********************************************!*\
  !*** ./node_modules/object-assign/index.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/*\nobject-assign\n(c) Sindre Sorhus\n@license MIT\n*/\n\n\n/* eslint-disable no-unused-vars */\nvar getOwnPropertySymbols = Object.getOwnPropertySymbols;\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nvar propIsEnumerable = Object.prototype.propertyIsEnumerable;\n\nfunction toObject(val) {\n\tif (val === null || val === undefined) {\n\t\tthrow new TypeError('Object.assign cannot be called with null or undefined');\n\t}\n\n\treturn Object(val);\n}\n\nfunction shouldUseNative() {\n\ttry {\n\t\tif (!Object.assign) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// Detect buggy property enumeration order in older V8 versions.\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=4118\n\t\tvar test1 = new String('abc');  // eslint-disable-line no-new-wrappers\n\t\ttest1[5] = 'de';\n\t\tif (Object.getOwnPropertyNames(test1)[0] === '5') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test2 = {};\n\t\tfor (var i = 0; i < 10; i++) {\n\t\t\ttest2['_' + String.fromCharCode(i)] = i;\n\t\t}\n\t\tvar order2 = Object.getOwnPropertyNames(test2).map(function (n) {\n\t\t\treturn test2[n];\n\t\t});\n\t\tif (order2.join('') !== '0123456789') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test3 = {};\n\t\t'abcdefghijklmnopqrst'.split('').forEach(function (letter) {\n\t\t\ttest3[letter] = letter;\n\t\t});\n\t\tif (Object.keys(Object.assign({}, test3)).join('') !==\n\t\t\t\t'abcdefghijklmnopqrst') {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn true;\n\t} catch (err) {\n\t\t// We don't expect any of the above to throw, but better to be safe.\n\t\treturn false;\n\t}\n}\n\nmodule.exports = shouldUseNative() ? Object.assign : function (target, source) {\n\tvar from;\n\tvar to = toObject(target);\n\tvar symbols;\n\n\tfor (var s = 1; s < arguments.length; s++) {\n\t\tfrom = Object(arguments[s]);\n\n\t\tfor (var key in from) {\n\t\t\tif (hasOwnProperty.call(from, key)) {\n\t\t\t\tto[key] = from[key];\n\t\t\t}\n\t\t}\n\n\t\tif (getOwnPropertySymbols) {\n\t\t\tsymbols = getOwnPropertySymbols(from);\n\t\t\tfor (var i = 0; i < symbols.length; i++) {\n\t\t\t\tif (propIsEnumerable.call(from, symbols[i])) {\n\t\t\t\t\tto[symbols[i]] = from[symbols[i]];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn to;\n};\n\n\n//# sourceURL=webpack:///./node_modules/object-assign/index.js?");

/***/ }),

/***/ "./node_modules/pako/lib/utils/common.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/utils/common.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n\nvar TYPED_OK =  (typeof Uint8Array !== 'undefined') &&\n                (typeof Uint16Array !== 'undefined') &&\n                (typeof Int32Array !== 'undefined');\n\nfunction _has(obj, key) {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\nexports.assign = function (obj /*from1, from2, from3, ...*/) {\n  var sources = Array.prototype.slice.call(arguments, 1);\n  while (sources.length) {\n    var source = sources.shift();\n    if (!source) { continue; }\n\n    if (typeof source !== 'object') {\n      throw new TypeError(source + 'must be non-object');\n    }\n\n    for (var p in source) {\n      if (_has(source, p)) {\n        obj[p] = source[p];\n      }\n    }\n  }\n\n  return obj;\n};\n\n\n// reduce buffer size, avoiding mem copy\nexports.shrinkBuf = function (buf, size) {\n  if (buf.length === size) { return buf; }\n  if (buf.subarray) { return buf.subarray(0, size); }\n  buf.length = size;\n  return buf;\n};\n\n\nvar fnTyped = {\n  arraySet: function (dest, src, src_offs, len, dest_offs) {\n    if (src.subarray && dest.subarray) {\n      dest.set(src.subarray(src_offs, src_offs + len), dest_offs);\n      return;\n    }\n    // Fallback to ordinary array\n    for (var i = 0; i < len; i++) {\n      dest[dest_offs + i] = src[src_offs + i];\n    }\n  },\n  // Join array of chunks to single array.\n  flattenChunks: function (chunks) {\n    var i, l, len, pos, chunk, result;\n\n    // calculate data length\n    len = 0;\n    for (i = 0, l = chunks.length; i < l; i++) {\n      len += chunks[i].length;\n    }\n\n    // join chunks\n    result = new Uint8Array(len);\n    pos = 0;\n    for (i = 0, l = chunks.length; i < l; i++) {\n      chunk = chunks[i];\n      result.set(chunk, pos);\n      pos += chunk.length;\n    }\n\n    return result;\n  }\n};\n\nvar fnUntyped = {\n  arraySet: function (dest, src, src_offs, len, dest_offs) {\n    for (var i = 0; i < len; i++) {\n      dest[dest_offs + i] = src[src_offs + i];\n    }\n  },\n  // Join array of chunks to single array.\n  flattenChunks: function (chunks) {\n    return [].concat.apply([], chunks);\n  }\n};\n\n\n// Enable/Disable typed arrays use, for testing\n//\nexports.setTyped = function (on) {\n  if (on) {\n    exports.Buf8  = Uint8Array;\n    exports.Buf16 = Uint16Array;\n    exports.Buf32 = Int32Array;\n    exports.assign(exports, fnTyped);\n  } else {\n    exports.Buf8  = Array;\n    exports.Buf16 = Array;\n    exports.Buf32 = Array;\n    exports.assign(exports, fnUntyped);\n  }\n};\n\nexports.setTyped(TYPED_OK);\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/utils/common.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/adler32.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/adler32.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// Note: adler32 takes 12% for level 0 and 2% for level 6.\n// It isn't worth it to make additional optimizations as in original.\n// Small size is preferable.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction adler32(adler, buf, len, pos) {\n  var s1 = (adler & 0xffff) |0,\n      s2 = ((adler >>> 16) & 0xffff) |0,\n      n = 0;\n\n  while (len !== 0) {\n    // Set limit ~ twice less than 5552, to keep\n    // s2 in 31-bits, because we force signed ints.\n    // in other case %= will fail.\n    n = len > 2000 ? 2000 : len;\n    len -= n;\n\n    do {\n      s1 = (s1 + buf[pos++]) |0;\n      s2 = (s2 + s1) |0;\n    } while (--n);\n\n    s1 %= 65521;\n    s2 %= 65521;\n  }\n\n  return (s1 | (s2 << 16)) |0;\n}\n\n\nmodule.exports = adler32;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/adler32.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/constants.js":
/*!*************************************************!*\
  !*** ./node_modules/pako/lib/zlib/constants.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nmodule.exports = {\n\n  /* Allowed flush values; see deflate() and inflate() below for details */\n  Z_NO_FLUSH:         0,\n  Z_PARTIAL_FLUSH:    1,\n  Z_SYNC_FLUSH:       2,\n  Z_FULL_FLUSH:       3,\n  Z_FINISH:           4,\n  Z_BLOCK:            5,\n  Z_TREES:            6,\n\n  /* Return codes for the compression/decompression functions. Negative values\n  * are errors, positive values are used for special but normal events.\n  */\n  Z_OK:               0,\n  Z_STREAM_END:       1,\n  Z_NEED_DICT:        2,\n  Z_ERRNO:           -1,\n  Z_STREAM_ERROR:    -2,\n  Z_DATA_ERROR:      -3,\n  //Z_MEM_ERROR:     -4,\n  Z_BUF_ERROR:       -5,\n  //Z_VERSION_ERROR: -6,\n\n  /* compression levels */\n  Z_NO_COMPRESSION:         0,\n  Z_BEST_SPEED:             1,\n  Z_BEST_COMPRESSION:       9,\n  Z_DEFAULT_COMPRESSION:   -1,\n\n\n  Z_FILTERED:               1,\n  Z_HUFFMAN_ONLY:           2,\n  Z_RLE:                    3,\n  Z_FIXED:                  4,\n  Z_DEFAULT_STRATEGY:       0,\n\n  /* Possible values of the data_type field (though see inflate()) */\n  Z_BINARY:                 0,\n  Z_TEXT:                   1,\n  //Z_ASCII:                1, // = Z_TEXT (deprecated)\n  Z_UNKNOWN:                2,\n\n  /* The deflate compression method */\n  Z_DEFLATED:               8\n  //Z_NULL:                 null // Use -1 or null inline, depending on var type\n};\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/constants.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/crc32.js":
/*!*********************************************!*\
  !*** ./node_modules/pako/lib/zlib/crc32.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// Note: we can't get significant speed boost here.\n// So write code to minimize size - no pregenerated tables\n// and array tools dependencies.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// Use ordinary array, since untyped makes no boost here\nfunction makeTable() {\n  var c, table = [];\n\n  for (var n = 0; n < 256; n++) {\n    c = n;\n    for (var k = 0; k < 8; k++) {\n      c = ((c & 1) ? (0xEDB88320 ^ (c >>> 1)) : (c >>> 1));\n    }\n    table[n] = c;\n  }\n\n  return table;\n}\n\n// Create table on load. Just 255 signed longs. Not a problem.\nvar crcTable = makeTable();\n\n\nfunction crc32(crc, buf, len, pos) {\n  var t = crcTable,\n      end = pos + len;\n\n  crc ^= -1;\n\n  for (var i = pos; i < end; i++) {\n    crc = (crc >>> 8) ^ t[(crc ^ buf[i]) & 0xFF];\n  }\n\n  return (crc ^ (-1)); // >>> 0;\n}\n\n\nmodule.exports = crc32;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/crc32.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/deflate.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/deflate.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils   = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\nvar trees   = __webpack_require__(/*! ./trees */ \"./node_modules/pako/lib/zlib/trees.js\");\nvar adler32 = __webpack_require__(/*! ./adler32 */ \"./node_modules/pako/lib/zlib/adler32.js\");\nvar crc32   = __webpack_require__(/*! ./crc32 */ \"./node_modules/pako/lib/zlib/crc32.js\");\nvar msg     = __webpack_require__(/*! ./messages */ \"./node_modules/pako/lib/zlib/messages.js\");\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n/* Allowed flush values; see deflate() and inflate() below for details */\nvar Z_NO_FLUSH      = 0;\nvar Z_PARTIAL_FLUSH = 1;\n//var Z_SYNC_FLUSH    = 2;\nvar Z_FULL_FLUSH    = 3;\nvar Z_FINISH        = 4;\nvar Z_BLOCK         = 5;\n//var Z_TREES         = 6;\n\n\n/* Return codes for the compression/decompression functions. Negative values\n * are errors, positive values are used for special but normal events.\n */\nvar Z_OK            = 0;\nvar Z_STREAM_END    = 1;\n//var Z_NEED_DICT     = 2;\n//var Z_ERRNO         = -1;\nvar Z_STREAM_ERROR  = -2;\nvar Z_DATA_ERROR    = -3;\n//var Z_MEM_ERROR     = -4;\nvar Z_BUF_ERROR     = -5;\n//var Z_VERSION_ERROR = -6;\n\n\n/* compression levels */\n//var Z_NO_COMPRESSION      = 0;\n//var Z_BEST_SPEED          = 1;\n//var Z_BEST_COMPRESSION    = 9;\nvar Z_DEFAULT_COMPRESSION = -1;\n\n\nvar Z_FILTERED            = 1;\nvar Z_HUFFMAN_ONLY        = 2;\nvar Z_RLE                 = 3;\nvar Z_FIXED               = 4;\nvar Z_DEFAULT_STRATEGY    = 0;\n\n/* Possible values of the data_type field (though see inflate()) */\n//var Z_BINARY              = 0;\n//var Z_TEXT                = 1;\n//var Z_ASCII               = 1; // = Z_TEXT\nvar Z_UNKNOWN             = 2;\n\n\n/* The deflate compression method */\nvar Z_DEFLATED  = 8;\n\n/*============================================================================*/\n\n\nvar MAX_MEM_LEVEL = 9;\n/* Maximum value for memLevel in deflateInit2 */\nvar MAX_WBITS = 15;\n/* 32K LZ77 window */\nvar DEF_MEM_LEVEL = 8;\n\n\nvar LENGTH_CODES  = 29;\n/* number of length codes, not counting the special END_BLOCK code */\nvar LITERALS      = 256;\n/* number of literal bytes 0..255 */\nvar L_CODES       = LITERALS + 1 + LENGTH_CODES;\n/* number of Literal or Length codes, including the END_BLOCK code */\nvar D_CODES       = 30;\n/* number of distance codes */\nvar BL_CODES      = 19;\n/* number of codes used to transfer the bit lengths */\nvar HEAP_SIZE     = 2 * L_CODES + 1;\n/* maximum heap size */\nvar MAX_BITS  = 15;\n/* All codes must not exceed MAX_BITS bits */\n\nvar MIN_MATCH = 3;\nvar MAX_MATCH = 258;\nvar MIN_LOOKAHEAD = (MAX_MATCH + MIN_MATCH + 1);\n\nvar PRESET_DICT = 0x20;\n\nvar INIT_STATE = 42;\nvar EXTRA_STATE = 69;\nvar NAME_STATE = 73;\nvar COMMENT_STATE = 91;\nvar HCRC_STATE = 103;\nvar BUSY_STATE = 113;\nvar FINISH_STATE = 666;\n\nvar BS_NEED_MORE      = 1; /* block not completed, need more input or more output */\nvar BS_BLOCK_DONE     = 2; /* block flush performed */\nvar BS_FINISH_STARTED = 3; /* finish started, need only more output at next deflate */\nvar BS_FINISH_DONE    = 4; /* finish done, accept no more input or output */\n\nvar OS_CODE = 0x03; // Unix :) . Don't detect, use this default.\n\nfunction err(strm, errorCode) {\n  strm.msg = msg[errorCode];\n  return errorCode;\n}\n\nfunction rank(f) {\n  return ((f) << 1) - ((f) > 4 ? 9 : 0);\n}\n\nfunction zero(buf) { var len = buf.length; while (--len >= 0) { buf[len] = 0; } }\n\n\n/* =========================================================================\n * Flush as much pending output as possible. All deflate() output goes\n * through this function so some applications may wish to modify it\n * to avoid allocating a large strm->output buffer and copying into it.\n * (See also read_buf()).\n */\nfunction flush_pending(strm) {\n  var s = strm.state;\n\n  //_tr_flush_bits(s);\n  var len = s.pending;\n  if (len > strm.avail_out) {\n    len = strm.avail_out;\n  }\n  if (len === 0) { return; }\n\n  utils.arraySet(strm.output, s.pending_buf, s.pending_out, len, strm.next_out);\n  strm.next_out += len;\n  s.pending_out += len;\n  strm.total_out += len;\n  strm.avail_out -= len;\n  s.pending -= len;\n  if (s.pending === 0) {\n    s.pending_out = 0;\n  }\n}\n\n\nfunction flush_block_only(s, last) {\n  trees._tr_flush_block(s, (s.block_start >= 0 ? s.block_start : -1), s.strstart - s.block_start, last);\n  s.block_start = s.strstart;\n  flush_pending(s.strm);\n}\n\n\nfunction put_byte(s, b) {\n  s.pending_buf[s.pending++] = b;\n}\n\n\n/* =========================================================================\n * Put a short in the pending buffer. The 16-bit value is put in MSB order.\n * IN assertion: the stream state is correct and there is enough room in\n * pending_buf.\n */\nfunction putShortMSB(s, b) {\n//  put_byte(s, (Byte)(b >> 8));\n//  put_byte(s, (Byte)(b & 0xff));\n  s.pending_buf[s.pending++] = (b >>> 8) & 0xff;\n  s.pending_buf[s.pending++] = b & 0xff;\n}\n\n\n/* ===========================================================================\n * Read a new buffer from the current input stream, update the adler32\n * and total number of bytes read.  All deflate() input goes through\n * this function so some applications may wish to modify it to avoid\n * allocating a large strm->input buffer and copying from it.\n * (See also flush_pending()).\n */\nfunction read_buf(strm, buf, start, size) {\n  var len = strm.avail_in;\n\n  if (len > size) { len = size; }\n  if (len === 0) { return 0; }\n\n  strm.avail_in -= len;\n\n  // zmemcpy(buf, strm->next_in, len);\n  utils.arraySet(buf, strm.input, strm.next_in, len, start);\n  if (strm.state.wrap === 1) {\n    strm.adler = adler32(strm.adler, buf, len, start);\n  }\n\n  else if (strm.state.wrap === 2) {\n    strm.adler = crc32(strm.adler, buf, len, start);\n  }\n\n  strm.next_in += len;\n  strm.total_in += len;\n\n  return len;\n}\n\n\n/* ===========================================================================\n * Set match_start to the longest match starting at the given string and\n * return its length. Matches shorter or equal to prev_length are discarded,\n * in which case the result is equal to prev_length and match_start is\n * garbage.\n * IN assertions: cur_match is the head of the hash chain for the current\n *   string (strstart) and its distance is <= MAX_DIST, and prev_length >= 1\n * OUT assertion: the match length is not greater than s->lookahead.\n */\nfunction longest_match(s, cur_match) {\n  var chain_length = s.max_chain_length;      /* max hash chain length */\n  var scan = s.strstart; /* current string */\n  var match;                       /* matched string */\n  var len;                           /* length of current match */\n  var best_len = s.prev_length;              /* best match length so far */\n  var nice_match = s.nice_match;             /* stop if match long enough */\n  var limit = (s.strstart > (s.w_size - MIN_LOOKAHEAD)) ?\n      s.strstart - (s.w_size - MIN_LOOKAHEAD) : 0/*NIL*/;\n\n  var _win = s.window; // shortcut\n\n  var wmask = s.w_mask;\n  var prev  = s.prev;\n\n  /* Stop when cur_match becomes <= limit. To simplify the code,\n   * we prevent matches with the string of window index 0.\n   */\n\n  var strend = s.strstart + MAX_MATCH;\n  var scan_end1  = _win[scan + best_len - 1];\n  var scan_end   = _win[scan + best_len];\n\n  /* The code is optimized for HASH_BITS >= 8 and MAX_MATCH-2 multiple of 16.\n   * It is easy to get rid of this optimization if necessary.\n   */\n  // Assert(s->hash_bits >= 8 && MAX_MATCH == 258, \"Code too clever\");\n\n  /* Do not waste too much time if we already have a good match: */\n  if (s.prev_length >= s.good_match) {\n    chain_length >>= 2;\n  }\n  /* Do not look for matches beyond the end of the input. This is necessary\n   * to make deflate deterministic.\n   */\n  if (nice_match > s.lookahead) { nice_match = s.lookahead; }\n\n  // Assert((ulg)s->strstart <= s->window_size-MIN_LOOKAHEAD, \"need lookahead\");\n\n  do {\n    // Assert(cur_match < s->strstart, \"no future\");\n    match = cur_match;\n\n    /* Skip to next match if the match length cannot increase\n     * or if the match length is less than 2.  Note that the checks below\n     * for insufficient lookahead only occur occasionally for performance\n     * reasons.  Therefore uninitialized memory will be accessed, and\n     * conditional jumps will be made that depend on those values.\n     * However the length of the match is limited to the lookahead, so\n     * the output of deflate is not affected by the uninitialized values.\n     */\n\n    if (_win[match + best_len]     !== scan_end  ||\n        _win[match + best_len - 1] !== scan_end1 ||\n        _win[match]                !== _win[scan] ||\n        _win[++match]              !== _win[scan + 1]) {\n      continue;\n    }\n\n    /* The check at best_len-1 can be removed because it will be made\n     * again later. (This heuristic is not always a win.)\n     * It is not necessary to compare scan[2] and match[2] since they\n     * are always equal when the other bytes match, given that\n     * the hash keys are equal and that HASH_BITS >= 8.\n     */\n    scan += 2;\n    match++;\n    // Assert(*scan == *match, \"match[2]?\");\n\n    /* We check for insufficient lookahead only every 8th comparison;\n     * the 256th check will be made at strstart+258.\n     */\n    do {\n      /*jshint noempty:false*/\n    } while (_win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             scan < strend);\n\n    // Assert(scan <= s->window+(unsigned)(s->window_size-1), \"wild scan\");\n\n    len = MAX_MATCH - (strend - scan);\n    scan = strend - MAX_MATCH;\n\n    if (len > best_len) {\n      s.match_start = cur_match;\n      best_len = len;\n      if (len >= nice_match) {\n        break;\n      }\n      scan_end1  = _win[scan + best_len - 1];\n      scan_end   = _win[scan + best_len];\n    }\n  } while ((cur_match = prev[cur_match & wmask]) > limit && --chain_length !== 0);\n\n  if (best_len <= s.lookahead) {\n    return best_len;\n  }\n  return s.lookahead;\n}\n\n\n/* ===========================================================================\n * Fill the window when the lookahead becomes insufficient.\n * Updates strstart and lookahead.\n *\n * IN assertion: lookahead < MIN_LOOKAHEAD\n * OUT assertions: strstart <= window_size-MIN_LOOKAHEAD\n *    At least one byte has been read, or avail_in == 0; reads are\n *    performed for at least two bytes (required for the zip translate_eol\n *    option -- not supported here).\n */\nfunction fill_window(s) {\n  var _w_size = s.w_size;\n  var p, n, m, more, str;\n\n  //Assert(s->lookahead < MIN_LOOKAHEAD, \"already enough lookahead\");\n\n  do {\n    more = s.window_size - s.lookahead - s.strstart;\n\n    // JS ints have 32 bit, block below not needed\n    /* Deal with !@#$% 64K limit: */\n    //if (sizeof(int) <= 2) {\n    //    if (more == 0 && s->strstart == 0 && s->lookahead == 0) {\n    //        more = wsize;\n    //\n    //  } else if (more == (unsigned)(-1)) {\n    //        /* Very unlikely, but possible on 16 bit machine if\n    //         * strstart == 0 && lookahead == 1 (input done a byte at time)\n    //         */\n    //        more--;\n    //    }\n    //}\n\n\n    /* If the window is almost full and there is insufficient lookahead,\n     * move the upper half to the lower one to make room in the upper half.\n     */\n    if (s.strstart >= _w_size + (_w_size - MIN_LOOKAHEAD)) {\n\n      utils.arraySet(s.window, s.window, _w_size, _w_size, 0);\n      s.match_start -= _w_size;\n      s.strstart -= _w_size;\n      /* we now have strstart >= MAX_DIST */\n      s.block_start -= _w_size;\n\n      /* Slide the hash table (could be avoided with 32 bit values\n       at the expense of memory usage). We slide even when level == 0\n       to keep the hash table consistent if we switch back to level > 0\n       later. (Using level 0 permanently is not an optimal usage of\n       zlib, so we don't care about this pathological case.)\n       */\n\n      n = s.hash_size;\n      p = n;\n      do {\n        m = s.head[--p];\n        s.head[p] = (m >= _w_size ? m - _w_size : 0);\n      } while (--n);\n\n      n = _w_size;\n      p = n;\n      do {\n        m = s.prev[--p];\n        s.prev[p] = (m >= _w_size ? m - _w_size : 0);\n        /* If n is not on any hash chain, prev[n] is garbage but\n         * its value will never be used.\n         */\n      } while (--n);\n\n      more += _w_size;\n    }\n    if (s.strm.avail_in === 0) {\n      break;\n    }\n\n    /* If there was no sliding:\n     *    strstart <= WSIZE+MAX_DIST-1 && lookahead <= MIN_LOOKAHEAD - 1 &&\n     *    more == window_size - lookahead - strstart\n     * => more >= window_size - (MIN_LOOKAHEAD-1 + WSIZE + MAX_DIST-1)\n     * => more >= window_size - 2*WSIZE + 2\n     * In the BIG_MEM or MMAP case (not yet supported),\n     *   window_size == input_size + MIN_LOOKAHEAD  &&\n     *   strstart + s->lookahead <= input_size => more >= MIN_LOOKAHEAD.\n     * Otherwise, window_size == 2*WSIZE so more >= 2.\n     * If there was sliding, more >= WSIZE. So in all cases, more >= 2.\n     */\n    //Assert(more >= 2, \"more < 2\");\n    n = read_buf(s.strm, s.window, s.strstart + s.lookahead, more);\n    s.lookahead += n;\n\n    /* Initialize the hash value now that we have some input: */\n    if (s.lookahead + s.insert >= MIN_MATCH) {\n      str = s.strstart - s.insert;\n      s.ins_h = s.window[str];\n\n      /* UPDATE_HASH(s, s->ins_h, s->window[str + 1]); */\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + 1]) & s.hash_mask;\n//#if MIN_MATCH != 3\n//        Call update_hash() MIN_MATCH-3 more times\n//#endif\n      while (s.insert) {\n        /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */\n        s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + MIN_MATCH - 1]) & s.hash_mask;\n\n        s.prev[str & s.w_mask] = s.head[s.ins_h];\n        s.head[s.ins_h] = str;\n        str++;\n        s.insert--;\n        if (s.lookahead + s.insert < MIN_MATCH) {\n          break;\n        }\n      }\n    }\n    /* If the whole input has less than MIN_MATCH bytes, ins_h is garbage,\n     * but this is not important since only literal bytes will be emitted.\n     */\n\n  } while (s.lookahead < MIN_LOOKAHEAD && s.strm.avail_in !== 0);\n\n  /* If the WIN_INIT bytes after the end of the current data have never been\n   * written, then zero those bytes in order to avoid memory check reports of\n   * the use of uninitialized (or uninitialised as Julian writes) bytes by\n   * the longest match routines.  Update the high water mark for the next\n   * time through here.  WIN_INIT is set to MAX_MATCH since the longest match\n   * routines allow scanning to strstart + MAX_MATCH, ignoring lookahead.\n   */\n//  if (s.high_water < s.window_size) {\n//    var curr = s.strstart + s.lookahead;\n//    var init = 0;\n//\n//    if (s.high_water < curr) {\n//      /* Previous high water mark below current data -- zero WIN_INIT\n//       * bytes or up to end of window, whichever is less.\n//       */\n//      init = s.window_size - curr;\n//      if (init > WIN_INIT)\n//        init = WIN_INIT;\n//      zmemzero(s->window + curr, (unsigned)init);\n//      s->high_water = curr + init;\n//    }\n//    else if (s->high_water < (ulg)curr + WIN_INIT) {\n//      /* High water mark at or above current data, but below current data\n//       * plus WIN_INIT -- zero out to current data plus WIN_INIT, or up\n//       * to end of window, whichever is less.\n//       */\n//      init = (ulg)curr + WIN_INIT - s->high_water;\n//      if (init > s->window_size - s->high_water)\n//        init = s->window_size - s->high_water;\n//      zmemzero(s->window + s->high_water, (unsigned)init);\n//      s->high_water += init;\n//    }\n//  }\n//\n//  Assert((ulg)s->strstart <= s->window_size - MIN_LOOKAHEAD,\n//    \"not enough room for search\");\n}\n\n/* ===========================================================================\n * Copy without compression as much as possible from the input stream, return\n * the current block state.\n * This function does not insert new strings in the dictionary since\n * uncompressible data is probably not useful. This function is used\n * only for the level=0 compression option.\n * NOTE: this function should be optimized to avoid extra copying from\n * window to pending_buf.\n */\nfunction deflate_stored(s, flush) {\n  /* Stored blocks are limited to 0xffff bytes, pending_buf is limited\n   * to pending_buf_size, and each stored block has a 5 byte header:\n   */\n  var max_block_size = 0xffff;\n\n  if (max_block_size > s.pending_buf_size - 5) {\n    max_block_size = s.pending_buf_size - 5;\n  }\n\n  /* Copy as much as possible from input to output: */\n  for (;;) {\n    /* Fill the window as much as possible: */\n    if (s.lookahead <= 1) {\n\n      //Assert(s->strstart < s->w_size+MAX_DIST(s) ||\n      //  s->block_start >= (long)s->w_size, \"slide too late\");\n//      if (!(s.strstart < s.w_size + (s.w_size - MIN_LOOKAHEAD) ||\n//        s.block_start >= s.w_size)) {\n//        throw  new Error(\"slide too late\");\n//      }\n\n      fill_window(s);\n      if (s.lookahead === 0 && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n\n      if (s.lookahead === 0) {\n        break;\n      }\n      /* flush the current block */\n    }\n    //Assert(s->block_start >= 0L, \"block gone\");\n//    if (s.block_start < 0) throw new Error(\"block gone\");\n\n    s.strstart += s.lookahead;\n    s.lookahead = 0;\n\n    /* Emit a stored block if pending_buf will be full: */\n    var max_start = s.block_start + max_block_size;\n\n    if (s.strstart === 0 || s.strstart >= max_start) {\n      /* strstart == 0 is possible when wraparound on 16-bit machine */\n      s.lookahead = s.strstart - max_start;\n      s.strstart = max_start;\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n\n\n    }\n    /* Flush if we may have to slide, otherwise block_start may become\n     * negative and the data will be gone:\n     */\n    if (s.strstart - s.block_start >= (s.w_size - MIN_LOOKAHEAD)) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n\n  s.insert = 0;\n\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n\n  if (s.strstart > s.block_start) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n\n  return BS_NEED_MORE;\n}\n\n/* ===========================================================================\n * Compress as much as possible from the input stream, return the current\n * block state.\n * This function does not perform lazy evaluation of matches and inserts\n * new strings in the dictionary only for unmatched strings or for short\n * matches. It is used only for the fast compression options.\n */\nfunction deflate_fast(s, flush) {\n  var hash_head;        /* head of the hash chain */\n  var bflush;           /* set if current block must be flushed */\n\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the next match, plus MIN_MATCH bytes to insert the\n     * string following the next match.\n     */\n    if (s.lookahead < MIN_LOOKAHEAD) {\n      fill_window(s);\n      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) {\n        break; /* flush the current block */\n      }\n    }\n\n    /* Insert the string window[strstart .. strstart+2] in the\n     * dictionary, and set hash_head to the head of the hash chain:\n     */\n    hash_head = 0/*NIL*/;\n    if (s.lookahead >= MIN_MATCH) {\n      /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n      s.head[s.ins_h] = s.strstart;\n      /***/\n    }\n\n    /* Find the longest match, discarding those <= prev_length.\n     * At this point we have always match_length < MIN_MATCH\n     */\n    if (hash_head !== 0/*NIL*/ && ((s.strstart - hash_head) <= (s.w_size - MIN_LOOKAHEAD))) {\n      /* To simplify the code, we prevent matches with the string\n       * of window index 0 (in particular we have to avoid a match\n       * of the string with itself at the start of the input file).\n       */\n      s.match_length = longest_match(s, hash_head);\n      /* longest_match() sets match_start */\n    }\n    if (s.match_length >= MIN_MATCH) {\n      // check_match(s, s.strstart, s.match_start, s.match_length); // for debug only\n\n      /*** _tr_tally_dist(s, s.strstart - s.match_start,\n                     s.match_length - MIN_MATCH, bflush); ***/\n      bflush = trees._tr_tally(s, s.strstart - s.match_start, s.match_length - MIN_MATCH);\n\n      s.lookahead -= s.match_length;\n\n      /* Insert new strings in the hash table only if the match length\n       * is not too large. This saves time but degrades compression.\n       */\n      if (s.match_length <= s.max_lazy_match/*max_insert_length*/ && s.lookahead >= MIN_MATCH) {\n        s.match_length--; /* string at strstart already in table */\n        do {\n          s.strstart++;\n          /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n          s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n          s.head[s.ins_h] = s.strstart;\n          /***/\n          /* strstart never exceeds WSIZE-MAX_MATCH, so there are\n           * always MIN_MATCH bytes ahead.\n           */\n        } while (--s.match_length !== 0);\n        s.strstart++;\n      } else\n      {\n        s.strstart += s.match_length;\n        s.match_length = 0;\n        s.ins_h = s.window[s.strstart];\n        /* UPDATE_HASH(s, s.ins_h, s.window[s.strstart+1]); */\n        s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + 1]) & s.hash_mask;\n\n//#if MIN_MATCH != 3\n//                Call UPDATE_HASH() MIN_MATCH-3 more times\n//#endif\n        /* If lookahead < MIN_MATCH, ins_h is garbage, but it does not\n         * matter since it will be recomputed at next deflate call.\n         */\n      }\n    } else {\n      /* No match, output a literal byte */\n      //Tracevv((stderr,\"%c\", s.window[s.strstart]));\n      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n      bflush = trees._tr_tally(s, 0, s.window[s.strstart]);\n\n      s.lookahead--;\n      s.strstart++;\n    }\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = ((s.strstart < (MIN_MATCH - 1)) ? s.strstart : MIN_MATCH - 1);\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n}\n\n/* ===========================================================================\n * Same as above, but achieves better compression. We use a lazy\n * evaluation for matches: a match is finally adopted only if there is\n * no better match at the next window position.\n */\nfunction deflate_slow(s, flush) {\n  var hash_head;          /* head of hash chain */\n  var bflush;              /* set if current block must be flushed */\n\n  var max_insert;\n\n  /* Process the input block. */\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the next match, plus MIN_MATCH bytes to insert the\n     * string following the next match.\n     */\n    if (s.lookahead < MIN_LOOKAHEAD) {\n      fill_window(s);\n      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) { break; } /* flush the current block */\n    }\n\n    /* Insert the string window[strstart .. strstart+2] in the\n     * dictionary, and set hash_head to the head of the hash chain:\n     */\n    hash_head = 0/*NIL*/;\n    if (s.lookahead >= MIN_MATCH) {\n      /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n      s.head[s.ins_h] = s.strstart;\n      /***/\n    }\n\n    /* Find the longest match, discarding those <= prev_length.\n     */\n    s.prev_length = s.match_length;\n    s.prev_match = s.match_start;\n    s.match_length = MIN_MATCH - 1;\n\n    if (hash_head !== 0/*NIL*/ && s.prev_length < s.max_lazy_match &&\n        s.strstart - hash_head <= (s.w_size - MIN_LOOKAHEAD)/*MAX_DIST(s)*/) {\n      /* To simplify the code, we prevent matches with the string\n       * of window index 0 (in particular we have to avoid a match\n       * of the string with itself at the start of the input file).\n       */\n      s.match_length = longest_match(s, hash_head);\n      /* longest_match() sets match_start */\n\n      if (s.match_length <= 5 &&\n         (s.strategy === Z_FILTERED || (s.match_length === MIN_MATCH && s.strstart - s.match_start > 4096/*TOO_FAR*/))) {\n\n        /* If prev_match is also MIN_MATCH, match_start is garbage\n         * but we will ignore the current match anyway.\n         */\n        s.match_length = MIN_MATCH - 1;\n      }\n    }\n    /* If there was a match at the previous step and the current\n     * match is not better, output the previous match:\n     */\n    if (s.prev_length >= MIN_MATCH && s.match_length <= s.prev_length) {\n      max_insert = s.strstart + s.lookahead - MIN_MATCH;\n      /* Do not insert strings in hash table beyond this. */\n\n      //check_match(s, s.strstart-1, s.prev_match, s.prev_length);\n\n      /***_tr_tally_dist(s, s.strstart - 1 - s.prev_match,\n                     s.prev_length - MIN_MATCH, bflush);***/\n      bflush = trees._tr_tally(s, s.strstart - 1 - s.prev_match, s.prev_length - MIN_MATCH);\n      /* Insert in hash table all strings up to the end of the match.\n       * strstart-1 and strstart are already inserted. If there is not\n       * enough lookahead, the last two strings are not inserted in\n       * the hash table.\n       */\n      s.lookahead -= s.prev_length - 1;\n      s.prev_length -= 2;\n      do {\n        if (++s.strstart <= max_insert) {\n          /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n          s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n          s.head[s.ins_h] = s.strstart;\n          /***/\n        }\n      } while (--s.prev_length !== 0);\n      s.match_available = 0;\n      s.match_length = MIN_MATCH - 1;\n      s.strstart++;\n\n      if (bflush) {\n        /*** FLUSH_BLOCK(s, 0); ***/\n        flush_block_only(s, false);\n        if (s.strm.avail_out === 0) {\n          return BS_NEED_MORE;\n        }\n        /***/\n      }\n\n    } else if (s.match_available) {\n      /* If there was no match at the previous position, output a\n       * single literal. If there was a match but the current match\n       * is longer, truncate the previous match to a single literal.\n       */\n      //Tracevv((stderr,\"%c\", s->window[s->strstart-1]));\n      /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/\n      bflush = trees._tr_tally(s, 0, s.window[s.strstart - 1]);\n\n      if (bflush) {\n        /*** FLUSH_BLOCK_ONLY(s, 0) ***/\n        flush_block_only(s, false);\n        /***/\n      }\n      s.strstart++;\n      s.lookahead--;\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n    } else {\n      /* There is no previous match to compare with, wait for\n       * the next step to decide.\n       */\n      s.match_available = 1;\n      s.strstart++;\n      s.lookahead--;\n    }\n  }\n  //Assert (flush != Z_NO_FLUSH, \"no flush?\");\n  if (s.match_available) {\n    //Tracevv((stderr,\"%c\", s->window[s->strstart-1]));\n    /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/\n    bflush = trees._tr_tally(s, 0, s.window[s.strstart - 1]);\n\n    s.match_available = 0;\n  }\n  s.insert = s.strstart < MIN_MATCH - 1 ? s.strstart : MIN_MATCH - 1;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n\n  return BS_BLOCK_DONE;\n}\n\n\n/* ===========================================================================\n * For Z_RLE, simply look for runs of bytes, generate matches only of distance\n * one.  Do not maintain a hash table.  (It will be regenerated if this run of\n * deflate switches away from Z_RLE.)\n */\nfunction deflate_rle(s, flush) {\n  var bflush;            /* set if current block must be flushed */\n  var prev;              /* byte at distance one to match */\n  var scan, strend;      /* scan goes up to strend for length of run */\n\n  var _win = s.window;\n\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the longest run, plus one for the unrolled loop.\n     */\n    if (s.lookahead <= MAX_MATCH) {\n      fill_window(s);\n      if (s.lookahead <= MAX_MATCH && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) { break; } /* flush the current block */\n    }\n\n    /* See how many times the previous byte repeats */\n    s.match_length = 0;\n    if (s.lookahead >= MIN_MATCH && s.strstart > 0) {\n      scan = s.strstart - 1;\n      prev = _win[scan];\n      if (prev === _win[++scan] && prev === _win[++scan] && prev === _win[++scan]) {\n        strend = s.strstart + MAX_MATCH;\n        do {\n          /*jshint noempty:false*/\n        } while (prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 scan < strend);\n        s.match_length = MAX_MATCH - (strend - scan);\n        if (s.match_length > s.lookahead) {\n          s.match_length = s.lookahead;\n        }\n      }\n      //Assert(scan <= s->window+(uInt)(s->window_size-1), \"wild scan\");\n    }\n\n    /* Emit match if have run of MIN_MATCH or longer, else emit literal */\n    if (s.match_length >= MIN_MATCH) {\n      //check_match(s, s.strstart, s.strstart - 1, s.match_length);\n\n      /*** _tr_tally_dist(s, 1, s.match_length - MIN_MATCH, bflush); ***/\n      bflush = trees._tr_tally(s, 1, s.match_length - MIN_MATCH);\n\n      s.lookahead -= s.match_length;\n      s.strstart += s.match_length;\n      s.match_length = 0;\n    } else {\n      /* No match, output a literal byte */\n      //Tracevv((stderr,\"%c\", s->window[s->strstart]));\n      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n      bflush = trees._tr_tally(s, 0, s.window[s.strstart]);\n\n      s.lookahead--;\n      s.strstart++;\n    }\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = 0;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n}\n\n/* ===========================================================================\n * For Z_HUFFMAN_ONLY, do not look for matches.  Do not maintain a hash table.\n * (It will be regenerated if this run of deflate switches away from Huffman.)\n */\nfunction deflate_huff(s, flush) {\n  var bflush;             /* set if current block must be flushed */\n\n  for (;;) {\n    /* Make sure that we have a literal to write. */\n    if (s.lookahead === 0) {\n      fill_window(s);\n      if (s.lookahead === 0) {\n        if (flush === Z_NO_FLUSH) {\n          return BS_NEED_MORE;\n        }\n        break;      /* flush the current block */\n      }\n    }\n\n    /* Output a literal byte */\n    s.match_length = 0;\n    //Tracevv((stderr,\"%c\", s->window[s->strstart]));\n    /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n    bflush = trees._tr_tally(s, 0, s.window[s.strstart]);\n    s.lookahead--;\n    s.strstart++;\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = 0;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n}\n\n/* Values for max_lazy_match, good_match and max_chain_length, depending on\n * the desired pack level (0..9). The values given below have been tuned to\n * exclude worst case performance for pathological files. Better values may be\n * found for specific files.\n */\nfunction Config(good_length, max_lazy, nice_length, max_chain, func) {\n  this.good_length = good_length;\n  this.max_lazy = max_lazy;\n  this.nice_length = nice_length;\n  this.max_chain = max_chain;\n  this.func = func;\n}\n\nvar configuration_table;\n\nconfiguration_table = [\n  /*      good lazy nice chain */\n  new Config(0, 0, 0, 0, deflate_stored),          /* 0 store only */\n  new Config(4, 4, 8, 4, deflate_fast),            /* 1 max speed, no lazy matches */\n  new Config(4, 5, 16, 8, deflate_fast),           /* 2 */\n  new Config(4, 6, 32, 32, deflate_fast),          /* 3 */\n\n  new Config(4, 4, 16, 16, deflate_slow),          /* 4 lazy matches */\n  new Config(8, 16, 32, 32, deflate_slow),         /* 5 */\n  new Config(8, 16, 128, 128, deflate_slow),       /* 6 */\n  new Config(8, 32, 128, 256, deflate_slow),       /* 7 */\n  new Config(32, 128, 258, 1024, deflate_slow),    /* 8 */\n  new Config(32, 258, 258, 4096, deflate_slow)     /* 9 max compression */\n];\n\n\n/* ===========================================================================\n * Initialize the \"longest match\" routines for a new zlib stream\n */\nfunction lm_init(s) {\n  s.window_size = 2 * s.w_size;\n\n  /*** CLEAR_HASH(s); ***/\n  zero(s.head); // Fill with NIL (= 0);\n\n  /* Set the default configuration parameters:\n   */\n  s.max_lazy_match = configuration_table[s.level].max_lazy;\n  s.good_match = configuration_table[s.level].good_length;\n  s.nice_match = configuration_table[s.level].nice_length;\n  s.max_chain_length = configuration_table[s.level].max_chain;\n\n  s.strstart = 0;\n  s.block_start = 0;\n  s.lookahead = 0;\n  s.insert = 0;\n  s.match_length = s.prev_length = MIN_MATCH - 1;\n  s.match_available = 0;\n  s.ins_h = 0;\n}\n\n\nfunction DeflateState() {\n  this.strm = null;            /* pointer back to this zlib stream */\n  this.status = 0;            /* as the name implies */\n  this.pending_buf = null;      /* output still pending */\n  this.pending_buf_size = 0;  /* size of pending_buf */\n  this.pending_out = 0;       /* next pending byte to output to the stream */\n  this.pending = 0;           /* nb of bytes in the pending buffer */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */\n  this.gzhead = null;         /* gzip header information to write */\n  this.gzindex = 0;           /* where in extra, name, or comment */\n  this.method = Z_DEFLATED; /* can only be DEFLATED */\n  this.last_flush = -1;   /* value of flush param for previous deflate call */\n\n  this.w_size = 0;  /* LZ77 window size (32K by default) */\n  this.w_bits = 0;  /* log2(w_size)  (8..16) */\n  this.w_mask = 0;  /* w_size - 1 */\n\n  this.window = null;\n  /* Sliding window. Input bytes are read into the second half of the window,\n   * and move to the first half later to keep a dictionary of at least wSize\n   * bytes. With this organization, matches are limited to a distance of\n   * wSize-MAX_MATCH bytes, but this ensures that IO is always\n   * performed with a length multiple of the block size.\n   */\n\n  this.window_size = 0;\n  /* Actual size of window: 2*wSize, except when the user input buffer\n   * is directly used as sliding window.\n   */\n\n  this.prev = null;\n  /* Link to older string with same hash index. To limit the size of this\n   * array to 64K, this link is maintained only for the last 32K strings.\n   * An index in this array is thus a window index modulo 32K.\n   */\n\n  this.head = null;   /* Heads of the hash chains or NIL. */\n\n  this.ins_h = 0;       /* hash index of string to be inserted */\n  this.hash_size = 0;   /* number of elements in hash table */\n  this.hash_bits = 0;   /* log2(hash_size) */\n  this.hash_mask = 0;   /* hash_size-1 */\n\n  this.hash_shift = 0;\n  /* Number of bits by which ins_h must be shifted at each input\n   * step. It must be such that after MIN_MATCH steps, the oldest\n   * byte no longer takes part in the hash key, that is:\n   *   hash_shift * MIN_MATCH >= hash_bits\n   */\n\n  this.block_start = 0;\n  /* Window position at the beginning of the current output block. Gets\n   * negative when the window is moved backwards.\n   */\n\n  this.match_length = 0;      /* length of best match */\n  this.prev_match = 0;        /* previous match */\n  this.match_available = 0;   /* set if previous match exists */\n  this.strstart = 0;          /* start of string to insert */\n  this.match_start = 0;       /* start of matching string */\n  this.lookahead = 0;         /* number of valid bytes ahead in window */\n\n  this.prev_length = 0;\n  /* Length of the best match at previous step. Matches not greater than this\n   * are discarded. This is used in the lazy match evaluation.\n   */\n\n  this.max_chain_length = 0;\n  /* To speed up deflation, hash chains are never searched beyond this\n   * length.  A higher limit improves compression ratio but degrades the\n   * speed.\n   */\n\n  this.max_lazy_match = 0;\n  /* Attempt to find a better match only when the current match is strictly\n   * smaller than this value. This mechanism is used only for compression\n   * levels >= 4.\n   */\n  // That's alias to max_lazy_match, don't use directly\n  //this.max_insert_length = 0;\n  /* Insert new strings in the hash table only if the match length is not\n   * greater than this length. This saves time but degrades compression.\n   * max_insert_length is used only for compression levels <= 3.\n   */\n\n  this.level = 0;     /* compression level (1..9) */\n  this.strategy = 0;  /* favor or force Huffman coding*/\n\n  this.good_match = 0;\n  /* Use a faster search when the previous match is longer than this */\n\n  this.nice_match = 0; /* Stop searching when current match exceeds this */\n\n              /* used by trees.c: */\n\n  /* Didn't use ct_data typedef below to suppress compiler warning */\n\n  // struct ct_data_s dyn_ltree[HEAP_SIZE];   /* literal and length tree */\n  // struct ct_data_s dyn_dtree[2*D_CODES+1]; /* distance tree */\n  // struct ct_data_s bl_tree[2*BL_CODES+1];  /* Huffman tree for bit lengths */\n\n  // Use flat array of DOUBLE size, with interleaved fata,\n  // because JS does not support effective\n  this.dyn_ltree  = new utils.Buf16(HEAP_SIZE * 2);\n  this.dyn_dtree  = new utils.Buf16((2 * D_CODES + 1) * 2);\n  this.bl_tree    = new utils.Buf16((2 * BL_CODES + 1) * 2);\n  zero(this.dyn_ltree);\n  zero(this.dyn_dtree);\n  zero(this.bl_tree);\n\n  this.l_desc   = null;         /* desc. for literal tree */\n  this.d_desc   = null;         /* desc. for distance tree */\n  this.bl_desc  = null;         /* desc. for bit length tree */\n\n  //ush bl_count[MAX_BITS+1];\n  this.bl_count = new utils.Buf16(MAX_BITS + 1);\n  /* number of codes at each bit length for an optimal tree */\n\n  //int heap[2*L_CODES+1];      /* heap used to build the Huffman trees */\n  this.heap = new utils.Buf16(2 * L_CODES + 1);  /* heap used to build the Huffman trees */\n  zero(this.heap);\n\n  this.heap_len = 0;               /* number of elements in the heap */\n  this.heap_max = 0;               /* element of largest frequency */\n  /* The sons of heap[n] are heap[2*n] and heap[2*n+1]. heap[0] is not used.\n   * The same heap array is used to build all trees.\n   */\n\n  this.depth = new utils.Buf16(2 * L_CODES + 1); //uch depth[2*L_CODES+1];\n  zero(this.depth);\n  /* Depth of each subtree used as tie breaker for trees of equal frequency\n   */\n\n  this.l_buf = 0;          /* buffer index for literals or lengths */\n\n  this.lit_bufsize = 0;\n  /* Size of match buffer for literals/lengths.  There are 4 reasons for\n   * limiting lit_bufsize to 64K:\n   *   - frequencies can be kept in 16 bit counters\n   *   - if compression is not successful for the first block, all input\n   *     data is still in the window so we can still emit a stored block even\n   *     when input comes from standard input.  (This can also be done for\n   *     all blocks if lit_bufsize is not greater than 32K.)\n   *   - if compression is not successful for a file smaller than 64K, we can\n   *     even emit a stored file instead of a stored block (saving 5 bytes).\n   *     This is applicable only for zip (not gzip or zlib).\n   *   - creating new Huffman trees less frequently may not provide fast\n   *     adaptation to changes in the input data statistics. (Take for\n   *     example a binary file with poorly compressible code followed by\n   *     a highly compressible string table.) Smaller buffer sizes give\n   *     fast adaptation but have of course the overhead of transmitting\n   *     trees more frequently.\n   *   - I can't count above 4\n   */\n\n  this.last_lit = 0;      /* running index in l_buf */\n\n  this.d_buf = 0;\n  /* Buffer index for distances. To simplify the code, d_buf and l_buf have\n   * the same number of elements. To use different lengths, an extra flag\n   * array would be necessary.\n   */\n\n  this.opt_len = 0;       /* bit length of current block with optimal trees */\n  this.static_len = 0;    /* bit length of current block with static trees */\n  this.matches = 0;       /* number of string matches in current block */\n  this.insert = 0;        /* bytes at end of window left to insert */\n\n\n  this.bi_buf = 0;\n  /* Output buffer. bits are inserted starting at the bottom (least\n   * significant bits).\n   */\n  this.bi_valid = 0;\n  /* Number of valid bits in bi_buf.  All bits above the last valid bit\n   * are always zero.\n   */\n\n  // Used for window memory init. We safely ignore it for JS. That makes\n  // sense only for pointers and memory check tools.\n  //this.high_water = 0;\n  /* High water mark offset in window for initialized bytes -- bytes above\n   * this are set to zero in order to avoid memory check warnings when\n   * longest match routines access bytes past the input.  This is then\n   * updated to the new high water mark.\n   */\n}\n\n\nfunction deflateResetKeep(strm) {\n  var s;\n\n  if (!strm || !strm.state) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n  strm.total_in = strm.total_out = 0;\n  strm.data_type = Z_UNKNOWN;\n\n  s = strm.state;\n  s.pending = 0;\n  s.pending_out = 0;\n\n  if (s.wrap < 0) {\n    s.wrap = -s.wrap;\n    /* was made negative by deflate(..., Z_FINISH); */\n  }\n  s.status = (s.wrap ? INIT_STATE : BUSY_STATE);\n  strm.adler = (s.wrap === 2) ?\n    0  // crc32(0, Z_NULL, 0)\n  :\n    1; // adler32(0, Z_NULL, 0)\n  s.last_flush = Z_NO_FLUSH;\n  trees._tr_init(s);\n  return Z_OK;\n}\n\n\nfunction deflateReset(strm) {\n  var ret = deflateResetKeep(strm);\n  if (ret === Z_OK) {\n    lm_init(strm.state);\n  }\n  return ret;\n}\n\n\nfunction deflateSetHeader(strm, head) {\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  if (strm.state.wrap !== 2) { return Z_STREAM_ERROR; }\n  strm.state.gzhead = head;\n  return Z_OK;\n}\n\n\nfunction deflateInit2(strm, level, method, windowBits, memLevel, strategy) {\n  if (!strm) { // === Z_NULL\n    return Z_STREAM_ERROR;\n  }\n  var wrap = 1;\n\n  if (level === Z_DEFAULT_COMPRESSION) {\n    level = 6;\n  }\n\n  if (windowBits < 0) { /* suppress zlib wrapper */\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n\n  else if (windowBits > 15) {\n    wrap = 2;           /* write gzip wrapper instead */\n    windowBits -= 16;\n  }\n\n\n  if (memLevel < 1 || memLevel > MAX_MEM_LEVEL || method !== Z_DEFLATED ||\n    windowBits < 8 || windowBits > 15 || level < 0 || level > 9 ||\n    strategy < 0 || strategy > Z_FIXED) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n\n  if (windowBits === 8) {\n    windowBits = 9;\n  }\n  /* until 256-byte window bug fixed */\n\n  var s = new DeflateState();\n\n  strm.state = s;\n  s.strm = strm;\n\n  s.wrap = wrap;\n  s.gzhead = null;\n  s.w_bits = windowBits;\n  s.w_size = 1 << s.w_bits;\n  s.w_mask = s.w_size - 1;\n\n  s.hash_bits = memLevel + 7;\n  s.hash_size = 1 << s.hash_bits;\n  s.hash_mask = s.hash_size - 1;\n  s.hash_shift = ~~((s.hash_bits + MIN_MATCH - 1) / MIN_MATCH);\n\n  s.window = new utils.Buf8(s.w_size * 2);\n  s.head = new utils.Buf16(s.hash_size);\n  s.prev = new utils.Buf16(s.w_size);\n\n  // Don't need mem init magic for JS.\n  //s.high_water = 0;  /* nothing written to s->window yet */\n\n  s.lit_bufsize = 1 << (memLevel + 6); /* 16K elements by default */\n\n  s.pending_buf_size = s.lit_bufsize * 4;\n\n  //overlay = (ushf *) ZALLOC(strm, s->lit_bufsize, sizeof(ush)+2);\n  //s->pending_buf = (uchf *) overlay;\n  s.pending_buf = new utils.Buf8(s.pending_buf_size);\n\n  // It is offset from `s.pending_buf` (size is `s.lit_bufsize * 2`)\n  //s->d_buf = overlay + s->lit_bufsize/sizeof(ush);\n  s.d_buf = 1 * s.lit_bufsize;\n\n  //s->l_buf = s->pending_buf + (1+sizeof(ush))*s->lit_bufsize;\n  s.l_buf = (1 + 2) * s.lit_bufsize;\n\n  s.level = level;\n  s.strategy = strategy;\n  s.method = method;\n\n  return deflateReset(strm);\n}\n\nfunction deflateInit(strm, level) {\n  return deflateInit2(strm, level, Z_DEFLATED, MAX_WBITS, DEF_MEM_LEVEL, Z_DEFAULT_STRATEGY);\n}\n\n\nfunction deflate(strm, flush) {\n  var old_flush, s;\n  var beg, val; // for gzip header write only\n\n  if (!strm || !strm.state ||\n    flush > Z_BLOCK || flush < 0) {\n    return strm ? err(strm, Z_STREAM_ERROR) : Z_STREAM_ERROR;\n  }\n\n  s = strm.state;\n\n  if (!strm.output ||\n      (!strm.input && strm.avail_in !== 0) ||\n      (s.status === FINISH_STATE && flush !== Z_FINISH)) {\n    return err(strm, (strm.avail_out === 0) ? Z_BUF_ERROR : Z_STREAM_ERROR);\n  }\n\n  s.strm = strm; /* just in case */\n  old_flush = s.last_flush;\n  s.last_flush = flush;\n\n  /* Write the header */\n  if (s.status === INIT_STATE) {\n\n    if (s.wrap === 2) { // GZIP header\n      strm.adler = 0;  //crc32(0L, Z_NULL, 0);\n      put_byte(s, 31);\n      put_byte(s, 139);\n      put_byte(s, 8);\n      if (!s.gzhead) { // s->gzhead == Z_NULL\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, s.level === 9 ? 2 :\n                    (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?\n                     4 : 0));\n        put_byte(s, OS_CODE);\n        s.status = BUSY_STATE;\n      }\n      else {\n        put_byte(s, (s.gzhead.text ? 1 : 0) +\n                    (s.gzhead.hcrc ? 2 : 0) +\n                    (!s.gzhead.extra ? 0 : 4) +\n                    (!s.gzhead.name ? 0 : 8) +\n                    (!s.gzhead.comment ? 0 : 16)\n        );\n        put_byte(s, s.gzhead.time & 0xff);\n        put_byte(s, (s.gzhead.time >> 8) & 0xff);\n        put_byte(s, (s.gzhead.time >> 16) & 0xff);\n        put_byte(s, (s.gzhead.time >> 24) & 0xff);\n        put_byte(s, s.level === 9 ? 2 :\n                    (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?\n                     4 : 0));\n        put_byte(s, s.gzhead.os & 0xff);\n        if (s.gzhead.extra && s.gzhead.extra.length) {\n          put_byte(s, s.gzhead.extra.length & 0xff);\n          put_byte(s, (s.gzhead.extra.length >> 8) & 0xff);\n        }\n        if (s.gzhead.hcrc) {\n          strm.adler = crc32(strm.adler, s.pending_buf, s.pending, 0);\n        }\n        s.gzindex = 0;\n        s.status = EXTRA_STATE;\n      }\n    }\n    else // DEFLATE header\n    {\n      var header = (Z_DEFLATED + ((s.w_bits - 8) << 4)) << 8;\n      var level_flags = -1;\n\n      if (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2) {\n        level_flags = 0;\n      } else if (s.level < 6) {\n        level_flags = 1;\n      } else if (s.level === 6) {\n        level_flags = 2;\n      } else {\n        level_flags = 3;\n      }\n      header |= (level_flags << 6);\n      if (s.strstart !== 0) { header |= PRESET_DICT; }\n      header += 31 - (header % 31);\n\n      s.status = BUSY_STATE;\n      putShortMSB(s, header);\n\n      /* Save the adler32 of the preset dictionary: */\n      if (s.strstart !== 0) {\n        putShortMSB(s, strm.adler >>> 16);\n        putShortMSB(s, strm.adler & 0xffff);\n      }\n      strm.adler = 1; // adler32(0L, Z_NULL, 0);\n    }\n  }\n\n//#ifdef GZIP\n  if (s.status === EXTRA_STATE) {\n    if (s.gzhead.extra/* != Z_NULL*/) {\n      beg = s.pending;  /* start of bytes to update crc */\n\n      while (s.gzindex < (s.gzhead.extra.length & 0xffff)) {\n        if (s.pending === s.pending_buf_size) {\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          flush_pending(strm);\n          beg = s.pending;\n          if (s.pending === s.pending_buf_size) {\n            break;\n          }\n        }\n        put_byte(s, s.gzhead.extra[s.gzindex] & 0xff);\n        s.gzindex++;\n      }\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      if (s.gzindex === s.gzhead.extra.length) {\n        s.gzindex = 0;\n        s.status = NAME_STATE;\n      }\n    }\n    else {\n      s.status = NAME_STATE;\n    }\n  }\n  if (s.status === NAME_STATE) {\n    if (s.gzhead.name/* != Z_NULL*/) {\n      beg = s.pending;  /* start of bytes to update crc */\n      //int val;\n\n      do {\n        if (s.pending === s.pending_buf_size) {\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          flush_pending(strm);\n          beg = s.pending;\n          if (s.pending === s.pending_buf_size) {\n            val = 1;\n            break;\n          }\n        }\n        // JS specific: little magic to add zero terminator to end of string\n        if (s.gzindex < s.gzhead.name.length) {\n          val = s.gzhead.name.charCodeAt(s.gzindex++) & 0xff;\n        } else {\n          val = 0;\n        }\n        put_byte(s, val);\n      } while (val !== 0);\n\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      if (val === 0) {\n        s.gzindex = 0;\n        s.status = COMMENT_STATE;\n      }\n    }\n    else {\n      s.status = COMMENT_STATE;\n    }\n  }\n  if (s.status === COMMENT_STATE) {\n    if (s.gzhead.comment/* != Z_NULL*/) {\n      beg = s.pending;  /* start of bytes to update crc */\n      //int val;\n\n      do {\n        if (s.pending === s.pending_buf_size) {\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          flush_pending(strm);\n          beg = s.pending;\n          if (s.pending === s.pending_buf_size) {\n            val = 1;\n            break;\n          }\n        }\n        // JS specific: little magic to add zero terminator to end of string\n        if (s.gzindex < s.gzhead.comment.length) {\n          val = s.gzhead.comment.charCodeAt(s.gzindex++) & 0xff;\n        } else {\n          val = 0;\n        }\n        put_byte(s, val);\n      } while (val !== 0);\n\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      if (val === 0) {\n        s.status = HCRC_STATE;\n      }\n    }\n    else {\n      s.status = HCRC_STATE;\n    }\n  }\n  if (s.status === HCRC_STATE) {\n    if (s.gzhead.hcrc) {\n      if (s.pending + 2 > s.pending_buf_size) {\n        flush_pending(strm);\n      }\n      if (s.pending + 2 <= s.pending_buf_size) {\n        put_byte(s, strm.adler & 0xff);\n        put_byte(s, (strm.adler >> 8) & 0xff);\n        strm.adler = 0; //crc32(0L, Z_NULL, 0);\n        s.status = BUSY_STATE;\n      }\n    }\n    else {\n      s.status = BUSY_STATE;\n    }\n  }\n//#endif\n\n  /* Flush as much pending output as possible */\n  if (s.pending !== 0) {\n    flush_pending(strm);\n    if (strm.avail_out === 0) {\n      /* Since avail_out is 0, deflate will be called again with\n       * more output space, but possibly with both pending and\n       * avail_in equal to zero. There won't be anything to do,\n       * but this is not an error situation so make sure we\n       * return OK instead of BUF_ERROR at next call of deflate:\n       */\n      s.last_flush = -1;\n      return Z_OK;\n    }\n\n    /* Make sure there is something to do and avoid duplicate consecutive\n     * flushes. For repeated and useless calls with Z_FINISH, we keep\n     * returning Z_STREAM_END instead of Z_BUF_ERROR.\n     */\n  } else if (strm.avail_in === 0 && rank(flush) <= rank(old_flush) &&\n    flush !== Z_FINISH) {\n    return err(strm, Z_BUF_ERROR);\n  }\n\n  /* User must not provide more input after the first FINISH: */\n  if (s.status === FINISH_STATE && strm.avail_in !== 0) {\n    return err(strm, Z_BUF_ERROR);\n  }\n\n  /* Start a new block or continue the current one.\n   */\n  if (strm.avail_in !== 0 || s.lookahead !== 0 ||\n    (flush !== Z_NO_FLUSH && s.status !== FINISH_STATE)) {\n    var bstate = (s.strategy === Z_HUFFMAN_ONLY) ? deflate_huff(s, flush) :\n      (s.strategy === Z_RLE ? deflate_rle(s, flush) :\n        configuration_table[s.level].func(s, flush));\n\n    if (bstate === BS_FINISH_STARTED || bstate === BS_FINISH_DONE) {\n      s.status = FINISH_STATE;\n    }\n    if (bstate === BS_NEED_MORE || bstate === BS_FINISH_STARTED) {\n      if (strm.avail_out === 0) {\n        s.last_flush = -1;\n        /* avoid BUF_ERROR next call, see above */\n      }\n      return Z_OK;\n      /* If flush != Z_NO_FLUSH && avail_out == 0, the next call\n       * of deflate should use the same flush parameter to make sure\n       * that the flush is complete. So we don't have to output an\n       * empty block here, this will be done at next call. This also\n       * ensures that for a very small output buffer, we emit at most\n       * one empty block.\n       */\n    }\n    if (bstate === BS_BLOCK_DONE) {\n      if (flush === Z_PARTIAL_FLUSH) {\n        trees._tr_align(s);\n      }\n      else if (flush !== Z_BLOCK) { /* FULL_FLUSH or SYNC_FLUSH */\n\n        trees._tr_stored_block(s, 0, 0, false);\n        /* For a full flush, this empty block will be recognized\n         * as a special marker by inflate_sync().\n         */\n        if (flush === Z_FULL_FLUSH) {\n          /*** CLEAR_HASH(s); ***/             /* forget history */\n          zero(s.head); // Fill with NIL (= 0);\n\n          if (s.lookahead === 0) {\n            s.strstart = 0;\n            s.block_start = 0;\n            s.insert = 0;\n          }\n        }\n      }\n      flush_pending(strm);\n      if (strm.avail_out === 0) {\n        s.last_flush = -1; /* avoid BUF_ERROR at next call, see above */\n        return Z_OK;\n      }\n    }\n  }\n  //Assert(strm->avail_out > 0, \"bug2\");\n  //if (strm.avail_out <= 0) { throw new Error(\"bug2\");}\n\n  if (flush !== Z_FINISH) { return Z_OK; }\n  if (s.wrap <= 0) { return Z_STREAM_END; }\n\n  /* Write the trailer */\n  if (s.wrap === 2) {\n    put_byte(s, strm.adler & 0xff);\n    put_byte(s, (strm.adler >> 8) & 0xff);\n    put_byte(s, (strm.adler >> 16) & 0xff);\n    put_byte(s, (strm.adler >> 24) & 0xff);\n    put_byte(s, strm.total_in & 0xff);\n    put_byte(s, (strm.total_in >> 8) & 0xff);\n    put_byte(s, (strm.total_in >> 16) & 0xff);\n    put_byte(s, (strm.total_in >> 24) & 0xff);\n  }\n  else\n  {\n    putShortMSB(s, strm.adler >>> 16);\n    putShortMSB(s, strm.adler & 0xffff);\n  }\n\n  flush_pending(strm);\n  /* If avail_out is zero, the application will call deflate again\n   * to flush the rest.\n   */\n  if (s.wrap > 0) { s.wrap = -s.wrap; }\n  /* write the trailer only once! */\n  return s.pending !== 0 ? Z_OK : Z_STREAM_END;\n}\n\nfunction deflateEnd(strm) {\n  var status;\n\n  if (!strm/*== Z_NULL*/ || !strm.state/*== Z_NULL*/) {\n    return Z_STREAM_ERROR;\n  }\n\n  status = strm.state.status;\n  if (status !== INIT_STATE &&\n    status !== EXTRA_STATE &&\n    status !== NAME_STATE &&\n    status !== COMMENT_STATE &&\n    status !== HCRC_STATE &&\n    status !== BUSY_STATE &&\n    status !== FINISH_STATE\n  ) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n  strm.state = null;\n\n  return status === BUSY_STATE ? err(strm, Z_DATA_ERROR) : Z_OK;\n}\n\n\n/* =========================================================================\n * Initializes the compression dictionary from the given byte\n * sequence without producing any compressed output.\n */\nfunction deflateSetDictionary(strm, dictionary) {\n  var dictLength = dictionary.length;\n\n  var s;\n  var str, n;\n  var wrap;\n  var avail;\n  var next;\n  var input;\n  var tmpDict;\n\n  if (!strm/*== Z_NULL*/ || !strm.state/*== Z_NULL*/) {\n    return Z_STREAM_ERROR;\n  }\n\n  s = strm.state;\n  wrap = s.wrap;\n\n  if (wrap === 2 || (wrap === 1 && s.status !== INIT_STATE) || s.lookahead) {\n    return Z_STREAM_ERROR;\n  }\n\n  /* when using zlib wrappers, compute Adler-32 for provided dictionary */\n  if (wrap === 1) {\n    /* adler32(strm->adler, dictionary, dictLength); */\n    strm.adler = adler32(strm.adler, dictionary, dictLength, 0);\n  }\n\n  s.wrap = 0;   /* avoid computing Adler-32 in read_buf */\n\n  /* if dictionary would fill window, just replace the history */\n  if (dictLength >= s.w_size) {\n    if (wrap === 0) {            /* already empty otherwise */\n      /*** CLEAR_HASH(s); ***/\n      zero(s.head); // Fill with NIL (= 0);\n      s.strstart = 0;\n      s.block_start = 0;\n      s.insert = 0;\n    }\n    /* use the tail */\n    // dictionary = dictionary.slice(dictLength - s.w_size);\n    tmpDict = new utils.Buf8(s.w_size);\n    utils.arraySet(tmpDict, dictionary, dictLength - s.w_size, s.w_size, 0);\n    dictionary = tmpDict;\n    dictLength = s.w_size;\n  }\n  /* insert dictionary into window and hash */\n  avail = strm.avail_in;\n  next = strm.next_in;\n  input = strm.input;\n  strm.avail_in = dictLength;\n  strm.next_in = 0;\n  strm.input = dictionary;\n  fill_window(s);\n  while (s.lookahead >= MIN_MATCH) {\n    str = s.strstart;\n    n = s.lookahead - (MIN_MATCH - 1);\n    do {\n      /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + MIN_MATCH - 1]) & s.hash_mask;\n\n      s.prev[str & s.w_mask] = s.head[s.ins_h];\n\n      s.head[s.ins_h] = str;\n      str++;\n    } while (--n);\n    s.strstart = str;\n    s.lookahead = MIN_MATCH - 1;\n    fill_window(s);\n  }\n  s.strstart += s.lookahead;\n  s.block_start = s.strstart;\n  s.insert = s.lookahead;\n  s.lookahead = 0;\n  s.match_length = s.prev_length = MIN_MATCH - 1;\n  s.match_available = 0;\n  strm.next_in = next;\n  strm.input = input;\n  strm.avail_in = avail;\n  s.wrap = wrap;\n  return Z_OK;\n}\n\n\nexports.deflateInit = deflateInit;\nexports.deflateInit2 = deflateInit2;\nexports.deflateReset = deflateReset;\nexports.deflateResetKeep = deflateResetKeep;\nexports.deflateSetHeader = deflateSetHeader;\nexports.deflate = deflate;\nexports.deflateEnd = deflateEnd;\nexports.deflateSetDictionary = deflateSetDictionary;\nexports.deflateInfo = 'pako deflate (from Nodeca project)';\n\n/* Not implemented\nexports.deflateBound = deflateBound;\nexports.deflateCopy = deflateCopy;\nexports.deflateParams = deflateParams;\nexports.deflatePending = deflatePending;\nexports.deflatePrime = deflatePrime;\nexports.deflateTune = deflateTune;\n*/\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/deflate.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/inffast.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/inffast.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// See state defs from inflate.js\nvar BAD = 30;       /* got a data error -- remain here until reset */\nvar TYPE = 12;      /* i: waiting for type bits, including last-flag bit */\n\n/*\n   Decode literal, length, and distance codes and write out the resulting\n   literal and match bytes until either not enough input or output is\n   available, an end-of-block is encountered, or a data error is encountered.\n   When large enough input and output buffers are supplied to inflate(), for\n   example, a 16K input buffer and a 64K output buffer, more than 95% of the\n   inflate execution time is spent in this routine.\n\n   Entry assumptions:\n\n        state.mode === LEN\n        strm.avail_in >= 6\n        strm.avail_out >= 258\n        start >= strm.avail_out\n        state.bits < 8\n\n   On return, state.mode is one of:\n\n        LEN -- ran out of enough output space or enough available input\n        TYPE -- reached end of block code, inflate() to interpret next block\n        BAD -- error in block data\n\n   Notes:\n\n    - The maximum input bits used by a length/distance pair is 15 bits for the\n      length code, 5 bits for the length extra, 15 bits for the distance code,\n      and 13 bits for the distance extra.  This totals 48 bits, or six bytes.\n      Therefore if strm.avail_in >= 6, then there is enough input to avoid\n      checking for available input while decoding.\n\n    - The maximum bytes that a single length/distance pair can output is 258\n      bytes, which is the maximum length that can be coded.  inflate_fast()\n      requires strm.avail_out >= 258 for each loop to avoid checking for\n      output space.\n */\nmodule.exports = function inflate_fast(strm, start) {\n  var state;\n  var _in;                    /* local strm.input */\n  var last;                   /* have enough input while in < last */\n  var _out;                   /* local strm.output */\n  var beg;                    /* inflate()'s initial strm.output */\n  var end;                    /* while out < end, enough space available */\n//#ifdef INFLATE_STRICT\n  var dmax;                   /* maximum distance from zlib header */\n//#endif\n  var wsize;                  /* window size or zero if not using window */\n  var whave;                  /* valid bytes in the window */\n  var wnext;                  /* window write index */\n  // Use `s_window` instead `window`, avoid conflict with instrumentation tools\n  var s_window;               /* allocated sliding window, if wsize != 0 */\n  var hold;                   /* local strm.hold */\n  var bits;                   /* local strm.bits */\n  var lcode;                  /* local strm.lencode */\n  var dcode;                  /* local strm.distcode */\n  var lmask;                  /* mask for first level of length codes */\n  var dmask;                  /* mask for first level of distance codes */\n  var here;                   /* retrieved table entry */\n  var op;                     /* code bits, operation, extra bits, or */\n                              /*  window position, window bytes to copy */\n  var len;                    /* match length, unused bytes */\n  var dist;                   /* match distance */\n  var from;                   /* where to copy match from */\n  var from_source;\n\n\n  var input, output; // JS specific, because we have no pointers\n\n  /* copy state to local variables */\n  state = strm.state;\n  //here = state.here;\n  _in = strm.next_in;\n  input = strm.input;\n  last = _in + (strm.avail_in - 5);\n  _out = strm.next_out;\n  output = strm.output;\n  beg = _out - (start - strm.avail_out);\n  end = _out + (strm.avail_out - 257);\n//#ifdef INFLATE_STRICT\n  dmax = state.dmax;\n//#endif\n  wsize = state.wsize;\n  whave = state.whave;\n  wnext = state.wnext;\n  s_window = state.window;\n  hold = state.hold;\n  bits = state.bits;\n  lcode = state.lencode;\n  dcode = state.distcode;\n  lmask = (1 << state.lenbits) - 1;\n  dmask = (1 << state.distbits) - 1;\n\n\n  /* decode literals and length/distances until end-of-block or not enough\n     input data or output space */\n\n  top:\n  do {\n    if (bits < 15) {\n      hold += input[_in++] << bits;\n      bits += 8;\n      hold += input[_in++] << bits;\n      bits += 8;\n    }\n\n    here = lcode[hold & lmask];\n\n    dolen:\n    for (;;) { // Goto emulation\n      op = here >>> 24/*here.bits*/;\n      hold >>>= op;\n      bits -= op;\n      op = (here >>> 16) & 0xff/*here.op*/;\n      if (op === 0) {                          /* literal */\n        //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n        //        \"inflate:         literal '%c'\\n\" :\n        //        \"inflate:         literal 0x%02x\\n\", here.val));\n        output[_out++] = here & 0xffff/*here.val*/;\n      }\n      else if (op & 16) {                     /* length base */\n        len = here & 0xffff/*here.val*/;\n        op &= 15;                           /* number of extra bits */\n        if (op) {\n          if (bits < op) {\n            hold += input[_in++] << bits;\n            bits += 8;\n          }\n          len += hold & ((1 << op) - 1);\n          hold >>>= op;\n          bits -= op;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", len));\n        if (bits < 15) {\n          hold += input[_in++] << bits;\n          bits += 8;\n          hold += input[_in++] << bits;\n          bits += 8;\n        }\n        here = dcode[hold & dmask];\n\n        dodist:\n        for (;;) { // goto emulation\n          op = here >>> 24/*here.bits*/;\n          hold >>>= op;\n          bits -= op;\n          op = (here >>> 16) & 0xff/*here.op*/;\n\n          if (op & 16) {                      /* distance base */\n            dist = here & 0xffff/*here.val*/;\n            op &= 15;                       /* number of extra bits */\n            if (bits < op) {\n              hold += input[_in++] << bits;\n              bits += 8;\n              if (bits < op) {\n                hold += input[_in++] << bits;\n                bits += 8;\n              }\n            }\n            dist += hold & ((1 << op) - 1);\n//#ifdef INFLATE_STRICT\n            if (dist > dmax) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break top;\n            }\n//#endif\n            hold >>>= op;\n            bits -= op;\n            //Tracevv((stderr, \"inflate:         distance %u\\n\", dist));\n            op = _out - beg;                /* max distance in output */\n            if (dist > op) {                /* see if copy from window */\n              op = dist - op;               /* distance back in window */\n              if (op > whave) {\n                if (state.sane) {\n                  strm.msg = 'invalid distance too far back';\n                  state.mode = BAD;\n                  break top;\n                }\n\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//                if (len <= op - whave) {\n//                  do {\n//                    output[_out++] = 0;\n//                  } while (--len);\n//                  continue top;\n//                }\n//                len -= op - whave;\n//                do {\n//                  output[_out++] = 0;\n//                } while (--op > whave);\n//                if (op === 0) {\n//                  from = _out - dist;\n//                  do {\n//                    output[_out++] = output[from++];\n//                  } while (--len);\n//                  continue top;\n//                }\n//#endif\n              }\n              from = 0; // window index\n              from_source = s_window;\n              if (wnext === 0) {           /* very common case */\n                from += wsize - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              else if (wnext < op) {      /* wrap around window */\n                from += wsize + wnext - op;\n                op -= wnext;\n                if (op < len) {         /* some from end of window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = 0;\n                  if (wnext < len) {  /* some from start of window */\n                    op = wnext;\n                    len -= op;\n                    do {\n                      output[_out++] = s_window[from++];\n                    } while (--op);\n                    from = _out - dist;      /* rest from output */\n                    from_source = output;\n                  }\n                }\n              }\n              else {                      /* contiguous in window */\n                from += wnext - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              while (len > 2) {\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                len -= 3;\n              }\n              if (len) {\n                output[_out++] = from_source[from++];\n                if (len > 1) {\n                  output[_out++] = from_source[from++];\n                }\n              }\n            }\n            else {\n              from = _out - dist;          /* copy direct from output */\n              do {                        /* minimum length is three */\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                len -= 3;\n              } while (len > 2);\n              if (len) {\n                output[_out++] = output[from++];\n                if (len > 1) {\n                  output[_out++] = output[from++];\n                }\n              }\n            }\n          }\n          else if ((op & 64) === 0) {          /* 2nd level distance code */\n            here = dcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n            continue dodist;\n          }\n          else {\n            strm.msg = 'invalid distance code';\n            state.mode = BAD;\n            break top;\n          }\n\n          break; // need to emulate goto via \"continue\"\n        }\n      }\n      else if ((op & 64) === 0) {              /* 2nd level length code */\n        here = lcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n        continue dolen;\n      }\n      else if (op & 32) {                     /* end-of-block */\n        //Tracevv((stderr, \"inflate:         end of block\\n\"));\n        state.mode = TYPE;\n        break top;\n      }\n      else {\n        strm.msg = 'invalid literal/length code';\n        state.mode = BAD;\n        break top;\n      }\n\n      break; // need to emulate goto via \"continue\"\n    }\n  } while (_in < last && _out < end);\n\n  /* return unused bytes (on entry, bits < 8, so in won't go too far back) */\n  len = bits >> 3;\n  _in -= len;\n  bits -= len << 3;\n  hold &= (1 << bits) - 1;\n\n  /* update state and return */\n  strm.next_in = _in;\n  strm.next_out = _out;\n  strm.avail_in = (_in < last ? 5 + (last - _in) : 5 - (_in - last));\n  strm.avail_out = (_out < end ? 257 + (end - _out) : 257 - (_out - end));\n  state.hold = hold;\n  state.bits = bits;\n  return;\n};\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/inffast.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/inflate.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/inflate.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils         = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\nvar adler32       = __webpack_require__(/*! ./adler32 */ \"./node_modules/pako/lib/zlib/adler32.js\");\nvar crc32         = __webpack_require__(/*! ./crc32 */ \"./node_modules/pako/lib/zlib/crc32.js\");\nvar inflate_fast  = __webpack_require__(/*! ./inffast */ \"./node_modules/pako/lib/zlib/inffast.js\");\nvar inflate_table = __webpack_require__(/*! ./inftrees */ \"./node_modules/pako/lib/zlib/inftrees.js\");\n\nvar CODES = 0;\nvar LENS = 1;\nvar DISTS = 2;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n/* Allowed flush values; see deflate() and inflate() below for details */\n//var Z_NO_FLUSH      = 0;\n//var Z_PARTIAL_FLUSH = 1;\n//var Z_SYNC_FLUSH    = 2;\n//var Z_FULL_FLUSH    = 3;\nvar Z_FINISH        = 4;\nvar Z_BLOCK         = 5;\nvar Z_TREES         = 6;\n\n\n/* Return codes for the compression/decompression functions. Negative values\n * are errors, positive values are used for special but normal events.\n */\nvar Z_OK            = 0;\nvar Z_STREAM_END    = 1;\nvar Z_NEED_DICT     = 2;\n//var Z_ERRNO         = -1;\nvar Z_STREAM_ERROR  = -2;\nvar Z_DATA_ERROR    = -3;\nvar Z_MEM_ERROR     = -4;\nvar Z_BUF_ERROR     = -5;\n//var Z_VERSION_ERROR = -6;\n\n/* The deflate compression method */\nvar Z_DEFLATED  = 8;\n\n\n/* STATES ====================================================================*/\n/* ===========================================================================*/\n\n\nvar    HEAD = 1;       /* i: waiting for magic header */\nvar    FLAGS = 2;      /* i: waiting for method and flags (gzip) */\nvar    TIME = 3;       /* i: waiting for modification time (gzip) */\nvar    OS = 4;         /* i: waiting for extra flags and operating system (gzip) */\nvar    EXLEN = 5;      /* i: waiting for extra length (gzip) */\nvar    EXTRA = 6;      /* i: waiting for extra bytes (gzip) */\nvar    NAME = 7;       /* i: waiting for end of file name (gzip) */\nvar    COMMENT = 8;    /* i: waiting for end of comment (gzip) */\nvar    HCRC = 9;       /* i: waiting for header crc (gzip) */\nvar    DICTID = 10;    /* i: waiting for dictionary check value */\nvar    DICT = 11;      /* waiting for inflateSetDictionary() call */\nvar        TYPE = 12;      /* i: waiting for type bits, including last-flag bit */\nvar        TYPEDO = 13;    /* i: same, but skip check to exit inflate on new block */\nvar        STORED = 14;    /* i: waiting for stored size (length and complement) */\nvar        COPY_ = 15;     /* i/o: same as COPY below, but only first time in */\nvar        COPY = 16;      /* i/o: waiting for input or output to copy stored block */\nvar        TABLE = 17;     /* i: waiting for dynamic block table lengths */\nvar        LENLENS = 18;   /* i: waiting for code length code lengths */\nvar        CODELENS = 19;  /* i: waiting for length/lit and distance code lengths */\nvar            LEN_ = 20;      /* i: same as LEN below, but only first time in */\nvar            LEN = 21;       /* i: waiting for length/lit/eob code */\nvar            LENEXT = 22;    /* i: waiting for length extra bits */\nvar            DIST = 23;      /* i: waiting for distance code */\nvar            DISTEXT = 24;   /* i: waiting for distance extra bits */\nvar            MATCH = 25;     /* o: waiting for output space to copy string */\nvar            LIT = 26;       /* o: waiting for output space to write literal */\nvar    CHECK = 27;     /* i: waiting for 32-bit check value */\nvar    LENGTH = 28;    /* i: waiting for 32-bit length (gzip) */\nvar    DONE = 29;      /* finished check, done -- remain here until reset */\nvar    BAD = 30;       /* got a data error -- remain here until reset */\nvar    MEM = 31;       /* got an inflate() memory error -- remain here until reset */\nvar    SYNC = 32;      /* looking for synchronization bytes to restart inflate() */\n\n/* ===========================================================================*/\n\n\n\nvar ENOUGH_LENS = 852;\nvar ENOUGH_DISTS = 592;\n//var ENOUGH =  (ENOUGH_LENS+ENOUGH_DISTS);\n\nvar MAX_WBITS = 15;\n/* 32K LZ77 window */\nvar DEF_WBITS = MAX_WBITS;\n\n\nfunction zswap32(q) {\n  return  (((q >>> 24) & 0xff) +\n          ((q >>> 8) & 0xff00) +\n          ((q & 0xff00) << 8) +\n          ((q & 0xff) << 24));\n}\n\n\nfunction InflateState() {\n  this.mode = 0;             /* current inflate mode */\n  this.last = false;          /* true if processing last block */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */\n  this.havedict = false;      /* true if dictionary provided */\n  this.flags = 0;             /* gzip header method and flags (0 if zlib) */\n  this.dmax = 0;              /* zlib header max distance (INFLATE_STRICT) */\n  this.check = 0;             /* protected copy of check value */\n  this.total = 0;             /* protected copy of output count */\n  // TODO: may be {}\n  this.head = null;           /* where to save gzip header information */\n\n  /* sliding window */\n  this.wbits = 0;             /* log base 2 of requested window size */\n  this.wsize = 0;             /* window size or zero if not using window */\n  this.whave = 0;             /* valid bytes in the window */\n  this.wnext = 0;             /* window write index */\n  this.window = null;         /* allocated sliding window, if needed */\n\n  /* bit accumulator */\n  this.hold = 0;              /* input bit accumulator */\n  this.bits = 0;              /* number of bits in \"in\" */\n\n  /* for string and stored block copying */\n  this.length = 0;            /* literal or length of data to copy */\n  this.offset = 0;            /* distance back to copy string from */\n\n  /* for table and code decoding */\n  this.extra = 0;             /* extra bits needed */\n\n  /* fixed and dynamic code tables */\n  this.lencode = null;          /* starting table for length/literal codes */\n  this.distcode = null;         /* starting table for distance codes */\n  this.lenbits = 0;           /* index bits for lencode */\n  this.distbits = 0;          /* index bits for distcode */\n\n  /* dynamic table building */\n  this.ncode = 0;             /* number of code length code lengths */\n  this.nlen = 0;              /* number of length code lengths */\n  this.ndist = 0;             /* number of distance code lengths */\n  this.have = 0;              /* number of code lengths in lens[] */\n  this.next = null;              /* next available space in codes[] */\n\n  this.lens = new utils.Buf16(320); /* temporary storage for code lengths */\n  this.work = new utils.Buf16(288); /* work area for code table building */\n\n  /*\n   because we don't have pointers in js, we use lencode and distcode directly\n   as buffers so we don't need codes\n  */\n  //this.codes = new utils.Buf32(ENOUGH);       /* space for code tables */\n  this.lendyn = null;              /* dynamic table for length/literal codes (JS specific) */\n  this.distdyn = null;             /* dynamic table for distance codes (JS specific) */\n  this.sane = 0;                   /* if false, allow invalid distance too far */\n  this.back = 0;                   /* bits back of last unprocessed length/lit */\n  this.was = 0;                    /* initial length of match */\n}\n\nfunction inflateResetKeep(strm) {\n  var state;\n\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  strm.total_in = strm.total_out = state.total = 0;\n  strm.msg = ''; /*Z_NULL*/\n  if (state.wrap) {       /* to support ill-conceived Java test suite */\n    strm.adler = state.wrap & 1;\n  }\n  state.mode = HEAD;\n  state.last = 0;\n  state.havedict = 0;\n  state.dmax = 32768;\n  state.head = null/*Z_NULL*/;\n  state.hold = 0;\n  state.bits = 0;\n  //state.lencode = state.distcode = state.next = state.codes;\n  state.lencode = state.lendyn = new utils.Buf32(ENOUGH_LENS);\n  state.distcode = state.distdyn = new utils.Buf32(ENOUGH_DISTS);\n\n  state.sane = 1;\n  state.back = -1;\n  //Tracev((stderr, \"inflate: reset\\n\"));\n  return Z_OK;\n}\n\nfunction inflateReset(strm) {\n  var state;\n\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  state.wsize = 0;\n  state.whave = 0;\n  state.wnext = 0;\n  return inflateResetKeep(strm);\n\n}\n\nfunction inflateReset2(strm, windowBits) {\n  var wrap;\n  var state;\n\n  /* get the state */\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n\n  /* extract wrap request from windowBits parameter */\n  if (windowBits < 0) {\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n  else {\n    wrap = (windowBits >> 4) + 1;\n    if (windowBits < 48) {\n      windowBits &= 15;\n    }\n  }\n\n  /* set number of window bits, free window if different */\n  if (windowBits && (windowBits < 8 || windowBits > 15)) {\n    return Z_STREAM_ERROR;\n  }\n  if (state.window !== null && state.wbits !== windowBits) {\n    state.window = null;\n  }\n\n  /* update state and reset the rest of it */\n  state.wrap = wrap;\n  state.wbits = windowBits;\n  return inflateReset(strm);\n}\n\nfunction inflateInit2(strm, windowBits) {\n  var ret;\n  var state;\n\n  if (!strm) { return Z_STREAM_ERROR; }\n  //strm.msg = Z_NULL;                 /* in case we return an error */\n\n  state = new InflateState();\n\n  //if (state === Z_NULL) return Z_MEM_ERROR;\n  //Tracev((stderr, \"inflate: allocated\\n\"));\n  strm.state = state;\n  state.window = null/*Z_NULL*/;\n  ret = inflateReset2(strm, windowBits);\n  if (ret !== Z_OK) {\n    strm.state = null/*Z_NULL*/;\n  }\n  return ret;\n}\n\nfunction inflateInit(strm) {\n  return inflateInit2(strm, DEF_WBITS);\n}\n\n\n/*\n Return state with length and distance decoding tables and index sizes set to\n fixed code decoding.  Normally this returns fixed tables from inffixed.h.\n If BUILDFIXED is defined, then instead this routine builds the tables the\n first time it's called, and returns those tables the first time and\n thereafter.  This reduces the size of the code by about 2K bytes, in\n exchange for a little execution time.  However, BUILDFIXED should not be\n used for threaded applications, since the rewriting of the tables and virgin\n may not be thread-safe.\n */\nvar virgin = true;\n\nvar lenfix, distfix; // We have no pointers in JS, so keep tables separate\n\nfunction fixedtables(state) {\n  /* build fixed huffman tables if first call (may not be thread safe) */\n  if (virgin) {\n    var sym;\n\n    lenfix = new utils.Buf32(512);\n    distfix = new utils.Buf32(32);\n\n    /* literal/length table */\n    sym = 0;\n    while (sym < 144) { state.lens[sym++] = 8; }\n    while (sym < 256) { state.lens[sym++] = 9; }\n    while (sym < 280) { state.lens[sym++] = 7; }\n    while (sym < 288) { state.lens[sym++] = 8; }\n\n    inflate_table(LENS,  state.lens, 0, 288, lenfix,   0, state.work, { bits: 9 });\n\n    /* distance table */\n    sym = 0;\n    while (sym < 32) { state.lens[sym++] = 5; }\n\n    inflate_table(DISTS, state.lens, 0, 32,   distfix, 0, state.work, { bits: 5 });\n\n    /* do this just once */\n    virgin = false;\n  }\n\n  state.lencode = lenfix;\n  state.lenbits = 9;\n  state.distcode = distfix;\n  state.distbits = 5;\n}\n\n\n/*\n Update the window with the last wsize (normally 32K) bytes written before\n returning.  If window does not exist yet, create it.  This is only called\n when a window is already in use, or when output has been written during this\n inflate call, but the end of the deflate stream has not been reached yet.\n It is also called to create a window for dictionary data when a dictionary\n is loaded.\n\n Providing output buffers larger than 32K to inflate() should provide a speed\n advantage, since only the last 32K of output is copied to the sliding window\n upon return from inflate(), and since all distances after the first 32K of\n output will fall in the output data, making match copies simpler and faster.\n The advantage may be dependent on the size of the processor's data caches.\n */\nfunction updatewindow(strm, src, end, copy) {\n  var dist;\n  var state = strm.state;\n\n  /* if it hasn't been done already, allocate space for the window */\n  if (state.window === null) {\n    state.wsize = 1 << state.wbits;\n    state.wnext = 0;\n    state.whave = 0;\n\n    state.window = new utils.Buf8(state.wsize);\n  }\n\n  /* copy state->wsize or less output bytes into the circular window */\n  if (copy >= state.wsize) {\n    utils.arraySet(state.window, src, end - state.wsize, state.wsize, 0);\n    state.wnext = 0;\n    state.whave = state.wsize;\n  }\n  else {\n    dist = state.wsize - state.wnext;\n    if (dist > copy) {\n      dist = copy;\n    }\n    //zmemcpy(state->window + state->wnext, end - copy, dist);\n    utils.arraySet(state.window, src, end - copy, dist, state.wnext);\n    copy -= dist;\n    if (copy) {\n      //zmemcpy(state->window, end - copy, copy);\n      utils.arraySet(state.window, src, end - copy, copy, 0);\n      state.wnext = copy;\n      state.whave = state.wsize;\n    }\n    else {\n      state.wnext += dist;\n      if (state.wnext === state.wsize) { state.wnext = 0; }\n      if (state.whave < state.wsize) { state.whave += dist; }\n    }\n  }\n  return 0;\n}\n\nfunction inflate(strm, flush) {\n  var state;\n  var input, output;          // input/output buffers\n  var next;                   /* next input INDEX */\n  var put;                    /* next output INDEX */\n  var have, left;             /* available input and output */\n  var hold;                   /* bit buffer */\n  var bits;                   /* bits in bit buffer */\n  var _in, _out;              /* save starting available input and output */\n  var copy;                   /* number of stored or match bytes to copy */\n  var from;                   /* where to copy match bytes from */\n  var from_source;\n  var here = 0;               /* current decoding table entry */\n  var here_bits, here_op, here_val; // paked \"here\" denormalized (JS specific)\n  //var last;                   /* parent table entry */\n  var last_bits, last_op, last_val; // paked \"last\" denormalized (JS specific)\n  var len;                    /* length to copy for repeats, bits to drop */\n  var ret;                    /* return code */\n  var hbuf = new utils.Buf8(4);    /* buffer for gzip header crc calculation */\n  var opts;\n\n  var n; // temporary var for NEED_BITS\n\n  var order = /* permutation of code lengths */\n    [ 16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15 ];\n\n\n  if (!strm || !strm.state || !strm.output ||\n      (!strm.input && strm.avail_in !== 0)) {\n    return Z_STREAM_ERROR;\n  }\n\n  state = strm.state;\n  if (state.mode === TYPE) { state.mode = TYPEDO; }    /* skip check */\n\n\n  //--- LOAD() ---\n  put = strm.next_out;\n  output = strm.output;\n  left = strm.avail_out;\n  next = strm.next_in;\n  input = strm.input;\n  have = strm.avail_in;\n  hold = state.hold;\n  bits = state.bits;\n  //---\n\n  _in = have;\n  _out = left;\n  ret = Z_OK;\n\n  inf_leave: // goto emulation\n  for (;;) {\n    switch (state.mode) {\n      case HEAD:\n        if (state.wrap === 0) {\n          state.mode = TYPEDO;\n          break;\n        }\n        //=== NEEDBITS(16);\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((state.wrap & 2) && hold === 0x8b1f) {  /* gzip header */\n          state.check = 0/*crc32(0L, Z_NULL, 0)*/;\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          state.mode = FLAGS;\n          break;\n        }\n        state.flags = 0;           /* expect zlib header */\n        if (state.head) {\n          state.head.done = false;\n        }\n        if (!(state.wrap & 1) ||   /* check if zlib header allowed */\n          (((hold & 0xff)/*BITS(8)*/ << 8) + (hold >> 8)) % 31) {\n          strm.msg = 'incorrect header check';\n          state.mode = BAD;\n          break;\n        }\n        if ((hold & 0x0f)/*BITS(4)*/ !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n        len = (hold & 0x0f)/*BITS(4)*/ + 8;\n        if (state.wbits === 0) {\n          state.wbits = len;\n        }\n        else if (len > state.wbits) {\n          strm.msg = 'invalid window size';\n          state.mode = BAD;\n          break;\n        }\n        state.dmax = 1 << len;\n        //Tracev((stderr, \"inflate:   zlib header ok\\n\"));\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = hold & 0x200 ? DICTID : TYPE;\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        break;\n      case FLAGS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.flags = hold;\n        if ((state.flags & 0xff) !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        if (state.flags & 0xe000) {\n          strm.msg = 'unknown header flags set';\n          state.mode = BAD;\n          break;\n        }\n        if (state.head) {\n          state.head.text = ((hold >> 8) & 1);\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = TIME;\n        /* falls through */\n      case TIME:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.time = hold;\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC4(state.check, hold)\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          hbuf[2] = (hold >>> 16) & 0xff;\n          hbuf[3] = (hold >>> 24) & 0xff;\n          state.check = crc32(state.check, hbuf, 4, 0);\n          //===\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = OS;\n        /* falls through */\n      case OS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.xflags = (hold & 0xff);\n          state.head.os = (hold >> 8);\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = EXLEN;\n        /* falls through */\n      case EXLEN:\n        if (state.flags & 0x0400) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length = hold;\n          if (state.head) {\n            state.head.extra_len = hold;\n          }\n          if (state.flags & 0x0200) {\n            //=== CRC2(state.check, hold);\n            hbuf[0] = hold & 0xff;\n            hbuf[1] = (hold >>> 8) & 0xff;\n            state.check = crc32(state.check, hbuf, 2, 0);\n            //===//\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        else if (state.head) {\n          state.head.extra = null/*Z_NULL*/;\n        }\n        state.mode = EXTRA;\n        /* falls through */\n      case EXTRA:\n        if (state.flags & 0x0400) {\n          copy = state.length;\n          if (copy > have) { copy = have; }\n          if (copy) {\n            if (state.head) {\n              len = state.head.extra_len - state.length;\n              if (!state.head.extra) {\n                // Use untyped array for more convenient processing later\n                state.head.extra = new Array(state.head.extra_len);\n              }\n              utils.arraySet(\n                state.head.extra,\n                input,\n                next,\n                // extra field is limited to 65536 bytes\n                // - no need for additional size check\n                copy,\n                /*len + copy > state.head.extra_max - len ? state.head.extra_max : copy,*/\n                len\n              );\n              //zmemcpy(state.head.extra + len, next,\n              //        len + copy > state.head.extra_max ?\n              //        state.head.extra_max - len : copy);\n            }\n            if (state.flags & 0x0200) {\n              state.check = crc32(state.check, input, copy, next);\n            }\n            have -= copy;\n            next += copy;\n            state.length -= copy;\n          }\n          if (state.length) { break inf_leave; }\n        }\n        state.length = 0;\n        state.mode = NAME;\n        /* falls through */\n      case NAME:\n        if (state.flags & 0x0800) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            // TODO: 2 or 1 bytes?\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.name_max*/)) {\n              state.head.name += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n\n          if (state.flags & 0x0200) {\n            state.check = crc32(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.name = null;\n        }\n        state.length = 0;\n        state.mode = COMMENT;\n        /* falls through */\n      case COMMENT:\n        if (state.flags & 0x1000) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.comm_max*/)) {\n              state.head.comment += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n          if (state.flags & 0x0200) {\n            state.check = crc32(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.comment = null;\n        }\n        state.mode = HCRC;\n        /* falls through */\n      case HCRC:\n        if (state.flags & 0x0200) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if (hold !== (state.check & 0xffff)) {\n            strm.msg = 'header crc mismatch';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        if (state.head) {\n          state.head.hcrc = ((state.flags >> 9) & 1);\n          state.head.done = true;\n        }\n        strm.adler = state.check = 0;\n        state.mode = TYPE;\n        break;\n      case DICTID:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        strm.adler = state.check = zswap32(hold);\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = DICT;\n        /* falls through */\n      case DICT:\n        if (state.havedict === 0) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          return Z_NEED_DICT;\n        }\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = TYPE;\n        /* falls through */\n      case TYPE:\n        if (flush === Z_BLOCK || flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case TYPEDO:\n        if (state.last) {\n          //--- BYTEBITS() ---//\n          hold >>>= bits & 7;\n          bits -= bits & 7;\n          //---//\n          state.mode = CHECK;\n          break;\n        }\n        //=== NEEDBITS(3); */\n        while (bits < 3) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.last = (hold & 0x01)/*BITS(1)*/;\n        //--- DROPBITS(1) ---//\n        hold >>>= 1;\n        bits -= 1;\n        //---//\n\n        switch ((hold & 0x03)/*BITS(2)*/) {\n          case 0:                             /* stored block */\n            //Tracev((stderr, \"inflate:     stored block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = STORED;\n            break;\n          case 1:                             /* fixed block */\n            fixedtables(state);\n            //Tracev((stderr, \"inflate:     fixed codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = LEN_;             /* decode codes */\n            if (flush === Z_TREES) {\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n              break inf_leave;\n            }\n            break;\n          case 2:                             /* dynamic block */\n            //Tracev((stderr, \"inflate:     dynamic codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = TABLE;\n            break;\n          case 3:\n            strm.msg = 'invalid block type';\n            state.mode = BAD;\n        }\n        //--- DROPBITS(2) ---//\n        hold >>>= 2;\n        bits -= 2;\n        //---//\n        break;\n      case STORED:\n        //--- BYTEBITS() ---// /* go to byte boundary */\n        hold >>>= bits & 7;\n        bits -= bits & 7;\n        //---//\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((hold & 0xffff) !== ((hold >>> 16) ^ 0xffff)) {\n          strm.msg = 'invalid stored block lengths';\n          state.mode = BAD;\n          break;\n        }\n        state.length = hold & 0xffff;\n        //Tracev((stderr, \"inflate:       stored length %u\\n\",\n        //        state.length));\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = COPY_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case COPY_:\n        state.mode = COPY;\n        /* falls through */\n      case COPY:\n        copy = state.length;\n        if (copy) {\n          if (copy > have) { copy = have; }\n          if (copy > left) { copy = left; }\n          if (copy === 0) { break inf_leave; }\n          //--- zmemcpy(put, next, copy); ---\n          utils.arraySet(output, input, next, copy, put);\n          //---//\n          have -= copy;\n          next += copy;\n          left -= copy;\n          put += copy;\n          state.length -= copy;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       stored end\\n\"));\n        state.mode = TYPE;\n        break;\n      case TABLE:\n        //=== NEEDBITS(14); */\n        while (bits < 14) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.nlen = (hold & 0x1f)/*BITS(5)*/ + 257;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ndist = (hold & 0x1f)/*BITS(5)*/ + 1;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ncode = (hold & 0x0f)/*BITS(4)*/ + 4;\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n//#ifndef PKZIP_BUG_WORKAROUND\n        if (state.nlen > 286 || state.ndist > 30) {\n          strm.msg = 'too many length or distance symbols';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracev((stderr, \"inflate:       table sizes ok\\n\"));\n        state.have = 0;\n        state.mode = LENLENS;\n        /* falls through */\n      case LENLENS:\n        while (state.have < state.ncode) {\n          //=== NEEDBITS(3);\n          while (bits < 3) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.lens[order[state.have++]] = (hold & 0x07);//BITS(3);\n          //--- DROPBITS(3) ---//\n          hold >>>= 3;\n          bits -= 3;\n          //---//\n        }\n        while (state.have < 19) {\n          state.lens[order[state.have++]] = 0;\n        }\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        //state.next = state.codes;\n        //state.lencode = state.next;\n        // Switch to use dynamic table\n        state.lencode = state.lendyn;\n        state.lenbits = 7;\n\n        opts = { bits: state.lenbits };\n        ret = inflate_table(CODES, state.lens, 0, 19, state.lencode, 0, state.work, opts);\n        state.lenbits = opts.bits;\n\n        if (ret) {\n          strm.msg = 'invalid code lengths set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       code lengths ok\\n\"));\n        state.have = 0;\n        state.mode = CODELENS;\n        /* falls through */\n      case CODELENS:\n        while (state.have < state.nlen + state.ndist) {\n          for (;;) {\n            here = state.lencode[hold & ((1 << state.lenbits) - 1)];/*BITS(state.lenbits)*/\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          if (here_val < 16) {\n            //--- DROPBITS(here.bits) ---//\n            hold >>>= here_bits;\n            bits -= here_bits;\n            //---//\n            state.lens[state.have++] = here_val;\n          }\n          else {\n            if (here_val === 16) {\n              //=== NEEDBITS(here.bits + 2);\n              n = here_bits + 2;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              if (state.have === 0) {\n                strm.msg = 'invalid bit length repeat';\n                state.mode = BAD;\n                break;\n              }\n              len = state.lens[state.have - 1];\n              copy = 3 + (hold & 0x03);//BITS(2);\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n            }\n            else if (here_val === 17) {\n              //=== NEEDBITS(here.bits + 3);\n              n = here_bits + 3;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 3 + (hold & 0x07);//BITS(3);\n              //--- DROPBITS(3) ---//\n              hold >>>= 3;\n              bits -= 3;\n              //---//\n            }\n            else {\n              //=== NEEDBITS(here.bits + 7);\n              n = here_bits + 7;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 11 + (hold & 0x7f);//BITS(7);\n              //--- DROPBITS(7) ---//\n              hold >>>= 7;\n              bits -= 7;\n              //---//\n            }\n            if (state.have + copy > state.nlen + state.ndist) {\n              strm.msg = 'invalid bit length repeat';\n              state.mode = BAD;\n              break;\n            }\n            while (copy--) {\n              state.lens[state.have++] = len;\n            }\n          }\n        }\n\n        /* handle error breaks in while */\n        if (state.mode === BAD) { break; }\n\n        /* check for end-of-block code (better have one) */\n        if (state.lens[256] === 0) {\n          strm.msg = 'invalid code -- missing end-of-block';\n          state.mode = BAD;\n          break;\n        }\n\n        /* build code tables -- note: do not change the lenbits or distbits\n           values here (9 and 6) without reading the comments in inftrees.h\n           concerning the ENOUGH constants, which depend on those values */\n        state.lenbits = 9;\n\n        opts = { bits: state.lenbits };\n        ret = inflate_table(LENS, state.lens, 0, state.nlen, state.lencode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.lenbits = opts.bits;\n        // state.lencode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid literal/lengths set';\n          state.mode = BAD;\n          break;\n        }\n\n        state.distbits = 6;\n        //state.distcode.copy(state.codes);\n        // Switch to use dynamic table\n        state.distcode = state.distdyn;\n        opts = { bits: state.distbits };\n        ret = inflate_table(DISTS, state.lens, state.nlen, state.ndist, state.distcode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.distbits = opts.bits;\n        // state.distcode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid distances set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, 'inflate:       codes ok\\n'));\n        state.mode = LEN_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case LEN_:\n        state.mode = LEN;\n        /* falls through */\n      case LEN:\n        if (have >= 6 && left >= 258) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          inflate_fast(strm, _out);\n          //--- LOAD() ---\n          put = strm.next_out;\n          output = strm.output;\n          left = strm.avail_out;\n          next = strm.next_in;\n          input = strm.input;\n          have = strm.avail_in;\n          hold = state.hold;\n          bits = state.bits;\n          //---\n\n          if (state.mode === TYPE) {\n            state.back = -1;\n          }\n          break;\n        }\n        state.back = 0;\n        for (;;) {\n          here = state.lencode[hold & ((1 << state.lenbits) - 1)];  /*BITS(state.lenbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if (here_bits <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if (here_op && (here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.lencode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        state.length = here_val;\n        if (here_op === 0) {\n          //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n          //        \"inflate:         literal '%c'\\n\" :\n          //        \"inflate:         literal 0x%02x\\n\", here.val));\n          state.mode = LIT;\n          break;\n        }\n        if (here_op & 32) {\n          //Tracevv((stderr, \"inflate:         end of block\\n\"));\n          state.back = -1;\n          state.mode = TYPE;\n          break;\n        }\n        if (here_op & 64) {\n          strm.msg = 'invalid literal/length code';\n          state.mode = BAD;\n          break;\n        }\n        state.extra = here_op & 15;\n        state.mode = LENEXT;\n        /* falls through */\n      case LENEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", state.length));\n        state.was = state.length;\n        state.mode = DIST;\n        /* falls through */\n      case DIST:\n        for (;;) {\n          here = state.distcode[hold & ((1 << state.distbits) - 1)];/*BITS(state.distbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if ((here_bits) <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if ((here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.distcode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        if (here_op & 64) {\n          strm.msg = 'invalid distance code';\n          state.mode = BAD;\n          break;\n        }\n        state.offset = here_val;\n        state.extra = (here_op) & 15;\n        state.mode = DISTEXT;\n        /* falls through */\n      case DISTEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.offset += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n//#ifdef INFLATE_STRICT\n        if (state.offset > state.dmax) {\n          strm.msg = 'invalid distance too far back';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracevv((stderr, \"inflate:         distance %u\\n\", state.offset));\n        state.mode = MATCH;\n        /* falls through */\n      case MATCH:\n        if (left === 0) { break inf_leave; }\n        copy = _out - left;\n        if (state.offset > copy) {         /* copy from window */\n          copy = state.offset - copy;\n          if (copy > state.whave) {\n            if (state.sane) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break;\n            }\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//          Trace((stderr, \"inflate.c too far\\n\"));\n//          copy -= state.whave;\n//          if (copy > state.length) { copy = state.length; }\n//          if (copy > left) { copy = left; }\n//          left -= copy;\n//          state.length -= copy;\n//          do {\n//            output[put++] = 0;\n//          } while (--copy);\n//          if (state.length === 0) { state.mode = LEN; }\n//          break;\n//#endif\n          }\n          if (copy > state.wnext) {\n            copy -= state.wnext;\n            from = state.wsize - copy;\n          }\n          else {\n            from = state.wnext - copy;\n          }\n          if (copy > state.length) { copy = state.length; }\n          from_source = state.window;\n        }\n        else {                              /* copy from output */\n          from_source = output;\n          from = put - state.offset;\n          copy = state.length;\n        }\n        if (copy > left) { copy = left; }\n        left -= copy;\n        state.length -= copy;\n        do {\n          output[put++] = from_source[from++];\n        } while (--copy);\n        if (state.length === 0) { state.mode = LEN; }\n        break;\n      case LIT:\n        if (left === 0) { break inf_leave; }\n        output[put++] = state.length;\n        left--;\n        state.mode = LEN;\n        break;\n      case CHECK:\n        if (state.wrap) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            // Use '|' instead of '+' to make sure that result is signed\n            hold |= input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          _out -= left;\n          strm.total_out += _out;\n          state.total += _out;\n          if (_out) {\n            strm.adler = state.check =\n                /*UPDATE(state.check, put - _out, _out);*/\n                (state.flags ? crc32(state.check, output, _out, put - _out) : adler32(state.check, output, _out, put - _out));\n\n          }\n          _out = left;\n          // NB: crc32 stored as signed 32-bit int, zswap32 returns signed too\n          if ((state.flags ? hold : zswap32(hold)) !== state.check) {\n            strm.msg = 'incorrect data check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   check matches trailer\\n\"));\n        }\n        state.mode = LENGTH;\n        /* falls through */\n      case LENGTH:\n        if (state.wrap && state.flags) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if (hold !== (state.total & 0xffffffff)) {\n            strm.msg = 'incorrect length check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   length matches trailer\\n\"));\n        }\n        state.mode = DONE;\n        /* falls through */\n      case DONE:\n        ret = Z_STREAM_END;\n        break inf_leave;\n      case BAD:\n        ret = Z_DATA_ERROR;\n        break inf_leave;\n      case MEM:\n        return Z_MEM_ERROR;\n      case SYNC:\n        /* falls through */\n      default:\n        return Z_STREAM_ERROR;\n    }\n  }\n\n  // inf_leave <- here is real place for \"goto inf_leave\", emulated via \"break inf_leave\"\n\n  /*\n     Return from inflate(), updating the total counts and the check value.\n     If there was no progress during the inflate() call, return a buffer\n     error.  Call updatewindow() to create and/or update the window state.\n     Note: a memory error from inflate() is non-recoverable.\n   */\n\n  //--- RESTORE() ---\n  strm.next_out = put;\n  strm.avail_out = left;\n  strm.next_in = next;\n  strm.avail_in = have;\n  state.hold = hold;\n  state.bits = bits;\n  //---\n\n  if (state.wsize || (_out !== strm.avail_out && state.mode < BAD &&\n                      (state.mode < CHECK || flush !== Z_FINISH))) {\n    if (updatewindow(strm, strm.output, strm.next_out, _out - strm.avail_out)) {\n      state.mode = MEM;\n      return Z_MEM_ERROR;\n    }\n  }\n  _in -= strm.avail_in;\n  _out -= strm.avail_out;\n  strm.total_in += _in;\n  strm.total_out += _out;\n  state.total += _out;\n  if (state.wrap && _out) {\n    strm.adler = state.check = /*UPDATE(state.check, strm.next_out - _out, _out);*/\n      (state.flags ? crc32(state.check, output, _out, strm.next_out - _out) : adler32(state.check, output, _out, strm.next_out - _out));\n  }\n  strm.data_type = state.bits + (state.last ? 64 : 0) +\n                    (state.mode === TYPE ? 128 : 0) +\n                    (state.mode === LEN_ || state.mode === COPY_ ? 256 : 0);\n  if (((_in === 0 && _out === 0) || flush === Z_FINISH) && ret === Z_OK) {\n    ret = Z_BUF_ERROR;\n  }\n  return ret;\n}\n\nfunction inflateEnd(strm) {\n\n  if (!strm || !strm.state /*|| strm->zfree == (free_func)0*/) {\n    return Z_STREAM_ERROR;\n  }\n\n  var state = strm.state;\n  if (state.window) {\n    state.window = null;\n  }\n  strm.state = null;\n  return Z_OK;\n}\n\nfunction inflateGetHeader(strm, head) {\n  var state;\n\n  /* check state */\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  if ((state.wrap & 2) === 0) { return Z_STREAM_ERROR; }\n\n  /* save header structure */\n  state.head = head;\n  head.done = false;\n  return Z_OK;\n}\n\nfunction inflateSetDictionary(strm, dictionary) {\n  var dictLength = dictionary.length;\n\n  var state;\n  var dictid;\n  var ret;\n\n  /* check state */\n  if (!strm /* == Z_NULL */ || !strm.state /* == Z_NULL */) { return Z_STREAM_ERROR; }\n  state = strm.state;\n\n  if (state.wrap !== 0 && state.mode !== DICT) {\n    return Z_STREAM_ERROR;\n  }\n\n  /* check for correct dictionary identifier */\n  if (state.mode === DICT) {\n    dictid = 1; /* adler32(0, null, 0)*/\n    /* dictid = adler32(dictid, dictionary, dictLength); */\n    dictid = adler32(dictid, dictionary, dictLength, 0);\n    if (dictid !== state.check) {\n      return Z_DATA_ERROR;\n    }\n  }\n  /* copy dictionary to window using updatewindow(), which will amend the\n   existing dictionary if appropriate */\n  ret = updatewindow(strm, dictionary, dictLength, dictLength);\n  if (ret) {\n    state.mode = MEM;\n    return Z_MEM_ERROR;\n  }\n  state.havedict = 1;\n  // Tracev((stderr, \"inflate:   dictionary set\\n\"));\n  return Z_OK;\n}\n\nexports.inflateReset = inflateReset;\nexports.inflateReset2 = inflateReset2;\nexports.inflateResetKeep = inflateResetKeep;\nexports.inflateInit = inflateInit;\nexports.inflateInit2 = inflateInit2;\nexports.inflate = inflate;\nexports.inflateEnd = inflateEnd;\nexports.inflateGetHeader = inflateGetHeader;\nexports.inflateSetDictionary = inflateSetDictionary;\nexports.inflateInfo = 'pako inflate (from Nodeca project)';\n\n/* Not implemented\nexports.inflateCopy = inflateCopy;\nexports.inflateGetDictionary = inflateGetDictionary;\nexports.inflateMark = inflateMark;\nexports.inflatePrime = inflatePrime;\nexports.inflateSync = inflateSync;\nexports.inflateSyncPoint = inflateSyncPoint;\nexports.inflateUndermine = inflateUndermine;\n*/\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/inflate.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/inftrees.js":
/*!************************************************!*\
  !*** ./node_modules/pako/lib/zlib/inftrees.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\n\nvar MAXBITS = 15;\nvar ENOUGH_LENS = 852;\nvar ENOUGH_DISTS = 592;\n//var ENOUGH = (ENOUGH_LENS+ENOUGH_DISTS);\n\nvar CODES = 0;\nvar LENS = 1;\nvar DISTS = 2;\n\nvar lbase = [ /* Length codes 257..285 base */\n  3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,\n  35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0\n];\n\nvar lext = [ /* Length codes 257..285 extra */\n  16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18,\n  19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 16, 72, 78\n];\n\nvar dbase = [ /* Distance codes 0..29 base */\n  1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,\n  257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,\n  8193, 12289, 16385, 24577, 0, 0\n];\n\nvar dext = [ /* Distance codes 0..29 extra */\n  16, 16, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22,\n  23, 23, 24, 24, 25, 25, 26, 26, 27, 27,\n  28, 28, 29, 29, 64, 64\n];\n\nmodule.exports = function inflate_table(type, lens, lens_index, codes, table, table_index, work, opts)\n{\n  var bits = opts.bits;\n      //here = opts.here; /* table entry for duplication */\n\n  var len = 0;               /* a code's length in bits */\n  var sym = 0;               /* index of code symbols */\n  var min = 0, max = 0;          /* minimum and maximum code lengths */\n  var root = 0;              /* number of index bits for root table */\n  var curr = 0;              /* number of index bits for current table */\n  var drop = 0;              /* code bits to drop for sub-table */\n  var left = 0;                   /* number of prefix codes available */\n  var used = 0;              /* code entries in table used */\n  var huff = 0;              /* Huffman code */\n  var incr;              /* for incrementing code, index */\n  var fill;              /* index for replicating entries */\n  var low;               /* low bits for current root entry */\n  var mask;              /* mask for low root bits */\n  var next;             /* next available space in table */\n  var base = null;     /* base value table to use */\n  var base_index = 0;\n//  var shoextra;    /* extra bits table to use */\n  var end;                    /* use base and extra for symbol > end */\n  var count = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];    /* number of codes of each length */\n  var offs = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];     /* offsets in table for each length */\n  var extra = null;\n  var extra_index = 0;\n\n  var here_bits, here_op, here_val;\n\n  /*\n   Process a set of code lengths to create a canonical Huffman code.  The\n   code lengths are lens[0..codes-1].  Each length corresponds to the\n   symbols 0..codes-1.  The Huffman code is generated by first sorting the\n   symbols by length from short to long, and retaining the symbol order\n   for codes with equal lengths.  Then the code starts with all zero bits\n   for the first code of the shortest length, and the codes are integer\n   increments for the same length, and zeros are appended as the length\n   increases.  For the deflate format, these bits are stored backwards\n   from their more natural integer increment ordering, and so when the\n   decoding tables are built in the large loop below, the integer codes\n   are incremented backwards.\n\n   This routine assumes, but does not check, that all of the entries in\n   lens[] are in the range 0..MAXBITS.  The caller must assure this.\n   1..MAXBITS is interpreted as that code length.  zero means that that\n   symbol does not occur in this code.\n\n   The codes are sorted by computing a count of codes for each length,\n   creating from that a table of starting indices for each length in the\n   sorted table, and then entering the symbols in order in the sorted\n   table.  The sorted table is work[], with that space being provided by\n   the caller.\n\n   The length counts are used for other purposes as well, i.e. finding\n   the minimum and maximum length codes, determining if there are any\n   codes at all, checking for a valid set of lengths, and looking ahead\n   at length counts to determine sub-table sizes when building the\n   decoding tables.\n   */\n\n  /* accumulate lengths for codes (assumes lens[] all in 0..MAXBITS) */\n  for (len = 0; len <= MAXBITS; len++) {\n    count[len] = 0;\n  }\n  for (sym = 0; sym < codes; sym++) {\n    count[lens[lens_index + sym]]++;\n  }\n\n  /* bound code lengths, force root to be within code lengths */\n  root = bits;\n  for (max = MAXBITS; max >= 1; max--) {\n    if (count[max] !== 0) { break; }\n  }\n  if (root > max) {\n    root = max;\n  }\n  if (max === 0) {                     /* no symbols to code at all */\n    //table.op[opts.table_index] = 64;  //here.op = (var char)64;    /* invalid code marker */\n    //table.bits[opts.table_index] = 1;   //here.bits = (var char)1;\n    //table.val[opts.table_index++] = 0;   //here.val = (var short)0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n\n    //table.op[opts.table_index] = 64;\n    //table.bits[opts.table_index] = 1;\n    //table.val[opts.table_index++] = 0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n    opts.bits = 1;\n    return 0;     /* no symbols, but wait for decoding to report error */\n  }\n  for (min = 1; min < max; min++) {\n    if (count[min] !== 0) { break; }\n  }\n  if (root < min) {\n    root = min;\n  }\n\n  /* check for an over-subscribed or incomplete set of lengths */\n  left = 1;\n  for (len = 1; len <= MAXBITS; len++) {\n    left <<= 1;\n    left -= count[len];\n    if (left < 0) {\n      return -1;\n    }        /* over-subscribed */\n  }\n  if (left > 0 && (type === CODES || max !== 1)) {\n    return -1;                      /* incomplete set */\n  }\n\n  /* generate offsets into symbol table for each length for sorting */\n  offs[1] = 0;\n  for (len = 1; len < MAXBITS; len++) {\n    offs[len + 1] = offs[len] + count[len];\n  }\n\n  /* sort symbols by length, by symbol order within each length */\n  for (sym = 0; sym < codes; sym++) {\n    if (lens[lens_index + sym] !== 0) {\n      work[offs[lens[lens_index + sym]]++] = sym;\n    }\n  }\n\n  /*\n   Create and fill in decoding tables.  In this loop, the table being\n   filled is at next and has curr index bits.  The code being used is huff\n   with length len.  That code is converted to an index by dropping drop\n   bits off of the bottom.  For codes where len is less than drop + curr,\n   those top drop + curr - len bits are incremented through all values to\n   fill the table with replicated entries.\n\n   root is the number of index bits for the root table.  When len exceeds\n   root, sub-tables are created pointed to by the root entry with an index\n   of the low root bits of huff.  This is saved in low to check for when a\n   new sub-table should be started.  drop is zero when the root table is\n   being filled, and drop is root when sub-tables are being filled.\n\n   When a new sub-table is needed, it is necessary to look ahead in the\n   code lengths to determine what size sub-table is needed.  The length\n   counts are used for this, and so count[] is decremented as codes are\n   entered in the tables.\n\n   used keeps track of how many table entries have been allocated from the\n   provided *table space.  It is checked for LENS and DIST tables against\n   the constants ENOUGH_LENS and ENOUGH_DISTS to guard against changes in\n   the initial root table size constants.  See the comments in inftrees.h\n   for more information.\n\n   sym increments through all symbols, and the loop terminates when\n   all codes of length max, i.e. all codes, have been processed.  This\n   routine permits incomplete codes, so another loop after this one fills\n   in the rest of the decoding tables with invalid code markers.\n   */\n\n  /* set up for code type */\n  // poor man optimization - use if-else instead of switch,\n  // to avoid deopts in old v8\n  if (type === CODES) {\n    base = extra = work;    /* dummy value--not used */\n    end = 19;\n\n  } else if (type === LENS) {\n    base = lbase;\n    base_index -= 257;\n    extra = lext;\n    extra_index -= 257;\n    end = 256;\n\n  } else {                    /* DISTS */\n    base = dbase;\n    extra = dext;\n    end = -1;\n  }\n\n  /* initialize opts for loop */\n  huff = 0;                   /* starting code */\n  sym = 0;                    /* starting code symbol */\n  len = min;                  /* starting code length */\n  next = table_index;              /* current table to fill in */\n  curr = root;                /* current table index bits */\n  drop = 0;                   /* current bits to drop from code for index */\n  low = -1;                   /* trigger new sub-table when len > root */\n  used = 1 << root;          /* use root table entries */\n  mask = used - 1;            /* mask for comparing low */\n\n  /* check available table space */\n  if ((type === LENS && used > ENOUGH_LENS) ||\n    (type === DISTS && used > ENOUGH_DISTS)) {\n    return 1;\n  }\n\n  /* process all codes and make table entries */\n  for (;;) {\n    /* create table entry */\n    here_bits = len - drop;\n    if (work[sym] < end) {\n      here_op = 0;\n      here_val = work[sym];\n    }\n    else if (work[sym] > end) {\n      here_op = extra[extra_index + work[sym]];\n      here_val = base[base_index + work[sym]];\n    }\n    else {\n      here_op = 32 + 64;         /* end of block */\n      here_val = 0;\n    }\n\n    /* replicate for those indices with low len bits equal to huff */\n    incr = 1 << (len - drop);\n    fill = 1 << curr;\n    min = fill;                 /* save offset to next table */\n    do {\n      fill -= incr;\n      table[next + (huff >> drop) + fill] = (here_bits << 24) | (here_op << 16) | here_val |0;\n    } while (fill !== 0);\n\n    /* backwards increment the len-bit code huff */\n    incr = 1 << (len - 1);\n    while (huff & incr) {\n      incr >>= 1;\n    }\n    if (incr !== 0) {\n      huff &= incr - 1;\n      huff += incr;\n    } else {\n      huff = 0;\n    }\n\n    /* go to next symbol, update count, len */\n    sym++;\n    if (--count[len] === 0) {\n      if (len === max) { break; }\n      len = lens[lens_index + work[sym]];\n    }\n\n    /* create new sub-table if needed */\n    if (len > root && (huff & mask) !== low) {\n      /* if first time, transition to sub-tables */\n      if (drop === 0) {\n        drop = root;\n      }\n\n      /* increment past last table */\n      next += min;            /* here min is 1 << curr */\n\n      /* determine length of next table */\n      curr = len - drop;\n      left = 1 << curr;\n      while (curr + drop < max) {\n        left -= count[curr + drop];\n        if (left <= 0) { break; }\n        curr++;\n        left <<= 1;\n      }\n\n      /* check for enough space */\n      used += 1 << curr;\n      if ((type === LENS && used > ENOUGH_LENS) ||\n        (type === DISTS && used > ENOUGH_DISTS)) {\n        return 1;\n      }\n\n      /* point entry in root table to sub-table */\n      low = huff & mask;\n      /*table.op[low] = curr;\n      table.bits[low] = root;\n      table.val[low] = next - opts.table_index;*/\n      table[low] = (root << 24) | (curr << 16) | (next - table_index) |0;\n    }\n  }\n\n  /* fill in remaining table entry if code is incomplete (guaranteed to have\n   at most one remaining entry, since if the code is incomplete, the\n   maximum code length that was allowed to get this far is one bit) */\n  if (huff !== 0) {\n    //table.op[next + huff] = 64;            /* invalid code marker */\n    //table.bits[next + huff] = len - drop;\n    //table.val[next + huff] = 0;\n    table[next + huff] = ((len - drop) << 24) | (64 << 16) |0;\n  }\n\n  /* set return parameters */\n  //opts.table_index += used;\n  opts.bits = root;\n  return 0;\n};\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/inftrees.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/messages.js":
/*!************************************************!*\
  !*** ./node_modules/pako/lib/zlib/messages.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nmodule.exports = {\n  2:      'need dictionary',     /* Z_NEED_DICT       2  */\n  1:      'stream end',          /* Z_STREAM_END      1  */\n  0:      '',                    /* Z_OK              0  */\n  '-1':   'file error',          /* Z_ERRNO         (-1) */\n  '-2':   'stream error',        /* Z_STREAM_ERROR  (-2) */\n  '-3':   'data error',          /* Z_DATA_ERROR    (-3) */\n  '-4':   'insufficient memory', /* Z_MEM_ERROR     (-4) */\n  '-5':   'buffer error',        /* Z_BUF_ERROR     (-5) */\n  '-6':   'incompatible version' /* Z_VERSION_ERROR (-6) */\n};\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/messages.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/trees.js":
/*!*********************************************!*\
  !*** ./node_modules/pako/lib/zlib/trees.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n/* eslint-disable space-unary-ops */\n\nvar utils = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n//var Z_FILTERED          = 1;\n//var Z_HUFFMAN_ONLY      = 2;\n//var Z_RLE               = 3;\nvar Z_FIXED               = 4;\n//var Z_DEFAULT_STRATEGY  = 0;\n\n/* Possible values of the data_type field (though see inflate()) */\nvar Z_BINARY              = 0;\nvar Z_TEXT                = 1;\n//var Z_ASCII             = 1; // = Z_TEXT\nvar Z_UNKNOWN             = 2;\n\n/*============================================================================*/\n\n\nfunction zero(buf) { var len = buf.length; while (--len >= 0) { buf[len] = 0; } }\n\n// From zutil.h\n\nvar STORED_BLOCK = 0;\nvar STATIC_TREES = 1;\nvar DYN_TREES    = 2;\n/* The three kinds of block type */\n\nvar MIN_MATCH    = 3;\nvar MAX_MATCH    = 258;\n/* The minimum and maximum match lengths */\n\n// From deflate.h\n/* ===========================================================================\n * Internal compression state.\n */\n\nvar LENGTH_CODES  = 29;\n/* number of length codes, not counting the special END_BLOCK code */\n\nvar LITERALS      = 256;\n/* number of literal bytes 0..255 */\n\nvar L_CODES       = LITERALS + 1 + LENGTH_CODES;\n/* number of Literal or Length codes, including the END_BLOCK code */\n\nvar D_CODES       = 30;\n/* number of distance codes */\n\nvar BL_CODES      = 19;\n/* number of codes used to transfer the bit lengths */\n\nvar HEAP_SIZE     = 2 * L_CODES + 1;\n/* maximum heap size */\n\nvar MAX_BITS      = 15;\n/* All codes must not exceed MAX_BITS bits */\n\nvar Buf_size      = 16;\n/* size of bit buffer in bi_buf */\n\n\n/* ===========================================================================\n * Constants\n */\n\nvar MAX_BL_BITS = 7;\n/* Bit length codes must not exceed MAX_BL_BITS bits */\n\nvar END_BLOCK   = 256;\n/* end of block literal code */\n\nvar REP_3_6     = 16;\n/* repeat previous bit length 3-6 times (2 bits of repeat count) */\n\nvar REPZ_3_10   = 17;\n/* repeat a zero length 3-10 times  (3 bits of repeat count) */\n\nvar REPZ_11_138 = 18;\n/* repeat a zero length 11-138 times  (7 bits of repeat count) */\n\n/* eslint-disable comma-spacing,array-bracket-spacing */\nvar extra_lbits =   /* extra bits for each length code */\n  [0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0];\n\nvar extra_dbits =   /* extra bits for each distance code */\n  [0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13];\n\nvar extra_blbits =  /* extra bits for each bit length code */\n  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,3,7];\n\nvar bl_order =\n  [16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15];\n/* eslint-enable comma-spacing,array-bracket-spacing */\n\n/* The lengths of the bit length codes are sent in order of decreasing\n * probability, to avoid transmitting the lengths for unused bit length codes.\n */\n\n/* ===========================================================================\n * Local data. These are initialized only once.\n */\n\n// We pre-fill arrays with 0 to avoid uninitialized gaps\n\nvar DIST_CODE_LEN = 512; /* see definition of array dist_code below */\n\n// !!!! Use flat array instead of structure, Freq = i*2, Len = i*2+1\nvar static_ltree  = new Array((L_CODES + 2) * 2);\nzero(static_ltree);\n/* The static literal tree. Since the bit lengths are imposed, there is no\n * need for the L_CODES extra codes used during heap construction. However\n * The codes 286 and 287 are needed to build a canonical tree (see _tr_init\n * below).\n */\n\nvar static_dtree  = new Array(D_CODES * 2);\nzero(static_dtree);\n/* The static distance tree. (Actually a trivial tree since all codes use\n * 5 bits.)\n */\n\nvar _dist_code    = new Array(DIST_CODE_LEN);\nzero(_dist_code);\n/* Distance codes. The first 256 values correspond to the distances\n * 3 .. 258, the last 256 values correspond to the top 8 bits of\n * the 15 bit distances.\n */\n\nvar _length_code  = new Array(MAX_MATCH - MIN_MATCH + 1);\nzero(_length_code);\n/* length code for each normalized match length (0 == MIN_MATCH) */\n\nvar base_length   = new Array(LENGTH_CODES);\nzero(base_length);\n/* First normalized length for each code (0 = MIN_MATCH) */\n\nvar base_dist     = new Array(D_CODES);\nzero(base_dist);\n/* First normalized distance for each code (0 = distance of 1) */\n\n\nfunction StaticTreeDesc(static_tree, extra_bits, extra_base, elems, max_length) {\n\n  this.static_tree  = static_tree;  /* static tree or NULL */\n  this.extra_bits   = extra_bits;   /* extra bits for each code or NULL */\n  this.extra_base   = extra_base;   /* base index for extra_bits */\n  this.elems        = elems;        /* max number of elements in the tree */\n  this.max_length   = max_length;   /* max bit length for the codes */\n\n  // show if `static_tree` has data or dummy - needed for monomorphic objects\n  this.has_stree    = static_tree && static_tree.length;\n}\n\n\nvar static_l_desc;\nvar static_d_desc;\nvar static_bl_desc;\n\n\nfunction TreeDesc(dyn_tree, stat_desc) {\n  this.dyn_tree = dyn_tree;     /* the dynamic tree */\n  this.max_code = 0;            /* largest code with non zero frequency */\n  this.stat_desc = stat_desc;   /* the corresponding static tree */\n}\n\n\n\nfunction d_code(dist) {\n  return dist < 256 ? _dist_code[dist] : _dist_code[256 + (dist >>> 7)];\n}\n\n\n/* ===========================================================================\n * Output a short LSB first on the stream.\n * IN assertion: there is enough room in pendingBuf.\n */\nfunction put_short(s, w) {\n//    put_byte(s, (uch)((w) & 0xff));\n//    put_byte(s, (uch)((ush)(w) >> 8));\n  s.pending_buf[s.pending++] = (w) & 0xff;\n  s.pending_buf[s.pending++] = (w >>> 8) & 0xff;\n}\n\n\n/* ===========================================================================\n * Send a value on a given number of bits.\n * IN assertion: length <= 16 and value fits in length bits.\n */\nfunction send_bits(s, value, length) {\n  if (s.bi_valid > (Buf_size - length)) {\n    s.bi_buf |= (value << s.bi_valid) & 0xffff;\n    put_short(s, s.bi_buf);\n    s.bi_buf = value >> (Buf_size - s.bi_valid);\n    s.bi_valid += length - Buf_size;\n  } else {\n    s.bi_buf |= (value << s.bi_valid) & 0xffff;\n    s.bi_valid += length;\n  }\n}\n\n\nfunction send_code(s, c, tree) {\n  send_bits(s, tree[c * 2]/*.Code*/, tree[c * 2 + 1]/*.Len*/);\n}\n\n\n/* ===========================================================================\n * Reverse the first len bits of a code, using straightforward code (a faster\n * method would use a table)\n * IN assertion: 1 <= len <= 15\n */\nfunction bi_reverse(code, len) {\n  var res = 0;\n  do {\n    res |= code & 1;\n    code >>>= 1;\n    res <<= 1;\n  } while (--len > 0);\n  return res >>> 1;\n}\n\n\n/* ===========================================================================\n * Flush the bit buffer, keeping at most 7 bits in it.\n */\nfunction bi_flush(s) {\n  if (s.bi_valid === 16) {\n    put_short(s, s.bi_buf);\n    s.bi_buf = 0;\n    s.bi_valid = 0;\n\n  } else if (s.bi_valid >= 8) {\n    s.pending_buf[s.pending++] = s.bi_buf & 0xff;\n    s.bi_buf >>= 8;\n    s.bi_valid -= 8;\n  }\n}\n\n\n/* ===========================================================================\n * Compute the optimal bit lengths for a tree and update the total bit length\n * for the current block.\n * IN assertion: the fields freq and dad are set, heap[heap_max] and\n *    above are the tree nodes sorted by increasing frequency.\n * OUT assertions: the field len is set to the optimal bit length, the\n *     array bl_count contains the frequencies for each bit length.\n *     The length opt_len is updated; static_len is also updated if stree is\n *     not null.\n */\nfunction gen_bitlen(s, desc)\n//    deflate_state *s;\n//    tree_desc *desc;    /* the tree descriptor */\n{\n  var tree            = desc.dyn_tree;\n  var max_code        = desc.max_code;\n  var stree           = desc.stat_desc.static_tree;\n  var has_stree       = desc.stat_desc.has_stree;\n  var extra           = desc.stat_desc.extra_bits;\n  var base            = desc.stat_desc.extra_base;\n  var max_length      = desc.stat_desc.max_length;\n  var h;              /* heap index */\n  var n, m;           /* iterate over the tree elements */\n  var bits;           /* bit length */\n  var xbits;          /* extra bits */\n  var f;              /* frequency */\n  var overflow = 0;   /* number of elements with bit length too large */\n\n  for (bits = 0; bits <= MAX_BITS; bits++) {\n    s.bl_count[bits] = 0;\n  }\n\n  /* In a first pass, compute the optimal bit lengths (which may\n   * overflow in the case of the bit length tree).\n   */\n  tree[s.heap[s.heap_max] * 2 + 1]/*.Len*/ = 0; /* root of the heap */\n\n  for (h = s.heap_max + 1; h < HEAP_SIZE; h++) {\n    n = s.heap[h];\n    bits = tree[tree[n * 2 + 1]/*.Dad*/ * 2 + 1]/*.Len*/ + 1;\n    if (bits > max_length) {\n      bits = max_length;\n      overflow++;\n    }\n    tree[n * 2 + 1]/*.Len*/ = bits;\n    /* We overwrite tree[n].Dad which is no longer needed */\n\n    if (n > max_code) { continue; } /* not a leaf node */\n\n    s.bl_count[bits]++;\n    xbits = 0;\n    if (n >= base) {\n      xbits = extra[n - base];\n    }\n    f = tree[n * 2]/*.Freq*/;\n    s.opt_len += f * (bits + xbits);\n    if (has_stree) {\n      s.static_len += f * (stree[n * 2 + 1]/*.Len*/ + xbits);\n    }\n  }\n  if (overflow === 0) { return; }\n\n  // Trace((stderr,\"\\nbit length overflow\\n\"));\n  /* This happens for example on obj2 and pic of the Calgary corpus */\n\n  /* Find the first bit length which could increase: */\n  do {\n    bits = max_length - 1;\n    while (s.bl_count[bits] === 0) { bits--; }\n    s.bl_count[bits]--;      /* move one leaf down the tree */\n    s.bl_count[bits + 1] += 2; /* move one overflow item as its brother */\n    s.bl_count[max_length]--;\n    /* The brother of the overflow item also moves one step up,\n     * but this does not affect bl_count[max_length]\n     */\n    overflow -= 2;\n  } while (overflow > 0);\n\n  /* Now recompute all bit lengths, scanning in increasing frequency.\n   * h is still equal to HEAP_SIZE. (It is simpler to reconstruct all\n   * lengths instead of fixing only the wrong ones. This idea is taken\n   * from 'ar' written by Haruhiko Okumura.)\n   */\n  for (bits = max_length; bits !== 0; bits--) {\n    n = s.bl_count[bits];\n    while (n !== 0) {\n      m = s.heap[--h];\n      if (m > max_code) { continue; }\n      if (tree[m * 2 + 1]/*.Len*/ !== bits) {\n        // Trace((stderr,\"code %d bits %d->%d\\n\", m, tree[m].Len, bits));\n        s.opt_len += (bits - tree[m * 2 + 1]/*.Len*/) * tree[m * 2]/*.Freq*/;\n        tree[m * 2 + 1]/*.Len*/ = bits;\n      }\n      n--;\n    }\n  }\n}\n\n\n/* ===========================================================================\n * Generate the codes for a given tree and bit counts (which need not be\n * optimal).\n * IN assertion: the array bl_count contains the bit length statistics for\n * the given tree and the field len is set for all tree elements.\n * OUT assertion: the field code is set for all tree elements of non\n *     zero code length.\n */\nfunction gen_codes(tree, max_code, bl_count)\n//    ct_data *tree;             /* the tree to decorate */\n//    int max_code;              /* largest code with non zero frequency */\n//    ushf *bl_count;            /* number of codes at each bit length */\n{\n  var next_code = new Array(MAX_BITS + 1); /* next code value for each bit length */\n  var code = 0;              /* running code value */\n  var bits;                  /* bit index */\n  var n;                     /* code index */\n\n  /* The distribution counts are first used to generate the code values\n   * without bit reversal.\n   */\n  for (bits = 1; bits <= MAX_BITS; bits++) {\n    next_code[bits] = code = (code + bl_count[bits - 1]) << 1;\n  }\n  /* Check that the bit counts in bl_count are consistent. The last code\n   * must be all ones.\n   */\n  //Assert (code + bl_count[MAX_BITS]-1 == (1<<MAX_BITS)-1,\n  //        \"inconsistent bit counts\");\n  //Tracev((stderr,\"\\ngen_codes: max_code %d \", max_code));\n\n  for (n = 0;  n <= max_code; n++) {\n    var len = tree[n * 2 + 1]/*.Len*/;\n    if (len === 0) { continue; }\n    /* Now reverse the bits */\n    tree[n * 2]/*.Code*/ = bi_reverse(next_code[len]++, len);\n\n    //Tracecv(tree != static_ltree, (stderr,\"\\nn %3d %c l %2d c %4x (%x) \",\n    //     n, (isgraph(n) ? n : ' '), len, tree[n].Code, next_code[len]-1));\n  }\n}\n\n\n/* ===========================================================================\n * Initialize the various 'constant' tables.\n */\nfunction tr_static_init() {\n  var n;        /* iterates over tree elements */\n  var bits;     /* bit counter */\n  var length;   /* length value */\n  var code;     /* code value */\n  var dist;     /* distance index */\n  var bl_count = new Array(MAX_BITS + 1);\n  /* number of codes at each bit length for an optimal tree */\n\n  // do check in _tr_init()\n  //if (static_init_done) return;\n\n  /* For some embedded targets, global variables are not initialized: */\n/*#ifdef NO_INIT_GLOBAL_POINTERS\n  static_l_desc.static_tree = static_ltree;\n  static_l_desc.extra_bits = extra_lbits;\n  static_d_desc.static_tree = static_dtree;\n  static_d_desc.extra_bits = extra_dbits;\n  static_bl_desc.extra_bits = extra_blbits;\n#endif*/\n\n  /* Initialize the mapping length (0..255) -> length code (0..28) */\n  length = 0;\n  for (code = 0; code < LENGTH_CODES - 1; code++) {\n    base_length[code] = length;\n    for (n = 0; n < (1 << extra_lbits[code]); n++) {\n      _length_code[length++] = code;\n    }\n  }\n  //Assert (length == 256, \"tr_static_init: length != 256\");\n  /* Note that the length 255 (match length 258) can be represented\n   * in two different ways: code 284 + 5 bits or code 285, so we\n   * overwrite length_code[255] to use the best encoding:\n   */\n  _length_code[length - 1] = code;\n\n  /* Initialize the mapping dist (0..32K) -> dist code (0..29) */\n  dist = 0;\n  for (code = 0; code < 16; code++) {\n    base_dist[code] = dist;\n    for (n = 0; n < (1 << extra_dbits[code]); n++) {\n      _dist_code[dist++] = code;\n    }\n  }\n  //Assert (dist == 256, \"tr_static_init: dist != 256\");\n  dist >>= 7; /* from now on, all distances are divided by 128 */\n  for (; code < D_CODES; code++) {\n    base_dist[code] = dist << 7;\n    for (n = 0; n < (1 << (extra_dbits[code] - 7)); n++) {\n      _dist_code[256 + dist++] = code;\n    }\n  }\n  //Assert (dist == 256, \"tr_static_init: 256+dist != 512\");\n\n  /* Construct the codes of the static literal tree */\n  for (bits = 0; bits <= MAX_BITS; bits++) {\n    bl_count[bits] = 0;\n  }\n\n  n = 0;\n  while (n <= 143) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 8;\n    n++;\n    bl_count[8]++;\n  }\n  while (n <= 255) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 9;\n    n++;\n    bl_count[9]++;\n  }\n  while (n <= 279) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 7;\n    n++;\n    bl_count[7]++;\n  }\n  while (n <= 287) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 8;\n    n++;\n    bl_count[8]++;\n  }\n  /* Codes 286 and 287 do not exist, but we must include them in the\n   * tree construction to get a canonical Huffman tree (longest code\n   * all ones)\n   */\n  gen_codes(static_ltree, L_CODES + 1, bl_count);\n\n  /* The static distance tree is trivial: */\n  for (n = 0; n < D_CODES; n++) {\n    static_dtree[n * 2 + 1]/*.Len*/ = 5;\n    static_dtree[n * 2]/*.Code*/ = bi_reverse(n, 5);\n  }\n\n  // Now data ready and we can init static trees\n  static_l_desc = new StaticTreeDesc(static_ltree, extra_lbits, LITERALS + 1, L_CODES, MAX_BITS);\n  static_d_desc = new StaticTreeDesc(static_dtree, extra_dbits, 0,          D_CODES, MAX_BITS);\n  static_bl_desc = new StaticTreeDesc(new Array(0), extra_blbits, 0,         BL_CODES, MAX_BL_BITS);\n\n  //static_init_done = true;\n}\n\n\n/* ===========================================================================\n * Initialize a new block.\n */\nfunction init_block(s) {\n  var n; /* iterates over tree elements */\n\n  /* Initialize the trees. */\n  for (n = 0; n < L_CODES;  n++) { s.dyn_ltree[n * 2]/*.Freq*/ = 0; }\n  for (n = 0; n < D_CODES;  n++) { s.dyn_dtree[n * 2]/*.Freq*/ = 0; }\n  for (n = 0; n < BL_CODES; n++) { s.bl_tree[n * 2]/*.Freq*/ = 0; }\n\n  s.dyn_ltree[END_BLOCK * 2]/*.Freq*/ = 1;\n  s.opt_len = s.static_len = 0;\n  s.last_lit = s.matches = 0;\n}\n\n\n/* ===========================================================================\n * Flush the bit buffer and align the output on a byte boundary\n */\nfunction bi_windup(s)\n{\n  if (s.bi_valid > 8) {\n    put_short(s, s.bi_buf);\n  } else if (s.bi_valid > 0) {\n    //put_byte(s, (Byte)s->bi_buf);\n    s.pending_buf[s.pending++] = s.bi_buf;\n  }\n  s.bi_buf = 0;\n  s.bi_valid = 0;\n}\n\n/* ===========================================================================\n * Copy a stored block, storing first the length and its\n * one's complement if requested.\n */\nfunction copy_block(s, buf, len, header)\n//DeflateState *s;\n//charf    *buf;    /* the input data */\n//unsigned len;     /* its length */\n//int      header;  /* true if block header must be written */\n{\n  bi_windup(s);        /* align on byte boundary */\n\n  if (header) {\n    put_short(s, len);\n    put_short(s, ~len);\n  }\n//  while (len--) {\n//    put_byte(s, *buf++);\n//  }\n  utils.arraySet(s.pending_buf, s.window, buf, len, s.pending);\n  s.pending += len;\n}\n\n/* ===========================================================================\n * Compares to subtrees, using the tree depth as tie breaker when\n * the subtrees have equal frequency. This minimizes the worst case length.\n */\nfunction smaller(tree, n, m, depth) {\n  var _n2 = n * 2;\n  var _m2 = m * 2;\n  return (tree[_n2]/*.Freq*/ < tree[_m2]/*.Freq*/ ||\n         (tree[_n2]/*.Freq*/ === tree[_m2]/*.Freq*/ && depth[n] <= depth[m]));\n}\n\n/* ===========================================================================\n * Restore the heap property by moving down the tree starting at node k,\n * exchanging a node with the smallest of its two sons if necessary, stopping\n * when the heap property is re-established (each father smaller than its\n * two sons).\n */\nfunction pqdownheap(s, tree, k)\n//    deflate_state *s;\n//    ct_data *tree;  /* the tree to restore */\n//    int k;               /* node to move down */\n{\n  var v = s.heap[k];\n  var j = k << 1;  /* left son of k */\n  while (j <= s.heap_len) {\n    /* Set j to the smallest of the two sons: */\n    if (j < s.heap_len &&\n      smaller(tree, s.heap[j + 1], s.heap[j], s.depth)) {\n      j++;\n    }\n    /* Exit if v is smaller than both sons */\n    if (smaller(tree, v, s.heap[j], s.depth)) { break; }\n\n    /* Exchange v with the smallest son */\n    s.heap[k] = s.heap[j];\n    k = j;\n\n    /* And continue down the tree, setting j to the left son of k */\n    j <<= 1;\n  }\n  s.heap[k] = v;\n}\n\n\n// inlined manually\n// var SMALLEST = 1;\n\n/* ===========================================================================\n * Send the block data compressed using the given Huffman trees\n */\nfunction compress_block(s, ltree, dtree)\n//    deflate_state *s;\n//    const ct_data *ltree; /* literal tree */\n//    const ct_data *dtree; /* distance tree */\n{\n  var dist;           /* distance of matched string */\n  var lc;             /* match length or unmatched char (if dist == 0) */\n  var lx = 0;         /* running index in l_buf */\n  var code;           /* the code to send */\n  var extra;          /* number of extra bits to send */\n\n  if (s.last_lit !== 0) {\n    do {\n      dist = (s.pending_buf[s.d_buf + lx * 2] << 8) | (s.pending_buf[s.d_buf + lx * 2 + 1]);\n      lc = s.pending_buf[s.l_buf + lx];\n      lx++;\n\n      if (dist === 0) {\n        send_code(s, lc, ltree); /* send a literal byte */\n        //Tracecv(isgraph(lc), (stderr,\" '%c' \", lc));\n      } else {\n        /* Here, lc is the match length - MIN_MATCH */\n        code = _length_code[lc];\n        send_code(s, code + LITERALS + 1, ltree); /* send the length code */\n        extra = extra_lbits[code];\n        if (extra !== 0) {\n          lc -= base_length[code];\n          send_bits(s, lc, extra);       /* send the extra length bits */\n        }\n        dist--; /* dist is now the match distance - 1 */\n        code = d_code(dist);\n        //Assert (code < D_CODES, \"bad d_code\");\n\n        send_code(s, code, dtree);       /* send the distance code */\n        extra = extra_dbits[code];\n        if (extra !== 0) {\n          dist -= base_dist[code];\n          send_bits(s, dist, extra);   /* send the extra distance bits */\n        }\n      } /* literal or match pair ? */\n\n      /* Check that the overlay between pending_buf and d_buf+l_buf is ok: */\n      //Assert((uInt)(s->pending) < s->lit_bufsize + 2*lx,\n      //       \"pendingBuf overflow\");\n\n    } while (lx < s.last_lit);\n  }\n\n  send_code(s, END_BLOCK, ltree);\n}\n\n\n/* ===========================================================================\n * Construct one Huffman tree and assigns the code bit strings and lengths.\n * Update the total bit length for the current block.\n * IN assertion: the field freq is set for all tree elements.\n * OUT assertions: the fields len and code are set to the optimal bit length\n *     and corresponding code. The length opt_len is updated; static_len is\n *     also updated if stree is not null. The field max_code is set.\n */\nfunction build_tree(s, desc)\n//    deflate_state *s;\n//    tree_desc *desc; /* the tree descriptor */\n{\n  var tree     = desc.dyn_tree;\n  var stree    = desc.stat_desc.static_tree;\n  var has_stree = desc.stat_desc.has_stree;\n  var elems    = desc.stat_desc.elems;\n  var n, m;          /* iterate over heap elements */\n  var max_code = -1; /* largest code with non zero frequency */\n  var node;          /* new node being created */\n\n  /* Construct the initial heap, with least frequent element in\n   * heap[SMALLEST]. The sons of heap[n] are heap[2*n] and heap[2*n+1].\n   * heap[0] is not used.\n   */\n  s.heap_len = 0;\n  s.heap_max = HEAP_SIZE;\n\n  for (n = 0; n < elems; n++) {\n    if (tree[n * 2]/*.Freq*/ !== 0) {\n      s.heap[++s.heap_len] = max_code = n;\n      s.depth[n] = 0;\n\n    } else {\n      tree[n * 2 + 1]/*.Len*/ = 0;\n    }\n  }\n\n  /* The pkzip format requires that at least one distance code exists,\n   * and that at least one bit should be sent even if there is only one\n   * possible code. So to avoid special checks later on we force at least\n   * two codes of non zero frequency.\n   */\n  while (s.heap_len < 2) {\n    node = s.heap[++s.heap_len] = (max_code < 2 ? ++max_code : 0);\n    tree[node * 2]/*.Freq*/ = 1;\n    s.depth[node] = 0;\n    s.opt_len--;\n\n    if (has_stree) {\n      s.static_len -= stree[node * 2 + 1]/*.Len*/;\n    }\n    /* node is 0 or 1 so it does not have extra bits */\n  }\n  desc.max_code = max_code;\n\n  /* The elements heap[heap_len/2+1 .. heap_len] are leaves of the tree,\n   * establish sub-heaps of increasing lengths:\n   */\n  for (n = (s.heap_len >> 1/*int /2*/); n >= 1; n--) { pqdownheap(s, tree, n); }\n\n  /* Construct the Huffman tree by repeatedly combining the least two\n   * frequent nodes.\n   */\n  node = elems;              /* next internal node of the tree */\n  do {\n    //pqremove(s, tree, n);  /* n = node of least frequency */\n    /*** pqremove ***/\n    n = s.heap[1/*SMALLEST*/];\n    s.heap[1/*SMALLEST*/] = s.heap[s.heap_len--];\n    pqdownheap(s, tree, 1/*SMALLEST*/);\n    /***/\n\n    m = s.heap[1/*SMALLEST*/]; /* m = node of next least frequency */\n\n    s.heap[--s.heap_max] = n; /* keep the nodes sorted by frequency */\n    s.heap[--s.heap_max] = m;\n\n    /* Create a new node father of n and m */\n    tree[node * 2]/*.Freq*/ = tree[n * 2]/*.Freq*/ + tree[m * 2]/*.Freq*/;\n    s.depth[node] = (s.depth[n] >= s.depth[m] ? s.depth[n] : s.depth[m]) + 1;\n    tree[n * 2 + 1]/*.Dad*/ = tree[m * 2 + 1]/*.Dad*/ = node;\n\n    /* and insert the new node in the heap */\n    s.heap[1/*SMALLEST*/] = node++;\n    pqdownheap(s, tree, 1/*SMALLEST*/);\n\n  } while (s.heap_len >= 2);\n\n  s.heap[--s.heap_max] = s.heap[1/*SMALLEST*/];\n\n  /* At this point, the fields freq and dad are set. We can now\n   * generate the bit lengths.\n   */\n  gen_bitlen(s, desc);\n\n  /* The field len is now set, we can generate the bit codes */\n  gen_codes(tree, max_code, s.bl_count);\n}\n\n\n/* ===========================================================================\n * Scan a literal or distance tree to determine the frequencies of the codes\n * in the bit length tree.\n */\nfunction scan_tree(s, tree, max_code)\n//    deflate_state *s;\n//    ct_data *tree;   /* the tree to be scanned */\n//    int max_code;    /* and its largest code of non zero frequency */\n{\n  var n;                     /* iterates over all tree elements */\n  var prevlen = -1;          /* last emitted length */\n  var curlen;                /* length of current code */\n\n  var nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */\n\n  var count = 0;             /* repeat count of the current code */\n  var max_count = 7;         /* max repeat count */\n  var min_count = 4;         /* min repeat count */\n\n  if (nextlen === 0) {\n    max_count = 138;\n    min_count = 3;\n  }\n  tree[(max_code + 1) * 2 + 1]/*.Len*/ = 0xffff; /* guard */\n\n  for (n = 0; n <= max_code; n++) {\n    curlen = nextlen;\n    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;\n\n    if (++count < max_count && curlen === nextlen) {\n      continue;\n\n    } else if (count < min_count) {\n      s.bl_tree[curlen * 2]/*.Freq*/ += count;\n\n    } else if (curlen !== 0) {\n\n      if (curlen !== prevlen) { s.bl_tree[curlen * 2]/*.Freq*/++; }\n      s.bl_tree[REP_3_6 * 2]/*.Freq*/++;\n\n    } else if (count <= 10) {\n      s.bl_tree[REPZ_3_10 * 2]/*.Freq*/++;\n\n    } else {\n      s.bl_tree[REPZ_11_138 * 2]/*.Freq*/++;\n    }\n\n    count = 0;\n    prevlen = curlen;\n\n    if (nextlen === 0) {\n      max_count = 138;\n      min_count = 3;\n\n    } else if (curlen === nextlen) {\n      max_count = 6;\n      min_count = 3;\n\n    } else {\n      max_count = 7;\n      min_count = 4;\n    }\n  }\n}\n\n\n/* ===========================================================================\n * Send a literal or distance tree in compressed form, using the codes in\n * bl_tree.\n */\nfunction send_tree(s, tree, max_code)\n//    deflate_state *s;\n//    ct_data *tree; /* the tree to be scanned */\n//    int max_code;       /* and its largest code of non zero frequency */\n{\n  var n;                     /* iterates over all tree elements */\n  var prevlen = -1;          /* last emitted length */\n  var curlen;                /* length of current code */\n\n  var nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */\n\n  var count = 0;             /* repeat count of the current code */\n  var max_count = 7;         /* max repeat count */\n  var min_count = 4;         /* min repeat count */\n\n  /* tree[max_code+1].Len = -1; */  /* guard already set */\n  if (nextlen === 0) {\n    max_count = 138;\n    min_count = 3;\n  }\n\n  for (n = 0; n <= max_code; n++) {\n    curlen = nextlen;\n    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;\n\n    if (++count < max_count && curlen === nextlen) {\n      continue;\n\n    } else if (count < min_count) {\n      do { send_code(s, curlen, s.bl_tree); } while (--count !== 0);\n\n    } else if (curlen !== 0) {\n      if (curlen !== prevlen) {\n        send_code(s, curlen, s.bl_tree);\n        count--;\n      }\n      //Assert(count >= 3 && count <= 6, \" 3_6?\");\n      send_code(s, REP_3_6, s.bl_tree);\n      send_bits(s, count - 3, 2);\n\n    } else if (count <= 10) {\n      send_code(s, REPZ_3_10, s.bl_tree);\n      send_bits(s, count - 3, 3);\n\n    } else {\n      send_code(s, REPZ_11_138, s.bl_tree);\n      send_bits(s, count - 11, 7);\n    }\n\n    count = 0;\n    prevlen = curlen;\n    if (nextlen === 0) {\n      max_count = 138;\n      min_count = 3;\n\n    } else if (curlen === nextlen) {\n      max_count = 6;\n      min_count = 3;\n\n    } else {\n      max_count = 7;\n      min_count = 4;\n    }\n  }\n}\n\n\n/* ===========================================================================\n * Construct the Huffman tree for the bit lengths and return the index in\n * bl_order of the last bit length code to send.\n */\nfunction build_bl_tree(s) {\n  var max_blindex;  /* index of last bit length code of non zero freq */\n\n  /* Determine the bit length frequencies for literal and distance trees */\n  scan_tree(s, s.dyn_ltree, s.l_desc.max_code);\n  scan_tree(s, s.dyn_dtree, s.d_desc.max_code);\n\n  /* Build the bit length tree: */\n  build_tree(s, s.bl_desc);\n  /* opt_len now includes the length of the tree representations, except\n   * the lengths of the bit lengths codes and the 5+5+4 bits for the counts.\n   */\n\n  /* Determine the number of bit length codes to send. The pkzip format\n   * requires that at least 4 bit length codes be sent. (appnote.txt says\n   * 3 but the actual value used is 4.)\n   */\n  for (max_blindex = BL_CODES - 1; max_blindex >= 3; max_blindex--) {\n    if (s.bl_tree[bl_order[max_blindex] * 2 + 1]/*.Len*/ !== 0) {\n      break;\n    }\n  }\n  /* Update opt_len to include the bit length tree and counts */\n  s.opt_len += 3 * (max_blindex + 1) + 5 + 5 + 4;\n  //Tracev((stderr, \"\\ndyn trees: dyn %ld, stat %ld\",\n  //        s->opt_len, s->static_len));\n\n  return max_blindex;\n}\n\n\n/* ===========================================================================\n * Send the header for a block using dynamic Huffman trees: the counts, the\n * lengths of the bit length codes, the literal tree and the distance tree.\n * IN assertion: lcodes >= 257, dcodes >= 1, blcodes >= 4.\n */\nfunction send_all_trees(s, lcodes, dcodes, blcodes)\n//    deflate_state *s;\n//    int lcodes, dcodes, blcodes; /* number of codes for each tree */\n{\n  var rank;                    /* index in bl_order */\n\n  //Assert (lcodes >= 257 && dcodes >= 1 && blcodes >= 4, \"not enough codes\");\n  //Assert (lcodes <= L_CODES && dcodes <= D_CODES && blcodes <= BL_CODES,\n  //        \"too many codes\");\n  //Tracev((stderr, \"\\nbl counts: \"));\n  send_bits(s, lcodes - 257, 5); /* not +255 as stated in appnote.txt */\n  send_bits(s, dcodes - 1,   5);\n  send_bits(s, blcodes - 4,  4); /* not -3 as stated in appnote.txt */\n  for (rank = 0; rank < blcodes; rank++) {\n    //Tracev((stderr, \"\\nbl code %2d \", bl_order[rank]));\n    send_bits(s, s.bl_tree[bl_order[rank] * 2 + 1]/*.Len*/, 3);\n  }\n  //Tracev((stderr, \"\\nbl tree: sent %ld\", s->bits_sent));\n\n  send_tree(s, s.dyn_ltree, lcodes - 1); /* literal tree */\n  //Tracev((stderr, \"\\nlit tree: sent %ld\", s->bits_sent));\n\n  send_tree(s, s.dyn_dtree, dcodes - 1); /* distance tree */\n  //Tracev((stderr, \"\\ndist tree: sent %ld\", s->bits_sent));\n}\n\n\n/* ===========================================================================\n * Check if the data type is TEXT or BINARY, using the following algorithm:\n * - TEXT if the two conditions below are satisfied:\n *    a) There are no non-portable control characters belonging to the\n *       \"black list\" (0..6, 14..25, 28..31).\n *    b) There is at least one printable character belonging to the\n *       \"white list\" (9 {TAB}, 10 {LF}, 13 {CR}, 32..255).\n * - BINARY otherwise.\n * - The following partially-portable control characters form a\n *   \"gray list\" that is ignored in this detection algorithm:\n *   (7 {BEL}, 8 {BS}, 11 {VT}, 12 {FF}, 26 {SUB}, 27 {ESC}).\n * IN assertion: the fields Freq of dyn_ltree are set.\n */\nfunction detect_data_type(s) {\n  /* black_mask is the bit mask of black-listed bytes\n   * set bits 0..6, 14..25, and 28..31\n   * 0xf3ffc07f = binary 11110011111111111100000001111111\n   */\n  var black_mask = 0xf3ffc07f;\n  var n;\n\n  /* Check for non-textual (\"black-listed\") bytes. */\n  for (n = 0; n <= 31; n++, black_mask >>>= 1) {\n    if ((black_mask & 1) && (s.dyn_ltree[n * 2]/*.Freq*/ !== 0)) {\n      return Z_BINARY;\n    }\n  }\n\n  /* Check for textual (\"white-listed\") bytes. */\n  if (s.dyn_ltree[9 * 2]/*.Freq*/ !== 0 || s.dyn_ltree[10 * 2]/*.Freq*/ !== 0 ||\n      s.dyn_ltree[13 * 2]/*.Freq*/ !== 0) {\n    return Z_TEXT;\n  }\n  for (n = 32; n < LITERALS; n++) {\n    if (s.dyn_ltree[n * 2]/*.Freq*/ !== 0) {\n      return Z_TEXT;\n    }\n  }\n\n  /* There are no \"black-listed\" or \"white-listed\" bytes:\n   * this stream either is empty or has tolerated (\"gray-listed\") bytes only.\n   */\n  return Z_BINARY;\n}\n\n\nvar static_init_done = false;\n\n/* ===========================================================================\n * Initialize the tree data structures for a new zlib stream.\n */\nfunction _tr_init(s)\n{\n\n  if (!static_init_done) {\n    tr_static_init();\n    static_init_done = true;\n  }\n\n  s.l_desc  = new TreeDesc(s.dyn_ltree, static_l_desc);\n  s.d_desc  = new TreeDesc(s.dyn_dtree, static_d_desc);\n  s.bl_desc = new TreeDesc(s.bl_tree, static_bl_desc);\n\n  s.bi_buf = 0;\n  s.bi_valid = 0;\n\n  /* Initialize the first block of the first file: */\n  init_block(s);\n}\n\n\n/* ===========================================================================\n * Send a stored block\n */\nfunction _tr_stored_block(s, buf, stored_len, last)\n//DeflateState *s;\n//charf *buf;       /* input block */\n//ulg stored_len;   /* length of input block */\n//int last;         /* one if this is the last block for a file */\n{\n  send_bits(s, (STORED_BLOCK << 1) + (last ? 1 : 0), 3);    /* send block type */\n  copy_block(s, buf, stored_len, true); /* with header */\n}\n\n\n/* ===========================================================================\n * Send one empty static block to give enough lookahead for inflate.\n * This takes 10 bits, of which 7 may remain in the bit buffer.\n */\nfunction _tr_align(s) {\n  send_bits(s, STATIC_TREES << 1, 3);\n  send_code(s, END_BLOCK, static_ltree);\n  bi_flush(s);\n}\n\n\n/* ===========================================================================\n * Determine the best encoding for the current block: dynamic trees, static\n * trees or store, and output the encoded block to the zip file.\n */\nfunction _tr_flush_block(s, buf, stored_len, last)\n//DeflateState *s;\n//charf *buf;       /* input block, or NULL if too old */\n//ulg stored_len;   /* length of input block */\n//int last;         /* one if this is the last block for a file */\n{\n  var opt_lenb, static_lenb;  /* opt_len and static_len in bytes */\n  var max_blindex = 0;        /* index of last bit length code of non zero freq */\n\n  /* Build the Huffman trees unless a stored block is forced */\n  if (s.level > 0) {\n\n    /* Check if the file is binary or text */\n    if (s.strm.data_type === Z_UNKNOWN) {\n      s.strm.data_type = detect_data_type(s);\n    }\n\n    /* Construct the literal and distance trees */\n    build_tree(s, s.l_desc);\n    // Tracev((stderr, \"\\nlit data: dyn %ld, stat %ld\", s->opt_len,\n    //        s->static_len));\n\n    build_tree(s, s.d_desc);\n    // Tracev((stderr, \"\\ndist data: dyn %ld, stat %ld\", s->opt_len,\n    //        s->static_len));\n    /* At this point, opt_len and static_len are the total bit lengths of\n     * the compressed block data, excluding the tree representations.\n     */\n\n    /* Build the bit length tree for the above two trees, and get the index\n     * in bl_order of the last bit length code to send.\n     */\n    max_blindex = build_bl_tree(s);\n\n    /* Determine the best encoding. Compute the block lengths in bytes. */\n    opt_lenb = (s.opt_len + 3 + 7) >>> 3;\n    static_lenb = (s.static_len + 3 + 7) >>> 3;\n\n    // Tracev((stderr, \"\\nopt %lu(%lu) stat %lu(%lu) stored %lu lit %u \",\n    //        opt_lenb, s->opt_len, static_lenb, s->static_len, stored_len,\n    //        s->last_lit));\n\n    if (static_lenb <= opt_lenb) { opt_lenb = static_lenb; }\n\n  } else {\n    // Assert(buf != (char*)0, \"lost buf\");\n    opt_lenb = static_lenb = stored_len + 5; /* force a stored block */\n  }\n\n  if ((stored_len + 4 <= opt_lenb) && (buf !== -1)) {\n    /* 4: two words for the lengths */\n\n    /* The test buf != NULL is only necessary if LIT_BUFSIZE > WSIZE.\n     * Otherwise we can't have processed more than WSIZE input bytes since\n     * the last block flush, because compression would have been\n     * successful. If LIT_BUFSIZE <= WSIZE, it is never too late to\n     * transform a block into a stored block.\n     */\n    _tr_stored_block(s, buf, stored_len, last);\n\n  } else if (s.strategy === Z_FIXED || static_lenb === opt_lenb) {\n\n    send_bits(s, (STATIC_TREES << 1) + (last ? 1 : 0), 3);\n    compress_block(s, static_ltree, static_dtree);\n\n  } else {\n    send_bits(s, (DYN_TREES << 1) + (last ? 1 : 0), 3);\n    send_all_trees(s, s.l_desc.max_code + 1, s.d_desc.max_code + 1, max_blindex + 1);\n    compress_block(s, s.dyn_ltree, s.dyn_dtree);\n  }\n  // Assert (s->compressed_len == s->bits_sent, \"bad compressed size\");\n  /* The above check is made mod 2^32, for files larger than 512 MB\n   * and uLong implemented on 32 bits.\n   */\n  init_block(s);\n\n  if (last) {\n    bi_windup(s);\n  }\n  // Tracev((stderr,\"\\ncomprlen %lu(%lu) \", s->compressed_len>>3,\n  //       s->compressed_len-7*last));\n}\n\n/* ===========================================================================\n * Save the match info and tally the frequency counts. Return true if\n * the current block must be flushed.\n */\nfunction _tr_tally(s, dist, lc)\n//    deflate_state *s;\n//    unsigned dist;  /* distance of matched string */\n//    unsigned lc;    /* match length-MIN_MATCH or unmatched char (if dist==0) */\n{\n  //var out_length, in_length, dcode;\n\n  s.pending_buf[s.d_buf + s.last_lit * 2]     = (dist >>> 8) & 0xff;\n  s.pending_buf[s.d_buf + s.last_lit * 2 + 1] = dist & 0xff;\n\n  s.pending_buf[s.l_buf + s.last_lit] = lc & 0xff;\n  s.last_lit++;\n\n  if (dist === 0) {\n    /* lc is the unmatched char */\n    s.dyn_ltree[lc * 2]/*.Freq*/++;\n  } else {\n    s.matches++;\n    /* Here, lc is the match length - MIN_MATCH */\n    dist--;             /* dist = match distance - 1 */\n    //Assert((ush)dist < (ush)MAX_DIST(s) &&\n    //       (ush)lc <= (ush)(MAX_MATCH-MIN_MATCH) &&\n    //       (ush)d_code(dist) < (ush)D_CODES,  \"_tr_tally: bad match\");\n\n    s.dyn_ltree[(_length_code[lc] + LITERALS + 1) * 2]/*.Freq*/++;\n    s.dyn_dtree[d_code(dist) * 2]/*.Freq*/++;\n  }\n\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n\n//#ifdef TRUNCATE_BLOCK\n//  /* Try to guess if it is profitable to stop the current block here */\n//  if ((s.last_lit & 0x1fff) === 0 && s.level > 2) {\n//    /* Compute an upper bound for the compressed length */\n//    out_length = s.last_lit*8;\n//    in_length = s.strstart - s.block_start;\n//\n//    for (dcode = 0; dcode < D_CODES; dcode++) {\n//      out_length += s.dyn_dtree[dcode*2]/*.Freq*/ * (5 + extra_dbits[dcode]);\n//    }\n//    out_length >>>= 3;\n//    //Tracev((stderr,\"\\nlast_lit %u, in %ld, out ~%ld(%ld%%) \",\n//    //       s->last_lit, in_length, out_length,\n//    //       100L - out_length*100L/in_length));\n//    if (s.matches < (s.last_lit>>1)/*int /2*/ && out_length < (in_length>>1)/*int /2*/) {\n//      return true;\n//    }\n//  }\n//#endif\n\n  return (s.last_lit === s.lit_bufsize - 1);\n  /* We avoid equality with lit_bufsize because of wraparound at 64K\n   * on 16 bit machines and because stored blocks are restricted to\n   * 64K-1 bytes.\n   */\n}\n\nexports._tr_init  = _tr_init;\nexports._tr_stored_block = _tr_stored_block;\nexports._tr_flush_block  = _tr_flush_block;\nexports._tr_tally = _tr_tally;\nexports._tr_align = _tr_align;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/trees.js?");

/***/ }),

/***/ "./node_modules/pako/lib/zlib/zstream.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/zstream.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction ZStream() {\n  /* next input byte */\n  this.input = null; // JS specific, because we have no pointers\n  this.next_in = 0;\n  /* number of bytes available at input */\n  this.avail_in = 0;\n  /* total number of input bytes read so far */\n  this.total_in = 0;\n  /* next output byte should be put there */\n  this.output = null; // JS specific, because we have no pointers\n  this.next_out = 0;\n  /* remaining free space at output */\n  this.avail_out = 0;\n  /* total number of bytes output so far */\n  this.total_out = 0;\n  /* last error message, NULL if no error */\n  this.msg = ''/*Z_NULL*/;\n  /* not visible by applications */\n  this.state = null;\n  /* best guess about the data type: binary or text */\n  this.data_type = 2/*Z_UNKNOWN*/;\n  /* adler32 value of the uncompressed data */\n  this.adler = 0;\n}\n\nmodule.exports = ZStream;\n\n\n//# sourceURL=webpack:///./node_modules/pako/lib/zlib/zstream.js?");

/***/ }),

/***/ "./node_modules/process-nextick-args/index.js":
/*!****************************************************!*\
  !*** ./node_modules/process-nextick-args/index.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process) {\n\nif (typeof process === 'undefined' ||\n    !process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = { nextTick: nextTick };\n} else {\n  module.exports = process\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/process-nextick-args/index.js?");

/***/ }),

/***/ "./node_modules/process/browser.js":
/*!*****************************************!*\
  !*** ./node_modules/process/browser.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n\n\n//# sourceURL=webpack:///./node_modules/process/browser.js?");

/***/ }),

/***/ "./node_modules/punycode/punycode.js":
/*!*******************************************!*\
  !*** ./node_modules/punycode/punycode.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n/** Highest positive signed 32-bit float value */\nconst maxInt = 2147483647; // aka. 0x7FFFFFFF or 2^31-1\n\n/** Bootstring parameters */\nconst base = 36;\nconst tMin = 1;\nconst tMax = 26;\nconst skew = 38;\nconst damp = 700;\nconst initialBias = 72;\nconst initialN = 128; // 0x80\nconst delimiter = '-'; // '\\x2D'\n\n/** Regular expressions */\nconst regexPunycode = /^xn--/;\nconst regexNonASCII = /[^\\0-\\x7E]/; // non-ASCII chars\nconst regexSeparators = /[\\x2E\\u3002\\uFF0E\\uFF61]/g; // RFC 3490 separators\n\n/** Error messages */\nconst errors = {\n\t'overflow': 'Overflow: input needs wider integers to process',\n\t'not-basic': 'Illegal input >= 0x80 (not a basic code point)',\n\t'invalid-input': 'Invalid input'\n};\n\n/** Convenience shortcuts */\nconst baseMinusTMin = base - tMin;\nconst floor = Math.floor;\nconst stringFromCharCode = String.fromCharCode;\n\n/*--------------------------------------------------------------------------*/\n\n/**\n * A generic error utility function.\n * @private\n * @param {String} type The error type.\n * @returns {Error} Throws a `RangeError` with the applicable error message.\n */\nfunction error(type) {\n\tthrow new RangeError(errors[type]);\n}\n\n/**\n * A generic `Array#map` utility function.\n * @private\n * @param {Array} array The array to iterate over.\n * @param {Function} callback The function that gets called for every array\n * item.\n * @returns {Array} A new array of values returned by the callback function.\n */\nfunction map(array, fn) {\n\tconst result = [];\n\tlet length = array.length;\n\twhile (length--) {\n\t\tresult[length] = fn(array[length]);\n\t}\n\treturn result;\n}\n\n/**\n * A simple `Array#map`-like wrapper to work with domain name strings or email\n * addresses.\n * @private\n * @param {String} domain The domain name or email address.\n * @param {Function} callback The function that gets called for every\n * character.\n * @returns {Array} A new string of characters returned by the callback\n * function.\n */\nfunction mapDomain(string, fn) {\n\tconst parts = string.split('@');\n\tlet result = '';\n\tif (parts.length > 1) {\n\t\t// In email addresses, only the domain name should be punycoded. Leave\n\t\t// the local part (i.e. everything up to `@`) intact.\n\t\tresult = parts[0] + '@';\n\t\tstring = parts[1];\n\t}\n\t// Avoid `split(regex)` for IE8 compatibility. See #17.\n\tstring = string.replace(regexSeparators, '\\x2E');\n\tconst labels = string.split('.');\n\tconst encoded = map(labels, fn).join('.');\n\treturn result + encoded;\n}\n\n/**\n * Creates an array containing the numeric code points of each Unicode\n * character in the string. While JavaScript uses UCS-2 internally,\n * this function will convert a pair of surrogate halves (each of which\n * UCS-2 exposes as separate characters) into a single code point,\n * matching UTF-16.\n * @see `punycode.ucs2.encode`\n * @see <https://mathiasbynens.be/notes/javascript-encoding>\n * @memberOf punycode.ucs2\n * @name decode\n * @param {String} string The Unicode input string (UCS-2).\n * @returns {Array} The new array of code points.\n */\nfunction ucs2decode(string) {\n\tconst output = [];\n\tlet counter = 0;\n\tconst length = string.length;\n\twhile (counter < length) {\n\t\tconst value = string.charCodeAt(counter++);\n\t\tif (value >= 0xD800 && value <= 0xDBFF && counter < length) {\n\t\t\t// It's a high surrogate, and there is a next character.\n\t\t\tconst extra = string.charCodeAt(counter++);\n\t\t\tif ((extra & 0xFC00) == 0xDC00) { // Low surrogate.\n\t\t\t\toutput.push(((value & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000);\n\t\t\t} else {\n\t\t\t\t// It's an unmatched surrogate; only append this code unit, in case the\n\t\t\t\t// next code unit is the high surrogate of a surrogate pair.\n\t\t\t\toutput.push(value);\n\t\t\t\tcounter--;\n\t\t\t}\n\t\t} else {\n\t\t\toutput.push(value);\n\t\t}\n\t}\n\treturn output;\n}\n\n/**\n * Creates a string based on an array of numeric code points.\n * @see `punycode.ucs2.decode`\n * @memberOf punycode.ucs2\n * @name encode\n * @param {Array} codePoints The array of numeric code points.\n * @returns {String} The new Unicode string (UCS-2).\n */\nconst ucs2encode = array => String.fromCodePoint(...array);\n\n/**\n * Converts a basic code point into a digit/integer.\n * @see `digitToBasic()`\n * @private\n * @param {Number} codePoint The basic numeric code point value.\n * @returns {Number} The numeric value of a basic code point (for use in\n * representing integers) in the range `0` to `base - 1`, or `base` if\n * the code point does not represent a value.\n */\nconst basicToDigit = function(codePoint) {\n\tif (codePoint - 0x30 < 0x0A) {\n\t\treturn codePoint - 0x16;\n\t}\n\tif (codePoint - 0x41 < 0x1A) {\n\t\treturn codePoint - 0x41;\n\t}\n\tif (codePoint - 0x61 < 0x1A) {\n\t\treturn codePoint - 0x61;\n\t}\n\treturn base;\n};\n\n/**\n * Converts a digit/integer into a basic code point.\n * @see `basicToDigit()`\n * @private\n * @param {Number} digit The numeric value of a basic code point.\n * @returns {Number} The basic code point whose value (when used for\n * representing integers) is `digit`, which needs to be in the range\n * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is\n * used; else, the lowercase form is used. The behavior is undefined\n * if `flag` is non-zero and `digit` has no uppercase form.\n */\nconst digitToBasic = function(digit, flag) {\n\t//  0..25 map to ASCII a..z or A..Z\n\t// 26..35 map to ASCII 0..9\n\treturn digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);\n};\n\n/**\n * Bias adaptation function as per section 3.4 of RFC 3492.\n * https://tools.ietf.org/html/rfc3492#section-3.4\n * @private\n */\nconst adapt = function(delta, numPoints, firstTime) {\n\tlet k = 0;\n\tdelta = firstTime ? floor(delta / damp) : delta >> 1;\n\tdelta += floor(delta / numPoints);\n\tfor (/* no initialization */; delta > baseMinusTMin * tMax >> 1; k += base) {\n\t\tdelta = floor(delta / baseMinusTMin);\n\t}\n\treturn floor(k + (baseMinusTMin + 1) * delta / (delta + skew));\n};\n\n/**\n * Converts a Punycode string of ASCII-only symbols to a string of Unicode\n * symbols.\n * @memberOf punycode\n * @param {String} input The Punycode string of ASCII-only symbols.\n * @returns {String} The resulting string of Unicode symbols.\n */\nconst decode = function(input) {\n\t// Don't use UCS-2.\n\tconst output = [];\n\tconst inputLength = input.length;\n\tlet i = 0;\n\tlet n = initialN;\n\tlet bias = initialBias;\n\n\t// Handle the basic code points: let `basic` be the number of input code\n\t// points before the last delimiter, or `0` if there is none, then copy\n\t// the first basic code points to the output.\n\n\tlet basic = input.lastIndexOf(delimiter);\n\tif (basic < 0) {\n\t\tbasic = 0;\n\t}\n\n\tfor (let j = 0; j < basic; ++j) {\n\t\t// if it's not a basic code point\n\t\tif (input.charCodeAt(j) >= 0x80) {\n\t\t\terror('not-basic');\n\t\t}\n\t\toutput.push(input.charCodeAt(j));\n\t}\n\n\t// Main decoding loop: start just after the last delimiter if any basic code\n\t// points were copied; start at the beginning otherwise.\n\n\tfor (let index = basic > 0 ? basic + 1 : 0; index < inputLength; /* no final expression */) {\n\n\t\t// `index` is the index of the next character to be consumed.\n\t\t// Decode a generalized variable-length integer into `delta`,\n\t\t// which gets added to `i`. The overflow checking is easier\n\t\t// if we increase `i` as we go, then subtract off its starting\n\t\t// value at the end to obtain `delta`.\n\t\tlet oldi = i;\n\t\tfor (let w = 1, k = base; /* no condition */; k += base) {\n\n\t\t\tif (index >= inputLength) {\n\t\t\t\terror('invalid-input');\n\t\t\t}\n\n\t\t\tconst digit = basicToDigit(input.charCodeAt(index++));\n\n\t\t\tif (digit >= base || digit > floor((maxInt - i) / w)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\ti += digit * w;\n\t\t\tconst t = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\n\t\t\tif (digit < t) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tconst baseMinusT = base - t;\n\t\t\tif (w > floor(maxInt / baseMinusT)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\tw *= baseMinusT;\n\n\t\t}\n\n\t\tconst out = output.length + 1;\n\t\tbias = adapt(i - oldi, out, oldi == 0);\n\n\t\t// `i` was supposed to wrap around from `out` to `0`,\n\t\t// incrementing `n` each time, so we'll fix that now:\n\t\tif (floor(i / out) > maxInt - n) {\n\t\t\terror('overflow');\n\t\t}\n\n\t\tn += floor(i / out);\n\t\ti %= out;\n\n\t\t// Insert `n` at position `i` of the output.\n\t\toutput.splice(i++, 0, n);\n\n\t}\n\n\treturn String.fromCodePoint(...output);\n};\n\n/**\n * Converts a string of Unicode symbols (e.g. a domain name label) to a\n * Punycode string of ASCII-only symbols.\n * @memberOf punycode\n * @param {String} input The string of Unicode symbols.\n * @returns {String} The resulting Punycode string of ASCII-only symbols.\n */\nconst encode = function(input) {\n\tconst output = [];\n\n\t// Convert the input in UCS-2 to an array of Unicode code points.\n\tinput = ucs2decode(input);\n\n\t// Cache the length.\n\tlet inputLength = input.length;\n\n\t// Initialize the state.\n\tlet n = initialN;\n\tlet delta = 0;\n\tlet bias = initialBias;\n\n\t// Handle the basic code points.\n\tfor (const currentValue of input) {\n\t\tif (currentValue < 0x80) {\n\t\t\toutput.push(stringFromCharCode(currentValue));\n\t\t}\n\t}\n\n\tlet basicLength = output.length;\n\tlet handledCPCount = basicLength;\n\n\t// `handledCPCount` is the number of code points that have been handled;\n\t// `basicLength` is the number of basic code points.\n\n\t// Finish the basic string with a delimiter unless it's empty.\n\tif (basicLength) {\n\t\toutput.push(delimiter);\n\t}\n\n\t// Main encoding loop:\n\twhile (handledCPCount < inputLength) {\n\n\t\t// All non-basic code points < n have been handled already. Find the next\n\t\t// larger one:\n\t\tlet m = maxInt;\n\t\tfor (const currentValue of input) {\n\t\t\tif (currentValue >= n && currentValue < m) {\n\t\t\t\tm = currentValue;\n\t\t\t}\n\t\t}\n\n\t\t// Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,\n\t\t// but guard against overflow.\n\t\tconst handledCPCountPlusOne = handledCPCount + 1;\n\t\tif (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {\n\t\t\terror('overflow');\n\t\t}\n\n\t\tdelta += (m - n) * handledCPCountPlusOne;\n\t\tn = m;\n\n\t\tfor (const currentValue of input) {\n\t\t\tif (currentValue < n && ++delta > maxInt) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\t\t\tif (currentValue == n) {\n\t\t\t\t// Represent delta as a generalized variable-length integer.\n\t\t\t\tlet q = delta;\n\t\t\t\tfor (let k = base; /* no condition */; k += base) {\n\t\t\t\t\tconst t = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\t\t\t\t\tif (q < t) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tconst qMinusT = q - t;\n\t\t\t\t\tconst baseMinusT = base - t;\n\t\t\t\t\toutput.push(\n\t\t\t\t\t\tstringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0))\n\t\t\t\t\t);\n\t\t\t\t\tq = floor(qMinusT / baseMinusT);\n\t\t\t\t}\n\n\t\t\t\toutput.push(stringFromCharCode(digitToBasic(q, 0)));\n\t\t\t\tbias = adapt(delta, handledCPCountPlusOne, handledCPCount == basicLength);\n\t\t\t\tdelta = 0;\n\t\t\t\t++handledCPCount;\n\t\t\t}\n\t\t}\n\n\t\t++delta;\n\t\t++n;\n\n\t}\n\treturn output.join('');\n};\n\n/**\n * Converts a Punycode string representing a domain name or an email address\n * to Unicode. Only the Punycoded parts of the input will be converted, i.e.\n * it doesn't matter if you call it on a string that has already been\n * converted to Unicode.\n * @memberOf punycode\n * @param {String} input The Punycoded domain name or email address to\n * convert to Unicode.\n * @returns {String} The Unicode representation of the given Punycode\n * string.\n */\nconst toUnicode = function(input) {\n\treturn mapDomain(input, function(string) {\n\t\treturn regexPunycode.test(string)\n\t\t\t? decode(string.slice(4).toLowerCase())\n\t\t\t: string;\n\t});\n};\n\n/**\n * Converts a Unicode string representing a domain name or an email address to\n * Punycode. Only the non-ASCII parts of the domain name will be converted,\n * i.e. it doesn't matter if you call it with a domain that's already in\n * ASCII.\n * @memberOf punycode\n * @param {String} input The domain name or email address to convert, as a\n * Unicode string.\n * @returns {String} The Punycode representation of the given domain name or\n * email address.\n */\nconst toASCII = function(input) {\n\treturn mapDomain(input, function(string) {\n\t\treturn regexNonASCII.test(string)\n\t\t\t? 'xn--' + encode(string)\n\t\t\t: string;\n\t});\n};\n\n/*--------------------------------------------------------------------------*/\n\n/** Define the public API */\nconst punycode = {\n\t/**\n\t * A string representing the current Punycode.js version number.\n\t * @memberOf punycode\n\t * @type String\n\t */\n\t'version': '2.1.0',\n\t/**\n\t * An object of methods to convert from JavaScript's internal character\n\t * representation (UCS-2) to Unicode code points, and back.\n\t * @see <https://mathiasbynens.be/notes/javascript-encoding>\n\t * @memberOf punycode\n\t * @type Object\n\t */\n\t'ucs2': {\n\t\t'decode': ucs2decode,\n\t\t'encode': ucs2encode\n\t},\n\t'decode': decode,\n\t'encode': encode,\n\t'toASCII': toASCII,\n\t'toUnicode': toUnicode\n};\n\nmodule.exports = punycode;\n\n\n//# sourceURL=webpack:///./node_modules/punycode/punycode.js?");

/***/ }),

/***/ "./node_modules/querystring-es3/decode.js":
/*!************************************************!*\
  !*** ./node_modules/querystring-es3/decode.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n// If obj.hasOwnProperty has been overridden, then calling\n// obj.hasOwnProperty(prop) will break.\n// See: https://github.com/joyent/node/issues/1707\nfunction hasOwnProperty(obj, prop) {\n  return Object.prototype.hasOwnProperty.call(obj, prop);\n}\n\nmodule.exports = function(qs, sep, eq, options) {\n  sep = sep || '&';\n  eq = eq || '=';\n  var obj = {};\n\n  if (typeof qs !== 'string' || qs.length === 0) {\n    return obj;\n  }\n\n  var regexp = /\\+/g;\n  qs = qs.split(sep);\n\n  var maxKeys = 1000;\n  if (options && typeof options.maxKeys === 'number') {\n    maxKeys = options.maxKeys;\n  }\n\n  var len = qs.length;\n  // maxKeys <= 0 means that we should not limit keys count\n  if (maxKeys > 0 && len > maxKeys) {\n    len = maxKeys;\n  }\n\n  for (var i = 0; i < len; ++i) {\n    var x = qs[i].replace(regexp, '%20'),\n        idx = x.indexOf(eq),\n        kstr, vstr, k, v;\n\n    if (idx >= 0) {\n      kstr = x.substr(0, idx);\n      vstr = x.substr(idx + 1);\n    } else {\n      kstr = x;\n      vstr = '';\n    }\n\n    k = decodeURIComponent(kstr);\n    v = decodeURIComponent(vstr);\n\n    if (!hasOwnProperty(obj, k)) {\n      obj[k] = v;\n    } else if (isArray(obj[k])) {\n      obj[k].push(v);\n    } else {\n      obj[k] = [obj[k], v];\n    }\n  }\n\n  return obj;\n};\n\nvar isArray = Array.isArray || function (xs) {\n  return Object.prototype.toString.call(xs) === '[object Array]';\n};\n\n\n//# sourceURL=webpack:///./node_modules/querystring-es3/decode.js?");

/***/ }),

/***/ "./node_modules/querystring-es3/encode.js":
/*!************************************************!*\
  !*** ./node_modules/querystring-es3/encode.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar stringifyPrimitive = function(v) {\n  switch (typeof v) {\n    case 'string':\n      return v;\n\n    case 'boolean':\n      return v ? 'true' : 'false';\n\n    case 'number':\n      return isFinite(v) ? v : '';\n\n    default:\n      return '';\n  }\n};\n\nmodule.exports = function(obj, sep, eq, name) {\n  sep = sep || '&';\n  eq = eq || '=';\n  if (obj === null) {\n    obj = undefined;\n  }\n\n  if (typeof obj === 'object') {\n    return map(objectKeys(obj), function(k) {\n      var ks = encodeURIComponent(stringifyPrimitive(k)) + eq;\n      if (isArray(obj[k])) {\n        return map(obj[k], function(v) {\n          return ks + encodeURIComponent(stringifyPrimitive(v));\n        }).join(sep);\n      } else {\n        return ks + encodeURIComponent(stringifyPrimitive(obj[k]));\n      }\n    }).join(sep);\n\n  }\n\n  if (!name) return '';\n  return encodeURIComponent(stringifyPrimitive(name)) + eq +\n         encodeURIComponent(stringifyPrimitive(obj));\n};\n\nvar isArray = Array.isArray || function (xs) {\n  return Object.prototype.toString.call(xs) === '[object Array]';\n};\n\nfunction map (xs, f) {\n  if (xs.map) return xs.map(f);\n  var res = [];\n  for (var i = 0; i < xs.length; i++) {\n    res.push(f(xs[i], i));\n  }\n  return res;\n}\n\nvar objectKeys = Object.keys || function (obj) {\n  var res = [];\n  for (var key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) res.push(key);\n  }\n  return res;\n};\n\n\n//# sourceURL=webpack:///./node_modules/querystring-es3/encode.js?");

/***/ }),

/***/ "./node_modules/querystring-es3/index.js":
/*!***********************************************!*\
  !*** ./node_modules/querystring-es3/index.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nexports.decode = exports.parse = __webpack_require__(/*! ./decode */ \"./node_modules/querystring-es3/decode.js\");\nexports.encode = exports.stringify = __webpack_require__(/*! ./encode */ \"./node_modules/querystring-es3/encode.js\");\n\n\n//# sourceURL=webpack:///./node_modules/querystring-es3/index.js?");

/***/ }),

/***/ "./node_modules/readable-stream/duplex-browser.js":
/*!********************************************************!*\
  !*** ./node_modules/readable-stream/duplex-browser.js ***!
  \********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = __webpack_require__(/*! ./lib/_stream_duplex.js */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n\n//# sourceURL=webpack:///./node_modules/readable-stream/duplex-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_duplex.js":
/*!************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_duplex.js ***!
  \************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = Object.create(__webpack_require__(/*! core-util-is */ \"./node_modules/core-util-is/lib/util.js\"));\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\nvar Readable = __webpack_require__(/*! ./_stream_readable */ \"./node_modules/readable-stream/lib/_stream_readable.js\");\nvar Writable = __webpack_require__(/*! ./_stream_writable */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/_stream_duplex.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_passthrough.js":
/*!*****************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_passthrough.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\n\nmodule.exports = PassThrough;\n\nvar Transform = __webpack_require__(/*! ./_stream_transform */ \"./node_modules/readable-stream/lib/_stream_transform.js\");\n\n/*<replacement>*/\nvar util = Object.create(__webpack_require__(/*! core-util-is */ \"./node_modules/core-util-is/lib/util.js\"));\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/_stream_passthrough.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_readable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_readable.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(global, process) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = __webpack_require__(/*! isarray */ \"./node_modules/isarray/index.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = __webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(/*! safe-buffer */ \"./node_modules/safe-buffer/index.js\").Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = Object.create(__webpack_require__(/*! core-util-is */ \"./node_modules/core-util-is/lib/util.js\"));\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = __webpack_require__(/*! util */ \"./node_modules/util/util.js\");\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = __webpack_require__(/*! ./internal/streams/BufferList */ \"./node_modules/readable-stream/lib/internal/streams/BufferList.js\");\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\");\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = __webpack_require__(/*! string_decoder/ */ \"./node_modules/string_decoder/lib/string_decoder.js\").StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = __webpack_require__(/*! string_decoder/ */ \"./node_modules/string_decoder/lib/string_decoder.js\").StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\"), __webpack_require__(/*! ./../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/_stream_readable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_transform.js":
/*!***************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_transform.js ***!
  \***************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\n\nmodule.exports = Transform;\n\nvar Duplex = __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n/*<replacement>*/\nvar util = Object.create(__webpack_require__(/*! core-util-is */ \"./node_modules/core-util-is/lib/util.js\"));\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/_stream_transform.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_writable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_writable.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/* WEBPACK VAR INJECTION */(function(process, setImmediate, global) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(__webpack_require__(/*! core-util-is */ \"./node_modules/core-util-is/lib/util.js\"));\nutil.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: __webpack_require__(/*! util-deprecate */ \"./node_modules/util-deprecate/node.js\")\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(/*! safe-buffer */ \"./node_modules/safe-buffer/index.js\").Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\");\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../process/browser.js */ \"./node_modules/process/browser.js\"), __webpack_require__(/*! ./../../timers-browserify/main.js */ \"./node_modules/timers-browserify/main.js\").setImmediate, __webpack_require__(/*! ./../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/_stream_writable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/BufferList.js":
/*!*************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/BufferList.js ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = __webpack_require__(/*! safe-buffer */ \"./node_modules/safe-buffer/index.js\").Buffer;\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\");\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/internal/streams/BufferList.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/destroy.js":
/*!**********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/destroy.js ***!
  \**********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\n/*<replacement>*/\n\nvar pna = __webpack_require__(/*! process-nextick-args */ \"./node_modules/process-nextick-args/index.js\");\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/internal/streams/destroy.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/stream-browser.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/stream-browser.js ***!
  \*****************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = __webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter;\n\n\n//# sourceURL=webpack:///./node_modules/readable-stream/lib/internal/streams/stream-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/passthrough.js":
/*!*****************************************************!*\
  !*** ./node_modules/readable-stream/passthrough.js ***!
  \*****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = __webpack_require__(/*! ./readable */ \"./node_modules/readable-stream/readable-browser.js\").PassThrough\n\n\n//# sourceURL=webpack:///./node_modules/readable-stream/passthrough.js?");

/***/ }),

/***/ "./node_modules/readable-stream/readable-browser.js":
/*!**********************************************************!*\
  !*** ./node_modules/readable-stream/readable-browser.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("exports = module.exports = __webpack_require__(/*! ./lib/_stream_readable.js */ \"./node_modules/readable-stream/lib/_stream_readable.js\");\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = __webpack_require__(/*! ./lib/_stream_writable.js */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\nexports.Duplex = __webpack_require__(/*! ./lib/_stream_duplex.js */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\nexports.Transform = __webpack_require__(/*! ./lib/_stream_transform.js */ \"./node_modules/readable-stream/lib/_stream_transform.js\");\nexports.PassThrough = __webpack_require__(/*! ./lib/_stream_passthrough.js */ \"./node_modules/readable-stream/lib/_stream_passthrough.js\");\n\n\n//# sourceURL=webpack:///./node_modules/readable-stream/readable-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/transform.js":
/*!***************************************************!*\
  !*** ./node_modules/readable-stream/transform.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = __webpack_require__(/*! ./readable */ \"./node_modules/readable-stream/readable-browser.js\").Transform\n\n\n//# sourceURL=webpack:///./node_modules/readable-stream/transform.js?");

/***/ }),

/***/ "./node_modules/readable-stream/writable-browser.js":
/*!**********************************************************!*\
  !*** ./node_modules/readable-stream/writable-browser.js ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = __webpack_require__(/*! ./lib/_stream_writable.js */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\n\n\n//# sourceURL=webpack:///./node_modules/readable-stream/writable-browser.js?");

/***/ }),

/***/ "./node_modules/safe-buffer/index.js":
/*!*******************************************!*\
  !*** ./node_modules/safe-buffer/index.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* eslint-disable node/no-deprecated-api */\nvar buffer = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n\n\n//# sourceURL=webpack:///./node_modules/safe-buffer/index.js?");

/***/ }),

/***/ "./node_modules/seedrandom/index.js":
/*!******************************************!*\
  !*** ./node_modules/seedrandom/index.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// A library of seedable RNGs implemented in Javascript.\n//\n// Usage:\n//\n// var seedrandom = require('seedrandom');\n// var random = seedrandom(1); // or any seed.\n// var x = random();       // 0 <= x < 1.  Every bit is random.\n// var x = random.quick(); // 0 <= x < 1.  32 bits of randomness.\n\n// alea, a 53-bit multiply-with-carry generator by Johannes Baagøe.\n// Period: ~2^116\n// Reported to pass all BigCrush tests.\nvar alea = __webpack_require__(/*! ./lib/alea */ \"./node_modules/seedrandom/lib/alea.js\");\n\n// xor128, a pure xor-shift generator by George Marsaglia.\n// Period: 2^128-1.\n// Reported to fail: MatrixRank and LinearComp.\nvar xor128 = __webpack_require__(/*! ./lib/xor128 */ \"./node_modules/seedrandom/lib/xor128.js\");\n\n// xorwow, George Marsaglia's 160-bit xor-shift combined plus weyl.\n// Period: 2^192-2^32\n// Reported to fail: CollisionOver, SimpPoker, and LinearComp.\nvar xorwow = __webpack_require__(/*! ./lib/xorwow */ \"./node_modules/seedrandom/lib/xorwow.js\");\n\n// xorshift7, by François Panneton and Pierre L'ecuyer, takes\n// a different approach: it adds robustness by allowing more shifts\n// than Marsaglia's original three.  It is a 7-shift generator\n// with 256 bits, that passes BigCrush with no systmatic failures.\n// Period 2^256-1.\n// No systematic BigCrush failures reported.\nvar xorshift7 = __webpack_require__(/*! ./lib/xorshift7 */ \"./node_modules/seedrandom/lib/xorshift7.js\");\n\n// xor4096, by Richard Brent, is a 4096-bit xor-shift with a\n// very long period that also adds a Weyl generator. It also passes\n// BigCrush with no systematic failures.  Its long period may\n// be useful if you have many generators and need to avoid\n// collisions.\n// Period: 2^4128-2^32.\n// No systematic BigCrush failures reported.\nvar xor4096 = __webpack_require__(/*! ./lib/xor4096 */ \"./node_modules/seedrandom/lib/xor4096.js\");\n\n// Tyche-i, by Samuel Neves and Filipe Araujo, is a bit-shifting random\n// number generator derived from ChaCha, a modern stream cipher.\n// https://eden.dei.uc.pt/~sneves/pubs/2011-snfa2.pdf\n// Period: ~2^127\n// No systematic BigCrush failures reported.\nvar tychei = __webpack_require__(/*! ./lib/tychei */ \"./node_modules/seedrandom/lib/tychei.js\");\n\n// The original ARC4-based prng included in this library.\n// Period: ~2^1600\nvar sr = __webpack_require__(/*! ./seedrandom */ \"./node_modules/seedrandom/seedrandom.js\");\n\nsr.alea = alea;\nsr.xor128 = xor128;\nsr.xorwow = xorwow;\nsr.xorshift7 = xorshift7;\nsr.xor4096 = xor4096;\nsr.tychei = tychei;\n\nmodule.exports = sr;\n\n\n//# sourceURL=webpack:///./node_modules/seedrandom/index.js?");

/***/ }),

/***/ "./node_modules/seedrandom/lib/alea.js":
/*!*********************************************!*\
  !*** ./node_modules/seedrandom/lib/alea.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(module) {var __WEBPACK_AMD_DEFINE_RESULT__;// A port of an algorithm by Johannes Baagøe <baagoe@baagoe.com>, 2010\n// http://baagoe.com/en/RandomMusings/javascript/\n// https://github.com/nquinlan/better-random-numbers-for-javascript-mirror\n// Original work is under MIT license -\n\n// Copyright (C) 2010 by Johannes Baagøe <baagoe@baagoe.org>\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n// \n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n// \n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n// THE SOFTWARE.\n\n\n\n(function(global, module, define) {\n\nfunction Alea(seed) {\n  var me = this, mash = Mash();\n\n  me.next = function() {\n    var t = 2091639 * me.s0 + me.c * 2.3283064365386963e-10; // 2^-32\n    me.s0 = me.s1;\n    me.s1 = me.s2;\n    return me.s2 = t - (me.c = t | 0);\n  };\n\n  // Apply the seeding algorithm from Baagoe.\n  me.c = 1;\n  me.s0 = mash(' ');\n  me.s1 = mash(' ');\n  me.s2 = mash(' ');\n  me.s0 -= mash(seed);\n  if (me.s0 < 0) { me.s0 += 1; }\n  me.s1 -= mash(seed);\n  if (me.s1 < 0) { me.s1 += 1; }\n  me.s2 -= mash(seed);\n  if (me.s2 < 0) { me.s2 += 1; }\n  mash = null;\n}\n\nfunction copy(f, t) {\n  t.c = f.c;\n  t.s0 = f.s0;\n  t.s1 = f.s1;\n  t.s2 = f.s2;\n  return t;\n}\n\nfunction impl(seed, opts) {\n  var xg = new Alea(seed),\n      state = opts && opts.state,\n      prng = xg.next;\n  prng.int32 = function() { return (xg.next() * 0x100000000) | 0; }\n  prng.double = function() {\n    return prng() + (prng() * 0x200000 | 0) * 1.1102230246251565e-16; // 2^-53\n  };\n  prng.quick = prng;\n  if (state) {\n    if (typeof(state) == 'object') copy(state, xg);\n    prng.state = function() { return copy(xg, {}); }\n  }\n  return prng;\n}\n\nfunction Mash() {\n  var n = 0xefc8249d;\n\n  var mash = function(data) {\n    data = data.toString();\n    for (var i = 0; i < data.length; i++) {\n      n += data.charCodeAt(i);\n      var h = 0.02519603282416938 * n;\n      n = h >>> 0;\n      h -= n;\n      h *= n;\n      n = h >>> 0;\n      h -= n;\n      n += h * 0x100000000; // 2^32\n    }\n    return (n >>> 0) * 2.3283064365386963e-10; // 2^-32\n  };\n\n  return mash;\n}\n\n\nif (module && module.exports) {\n  module.exports = impl;\n} else if (__webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\") && __webpack_require__(/*! !webpack amd options */ \"./node_modules/webpack/buildin/amd-options.js\")) {\n  !(__WEBPACK_AMD_DEFINE_RESULT__ = (function() { return impl; }).call(exports, __webpack_require__, exports, module),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n} else {\n  this.alea = impl;\n}\n\n})(\n  this,\n   true && module,    // present in node.js\n  __webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\")   // present with an AMD loader\n);\n\n\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/module.js */ \"./node_modules/webpack/buildin/module.js\")(module)))\n\n//# sourceURL=webpack:///./node_modules/seedrandom/lib/alea.js?");

/***/ }),

/***/ "./node_modules/seedrandom/lib/tychei.js":
/*!***********************************************!*\
  !*** ./node_modules/seedrandom/lib/tychei.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(module) {var __WEBPACK_AMD_DEFINE_RESULT__;// A Javascript implementaion of the \"Tyche-i\" prng algorithm by\n// Samuel Neves and Filipe Araujo.\n// See https://eden.dei.uc.pt/~sneves/pubs/2011-snfa2.pdf\n\n(function(global, module, define) {\n\nfunction XorGen(seed) {\n  var me = this, strseed = '';\n\n  // Set up generator function.\n  me.next = function() {\n    var b = me.b, c = me.c, d = me.d, a = me.a;\n    b = (b << 25) ^ (b >>> 7) ^ c;\n    c = (c - d) | 0;\n    d = (d << 24) ^ (d >>> 8) ^ a;\n    a = (a - b) | 0;\n    me.b = b = (b << 20) ^ (b >>> 12) ^ c;\n    me.c = c = (c - d) | 0;\n    me.d = (d << 16) ^ (c >>> 16) ^ a;\n    return me.a = (a - b) | 0;\n  };\n\n  /* The following is non-inverted tyche, which has better internal\n   * bit diffusion, but which is about 25% slower than tyche-i in JS.\n  me.next = function() {\n    var a = me.a, b = me.b, c = me.c, d = me.d;\n    a = (me.a + me.b | 0) >>> 0;\n    d = me.d ^ a; d = d << 16 ^ d >>> 16;\n    c = me.c + d | 0;\n    b = me.b ^ c; b = b << 12 ^ d >>> 20;\n    me.a = a = a + b | 0;\n    d = d ^ a; me.d = d = d << 8 ^ d >>> 24;\n    me.c = c = c + d | 0;\n    b = b ^ c;\n    return me.b = (b << 7 ^ b >>> 25);\n  }\n  */\n\n  me.a = 0;\n  me.b = 0;\n  me.c = 2654435769 | 0;\n  me.d = 1367130551;\n\n  if (seed === Math.floor(seed)) {\n    // Integer seed.\n    me.a = (seed / 0x100000000) | 0;\n    me.b = seed | 0;\n  } else {\n    // String seed.\n    strseed += seed;\n  }\n\n  // Mix in string seed, then discard an initial batch of 64 values.\n  for (var k = 0; k < strseed.length + 20; k++) {\n    me.b ^= strseed.charCodeAt(k) | 0;\n    me.next();\n  }\n}\n\nfunction copy(f, t) {\n  t.a = f.a;\n  t.b = f.b;\n  t.c = f.c;\n  t.d = f.d;\n  return t;\n};\n\nfunction impl(seed, opts) {\n  var xg = new XorGen(seed),\n      state = opts && opts.state,\n      prng = function() { return (xg.next() >>> 0) / 0x100000000; };\n  prng.double = function() {\n    do {\n      var top = xg.next() >>> 11,\n          bot = (xg.next() >>> 0) / 0x100000000,\n          result = (top + bot) / (1 << 21);\n    } while (result === 0);\n    return result;\n  };\n  prng.int32 = xg.next;\n  prng.quick = prng;\n  if (state) {\n    if (typeof(state) == 'object') copy(state, xg);\n    prng.state = function() { return copy(xg, {}); }\n  }\n  return prng;\n}\n\nif (module && module.exports) {\n  module.exports = impl;\n} else if (__webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\") && __webpack_require__(/*! !webpack amd options */ \"./node_modules/webpack/buildin/amd-options.js\")) {\n  !(__WEBPACK_AMD_DEFINE_RESULT__ = (function() { return impl; }).call(exports, __webpack_require__, exports, module),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n} else {\n  this.tychei = impl;\n}\n\n})(\n  this,\n   true && module,    // present in node.js\n  __webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\")   // present with an AMD loader\n);\n\n\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/module.js */ \"./node_modules/webpack/buildin/module.js\")(module)))\n\n//# sourceURL=webpack:///./node_modules/seedrandom/lib/tychei.js?");

/***/ }),

/***/ "./node_modules/seedrandom/lib/xor128.js":
/*!***********************************************!*\
  !*** ./node_modules/seedrandom/lib/xor128.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(module) {var __WEBPACK_AMD_DEFINE_RESULT__;// A Javascript implementaion of the \"xor128\" prng algorithm by\n// George Marsaglia.  See http://www.jstatsoft.org/v08/i14/paper\n\n(function(global, module, define) {\n\nfunction XorGen(seed) {\n  var me = this, strseed = '';\n\n  me.x = 0;\n  me.y = 0;\n  me.z = 0;\n  me.w = 0;\n\n  // Set up generator function.\n  me.next = function() {\n    var t = me.x ^ (me.x << 11);\n    me.x = me.y;\n    me.y = me.z;\n    me.z = me.w;\n    return me.w ^= (me.w >>> 19) ^ t ^ (t >>> 8);\n  };\n\n  if (seed === (seed | 0)) {\n    // Integer seed.\n    me.x = seed;\n  } else {\n    // String seed.\n    strseed += seed;\n  }\n\n  // Mix in string seed, then discard an initial batch of 64 values.\n  for (var k = 0; k < strseed.length + 64; k++) {\n    me.x ^= strseed.charCodeAt(k) | 0;\n    me.next();\n  }\n}\n\nfunction copy(f, t) {\n  t.x = f.x;\n  t.y = f.y;\n  t.z = f.z;\n  t.w = f.w;\n  return t;\n}\n\nfunction impl(seed, opts) {\n  var xg = new XorGen(seed),\n      state = opts && opts.state,\n      prng = function() { return (xg.next() >>> 0) / 0x100000000; };\n  prng.double = function() {\n    do {\n      var top = xg.next() >>> 11,\n          bot = (xg.next() >>> 0) / 0x100000000,\n          result = (top + bot) / (1 << 21);\n    } while (result === 0);\n    return result;\n  };\n  prng.int32 = xg.next;\n  prng.quick = prng;\n  if (state) {\n    if (typeof(state) == 'object') copy(state, xg);\n    prng.state = function() { return copy(xg, {}); }\n  }\n  return prng;\n}\n\nif (module && module.exports) {\n  module.exports = impl;\n} else if (__webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\") && __webpack_require__(/*! !webpack amd options */ \"./node_modules/webpack/buildin/amd-options.js\")) {\n  !(__WEBPACK_AMD_DEFINE_RESULT__ = (function() { return impl; }).call(exports, __webpack_require__, exports, module),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n} else {\n  this.xor128 = impl;\n}\n\n})(\n  this,\n   true && module,    // present in node.js\n  __webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\")   // present with an AMD loader\n);\n\n\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/module.js */ \"./node_modules/webpack/buildin/module.js\")(module)))\n\n//# sourceURL=webpack:///./node_modules/seedrandom/lib/xor128.js?");

/***/ }),

/***/ "./node_modules/seedrandom/lib/xor4096.js":
/*!************************************************!*\
  !*** ./node_modules/seedrandom/lib/xor4096.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(module) {var __WEBPACK_AMD_DEFINE_RESULT__;// A Javascript implementaion of Richard Brent's Xorgens xor4096 algorithm.\n//\n// This fast non-cryptographic random number generator is designed for\n// use in Monte-Carlo algorithms. It combines a long-period xorshift\n// generator with a Weyl generator, and it passes all common batteries\n// of stasticial tests for randomness while consuming only a few nanoseconds\n// for each prng generated.  For background on the generator, see Brent's\n// paper: \"Some long-period random number generators using shifts and xors.\"\n// http://arxiv.org/pdf/1004.3115v1.pdf\n//\n// Usage:\n//\n// var xor4096 = require('xor4096');\n// random = xor4096(1);                        // Seed with int32 or string.\n// assert.equal(random(), 0.1520436450538547); // (0, 1) range, 53 bits.\n// assert.equal(random.int32(), 1806534897);   // signed int32, 32 bits.\n//\n// For nonzero numeric keys, this impelementation provides a sequence\n// identical to that by Brent's xorgens 3 implementaion in C.  This\n// implementation also provides for initalizing the generator with\n// string seeds, or for saving and restoring the state of the generator.\n//\n// On Chrome, this prng benchmarks about 2.1 times slower than\n// Javascript's built-in Math.random().\n\n(function(global, module, define) {\n\nfunction XorGen(seed) {\n  var me = this;\n\n  // Set up generator function.\n  me.next = function() {\n    var w = me.w,\n        X = me.X, i = me.i, t, v;\n    // Update Weyl generator.\n    me.w = w = (w + 0x61c88647) | 0;\n    // Update xor generator.\n    v = X[(i + 34) & 127];\n    t = X[i = ((i + 1) & 127)];\n    v ^= v << 13;\n    t ^= t << 17;\n    v ^= v >>> 15;\n    t ^= t >>> 12;\n    // Update Xor generator array state.\n    v = X[i] = v ^ t;\n    me.i = i;\n    // Result is the combination.\n    return (v + (w ^ (w >>> 16))) | 0;\n  };\n\n  function init(me, seed) {\n    var t, v, i, j, w, X = [], limit = 128;\n    if (seed === (seed | 0)) {\n      // Numeric seeds initialize v, which is used to generates X.\n      v = seed;\n      seed = null;\n    } else {\n      // String seeds are mixed into v and X one character at a time.\n      seed = seed + '\\0';\n      v = 0;\n      limit = Math.max(limit, seed.length);\n    }\n    // Initialize circular array and weyl value.\n    for (i = 0, j = -32; j < limit; ++j) {\n      // Put the unicode characters into the array, and shuffle them.\n      if (seed) v ^= seed.charCodeAt((j + 32) % seed.length);\n      // After 32 shuffles, take v as the starting w value.\n      if (j === 0) w = v;\n      v ^= v << 10;\n      v ^= v >>> 15;\n      v ^= v << 4;\n      v ^= v >>> 13;\n      if (j >= 0) {\n        w = (w + 0x61c88647) | 0;     // Weyl.\n        t = (X[j & 127] ^= (v + w));  // Combine xor and weyl to init array.\n        i = (0 == t) ? i + 1 : 0;     // Count zeroes.\n      }\n    }\n    // We have detected all zeroes; make the key nonzero.\n    if (i >= 128) {\n      X[(seed && seed.length || 0) & 127] = -1;\n    }\n    // Run the generator 512 times to further mix the state before using it.\n    // Factoring this as a function slows the main generator, so it is just\n    // unrolled here.  The weyl generator is not advanced while warming up.\n    i = 127;\n    for (j = 4 * 128; j > 0; --j) {\n      v = X[(i + 34) & 127];\n      t = X[i = ((i + 1) & 127)];\n      v ^= v << 13;\n      t ^= t << 17;\n      v ^= v >>> 15;\n      t ^= t >>> 12;\n      X[i] = v ^ t;\n    }\n    // Storing state as object members is faster than using closure variables.\n    me.w = w;\n    me.X = X;\n    me.i = i;\n  }\n\n  init(me, seed);\n}\n\nfunction copy(f, t) {\n  t.i = f.i;\n  t.w = f.w;\n  t.X = f.X.slice();\n  return t;\n};\n\nfunction impl(seed, opts) {\n  if (seed == null) seed = +(new Date);\n  var xg = new XorGen(seed),\n      state = opts && opts.state,\n      prng = function() { return (xg.next() >>> 0) / 0x100000000; };\n  prng.double = function() {\n    do {\n      var top = xg.next() >>> 11,\n          bot = (xg.next() >>> 0) / 0x100000000,\n          result = (top + bot) / (1 << 21);\n    } while (result === 0);\n    return result;\n  };\n  prng.int32 = xg.next;\n  prng.quick = prng;\n  if (state) {\n    if (state.X) copy(state, xg);\n    prng.state = function() { return copy(xg, {}); }\n  }\n  return prng;\n}\n\nif (module && module.exports) {\n  module.exports = impl;\n} else if (__webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\") && __webpack_require__(/*! !webpack amd options */ \"./node_modules/webpack/buildin/amd-options.js\")) {\n  !(__WEBPACK_AMD_DEFINE_RESULT__ = (function() { return impl; }).call(exports, __webpack_require__, exports, module),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n} else {\n  this.xor4096 = impl;\n}\n\n})(\n  this,                                     // window object or global\n   true && module,    // present in node.js\n  __webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\")   // present with an AMD loader\n);\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/module.js */ \"./node_modules/webpack/buildin/module.js\")(module)))\n\n//# sourceURL=webpack:///./node_modules/seedrandom/lib/xor4096.js?");

/***/ }),

/***/ "./node_modules/seedrandom/lib/xorshift7.js":
/*!**************************************************!*\
  !*** ./node_modules/seedrandom/lib/xorshift7.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(module) {var __WEBPACK_AMD_DEFINE_RESULT__;// A Javascript implementaion of the \"xorshift7\" algorithm by\n// François Panneton and Pierre L'ecuyer:\n// \"On the Xorgshift Random Number Generators\"\n// http://saluc.engr.uconn.edu/refs/crypto/rng/panneton05onthexorshift.pdf\n\n(function(global, module, define) {\n\nfunction XorGen(seed) {\n  var me = this;\n\n  // Set up generator function.\n  me.next = function() {\n    // Update xor generator.\n    var X = me.x, i = me.i, t, v, w;\n    t = X[i]; t ^= (t >>> 7); v = t ^ (t << 24);\n    t = X[(i + 1) & 7]; v ^= t ^ (t >>> 10);\n    t = X[(i + 3) & 7]; v ^= t ^ (t >>> 3);\n    t = X[(i + 4) & 7]; v ^= t ^ (t << 7);\n    t = X[(i + 7) & 7]; t = t ^ (t << 13); v ^= t ^ (t << 9);\n    X[i] = v;\n    me.i = (i + 1) & 7;\n    return v;\n  };\n\n  function init(me, seed) {\n    var j, w, X = [];\n\n    if (seed === (seed | 0)) {\n      // Seed state array using a 32-bit integer.\n      w = X[0] = seed;\n    } else {\n      // Seed state using a string.\n      seed = '' + seed;\n      for (j = 0; j < seed.length; ++j) {\n        X[j & 7] = (X[j & 7] << 15) ^\n            (seed.charCodeAt(j) + X[(j + 1) & 7] << 13);\n      }\n    }\n    // Enforce an array length of 8, not all zeroes.\n    while (X.length < 8) X.push(0);\n    for (j = 0; j < 8 && X[j] === 0; ++j);\n    if (j == 8) w = X[7] = -1; else w = X[j];\n\n    me.x = X;\n    me.i = 0;\n\n    // Discard an initial 256 values.\n    for (j = 256; j > 0; --j) {\n      me.next();\n    }\n  }\n\n  init(me, seed);\n}\n\nfunction copy(f, t) {\n  t.x = f.x.slice();\n  t.i = f.i;\n  return t;\n}\n\nfunction impl(seed, opts) {\n  if (seed == null) seed = +(new Date);\n  var xg = new XorGen(seed),\n      state = opts && opts.state,\n      prng = function() { return (xg.next() >>> 0) / 0x100000000; };\n  prng.double = function() {\n    do {\n      var top = xg.next() >>> 11,\n          bot = (xg.next() >>> 0) / 0x100000000,\n          result = (top + bot) / (1 << 21);\n    } while (result === 0);\n    return result;\n  };\n  prng.int32 = xg.next;\n  prng.quick = prng;\n  if (state) {\n    if (state.x) copy(state, xg);\n    prng.state = function() { return copy(xg, {}); }\n  }\n  return prng;\n}\n\nif (module && module.exports) {\n  module.exports = impl;\n} else if (__webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\") && __webpack_require__(/*! !webpack amd options */ \"./node_modules/webpack/buildin/amd-options.js\")) {\n  !(__WEBPACK_AMD_DEFINE_RESULT__ = (function() { return impl; }).call(exports, __webpack_require__, exports, module),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n} else {\n  this.xorshift7 = impl;\n}\n\n})(\n  this,\n   true && module,    // present in node.js\n  __webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\")   // present with an AMD loader\n);\n\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/module.js */ \"./node_modules/webpack/buildin/module.js\")(module)))\n\n//# sourceURL=webpack:///./node_modules/seedrandom/lib/xorshift7.js?");

/***/ }),

/***/ "./node_modules/seedrandom/lib/xorwow.js":
/*!***********************************************!*\
  !*** ./node_modules/seedrandom/lib/xorwow.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(module) {var __WEBPACK_AMD_DEFINE_RESULT__;// A Javascript implementaion of the \"xorwow\" prng algorithm by\n// George Marsaglia.  See http://www.jstatsoft.org/v08/i14/paper\n\n(function(global, module, define) {\n\nfunction XorGen(seed) {\n  var me = this, strseed = '';\n\n  // Set up generator function.\n  me.next = function() {\n    var t = (me.x ^ (me.x >>> 2));\n    me.x = me.y; me.y = me.z; me.z = me.w; me.w = me.v;\n    return (me.d = (me.d + 362437 | 0)) +\n       (me.v = (me.v ^ (me.v << 4)) ^ (t ^ (t << 1))) | 0;\n  };\n\n  me.x = 0;\n  me.y = 0;\n  me.z = 0;\n  me.w = 0;\n  me.v = 0;\n\n  if (seed === (seed | 0)) {\n    // Integer seed.\n    me.x = seed;\n  } else {\n    // String seed.\n    strseed += seed;\n  }\n\n  // Mix in string seed, then discard an initial batch of 64 values.\n  for (var k = 0; k < strseed.length + 64; k++) {\n    me.x ^= strseed.charCodeAt(k) | 0;\n    if (k == strseed.length) {\n      me.d = me.x << 10 ^ me.x >>> 4;\n    }\n    me.next();\n  }\n}\n\nfunction copy(f, t) {\n  t.x = f.x;\n  t.y = f.y;\n  t.z = f.z;\n  t.w = f.w;\n  t.v = f.v;\n  t.d = f.d;\n  return t;\n}\n\nfunction impl(seed, opts) {\n  var xg = new XorGen(seed),\n      state = opts && opts.state,\n      prng = function() { return (xg.next() >>> 0) / 0x100000000; };\n  prng.double = function() {\n    do {\n      var top = xg.next() >>> 11,\n          bot = (xg.next() >>> 0) / 0x100000000,\n          result = (top + bot) / (1 << 21);\n    } while (result === 0);\n    return result;\n  };\n  prng.int32 = xg.next;\n  prng.quick = prng;\n  if (state) {\n    if (typeof(state) == 'object') copy(state, xg);\n    prng.state = function() { return copy(xg, {}); }\n  }\n  return prng;\n}\n\nif (module && module.exports) {\n  module.exports = impl;\n} else if (__webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\") && __webpack_require__(/*! !webpack amd options */ \"./node_modules/webpack/buildin/amd-options.js\")) {\n  !(__WEBPACK_AMD_DEFINE_RESULT__ = (function() { return impl; }).call(exports, __webpack_require__, exports, module),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n} else {\n  this.xorwow = impl;\n}\n\n})(\n  this,\n   true && module,    // present in node.js\n  __webpack_require__(/*! !webpack amd define */ \"./node_modules/webpack/buildin/amd-define.js\")   // present with an AMD loader\n);\n\n\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/module.js */ \"./node_modules/webpack/buildin/module.js\")(module)))\n\n//# sourceURL=webpack:///./node_modules/seedrandom/lib/xorwow.js?");

/***/ }),

/***/ "./node_modules/seedrandom/seedrandom.js":
/*!***********************************************!*\
  !*** ./node_modules/seedrandom/seedrandom.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_RESULT__;/*\nCopyright 2014 David Bau.\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n*/\n\n(function (pool, math) {\n//\n// The following constants are related to IEEE 754 limits.\n//\nvar global = this,\n    width = 256,        // each RC4 output is 0 <= x < 256\n    chunks = 6,         // at least six RC4 outputs for each double\n    digits = 52,        // there are 52 significant digits in a double\n    rngname = 'random', // rngname: name for Math.random and Math.seedrandom\n    startdenom = math.pow(width, chunks),\n    significance = math.pow(2, digits),\n    overflow = significance * 2,\n    mask = width - 1,\n    nodecrypto;         // node.js crypto module, initialized at the bottom.\n\n//\n// seedrandom()\n// This is the seedrandom function described above.\n//\nfunction seedrandom(seed, options, callback) {\n  var key = [];\n  options = (options == true) ? { entropy: true } : (options || {});\n\n  // Flatten the seed string or build one from local entropy if needed.\n  var shortseed = mixkey(flatten(\n    options.entropy ? [seed, tostring(pool)] :\n    (seed == null) ? autoseed() : seed, 3), key);\n\n  // Use the seed to initialize an ARC4 generator.\n  var arc4 = new ARC4(key);\n\n  // This function returns a random double in [0, 1) that contains\n  // randomness in every bit of the mantissa of the IEEE 754 value.\n  var prng = function() {\n    var n = arc4.g(chunks),             // Start with a numerator n < 2 ^ 48\n        d = startdenom,                 //   and denominator d = 2 ^ 48.\n        x = 0;                          //   and no 'extra last byte'.\n    while (n < significance) {          // Fill up all significant digits by\n      n = (n + x) * width;              //   shifting numerator and\n      d *= width;                       //   denominator and generating a\n      x = arc4.g(1);                    //   new least-significant-byte.\n    }\n    while (n >= overflow) {             // To avoid rounding up, before adding\n      n /= 2;                           //   last byte, shift everything\n      d /= 2;                           //   right using integer math until\n      x >>>= 1;                         //   we have exactly the desired bits.\n    }\n    return (n + x) / d;                 // Form the number within [0, 1).\n  };\n\n  prng.int32 = function() { return arc4.g(4) | 0; }\n  prng.quick = function() { return arc4.g(4) / 0x100000000; }\n  prng.double = prng;\n\n  // Mix the randomness into accumulated entropy.\n  mixkey(tostring(arc4.S), pool);\n\n  // Calling convention: what to return as a function of prng, seed, is_math.\n  return (options.pass || callback ||\n      function(prng, seed, is_math_call, state) {\n        if (state) {\n          // Load the arc4 state from the given state if it has an S array.\n          if (state.S) { copy(state, arc4); }\n          // Only provide the .state method if requested via options.state.\n          prng.state = function() { return copy(arc4, {}); }\n        }\n\n        // If called as a method of Math (Math.seedrandom()), mutate\n        // Math.random because that is how seedrandom.js has worked since v1.0.\n        if (is_math_call) { math[rngname] = prng; return seed; }\n\n        // Otherwise, it is a newer calling convention, so return the\n        // prng directly.\n        else return prng;\n      })(\n  prng,\n  shortseed,\n  'global' in options ? options.global : (this == math),\n  options.state);\n}\nmath['seed' + rngname] = seedrandom;\n\n//\n// ARC4\n//\n// An ARC4 implementation.  The constructor takes a key in the form of\n// an array of at most (width) integers that should be 0 <= x < (width).\n//\n// The g(count) method returns a pseudorandom integer that concatenates\n// the next (count) outputs from ARC4.  Its return value is a number x\n// that is in the range 0 <= x < (width ^ count).\n//\nfunction ARC4(key) {\n  var t, keylen = key.length,\n      me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];\n\n  // The empty key [] is treated as [0].\n  if (!keylen) { key = [keylen++]; }\n\n  // Set up S using the standard key scheduling algorithm.\n  while (i < width) {\n    s[i] = i++;\n  }\n  for (i = 0; i < width; i++) {\n    s[i] = s[j = mask & (j + key[i % keylen] + (t = s[i]))];\n    s[j] = t;\n  }\n\n  // The \"g\" method returns the next (count) outputs as one number.\n  (me.g = function(count) {\n    // Using instance members instead of closure state nearly doubles speed.\n    var t, r = 0,\n        i = me.i, j = me.j, s = me.S;\n    while (count--) {\n      t = s[i = mask & (i + 1)];\n      r = r * width + s[mask & ((s[i] = s[j = mask & (j + t)]) + (s[j] = t))];\n    }\n    me.i = i; me.j = j;\n    return r;\n    // For robust unpredictability, the function call below automatically\n    // discards an initial batch of values.  This is called RC4-drop[256].\n    // See http://google.com/search?q=rsa+fluhrer+response&btnI\n  })(width);\n}\n\n//\n// copy()\n// Copies internal state of ARC4 to or from a plain object.\n//\nfunction copy(f, t) {\n  t.i = f.i;\n  t.j = f.j;\n  t.S = f.S.slice();\n  return t;\n};\n\n//\n// flatten()\n// Converts an object tree to nested arrays of strings.\n//\nfunction flatten(obj, depth) {\n  var result = [], typ = (typeof obj), prop;\n  if (depth && typ == 'object') {\n    for (prop in obj) {\n      try { result.push(flatten(obj[prop], depth - 1)); } catch (e) {}\n    }\n  }\n  return (result.length ? result : typ == 'string' ? obj : obj + '\\0');\n}\n\n//\n// mixkey()\n// Mixes a string seed into a key that is an array of integers, and\n// returns a shortened string seed that is equivalent to the result key.\n//\nfunction mixkey(seed, key) {\n  var stringseed = seed + '', smear, j = 0;\n  while (j < stringseed.length) {\n    key[mask & j] =\n      mask & ((smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++));\n  }\n  return tostring(key);\n}\n\n//\n// autoseed()\n// Returns an object for autoseeding, using window.crypto and Node crypto\n// module if available.\n//\nfunction autoseed() {\n  try {\n    var out;\n    if (nodecrypto && (out = nodecrypto.randomBytes)) {\n      // The use of 'out' to remember randomBytes makes tight minified code.\n      out = out(width);\n    } else {\n      out = new Uint8Array(width);\n      (global.crypto || global.msCrypto).getRandomValues(out);\n    }\n    return tostring(out);\n  } catch (e) {\n    var browser = global.navigator,\n        plugins = browser && browser.plugins;\n    return [+new Date, global, plugins, global.screen, tostring(pool)];\n  }\n}\n\n//\n// tostring()\n// Converts an array of charcodes to a string\n//\nfunction tostring(a) {\n  return String.fromCharCode.apply(0, a);\n}\n\n//\n// When seedrandom.js is loaded, we immediately mix a few bits\n// from the built-in RNG into the entropy pool.  Because we do\n// not want to interfere with deterministic PRNG state later,\n// seedrandom will not call math.random on its own again after\n// initialization.\n//\nmixkey(math.random(), pool);\n\n//\n// Nodejs and AMD support: export the implementation as a module using\n// either convention.\n//\nif ( true && module.exports) {\n  module.exports = seedrandom;\n  // When in node.js, try using crypto package for autoseeding.\n  try {\n    nodecrypto = __webpack_require__(/*! crypto */ 0);\n  } catch (ex) {}\n} else if (true) {\n  !(__WEBPACK_AMD_DEFINE_RESULT__ = (function() { return seedrandom; }).call(exports, __webpack_require__, exports, module),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n}\n\n// End anonymous scope, and pass initial values.\n})(\n  [],     // pool: entropy pool starts empty\n  Math    // math: package containing random, pow, and seedrandom\n);\n\n\n//# sourceURL=webpack:///./node_modules/seedrandom/seedrandom.js?");

/***/ }),

/***/ "./node_modules/setimmediate/setImmediate.js":
/*!***************************************************!*\
  !*** ./node_modules/setimmediate/setImmediate.js ***!
  \***************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global, process) {(function (global, undefined) {\n    \"use strict\";\n\n    if (global.setImmediate) {\n        return;\n    }\n\n    var nextHandle = 1; // Spec says greater than zero\n    var tasksByHandle = {};\n    var currentlyRunningATask = false;\n    var doc = global.document;\n    var registerImmediate;\n\n    function setImmediate(callback) {\n      // Callback can either be a function or a string\n      if (typeof callback !== \"function\") {\n        callback = new Function(\"\" + callback);\n      }\n      // Copy function arguments\n      var args = new Array(arguments.length - 1);\n      for (var i = 0; i < args.length; i++) {\n          args[i] = arguments[i + 1];\n      }\n      // Store and register the task\n      var task = { callback: callback, args: args };\n      tasksByHandle[nextHandle] = task;\n      registerImmediate(nextHandle);\n      return nextHandle++;\n    }\n\n    function clearImmediate(handle) {\n        delete tasksByHandle[handle];\n    }\n\n    function run(task) {\n        var callback = task.callback;\n        var args = task.args;\n        switch (args.length) {\n        case 0:\n            callback();\n            break;\n        case 1:\n            callback(args[0]);\n            break;\n        case 2:\n            callback(args[0], args[1]);\n            break;\n        case 3:\n            callback(args[0], args[1], args[2]);\n            break;\n        default:\n            callback.apply(undefined, args);\n            break;\n        }\n    }\n\n    function runIfPresent(handle) {\n        // From the spec: \"Wait until any invocations of this algorithm started before this one have completed.\"\n        // So if we're currently running a task, we'll need to delay this invocation.\n        if (currentlyRunningATask) {\n            // Delay by doing a setTimeout. setImmediate was tried instead, but in Firefox 7 it generated a\n            // \"too much recursion\" error.\n            setTimeout(runIfPresent, 0, handle);\n        } else {\n            var task = tasksByHandle[handle];\n            if (task) {\n                currentlyRunningATask = true;\n                try {\n                    run(task);\n                } finally {\n                    clearImmediate(handle);\n                    currentlyRunningATask = false;\n                }\n            }\n        }\n    }\n\n    function installNextTickImplementation() {\n        registerImmediate = function(handle) {\n            process.nextTick(function () { runIfPresent(handle); });\n        };\n    }\n\n    function canUsePostMessage() {\n        // The test against `importScripts` prevents this implementation from being installed inside a web worker,\n        // where `global.postMessage` means something completely different and can't be used for this purpose.\n        if (global.postMessage && !global.importScripts) {\n            var postMessageIsAsynchronous = true;\n            var oldOnMessage = global.onmessage;\n            global.onmessage = function() {\n                postMessageIsAsynchronous = false;\n            };\n            global.postMessage(\"\", \"*\");\n            global.onmessage = oldOnMessage;\n            return postMessageIsAsynchronous;\n        }\n    }\n\n    function installPostMessageImplementation() {\n        // Installs an event handler on `global` for the `message` event: see\n        // * https://developer.mozilla.org/en/DOM/window.postMessage\n        // * http://www.whatwg.org/specs/web-apps/current-work/multipage/comms.html#crossDocumentMessages\n\n        var messagePrefix = \"setImmediate$\" + Math.random() + \"$\";\n        var onGlobalMessage = function(event) {\n            if (event.source === global &&\n                typeof event.data === \"string\" &&\n                event.data.indexOf(messagePrefix) === 0) {\n                runIfPresent(+event.data.slice(messagePrefix.length));\n            }\n        };\n\n        if (global.addEventListener) {\n            global.addEventListener(\"message\", onGlobalMessage, false);\n        } else {\n            global.attachEvent(\"onmessage\", onGlobalMessage);\n        }\n\n        registerImmediate = function(handle) {\n            global.postMessage(messagePrefix + handle, \"*\");\n        };\n    }\n\n    function installMessageChannelImplementation() {\n        var channel = new MessageChannel();\n        channel.port1.onmessage = function(event) {\n            var handle = event.data;\n            runIfPresent(handle);\n        };\n\n        registerImmediate = function(handle) {\n            channel.port2.postMessage(handle);\n        };\n    }\n\n    function installReadyStateChangeImplementation() {\n        var html = doc.documentElement;\n        registerImmediate = function(handle) {\n            // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n            // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n            var script = doc.createElement(\"script\");\n            script.onreadystatechange = function () {\n                runIfPresent(handle);\n                script.onreadystatechange = null;\n                html.removeChild(script);\n                script = null;\n            };\n            html.appendChild(script);\n        };\n    }\n\n    function installSetTimeoutImplementation() {\n        registerImmediate = function(handle) {\n            setTimeout(runIfPresent, 0, handle);\n        };\n    }\n\n    // If supported, we should attach to the prototype of global, since that is where setTimeout et al. live.\n    var attachTo = Object.getPrototypeOf && Object.getPrototypeOf(global);\n    attachTo = attachTo && attachTo.setTimeout ? attachTo : global;\n\n    // Don't get fooled by e.g. browserify environments.\n    if ({}.toString.call(global.process) === \"[object process]\") {\n        // For Node.js before 0.9\n        installNextTickImplementation();\n\n    } else if (canUsePostMessage()) {\n        // For non-IE10 modern browsers\n        installPostMessageImplementation();\n\n    } else if (global.MessageChannel) {\n        // For web workers, where supported\n        installMessageChannelImplementation();\n\n    } else if (doc && \"onreadystatechange\" in doc.createElement(\"script\")) {\n        // For IE 6–8\n        installReadyStateChangeImplementation();\n\n    } else {\n        // For older browsers\n        installSetTimeoutImplementation();\n    }\n\n    attachTo.setImmediate = setImmediate;\n    attachTo.clearImmediate = clearImmediate;\n}(typeof self === \"undefined\" ? typeof global === \"undefined\" ? this : global : self));\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\"), __webpack_require__(/*! ./../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/setimmediate/setImmediate.js?");

/***/ }),

/***/ "./node_modules/stream-browserify/index.js":
/*!*************************************************!*\
  !*** ./node_modules/stream-browserify/index.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = Stream;\n\nvar EE = __webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter;\nvar inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n\ninherits(Stream, EE);\nStream.Readable = __webpack_require__(/*! readable-stream/readable.js */ \"./node_modules/readable-stream/readable-browser.js\");\nStream.Writable = __webpack_require__(/*! readable-stream/writable.js */ \"./node_modules/readable-stream/writable-browser.js\");\nStream.Duplex = __webpack_require__(/*! readable-stream/duplex.js */ \"./node_modules/readable-stream/duplex-browser.js\");\nStream.Transform = __webpack_require__(/*! readable-stream/transform.js */ \"./node_modules/readable-stream/transform.js\");\nStream.PassThrough = __webpack_require__(/*! readable-stream/passthrough.js */ \"./node_modules/readable-stream/passthrough.js\");\n\n// Backwards-compat with node 0.4.x\nStream.Stream = Stream;\n\n\n\n// old-style streams.  Note that the pipe method (the only relevant\n// part of this class) is overridden in the Readable class.\n\nfunction Stream() {\n  EE.call(this);\n}\n\nStream.prototype.pipe = function(dest, options) {\n  var source = this;\n\n  function ondata(chunk) {\n    if (dest.writable) {\n      if (false === dest.write(chunk) && source.pause) {\n        source.pause();\n      }\n    }\n  }\n\n  source.on('data', ondata);\n\n  function ondrain() {\n    if (source.readable && source.resume) {\n      source.resume();\n    }\n  }\n\n  dest.on('drain', ondrain);\n\n  // If the 'end' option is not supplied, dest.end() will be called when\n  // source gets the 'end' or 'close' events.  Only dest.end() once.\n  if (!dest._isStdio && (!options || options.end !== false)) {\n    source.on('end', onend);\n    source.on('close', onclose);\n  }\n\n  var didOnEnd = false;\n  function onend() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    dest.end();\n  }\n\n\n  function onclose() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    if (typeof dest.destroy === 'function') dest.destroy();\n  }\n\n  // don't leave dangling pipes when there are errors.\n  function onerror(er) {\n    cleanup();\n    if (EE.listenerCount(this, 'error') === 0) {\n      throw er; // Unhandled stream error in pipe.\n    }\n  }\n\n  source.on('error', onerror);\n  dest.on('error', onerror);\n\n  // remove all the event listeners that were added.\n  function cleanup() {\n    source.removeListener('data', ondata);\n    dest.removeListener('drain', ondrain);\n\n    source.removeListener('end', onend);\n    source.removeListener('close', onclose);\n\n    source.removeListener('error', onerror);\n    dest.removeListener('error', onerror);\n\n    source.removeListener('end', cleanup);\n    source.removeListener('close', cleanup);\n\n    dest.removeListener('close', cleanup);\n  }\n\n  source.on('end', cleanup);\n  source.on('close', cleanup);\n\n  dest.on('close', cleanup);\n\n  dest.emit('pipe', source);\n\n  // Allow for unix-like usage: A.pipe(B).pipe(C)\n  return dest;\n};\n\n\n//# sourceURL=webpack:///./node_modules/stream-browserify/index.js?");

/***/ }),

/***/ "./node_modules/stream-http/index.js":
/*!*******************************************!*\
  !*** ./node_modules/stream-http/index.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global) {var ClientRequest = __webpack_require__(/*! ./lib/request */ \"./node_modules/stream-http/lib/request.js\")\nvar response = __webpack_require__(/*! ./lib/response */ \"./node_modules/stream-http/lib/response.js\")\nvar extend = __webpack_require__(/*! xtend */ \"./node_modules/xtend/immutable.js\")\nvar statusCodes = __webpack_require__(/*! builtin-status-codes */ \"./node_modules/builtin-status-codes/index.js\")\nvar url = __webpack_require__(/*! url */ \"./node_modules/url/url.js\")\n\nvar http = exports\n\nhttp.request = function (opts, cb) {\n\tif (typeof opts === 'string')\n\t\topts = url.parse(opts)\n\telse\n\t\topts = extend(opts)\n\n\t// Normally, the page is loaded from http or https, so not specifying a protocol\n\t// will result in a (valid) protocol-relative url. However, this won't work if\n\t// the protocol is something else, like 'file:'\n\tvar defaultProtocol = global.location.protocol.search(/^https?:$/) === -1 ? 'http:' : ''\n\n\tvar protocol = opts.protocol || defaultProtocol\n\tvar host = opts.hostname || opts.host\n\tvar port = opts.port\n\tvar path = opts.path || '/'\n\n\t// Necessary for IPv6 addresses\n\tif (host && host.indexOf(':') !== -1)\n\t\thost = '[' + host + ']'\n\n\t// This may be a relative url. The browser should always be able to interpret it correctly.\n\topts.url = (host ? (protocol + '//' + host) : '') + (port ? ':' + port : '') + path\n\topts.method = (opts.method || 'GET').toUpperCase()\n\topts.headers = opts.headers || {}\n\n\t// Also valid opts.auth, opts.mode\n\n\tvar req = new ClientRequest(opts)\n\tif (cb)\n\t\treq.on('response', cb)\n\treturn req\n}\n\nhttp.get = function get (opts, cb) {\n\tvar req = http.request(opts, cb)\n\treq.end()\n\treturn req\n}\n\nhttp.ClientRequest = ClientRequest\nhttp.IncomingMessage = response.IncomingMessage\n\nhttp.Agent = function () {}\nhttp.Agent.defaultMaxSockets = 4\n\nhttp.globalAgent = new http.Agent()\n\nhttp.STATUS_CODES = statusCodes\n\nhttp.METHODS = [\n\t'CHECKOUT',\n\t'CONNECT',\n\t'COPY',\n\t'DELETE',\n\t'GET',\n\t'HEAD',\n\t'LOCK',\n\t'M-SEARCH',\n\t'MERGE',\n\t'MKACTIVITY',\n\t'MKCOL',\n\t'MOVE',\n\t'NOTIFY',\n\t'OPTIONS',\n\t'PATCH',\n\t'POST',\n\t'PROPFIND',\n\t'PROPPATCH',\n\t'PURGE',\n\t'PUT',\n\t'REPORT',\n\t'SEARCH',\n\t'SUBSCRIBE',\n\t'TRACE',\n\t'UNLOCK',\n\t'UNSUBSCRIBE'\n]\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/stream-http/index.js?");

/***/ }),

/***/ "./node_modules/stream-http/lib/capability.js":
/*!****************************************************!*\
  !*** ./node_modules/stream-http/lib/capability.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global) {exports.fetch = isFunction(global.fetch) && isFunction(global.ReadableStream)\n\nexports.writableStream = isFunction(global.WritableStream)\n\nexports.abortController = isFunction(global.AbortController)\n\nexports.blobConstructor = false\ntry {\n\tnew Blob([new ArrayBuffer(1)])\n\texports.blobConstructor = true\n} catch (e) {}\n\n// The xhr request to example.com may violate some restrictive CSP configurations,\n// so if we're running in a browser that supports `fetch`, avoid calling getXHR()\n// and assume support for certain features below.\nvar xhr\nfunction getXHR () {\n\t// Cache the xhr value\n\tif (xhr !== undefined) return xhr\n\n\tif (global.XMLHttpRequest) {\n\t\txhr = new global.XMLHttpRequest()\n\t\t// If XDomainRequest is available (ie only, where xhr might not work\n\t\t// cross domain), use the page location. Otherwise use example.com\n\t\t// Note: this doesn't actually make an http request.\n\t\ttry {\n\t\t\txhr.open('GET', global.XDomainRequest ? '/' : 'https://example.com')\n\t\t} catch(e) {\n\t\t\txhr = null\n\t\t}\n\t} else {\n\t\t// Service workers don't have XHR\n\t\txhr = null\n\t}\n\treturn xhr\n}\n\nfunction checkTypeSupport (type) {\n\tvar xhr = getXHR()\n\tif (!xhr) return false\n\ttry {\n\t\txhr.responseType = type\n\t\treturn xhr.responseType === type\n\t} catch (e) {}\n\treturn false\n}\n\n// For some strange reason, Safari 7.0 reports typeof global.ArrayBuffer === 'object'.\n// Safari 7.1 appears to have fixed this bug.\nvar haveArrayBuffer = typeof global.ArrayBuffer !== 'undefined'\nvar haveSlice = haveArrayBuffer && isFunction(global.ArrayBuffer.prototype.slice)\n\n// If fetch is supported, then arraybuffer will be supported too. Skip calling\n// checkTypeSupport(), since that calls getXHR().\nexports.arraybuffer = exports.fetch || (haveArrayBuffer && checkTypeSupport('arraybuffer'))\n\n// These next two tests unavoidably show warnings in Chrome. Since fetch will always\n// be used if it's available, just return false for these to avoid the warnings.\nexports.msstream = !exports.fetch && haveSlice && checkTypeSupport('ms-stream')\nexports.mozchunkedarraybuffer = !exports.fetch && haveArrayBuffer &&\n\tcheckTypeSupport('moz-chunked-arraybuffer')\n\n// If fetch is supported, then overrideMimeType will be supported too. Skip calling\n// getXHR().\nexports.overrideMimeType = exports.fetch || (getXHR() ? isFunction(getXHR().overrideMimeType) : false)\n\nexports.vbArray = isFunction(global.VBArray)\n\nfunction isFunction (value) {\n\treturn typeof value === 'function'\n}\n\nxhr = null // Help gc\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/stream-http/lib/capability.js?");

/***/ }),

/***/ "./node_modules/stream-http/lib/request.js":
/*!*************************************************!*\
  !*** ./node_modules/stream-http/lib/request.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(Buffer, global, process) {var capability = __webpack_require__(/*! ./capability */ \"./node_modules/stream-http/lib/capability.js\")\nvar inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\")\nvar response = __webpack_require__(/*! ./response */ \"./node_modules/stream-http/lib/response.js\")\nvar stream = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/readable-browser.js\")\nvar toArrayBuffer = __webpack_require__(/*! to-arraybuffer */ \"./node_modules/to-arraybuffer/index.js\")\n\nvar IncomingMessage = response.IncomingMessage\nvar rStates = response.readyStates\n\nfunction decideMode (preferBinary, useFetch) {\n\tif (capability.fetch && useFetch) {\n\t\treturn 'fetch'\n\t} else if (capability.mozchunkedarraybuffer) {\n\t\treturn 'moz-chunked-arraybuffer'\n\t} else if (capability.msstream) {\n\t\treturn 'ms-stream'\n\t} else if (capability.arraybuffer && preferBinary) {\n\t\treturn 'arraybuffer'\n\t} else if (capability.vbArray && preferBinary) {\n\t\treturn 'text:vbarray'\n\t} else {\n\t\treturn 'text'\n\t}\n}\n\nvar ClientRequest = module.exports = function (opts) {\n\tvar self = this\n\tstream.Writable.call(self)\n\n\tself._opts = opts\n\tself._body = []\n\tself._headers = {}\n\tif (opts.auth)\n\t\tself.setHeader('Authorization', 'Basic ' + new Buffer(opts.auth).toString('base64'))\n\tObject.keys(opts.headers).forEach(function (name) {\n\t\tself.setHeader(name, opts.headers[name])\n\t})\n\n\tvar preferBinary\n\tvar useFetch = true\n\tif (opts.mode === 'disable-fetch' || ('requestTimeout' in opts && !capability.abortController)) {\n\t\t// If the use of XHR should be preferred. Not typically needed.\n\t\tuseFetch = false\n\t\tpreferBinary = true\n\t} else if (opts.mode === 'prefer-streaming') {\n\t\t// If streaming is a high priority but binary compatibility and\n\t\t// the accuracy of the 'content-type' header aren't\n\t\tpreferBinary = false\n\t} else if (opts.mode === 'allow-wrong-content-type') {\n\t\t// If streaming is more important than preserving the 'content-type' header\n\t\tpreferBinary = !capability.overrideMimeType\n\t} else if (!opts.mode || opts.mode === 'default' || opts.mode === 'prefer-fast') {\n\t\t// Use binary if text streaming may corrupt data or the content-type header, or for speed\n\t\tpreferBinary = true\n\t} else {\n\t\tthrow new Error('Invalid value for opts.mode')\n\t}\n\tself._mode = decideMode(preferBinary, useFetch)\n\tself._fetchTimer = null\n\n\tself.on('finish', function () {\n\t\tself._onFinish()\n\t})\n}\n\ninherits(ClientRequest, stream.Writable)\n\nClientRequest.prototype.setHeader = function (name, value) {\n\tvar self = this\n\tvar lowerName = name.toLowerCase()\n\t// This check is not necessary, but it prevents warnings from browsers about setting unsafe\n\t// headers. To be honest I'm not entirely sure hiding these warnings is a good thing, but\n\t// http-browserify did it, so I will too.\n\tif (unsafeHeaders.indexOf(lowerName) !== -1)\n\t\treturn\n\n\tself._headers[lowerName] = {\n\t\tname: name,\n\t\tvalue: value\n\t}\n}\n\nClientRequest.prototype.getHeader = function (name) {\n\tvar header = this._headers[name.toLowerCase()]\n\tif (header)\n\t\treturn header.value\n\treturn null\n}\n\nClientRequest.prototype.removeHeader = function (name) {\n\tvar self = this\n\tdelete self._headers[name.toLowerCase()]\n}\n\nClientRequest.prototype._onFinish = function () {\n\tvar self = this\n\n\tif (self._destroyed)\n\t\treturn\n\tvar opts = self._opts\n\n\tvar headersObj = self._headers\n\tvar body = null\n\tif (opts.method !== 'GET' && opts.method !== 'HEAD') {\n\t\tif (capability.arraybuffer) {\n\t\t\tbody = toArrayBuffer(Buffer.concat(self._body))\n\t\t} else if (capability.blobConstructor) {\n\t\t\tbody = new global.Blob(self._body.map(function (buffer) {\n\t\t\t\treturn toArrayBuffer(buffer)\n\t\t\t}), {\n\t\t\t\ttype: (headersObj['content-type'] || {}).value || ''\n\t\t\t})\n\t\t} else {\n\t\t\t// get utf8 string\n\t\t\tbody = Buffer.concat(self._body).toString()\n\t\t}\n\t}\n\n\t// create flattened list of headers\n\tvar headersList = []\n\tObject.keys(headersObj).forEach(function (keyName) {\n\t\tvar name = headersObj[keyName].name\n\t\tvar value = headersObj[keyName].value\n\t\tif (Array.isArray(value)) {\n\t\t\tvalue.forEach(function (v) {\n\t\t\t\theadersList.push([name, v])\n\t\t\t})\n\t\t} else {\n\t\t\theadersList.push([name, value])\n\t\t}\n\t})\n\n\tif (self._mode === 'fetch') {\n\t\tvar signal = null\n\t\tvar fetchTimer = null\n\t\tif (capability.abortController) {\n\t\t\tvar controller = new AbortController()\n\t\t\tsignal = controller.signal\n\t\t\tself._fetchAbortController = controller\n\n\t\t\tif ('requestTimeout' in opts && opts.requestTimeout !== 0) {\n\t\t\t\tself._fetchTimer = global.setTimeout(function () {\n\t\t\t\t\tself.emit('requestTimeout')\n\t\t\t\t\tif (self._fetchAbortController)\n\t\t\t\t\t\tself._fetchAbortController.abort()\n\t\t\t\t}, opts.requestTimeout)\n\t\t\t}\n\t\t}\n\n\t\tglobal.fetch(self._opts.url, {\n\t\t\tmethod: self._opts.method,\n\t\t\theaders: headersList,\n\t\t\tbody: body || undefined,\n\t\t\tmode: 'cors',\n\t\t\tcredentials: opts.withCredentials ? 'include' : 'same-origin',\n\t\t\tsignal: signal\n\t\t}).then(function (response) {\n\t\t\tself._fetchResponse = response\n\t\t\tself._connect()\n\t\t}, function (reason) {\n\t\t\tglobal.clearTimeout(self._fetchTimer)\n\t\t\tif (!self._destroyed)\n\t\t\t\tself.emit('error', reason)\n\t\t})\n\t} else {\n\t\tvar xhr = self._xhr = new global.XMLHttpRequest()\n\t\ttry {\n\t\t\txhr.open(self._opts.method, self._opts.url, true)\n\t\t} catch (err) {\n\t\t\tprocess.nextTick(function () {\n\t\t\t\tself.emit('error', err)\n\t\t\t})\n\t\t\treturn\n\t\t}\n\n\t\t// Can't set responseType on really old browsers\n\t\tif ('responseType' in xhr)\n\t\t\txhr.responseType = self._mode.split(':')[0]\n\n\t\tif ('withCredentials' in xhr)\n\t\t\txhr.withCredentials = !!opts.withCredentials\n\n\t\tif (self._mode === 'text' && 'overrideMimeType' in xhr)\n\t\t\txhr.overrideMimeType('text/plain; charset=x-user-defined')\n\n\t\tif ('requestTimeout' in opts) {\n\t\t\txhr.timeout = opts.requestTimeout\n\t\t\txhr.ontimeout = function () {\n\t\t\t\tself.emit('requestTimeout')\n\t\t\t}\n\t\t}\n\n\t\theadersList.forEach(function (header) {\n\t\t\txhr.setRequestHeader(header[0], header[1])\n\t\t})\n\n\t\tself._response = null\n\t\txhr.onreadystatechange = function () {\n\t\t\tswitch (xhr.readyState) {\n\t\t\t\tcase rStates.LOADING:\n\t\t\t\tcase rStates.DONE:\n\t\t\t\t\tself._onXHRProgress()\n\t\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\t// Necessary for streaming in Firefox, since xhr.response is ONLY defined\n\t\t// in onprogress, not in onreadystatechange with xhr.readyState = 3\n\t\tif (self._mode === 'moz-chunked-arraybuffer') {\n\t\t\txhr.onprogress = function () {\n\t\t\t\tself._onXHRProgress()\n\t\t\t}\n\t\t}\n\n\t\txhr.onerror = function () {\n\t\t\tif (self._destroyed)\n\t\t\t\treturn\n\t\t\tself.emit('error', new Error('XHR error'))\n\t\t}\n\n\t\ttry {\n\t\t\txhr.send(body)\n\t\t} catch (err) {\n\t\t\tprocess.nextTick(function () {\n\t\t\t\tself.emit('error', err)\n\t\t\t})\n\t\t\treturn\n\t\t}\n\t}\n}\n\n/**\n * Checks if xhr.status is readable and non-zero, indicating no error.\n * Even though the spec says it should be available in readyState 3,\n * accessing it throws an exception in IE8\n */\nfunction statusValid (xhr) {\n\ttry {\n\t\tvar status = xhr.status\n\t\treturn (status !== null && status !== 0)\n\t} catch (e) {\n\t\treturn false\n\t}\n}\n\nClientRequest.prototype._onXHRProgress = function () {\n\tvar self = this\n\n\tif (!statusValid(self._xhr) || self._destroyed)\n\t\treturn\n\n\tif (!self._response)\n\t\tself._connect()\n\n\tself._response._onXHRProgress()\n}\n\nClientRequest.prototype._connect = function () {\n\tvar self = this\n\n\tif (self._destroyed)\n\t\treturn\n\n\tself._response = new IncomingMessage(self._xhr, self._fetchResponse, self._mode, self._fetchTimer)\n\tself._response.on('error', function(err) {\n\t\tself.emit('error', err)\n\t})\n\n\tself.emit('response', self._response)\n}\n\nClientRequest.prototype._write = function (chunk, encoding, cb) {\n\tvar self = this\n\n\tself._body.push(chunk)\n\tcb()\n}\n\nClientRequest.prototype.abort = ClientRequest.prototype.destroy = function () {\n\tvar self = this\n\tself._destroyed = true\n\tglobal.clearTimeout(self._fetchTimer)\n\tif (self._response)\n\t\tself._response._destroyed = true\n\tif (self._xhr)\n\t\tself._xhr.abort()\n\telse if (self._fetchAbortController)\n\t\tself._fetchAbortController.abort()\n}\n\nClientRequest.prototype.end = function (data, encoding, cb) {\n\tvar self = this\n\tif (typeof data === 'function') {\n\t\tcb = data\n\t\tdata = undefined\n\t}\n\n\tstream.Writable.prototype.end.call(self, data, encoding, cb)\n}\n\nClientRequest.prototype.flushHeaders = function () {}\nClientRequest.prototype.setTimeout = function () {}\nClientRequest.prototype.setNoDelay = function () {}\nClientRequest.prototype.setSocketKeepAlive = function () {}\n\n// Taken from http://www.w3.org/TR/XMLHttpRequest/#the-setrequestheader%28%29-method\nvar unsafeHeaders = [\n\t'accept-charset',\n\t'accept-encoding',\n\t'access-control-request-headers',\n\t'access-control-request-method',\n\t'connection',\n\t'content-length',\n\t'cookie',\n\t'cookie2',\n\t'date',\n\t'dnt',\n\t'expect',\n\t'host',\n\t'keep-alive',\n\t'origin',\n\t'referer',\n\t'te',\n\t'trailer',\n\t'transfer-encoding',\n\t'upgrade',\n\t'via'\n]\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer, __webpack_require__(/*! ./../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\"), __webpack_require__(/*! ./../../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/stream-http/lib/request.js?");

/***/ }),

/***/ "./node_modules/stream-http/lib/response.js":
/*!**************************************************!*\
  !*** ./node_modules/stream-http/lib/response.js ***!
  \**************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(process, Buffer, global) {var capability = __webpack_require__(/*! ./capability */ \"./node_modules/stream-http/lib/capability.js\")\nvar inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\")\nvar stream = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/readable-browser.js\")\n\nvar rStates = exports.readyStates = {\n\tUNSENT: 0,\n\tOPENED: 1,\n\tHEADERS_RECEIVED: 2,\n\tLOADING: 3,\n\tDONE: 4\n}\n\nvar IncomingMessage = exports.IncomingMessage = function (xhr, response, mode, fetchTimer) {\n\tvar self = this\n\tstream.Readable.call(self)\n\n\tself._mode = mode\n\tself.headers = {}\n\tself.rawHeaders = []\n\tself.trailers = {}\n\tself.rawTrailers = []\n\n\t// Fake the 'close' event, but only once 'end' fires\n\tself.on('end', function () {\n\t\t// The nextTick is necessary to prevent the 'request' module from causing an infinite loop\n\t\tprocess.nextTick(function () {\n\t\t\tself.emit('close')\n\t\t})\n\t})\n\n\tif (mode === 'fetch') {\n\t\tself._fetchResponse = response\n\n\t\tself.url = response.url\n\t\tself.statusCode = response.status\n\t\tself.statusMessage = response.statusText\n\t\t\n\t\tresponse.headers.forEach(function (header, key){\n\t\t\tself.headers[key.toLowerCase()] = header\n\t\t\tself.rawHeaders.push(key, header)\n\t\t})\n\n\t\tif (capability.writableStream) {\n\t\t\tvar writable = new WritableStream({\n\t\t\t\twrite: function (chunk) {\n\t\t\t\t\treturn new Promise(function (resolve, reject) {\n\t\t\t\t\t\tif (self._destroyed) {\n\t\t\t\t\t\t\treject()\n\t\t\t\t\t\t} else if(self.push(new Buffer(chunk))) {\n\t\t\t\t\t\t\tresolve()\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tself._resumeFetch = resolve\n\t\t\t\t\t\t}\n\t\t\t\t\t})\n\t\t\t\t},\n\t\t\t\tclose: function () {\n\t\t\t\t\tglobal.clearTimeout(fetchTimer)\n\t\t\t\t\tif (!self._destroyed)\n\t\t\t\t\t\tself.push(null)\n\t\t\t\t},\n\t\t\t\tabort: function (err) {\n\t\t\t\t\tif (!self._destroyed)\n\t\t\t\t\t\tself.emit('error', err)\n\t\t\t\t}\n\t\t\t})\n\n\t\t\ttry {\n\t\t\t\tresponse.body.pipeTo(writable).catch(function (err) {\n\t\t\t\t\tglobal.clearTimeout(fetchTimer)\n\t\t\t\t\tif (!self._destroyed)\n\t\t\t\t\t\tself.emit('error', err)\n\t\t\t\t})\n\t\t\t\treturn\n\t\t\t} catch (e) {} // pipeTo method isn't defined. Can't find a better way to feature test this\n\t\t}\n\t\t// fallback for when writableStream or pipeTo aren't available\n\t\tvar reader = response.body.getReader()\n\t\tfunction read () {\n\t\t\treader.read().then(function (result) {\n\t\t\t\tif (self._destroyed)\n\t\t\t\t\treturn\n\t\t\t\tif (result.done) {\n\t\t\t\t\tglobal.clearTimeout(fetchTimer)\n\t\t\t\t\tself.push(null)\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t\tself.push(new Buffer(result.value))\n\t\t\t\tread()\n\t\t\t}).catch(function (err) {\n\t\t\t\tglobal.clearTimeout(fetchTimer)\n\t\t\t\tif (!self._destroyed)\n\t\t\t\t\tself.emit('error', err)\n\t\t\t})\n\t\t}\n\t\tread()\n\t} else {\n\t\tself._xhr = xhr\n\t\tself._pos = 0\n\n\t\tself.url = xhr.responseURL\n\t\tself.statusCode = xhr.status\n\t\tself.statusMessage = xhr.statusText\n\t\tvar headers = xhr.getAllResponseHeaders().split(/\\r?\\n/)\n\t\theaders.forEach(function (header) {\n\t\t\tvar matches = header.match(/^([^:]+):\\s*(.*)/)\n\t\t\tif (matches) {\n\t\t\t\tvar key = matches[1].toLowerCase()\n\t\t\t\tif (key === 'set-cookie') {\n\t\t\t\t\tif (self.headers[key] === undefined) {\n\t\t\t\t\t\tself.headers[key] = []\n\t\t\t\t\t}\n\t\t\t\t\tself.headers[key].push(matches[2])\n\t\t\t\t} else if (self.headers[key] !== undefined) {\n\t\t\t\t\tself.headers[key] += ', ' + matches[2]\n\t\t\t\t} else {\n\t\t\t\t\tself.headers[key] = matches[2]\n\t\t\t\t}\n\t\t\t\tself.rawHeaders.push(matches[1], matches[2])\n\t\t\t}\n\t\t})\n\n\t\tself._charset = 'x-user-defined'\n\t\tif (!capability.overrideMimeType) {\n\t\t\tvar mimeType = self.rawHeaders['mime-type']\n\t\t\tif (mimeType) {\n\t\t\t\tvar charsetMatch = mimeType.match(/;\\s*charset=([^;])(;|$)/)\n\t\t\t\tif (charsetMatch) {\n\t\t\t\t\tself._charset = charsetMatch[1].toLowerCase()\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!self._charset)\n\t\t\t\tself._charset = 'utf-8' // best guess\n\t\t}\n\t}\n}\n\ninherits(IncomingMessage, stream.Readable)\n\nIncomingMessage.prototype._read = function () {\n\tvar self = this\n\n\tvar resolve = self._resumeFetch\n\tif (resolve) {\n\t\tself._resumeFetch = null\n\t\tresolve()\n\t}\n}\n\nIncomingMessage.prototype._onXHRProgress = function () {\n\tvar self = this\n\n\tvar xhr = self._xhr\n\n\tvar response = null\n\tswitch (self._mode) {\n\t\tcase 'text:vbarray': // For IE9\n\t\t\tif (xhr.readyState !== rStates.DONE)\n\t\t\t\tbreak\n\t\t\ttry {\n\t\t\t\t// This fails in IE8\n\t\t\t\tresponse = new global.VBArray(xhr.responseBody).toArray()\n\t\t\t} catch (e) {}\n\t\t\tif (response !== null) {\n\t\t\t\tself.push(new Buffer(response))\n\t\t\t\tbreak\n\t\t\t}\n\t\t\t// Falls through in IE8\t\n\t\tcase 'text':\n\t\t\ttry { // This will fail when readyState = 3 in IE9. Switch mode and wait for readyState = 4\n\t\t\t\tresponse = xhr.responseText\n\t\t\t} catch (e) {\n\t\t\t\tself._mode = 'text:vbarray'\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif (response.length > self._pos) {\n\t\t\t\tvar newData = response.substr(self._pos)\n\t\t\t\tif (self._charset === 'x-user-defined') {\n\t\t\t\t\tvar buffer = new Buffer(newData.length)\n\t\t\t\t\tfor (var i = 0; i < newData.length; i++)\n\t\t\t\t\t\tbuffer[i] = newData.charCodeAt(i) & 0xff\n\n\t\t\t\t\tself.push(buffer)\n\t\t\t\t} else {\n\t\t\t\t\tself.push(newData, self._charset)\n\t\t\t\t}\n\t\t\t\tself._pos = response.length\n\t\t\t}\n\t\t\tbreak\n\t\tcase 'arraybuffer':\n\t\t\tif (xhr.readyState !== rStates.DONE || !xhr.response)\n\t\t\t\tbreak\n\t\t\tresponse = xhr.response\n\t\t\tself.push(new Buffer(new Uint8Array(response)))\n\t\t\tbreak\n\t\tcase 'moz-chunked-arraybuffer': // take whole\n\t\t\tresponse = xhr.response\n\t\t\tif (xhr.readyState !== rStates.LOADING || !response)\n\t\t\t\tbreak\n\t\t\tself.push(new Buffer(new Uint8Array(response)))\n\t\t\tbreak\n\t\tcase 'ms-stream':\n\t\t\tresponse = xhr.response\n\t\t\tif (xhr.readyState !== rStates.LOADING)\n\t\t\t\tbreak\n\t\t\tvar reader = new global.MSStreamReader()\n\t\t\treader.onprogress = function () {\n\t\t\t\tif (reader.result.byteLength > self._pos) {\n\t\t\t\t\tself.push(new Buffer(new Uint8Array(reader.result.slice(self._pos))))\n\t\t\t\t\tself._pos = reader.result.byteLength\n\t\t\t\t}\n\t\t\t}\n\t\t\treader.onload = function () {\n\t\t\t\tself.push(null)\n\t\t\t}\n\t\t\t// reader.onerror = ??? // TODO: this\n\t\t\treader.readAsArrayBuffer(response)\n\t\t\tbreak\n\t}\n\n\t// The ms-stream case handles end separately in reader.onload()\n\tif (self._xhr.readyState === rStates.DONE && self._mode !== 'ms-stream') {\n\t\tself.push(null)\n\t}\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../process/browser.js */ \"./node_modules/process/browser.js\"), __webpack_require__(/*! ./../../buffer/index.js */ \"./node_modules/buffer/index.js\").Buffer, __webpack_require__(/*! ./../../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/stream-http/lib/response.js?");

/***/ }),

/***/ "./node_modules/string_decoder/lib/string_decoder.js":
/*!***********************************************************!*\
  !*** ./node_modules/string_decoder/lib/string_decoder.js ***!
  \***********************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar Buffer = __webpack_require__(/*! safe-buffer */ \"./node_modules/safe-buffer/index.js\").Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}\n\n//# sourceURL=webpack:///./node_modules/string_decoder/lib/string_decoder.js?");

/***/ }),

/***/ "./node_modules/timers-browserify/main.js":
/*!************************************************!*\
  !*** ./node_modules/timers-browserify/main.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global) {var scope = (typeof global !== \"undefined\" && global) ||\n            (typeof self !== \"undefined\" && self) ||\n            window;\nvar apply = Function.prototype.apply;\n\n// DOM APIs, for completeness\n\nexports.setTimeout = function() {\n  return new Timeout(apply.call(setTimeout, scope, arguments), clearTimeout);\n};\nexports.setInterval = function() {\n  return new Timeout(apply.call(setInterval, scope, arguments), clearInterval);\n};\nexports.clearTimeout =\nexports.clearInterval = function(timeout) {\n  if (timeout) {\n    timeout.close();\n  }\n};\n\nfunction Timeout(id, clearFn) {\n  this._id = id;\n  this._clearFn = clearFn;\n}\nTimeout.prototype.unref = Timeout.prototype.ref = function() {};\nTimeout.prototype.close = function() {\n  this._clearFn.call(scope, this._id);\n};\n\n// Does not start the time, just sets up the members needed.\nexports.enroll = function(item, msecs) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = msecs;\n};\n\nexports.unenroll = function(item) {\n  clearTimeout(item._idleTimeoutId);\n  item._idleTimeout = -1;\n};\n\nexports._unrefActive = exports.active = function(item) {\n  clearTimeout(item._idleTimeoutId);\n\n  var msecs = item._idleTimeout;\n  if (msecs >= 0) {\n    item._idleTimeoutId = setTimeout(function onTimeout() {\n      if (item._onTimeout)\n        item._onTimeout();\n    }, msecs);\n  }\n};\n\n// setimmediate attaches itself to the global object\n__webpack_require__(/*! setimmediate */ \"./node_modules/setimmediate/setImmediate.js\");\n// On some exotic environments, it's not clear which object `setimmediate` was\n// able to install onto.  Search each possibility in the same order as the\n// `setimmediate` library.\nexports.setImmediate = (typeof self !== \"undefined\" && self.setImmediate) ||\n                       (typeof global !== \"undefined\" && global.setImmediate) ||\n                       (this && this.setImmediate);\nexports.clearImmediate = (typeof self !== \"undefined\" && self.clearImmediate) ||\n                         (typeof global !== \"undefined\" && global.clearImmediate) ||\n                         (this && this.clearImmediate);\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/timers-browserify/main.js?");

/***/ }),

/***/ "./node_modules/to-arraybuffer/index.js":
/*!**********************************************!*\
  !*** ./node_modules/to-arraybuffer/index.js ***!
  \**********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var Buffer = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\").Buffer\n\nmodule.exports = function (buf) {\n\t// If the buffer is backed by a Uint8Array, a faster version will work\n\tif (buf instanceof Uint8Array) {\n\t\t// If the buffer isn't a subarray, return the underlying ArrayBuffer\n\t\tif (buf.byteOffset === 0 && buf.byteLength === buf.buffer.byteLength) {\n\t\t\treturn buf.buffer\n\t\t} else if (typeof buf.buffer.slice === 'function') {\n\t\t\t// Otherwise we need to get a proper copy\n\t\t\treturn buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength)\n\t\t}\n\t}\n\n\tif (Buffer.isBuffer(buf)) {\n\t\t// This is the slow version that will work with any Buffer\n\t\t// implementation (even in old browsers)\n\t\tvar arrayCopy = new Uint8Array(buf.length)\n\t\tvar len = buf.length\n\t\tfor (var i = 0; i < len; i++) {\n\t\t\tarrayCopy[i] = buf[i]\n\t\t}\n\t\treturn arrayCopy.buffer\n\t} else {\n\t\tthrow new Error('Argument must be a Buffer')\n\t}\n}\n\n\n//# sourceURL=webpack:///./node_modules/to-arraybuffer/index.js?");

/***/ }),

/***/ "./node_modules/tslib/tslib.js":
/*!*************************************!*\
  !*** ./node_modules/tslib/tslib.js ***!
  \*************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global) {var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;/*! *****************************************************************************\r\nCopyright (c) Microsoft Corporation.\r\n\r\nPermission to use, copy, modify, and/or distribute this software for any\r\npurpose with or without fee is hereby granted.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\r\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\r\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\r\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\r\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\r\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\r\nPERFORMANCE OF THIS SOFTWARE.\r\n***************************************************************************** */\r\n\r\n/* global global, define, System, Reflect, Promise */\r\nvar __extends;\r\nvar __assign;\r\nvar __rest;\r\nvar __decorate;\r\nvar __param;\r\nvar __metadata;\r\nvar __awaiter;\r\nvar __generator;\r\nvar __exportStar;\r\nvar __values;\r\nvar __read;\r\nvar __spread;\r\nvar __spreadArrays;\r\nvar __await;\r\nvar __asyncGenerator;\r\nvar __asyncDelegator;\r\nvar __asyncValues;\r\nvar __makeTemplateObject;\r\nvar __importStar;\r\nvar __importDefault;\r\nvar __classPrivateFieldGet;\r\nvar __classPrivateFieldSet;\r\nvar __createBinding;\r\n(function (factory) {\r\n    var root = typeof global === \"object\" ? global : typeof self === \"object\" ? self : typeof this === \"object\" ? this : {};\r\n    if (true) {\r\n        !(__WEBPACK_AMD_DEFINE_ARRAY__ = [exports], __WEBPACK_AMD_DEFINE_RESULT__ = (function (exports) { factory(createExporter(root, createExporter(exports))); }).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\r\n    }\r\n    else {}\r\n    function createExporter(exports, previous) {\r\n        if (exports !== root) {\r\n            if (typeof Object.create === \"function\") {\r\n                Object.defineProperty(exports, \"__esModule\", { value: true });\r\n            }\r\n            else {\r\n                exports.__esModule = true;\r\n            }\r\n        }\r\n        return function (id, v) { return exports[id] = previous ? previous(id, v) : v; };\r\n    }\r\n})\r\n(function (exporter) {\r\n    var extendStatics = Object.setPrototypeOf ||\r\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\r\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\r\n\r\n    __extends = function (d, b) {\r\n        extendStatics(d, b);\r\n        function __() { this.constructor = d; }\r\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n    };\r\n\r\n    __assign = Object.assign || function (t) {\r\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\r\n            s = arguments[i];\r\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\r\n        }\r\n        return t;\r\n    };\r\n\r\n    __rest = function (s, e) {\r\n        var t = {};\r\n        for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\r\n            t[p] = s[p];\r\n        if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\r\n            for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\r\n                if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\r\n                    t[p[i]] = s[p[i]];\r\n            }\r\n        return t;\r\n    };\r\n\r\n    __decorate = function (decorators, target, key, desc) {\r\n        var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\r\n        if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\r\n        else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\r\n        return c > 3 && r && Object.defineProperty(target, key, r), r;\r\n    };\r\n\r\n    __param = function (paramIndex, decorator) {\r\n        return function (target, key) { decorator(target, key, paramIndex); }\r\n    };\r\n\r\n    __metadata = function (metadataKey, metadataValue) {\r\n        if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\r\n    };\r\n\r\n    __awaiter = function (thisArg, _arguments, P, generator) {\r\n        function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n        return new (P || (P = Promise))(function (resolve, reject) {\r\n            function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n            function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n            function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n            step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n        });\r\n    };\r\n\r\n    __generator = function (thisArg, body) {\r\n        var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\r\n        return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\r\n        function verb(n) { return function (v) { return step([n, v]); }; }\r\n        function step(op) {\r\n            if (f) throw new TypeError(\"Generator is already executing.\");\r\n            while (_) try {\r\n                if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\r\n                if (y = 0, t) op = [op[0] & 2, t.value];\r\n                switch (op[0]) {\r\n                    case 0: case 1: t = op; break;\r\n                    case 4: _.label++; return { value: op[1], done: false };\r\n                    case 5: _.label++; y = op[1]; op = [0]; continue;\r\n                    case 7: op = _.ops.pop(); _.trys.pop(); continue;\r\n                    default:\r\n                        if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\r\n                        if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\r\n                        if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\r\n                        if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\r\n                        if (t[2]) _.ops.pop();\r\n                        _.trys.pop(); continue;\r\n                }\r\n                op = body.call(thisArg, _);\r\n            } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\r\n            if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\r\n        }\r\n    };\r\n\r\n    __createBinding = function(o, m, k, k2) {\r\n        if (k2 === undefined) k2 = k;\r\n        o[k2] = m[k];\r\n    };\r\n\r\n    __exportStar = function (m, exports) {\r\n        for (var p in m) if (p !== \"default\" && !exports.hasOwnProperty(p)) exports[p] = m[p];\r\n    };\r\n\r\n    __values = function (o) {\r\n        var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\r\n        if (m) return m.call(o);\r\n        if (o && typeof o.length === \"number\") return {\r\n            next: function () {\r\n                if (o && i >= o.length) o = void 0;\r\n                return { value: o && o[i++], done: !o };\r\n            }\r\n        };\r\n        throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\r\n    };\r\n\r\n    __read = function (o, n) {\r\n        var m = typeof Symbol === \"function\" && o[Symbol.iterator];\r\n        if (!m) return o;\r\n        var i = m.call(o), r, ar = [], e;\r\n        try {\r\n            while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\r\n        }\r\n        catch (error) { e = { error: error }; }\r\n        finally {\r\n            try {\r\n                if (r && !r.done && (m = i[\"return\"])) m.call(i);\r\n            }\r\n            finally { if (e) throw e.error; }\r\n        }\r\n        return ar;\r\n    };\r\n\r\n    __spread = function () {\r\n        for (var ar = [], i = 0; i < arguments.length; i++)\r\n            ar = ar.concat(__read(arguments[i]));\r\n        return ar;\r\n    };\r\n\r\n    __spreadArrays = function () {\r\n        for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\r\n        for (var r = Array(s), k = 0, i = 0; i < il; i++)\r\n            for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\r\n                r[k] = a[j];\r\n        return r;\r\n    };\r\n\r\n    __await = function (v) {\r\n        return this instanceof __await ? (this.v = v, this) : new __await(v);\r\n    };\r\n\r\n    __asyncGenerator = function (thisArg, _arguments, generator) {\r\n        if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n        var g = generator.apply(thisArg, _arguments || []), i, q = [];\r\n        return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\r\n        function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\r\n        function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\r\n        function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r);  }\r\n        function fulfill(value) { resume(\"next\", value); }\r\n        function reject(value) { resume(\"throw\", value); }\r\n        function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\r\n    };\r\n\r\n    __asyncDelegator = function (o) {\r\n        var i, p;\r\n        return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\r\n        function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: n === \"return\" } : f ? f(v) : v; } : f; }\r\n    };\r\n\r\n    __asyncValues = function (o) {\r\n        if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n        var m = o[Symbol.asyncIterator], i;\r\n        return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\r\n        function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\r\n        function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\r\n    };\r\n\r\n    __makeTemplateObject = function (cooked, raw) {\r\n        if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\r\n        return cooked;\r\n    };\r\n\r\n    __importStar = function (mod) {\r\n        if (mod && mod.__esModule) return mod;\r\n        var result = {};\r\n        if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\r\n        result[\"default\"] = mod;\r\n        return result;\r\n    };\r\n\r\n    __importDefault = function (mod) {\r\n        return (mod && mod.__esModule) ? mod : { \"default\": mod };\r\n    };\r\n\r\n    __classPrivateFieldGet = function (receiver, privateMap) {\r\n        if (!privateMap.has(receiver)) {\r\n            throw new TypeError(\"attempted to get private field on non-instance\");\r\n        }\r\n        return privateMap.get(receiver);\r\n    };\r\n\r\n    __classPrivateFieldSet = function (receiver, privateMap, value) {\r\n        if (!privateMap.has(receiver)) {\r\n            throw new TypeError(\"attempted to set private field on non-instance\");\r\n        }\r\n        privateMap.set(receiver, value);\r\n        return value;\r\n    };\r\n\r\n    exporter(\"__extends\", __extends);\r\n    exporter(\"__assign\", __assign);\r\n    exporter(\"__rest\", __rest);\r\n    exporter(\"__decorate\", __decorate);\r\n    exporter(\"__param\", __param);\r\n    exporter(\"__metadata\", __metadata);\r\n    exporter(\"__awaiter\", __awaiter);\r\n    exporter(\"__generator\", __generator);\r\n    exporter(\"__exportStar\", __exportStar);\r\n    exporter(\"__createBinding\", __createBinding);\r\n    exporter(\"__values\", __values);\r\n    exporter(\"__read\", __read);\r\n    exporter(\"__spread\", __spread);\r\n    exporter(\"__spreadArrays\", __spreadArrays);\r\n    exporter(\"__await\", __await);\r\n    exporter(\"__asyncGenerator\", __asyncGenerator);\r\n    exporter(\"__asyncDelegator\", __asyncDelegator);\r\n    exporter(\"__asyncValues\", __asyncValues);\r\n    exporter(\"__makeTemplateObject\", __makeTemplateObject);\r\n    exporter(\"__importStar\", __importStar);\r\n    exporter(\"__importDefault\", __importDefault);\r\n    exporter(\"__classPrivateFieldGet\", __classPrivateFieldGet);\r\n    exporter(\"__classPrivateFieldSet\", __classPrivateFieldSet);\r\n});\r\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/tslib/tslib.js?");

/***/ }),

/***/ "./node_modules/url/url.js":
/*!*********************************!*\
  !*** ./node_modules/url/url.js ***!
  \*********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar punycode = __webpack_require__(/*! punycode */ \"./node_modules/punycode/punycode.js\");\nvar util = __webpack_require__(/*! ./util */ \"./node_modules/url/util.js\");\n\nexports.parse = urlParse;\nexports.resolve = urlResolve;\nexports.resolveObject = urlResolveObject;\nexports.format = urlFormat;\n\nexports.Url = Url;\n\nfunction Url() {\n  this.protocol = null;\n  this.slashes = null;\n  this.auth = null;\n  this.host = null;\n  this.port = null;\n  this.hostname = null;\n  this.hash = null;\n  this.search = null;\n  this.query = null;\n  this.pathname = null;\n  this.path = null;\n  this.href = null;\n}\n\n// Reference: RFC 3986, RFC 1808, RFC 2396\n\n// define these here so at least they only have to be\n// compiled once on the first module load.\nvar protocolPattern = /^([a-z0-9.+-]+:)/i,\n    portPattern = /:[0-9]*$/,\n\n    // Special case for a simple path URL\n    simplePathPattern = /^(\\/\\/?(?!\\/)[^\\?\\s]*)(\\?[^\\s]*)?$/,\n\n    // RFC 2396: characters reserved for delimiting URLs.\n    // We actually just auto-escape these.\n    delims = ['<', '>', '\"', '`', ' ', '\\r', '\\n', '\\t'],\n\n    // RFC 2396: characters not allowed for various reasons.\n    unwise = ['{', '}', '|', '\\\\', '^', '`'].concat(delims),\n\n    // Allowed by RFCs, but cause of XSS attacks.  Always escape these.\n    autoEscape = ['\\''].concat(unwise),\n    // Characters that are never ever allowed in a hostname.\n    // Note that any invalid chars are also handled, but these\n    // are the ones that are *expected* to be seen, so we fast-path\n    // them.\n    nonHostChars = ['%', '/', '?', ';', '#'].concat(autoEscape),\n    hostEndingChars = ['/', '?', '#'],\n    hostnameMaxLen = 255,\n    hostnamePartPattern = /^[+a-z0-9A-Z_-]{0,63}$/,\n    hostnamePartStart = /^([+a-z0-9A-Z_-]{0,63})(.*)$/,\n    // protocols that can allow \"unsafe\" and \"unwise\" chars.\n    unsafeProtocol = {\n      'javascript': true,\n      'javascript:': true\n    },\n    // protocols that never have a hostname.\n    hostlessProtocol = {\n      'javascript': true,\n      'javascript:': true\n    },\n    // protocols that always contain a // bit.\n    slashedProtocol = {\n      'http': true,\n      'https': true,\n      'ftp': true,\n      'gopher': true,\n      'file': true,\n      'http:': true,\n      'https:': true,\n      'ftp:': true,\n      'gopher:': true,\n      'file:': true\n    },\n    querystring = __webpack_require__(/*! querystring */ \"./node_modules/querystring-es3/index.js\");\n\nfunction urlParse(url, parseQueryString, slashesDenoteHost) {\n  if (url && util.isObject(url) && url instanceof Url) return url;\n\n  var u = new Url;\n  u.parse(url, parseQueryString, slashesDenoteHost);\n  return u;\n}\n\nUrl.prototype.parse = function(url, parseQueryString, slashesDenoteHost) {\n  if (!util.isString(url)) {\n    throw new TypeError(\"Parameter 'url' must be a string, not \" + typeof url);\n  }\n\n  // Copy chrome, IE, opera backslash-handling behavior.\n  // Back slashes before the query string get converted to forward slashes\n  // See: https://code.google.com/p/chromium/issues/detail?id=25916\n  var queryIndex = url.indexOf('?'),\n      splitter =\n          (queryIndex !== -1 && queryIndex < url.indexOf('#')) ? '?' : '#',\n      uSplit = url.split(splitter),\n      slashRegex = /\\\\/g;\n  uSplit[0] = uSplit[0].replace(slashRegex, '/');\n  url = uSplit.join(splitter);\n\n  var rest = url;\n\n  // trim before proceeding.\n  // This is to support parse stuff like \"  http://foo.com  \\n\"\n  rest = rest.trim();\n\n  if (!slashesDenoteHost && url.split('#').length === 1) {\n    // Try fast path regexp\n    var simplePath = simplePathPattern.exec(rest);\n    if (simplePath) {\n      this.path = rest;\n      this.href = rest;\n      this.pathname = simplePath[1];\n      if (simplePath[2]) {\n        this.search = simplePath[2];\n        if (parseQueryString) {\n          this.query = querystring.parse(this.search.substr(1));\n        } else {\n          this.query = this.search.substr(1);\n        }\n      } else if (parseQueryString) {\n        this.search = '';\n        this.query = {};\n      }\n      return this;\n    }\n  }\n\n  var proto = protocolPattern.exec(rest);\n  if (proto) {\n    proto = proto[0];\n    var lowerProto = proto.toLowerCase();\n    this.protocol = lowerProto;\n    rest = rest.substr(proto.length);\n  }\n\n  // figure out if it's got a host\n  // user@server is *always* interpreted as a hostname, and url\n  // resolution will treat //foo/bar as host=foo,path=bar because that's\n  // how the browser resolves relative URLs.\n  if (slashesDenoteHost || proto || rest.match(/^\\/\\/[^@\\/]+@[^@\\/]+/)) {\n    var slashes = rest.substr(0, 2) === '//';\n    if (slashes && !(proto && hostlessProtocol[proto])) {\n      rest = rest.substr(2);\n      this.slashes = true;\n    }\n  }\n\n  if (!hostlessProtocol[proto] &&\n      (slashes || (proto && !slashedProtocol[proto]))) {\n\n    // there's a hostname.\n    // the first instance of /, ?, ;, or # ends the host.\n    //\n    // If there is an @ in the hostname, then non-host chars *are* allowed\n    // to the left of the last @ sign, unless some host-ending character\n    // comes *before* the @-sign.\n    // URLs are obnoxious.\n    //\n    // ex:\n    // http://a@b@c/ => user:a@b host:c\n    // http://a@b?@c => user:a host:c path:/?@c\n\n    // v0.12 TODO(isaacs): This is not quite how Chrome does things.\n    // Review our test case against browsers more comprehensively.\n\n    // find the first instance of any hostEndingChars\n    var hostEnd = -1;\n    for (var i = 0; i < hostEndingChars.length; i++) {\n      var hec = rest.indexOf(hostEndingChars[i]);\n      if (hec !== -1 && (hostEnd === -1 || hec < hostEnd))\n        hostEnd = hec;\n    }\n\n    // at this point, either we have an explicit point where the\n    // auth portion cannot go past, or the last @ char is the decider.\n    var auth, atSign;\n    if (hostEnd === -1) {\n      // atSign can be anywhere.\n      atSign = rest.lastIndexOf('@');\n    } else {\n      // atSign must be in auth portion.\n      // http://a@b/c@d => host:b auth:a path:/c@d\n      atSign = rest.lastIndexOf('@', hostEnd);\n    }\n\n    // Now we have a portion which is definitely the auth.\n    // Pull that off.\n    if (atSign !== -1) {\n      auth = rest.slice(0, atSign);\n      rest = rest.slice(atSign + 1);\n      this.auth = decodeURIComponent(auth);\n    }\n\n    // the host is the remaining to the left of the first non-host char\n    hostEnd = -1;\n    for (var i = 0; i < nonHostChars.length; i++) {\n      var hec = rest.indexOf(nonHostChars[i]);\n      if (hec !== -1 && (hostEnd === -1 || hec < hostEnd))\n        hostEnd = hec;\n    }\n    // if we still have not hit it, then the entire thing is a host.\n    if (hostEnd === -1)\n      hostEnd = rest.length;\n\n    this.host = rest.slice(0, hostEnd);\n    rest = rest.slice(hostEnd);\n\n    // pull out port.\n    this.parseHost();\n\n    // we've indicated that there is a hostname,\n    // so even if it's empty, it has to be present.\n    this.hostname = this.hostname || '';\n\n    // if hostname begins with [ and ends with ]\n    // assume that it's an IPv6 address.\n    var ipv6Hostname = this.hostname[0] === '[' &&\n        this.hostname[this.hostname.length - 1] === ']';\n\n    // validate a little.\n    if (!ipv6Hostname) {\n      var hostparts = this.hostname.split(/\\./);\n      for (var i = 0, l = hostparts.length; i < l; i++) {\n        var part = hostparts[i];\n        if (!part) continue;\n        if (!part.match(hostnamePartPattern)) {\n          var newpart = '';\n          for (var j = 0, k = part.length; j < k; j++) {\n            if (part.charCodeAt(j) > 127) {\n              // we replace non-ASCII char with a temporary placeholder\n              // we need this to make sure size of hostname is not\n              // broken by replacing non-ASCII by nothing\n              newpart += 'x';\n            } else {\n              newpart += part[j];\n            }\n          }\n          // we test again with ASCII char only\n          if (!newpart.match(hostnamePartPattern)) {\n            var validParts = hostparts.slice(0, i);\n            var notHost = hostparts.slice(i + 1);\n            var bit = part.match(hostnamePartStart);\n            if (bit) {\n              validParts.push(bit[1]);\n              notHost.unshift(bit[2]);\n            }\n            if (notHost.length) {\n              rest = '/' + notHost.join('.') + rest;\n            }\n            this.hostname = validParts.join('.');\n            break;\n          }\n        }\n      }\n    }\n\n    if (this.hostname.length > hostnameMaxLen) {\n      this.hostname = '';\n    } else {\n      // hostnames are always lower case.\n      this.hostname = this.hostname.toLowerCase();\n    }\n\n    if (!ipv6Hostname) {\n      // IDNA Support: Returns a punycoded representation of \"domain\".\n      // It only converts parts of the domain name that\n      // have non-ASCII characters, i.e. it doesn't matter if\n      // you call it with a domain that already is ASCII-only.\n      this.hostname = punycode.toASCII(this.hostname);\n    }\n\n    var p = this.port ? ':' + this.port : '';\n    var h = this.hostname || '';\n    this.host = h + p;\n    this.href += this.host;\n\n    // strip [ and ] from the hostname\n    // the host field still retains them, though\n    if (ipv6Hostname) {\n      this.hostname = this.hostname.substr(1, this.hostname.length - 2);\n      if (rest[0] !== '/') {\n        rest = '/' + rest;\n      }\n    }\n  }\n\n  // now rest is set to the post-host stuff.\n  // chop off any delim chars.\n  if (!unsafeProtocol[lowerProto]) {\n\n    // First, make 100% sure that any \"autoEscape\" chars get\n    // escaped, even if encodeURIComponent doesn't think they\n    // need to be.\n    for (var i = 0, l = autoEscape.length; i < l; i++) {\n      var ae = autoEscape[i];\n      if (rest.indexOf(ae) === -1)\n        continue;\n      var esc = encodeURIComponent(ae);\n      if (esc === ae) {\n        esc = escape(ae);\n      }\n      rest = rest.split(ae).join(esc);\n    }\n  }\n\n\n  // chop off from the tail first.\n  var hash = rest.indexOf('#');\n  if (hash !== -1) {\n    // got a fragment string.\n    this.hash = rest.substr(hash);\n    rest = rest.slice(0, hash);\n  }\n  var qm = rest.indexOf('?');\n  if (qm !== -1) {\n    this.search = rest.substr(qm);\n    this.query = rest.substr(qm + 1);\n    if (parseQueryString) {\n      this.query = querystring.parse(this.query);\n    }\n    rest = rest.slice(0, qm);\n  } else if (parseQueryString) {\n    // no query string, but parseQueryString still requested\n    this.search = '';\n    this.query = {};\n  }\n  if (rest) this.pathname = rest;\n  if (slashedProtocol[lowerProto] &&\n      this.hostname && !this.pathname) {\n    this.pathname = '/';\n  }\n\n  //to support http.request\n  if (this.pathname || this.search) {\n    var p = this.pathname || '';\n    var s = this.search || '';\n    this.path = p + s;\n  }\n\n  // finally, reconstruct the href based on what has been validated.\n  this.href = this.format();\n  return this;\n};\n\n// format a parsed object into a url string\nfunction urlFormat(obj) {\n  // ensure it's an object, and not a string url.\n  // If it's an obj, this is a no-op.\n  // this way, you can call url_format() on strings\n  // to clean up potentially wonky urls.\n  if (util.isString(obj)) obj = urlParse(obj);\n  if (!(obj instanceof Url)) return Url.prototype.format.call(obj);\n  return obj.format();\n}\n\nUrl.prototype.format = function() {\n  var auth = this.auth || '';\n  if (auth) {\n    auth = encodeURIComponent(auth);\n    auth = auth.replace(/%3A/i, ':');\n    auth += '@';\n  }\n\n  var protocol = this.protocol || '',\n      pathname = this.pathname || '',\n      hash = this.hash || '',\n      host = false,\n      query = '';\n\n  if (this.host) {\n    host = auth + this.host;\n  } else if (this.hostname) {\n    host = auth + (this.hostname.indexOf(':') === -1 ?\n        this.hostname :\n        '[' + this.hostname + ']');\n    if (this.port) {\n      host += ':' + this.port;\n    }\n  }\n\n  if (this.query &&\n      util.isObject(this.query) &&\n      Object.keys(this.query).length) {\n    query = querystring.stringify(this.query);\n  }\n\n  var search = this.search || (query && ('?' + query)) || '';\n\n  if (protocol && protocol.substr(-1) !== ':') protocol += ':';\n\n  // only the slashedProtocols get the //.  Not mailto:, xmpp:, etc.\n  // unless they had them to begin with.\n  if (this.slashes ||\n      (!protocol || slashedProtocol[protocol]) && host !== false) {\n    host = '//' + (host || '');\n    if (pathname && pathname.charAt(0) !== '/') pathname = '/' + pathname;\n  } else if (!host) {\n    host = '';\n  }\n\n  if (hash && hash.charAt(0) !== '#') hash = '#' + hash;\n  if (search && search.charAt(0) !== '?') search = '?' + search;\n\n  pathname = pathname.replace(/[?#]/g, function(match) {\n    return encodeURIComponent(match);\n  });\n  search = search.replace('#', '%23');\n\n  return protocol + host + pathname + search + hash;\n};\n\nfunction urlResolve(source, relative) {\n  return urlParse(source, false, true).resolve(relative);\n}\n\nUrl.prototype.resolve = function(relative) {\n  return this.resolveObject(urlParse(relative, false, true)).format();\n};\n\nfunction urlResolveObject(source, relative) {\n  if (!source) return relative;\n  return urlParse(source, false, true).resolveObject(relative);\n}\n\nUrl.prototype.resolveObject = function(relative) {\n  if (util.isString(relative)) {\n    var rel = new Url();\n    rel.parse(relative, false, true);\n    relative = rel;\n  }\n\n  var result = new Url();\n  var tkeys = Object.keys(this);\n  for (var tk = 0; tk < tkeys.length; tk++) {\n    var tkey = tkeys[tk];\n    result[tkey] = this[tkey];\n  }\n\n  // hash is always overridden, no matter what.\n  // even href=\"\" will remove it.\n  result.hash = relative.hash;\n\n  // if the relative url is empty, then there's nothing left to do here.\n  if (relative.href === '') {\n    result.href = result.format();\n    return result;\n  }\n\n  // hrefs like //foo/bar always cut to the protocol.\n  if (relative.slashes && !relative.protocol) {\n    // take everything except the protocol from relative\n    var rkeys = Object.keys(relative);\n    for (var rk = 0; rk < rkeys.length; rk++) {\n      var rkey = rkeys[rk];\n      if (rkey !== 'protocol')\n        result[rkey] = relative[rkey];\n    }\n\n    //urlParse appends trailing / to urls like http://www.example.com\n    if (slashedProtocol[result.protocol] &&\n        result.hostname && !result.pathname) {\n      result.path = result.pathname = '/';\n    }\n\n    result.href = result.format();\n    return result;\n  }\n\n  if (relative.protocol && relative.protocol !== result.protocol) {\n    // if it's a known url protocol, then changing\n    // the protocol does weird things\n    // first, if it's not file:, then we MUST have a host,\n    // and if there was a path\n    // to begin with, then we MUST have a path.\n    // if it is file:, then the host is dropped,\n    // because that's known to be hostless.\n    // anything else is assumed to be absolute.\n    if (!slashedProtocol[relative.protocol]) {\n      var keys = Object.keys(relative);\n      for (var v = 0; v < keys.length; v++) {\n        var k = keys[v];\n        result[k] = relative[k];\n      }\n      result.href = result.format();\n      return result;\n    }\n\n    result.protocol = relative.protocol;\n    if (!relative.host && !hostlessProtocol[relative.protocol]) {\n      var relPath = (relative.pathname || '').split('/');\n      while (relPath.length && !(relative.host = relPath.shift()));\n      if (!relative.host) relative.host = '';\n      if (!relative.hostname) relative.hostname = '';\n      if (relPath[0] !== '') relPath.unshift('');\n      if (relPath.length < 2) relPath.unshift('');\n      result.pathname = relPath.join('/');\n    } else {\n      result.pathname = relative.pathname;\n    }\n    result.search = relative.search;\n    result.query = relative.query;\n    result.host = relative.host || '';\n    result.auth = relative.auth;\n    result.hostname = relative.hostname || relative.host;\n    result.port = relative.port;\n    // to support http.request\n    if (result.pathname || result.search) {\n      var p = result.pathname || '';\n      var s = result.search || '';\n      result.path = p + s;\n    }\n    result.slashes = result.slashes || relative.slashes;\n    result.href = result.format();\n    return result;\n  }\n\n  var isSourceAbs = (result.pathname && result.pathname.charAt(0) === '/'),\n      isRelAbs = (\n          relative.host ||\n          relative.pathname && relative.pathname.charAt(0) === '/'\n      ),\n      mustEndAbs = (isRelAbs || isSourceAbs ||\n                    (result.host && relative.pathname)),\n      removeAllDots = mustEndAbs,\n      srcPath = result.pathname && result.pathname.split('/') || [],\n      relPath = relative.pathname && relative.pathname.split('/') || [],\n      psychotic = result.protocol && !slashedProtocol[result.protocol];\n\n  // if the url is a non-slashed url, then relative\n  // links like ../.. should be able\n  // to crawl up to the hostname, as well.  This is strange.\n  // result.protocol has already been set by now.\n  // Later on, put the first path part into the host field.\n  if (psychotic) {\n    result.hostname = '';\n    result.port = null;\n    if (result.host) {\n      if (srcPath[0] === '') srcPath[0] = result.host;\n      else srcPath.unshift(result.host);\n    }\n    result.host = '';\n    if (relative.protocol) {\n      relative.hostname = null;\n      relative.port = null;\n      if (relative.host) {\n        if (relPath[0] === '') relPath[0] = relative.host;\n        else relPath.unshift(relative.host);\n      }\n      relative.host = null;\n    }\n    mustEndAbs = mustEndAbs && (relPath[0] === '' || srcPath[0] === '');\n  }\n\n  if (isRelAbs) {\n    // it's absolute.\n    result.host = (relative.host || relative.host === '') ?\n                  relative.host : result.host;\n    result.hostname = (relative.hostname || relative.hostname === '') ?\n                      relative.hostname : result.hostname;\n    result.search = relative.search;\n    result.query = relative.query;\n    srcPath = relPath;\n    // fall through to the dot-handling below.\n  } else if (relPath.length) {\n    // it's relative\n    // throw away the existing file, and take the new path instead.\n    if (!srcPath) srcPath = [];\n    srcPath.pop();\n    srcPath = srcPath.concat(relPath);\n    result.search = relative.search;\n    result.query = relative.query;\n  } else if (!util.isNullOrUndefined(relative.search)) {\n    // just pull out the search.\n    // like href='?foo'.\n    // Put this after the other two cases because it simplifies the booleans\n    if (psychotic) {\n      result.hostname = result.host = srcPath.shift();\n      //occationaly the auth can get stuck only in host\n      //this especially happens in cases like\n      //url.resolveObject('mailto:local1@domain1', 'local2@domain2')\n      var authInHost = result.host && result.host.indexOf('@') > 0 ?\n                       result.host.split('@') : false;\n      if (authInHost) {\n        result.auth = authInHost.shift();\n        result.host = result.hostname = authInHost.shift();\n      }\n    }\n    result.search = relative.search;\n    result.query = relative.query;\n    //to support http.request\n    if (!util.isNull(result.pathname) || !util.isNull(result.search)) {\n      result.path = (result.pathname ? result.pathname : '') +\n                    (result.search ? result.search : '');\n    }\n    result.href = result.format();\n    return result;\n  }\n\n  if (!srcPath.length) {\n    // no path at all.  easy.\n    // we've already handled the other stuff above.\n    result.pathname = null;\n    //to support http.request\n    if (result.search) {\n      result.path = '/' + result.search;\n    } else {\n      result.path = null;\n    }\n    result.href = result.format();\n    return result;\n  }\n\n  // if a url ENDs in . or .., then it must get a trailing slash.\n  // however, if it ends in anything else non-slashy,\n  // then it must NOT get a trailing slash.\n  var last = srcPath.slice(-1)[0];\n  var hasTrailingSlash = (\n      (result.host || relative.host || srcPath.length > 1) &&\n      (last === '.' || last === '..') || last === '');\n\n  // strip single dots, resolve double dots to parent dir\n  // if the path tries to go above the root, `up` ends up > 0\n  var up = 0;\n  for (var i = srcPath.length; i >= 0; i--) {\n    last = srcPath[i];\n    if (last === '.') {\n      srcPath.splice(i, 1);\n    } else if (last === '..') {\n      srcPath.splice(i, 1);\n      up++;\n    } else if (up) {\n      srcPath.splice(i, 1);\n      up--;\n    }\n  }\n\n  // if the path is allowed to go above the root, restore leading ..s\n  if (!mustEndAbs && !removeAllDots) {\n    for (; up--; up) {\n      srcPath.unshift('..');\n    }\n  }\n\n  if (mustEndAbs && srcPath[0] !== '' &&\n      (!srcPath[0] || srcPath[0].charAt(0) !== '/')) {\n    srcPath.unshift('');\n  }\n\n  if (hasTrailingSlash && (srcPath.join('/').substr(-1) !== '/')) {\n    srcPath.push('');\n  }\n\n  var isAbsolute = srcPath[0] === '' ||\n      (srcPath[0] && srcPath[0].charAt(0) === '/');\n\n  // put the host back\n  if (psychotic) {\n    result.hostname = result.host = isAbsolute ? '' :\n                                    srcPath.length ? srcPath.shift() : '';\n    //occationaly the auth can get stuck only in host\n    //this especially happens in cases like\n    //url.resolveObject('mailto:local1@domain1', 'local2@domain2')\n    var authInHost = result.host && result.host.indexOf('@') > 0 ?\n                     result.host.split('@') : false;\n    if (authInHost) {\n      result.auth = authInHost.shift();\n      result.host = result.hostname = authInHost.shift();\n    }\n  }\n\n  mustEndAbs = mustEndAbs || (result.host && srcPath.length);\n\n  if (mustEndAbs && !isAbsolute) {\n    srcPath.unshift('');\n  }\n\n  if (!srcPath.length) {\n    result.pathname = null;\n    result.path = null;\n  } else {\n    result.pathname = srcPath.join('/');\n  }\n\n  //to support request.http\n  if (!util.isNull(result.pathname) || !util.isNull(result.search)) {\n    result.path = (result.pathname ? result.pathname : '') +\n                  (result.search ? result.search : '');\n  }\n  result.auth = relative.auth || result.auth;\n  result.slashes = result.slashes || relative.slashes;\n  result.href = result.format();\n  return result;\n};\n\nUrl.prototype.parseHost = function() {\n  var host = this.host;\n  var port = portPattern.exec(host);\n  if (port) {\n    port = port[0];\n    if (port !== ':') {\n      this.port = port.substr(1);\n    }\n    host = host.substr(0, host.length - port.length);\n  }\n  if (host) this.hostname = host;\n};\n\n\n//# sourceURL=webpack:///./node_modules/url/url.js?");

/***/ }),

/***/ "./node_modules/url/util.js":
/*!**********************************!*\
  !*** ./node_modules/url/util.js ***!
  \**********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nmodule.exports = {\n  isString: function(arg) {\n    return typeof(arg) === 'string';\n  },\n  isObject: function(arg) {\n    return typeof(arg) === 'object' && arg !== null;\n  },\n  isNull: function(arg) {\n    return arg === null;\n  },\n  isNullOrUndefined: function(arg) {\n    return arg == null;\n  }\n};\n\n\n//# sourceURL=webpack:///./node_modules/url/util.js?");

/***/ }),

/***/ "./node_modules/util-deprecate/node.js":
/*!*********************************************!*\
  !*** ./node_modules/util-deprecate/node.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("\n/**\n * For Node.js, simply re-export the core `util.deprecate` function.\n */\n\nmodule.exports = __webpack_require__(/*! util */ \"./node_modules/util/util.js\").deprecate;\n\n\n//# sourceURL=webpack:///./node_modules/util-deprecate/node.js?");

/***/ }),

/***/ "./node_modules/util/support/isBufferBrowser.js":
/*!******************************************************!*\
  !*** ./node_modules/util/support/isBufferBrowser.js ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = function isBuffer(arg) {\n  return arg && typeof arg === 'object'\n    && typeof arg.copy === 'function'\n    && typeof arg.fill === 'function'\n    && typeof arg.readUInt8 === 'function';\n}\n\n//# sourceURL=webpack:///./node_modules/util/support/isBufferBrowser.js?");

/***/ }),

/***/ "./node_modules/util/util.js":
/*!***********************************!*\
  !*** ./node_modules/util/util.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(process) {// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar getOwnPropertyDescriptors = Object.getOwnPropertyDescriptors ||\n  function getOwnPropertyDescriptors(obj) {\n    var keys = Object.keys(obj);\n    var descriptors = {};\n    for (var i = 0; i < keys.length; i++) {\n      descriptors[keys[i]] = Object.getOwnPropertyDescriptor(obj, keys[i]);\n    }\n    return descriptors;\n  };\n\nvar formatRegExp = /%[sdj%]/g;\nexports.format = function(f) {\n  if (!isString(f)) {\n    var objects = [];\n    for (var i = 0; i < arguments.length; i++) {\n      objects.push(inspect(arguments[i]));\n    }\n    return objects.join(' ');\n  }\n\n  var i = 1;\n  var args = arguments;\n  var len = args.length;\n  var str = String(f).replace(formatRegExp, function(x) {\n    if (x === '%%') return '%';\n    if (i >= len) return x;\n    switch (x) {\n      case '%s': return String(args[i++]);\n      case '%d': return Number(args[i++]);\n      case '%j':\n        try {\n          return JSON.stringify(args[i++]);\n        } catch (_) {\n          return '[Circular]';\n        }\n      default:\n        return x;\n    }\n  });\n  for (var x = args[i]; i < len; x = args[++i]) {\n    if (isNull(x) || !isObject(x)) {\n      str += ' ' + x;\n    } else {\n      str += ' ' + inspect(x);\n    }\n  }\n  return str;\n};\n\n\n// Mark that a method should not be used.\n// Returns a modified function which warns once by default.\n// If --no-deprecation is set, then it is a no-op.\nexports.deprecate = function(fn, msg) {\n  if (typeof process !== 'undefined' && process.noDeprecation === true) {\n    return fn;\n  }\n\n  // Allow for deprecating things in the process of starting up.\n  if (typeof process === 'undefined') {\n    return function() {\n      return exports.deprecate(fn, msg).apply(this, arguments);\n    };\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (process.throwDeprecation) {\n        throw new Error(msg);\n      } else if (process.traceDeprecation) {\n        console.trace(msg);\n      } else {\n        console.error(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n};\n\n\nvar debugs = {};\nvar debugEnviron;\nexports.debuglog = function(set) {\n  if (isUndefined(debugEnviron))\n    debugEnviron = process.env.NODE_DEBUG || '';\n  set = set.toUpperCase();\n  if (!debugs[set]) {\n    if (new RegExp('\\\\b' + set + '\\\\b', 'i').test(debugEnviron)) {\n      var pid = process.pid;\n      debugs[set] = function() {\n        var msg = exports.format.apply(exports, arguments);\n        console.error('%s %d: %s', set, pid, msg);\n      };\n    } else {\n      debugs[set] = function() {};\n    }\n  }\n  return debugs[set];\n};\n\n\n/**\n * Echos the value of a value. Trys to print the value out\n * in the best way possible given the different types.\n *\n * @param {Object} obj The object to print out.\n * @param {Object} opts Optional options object that alters the output.\n */\n/* legacy: obj, showHidden, depth, colors*/\nfunction inspect(obj, opts) {\n  // default options\n  var ctx = {\n    seen: [],\n    stylize: stylizeNoColor\n  };\n  // legacy...\n  if (arguments.length >= 3) ctx.depth = arguments[2];\n  if (arguments.length >= 4) ctx.colors = arguments[3];\n  if (isBoolean(opts)) {\n    // legacy...\n    ctx.showHidden = opts;\n  } else if (opts) {\n    // got an \"options\" object\n    exports._extend(ctx, opts);\n  }\n  // set default options\n  if (isUndefined(ctx.showHidden)) ctx.showHidden = false;\n  if (isUndefined(ctx.depth)) ctx.depth = 2;\n  if (isUndefined(ctx.colors)) ctx.colors = false;\n  if (isUndefined(ctx.customInspect)) ctx.customInspect = true;\n  if (ctx.colors) ctx.stylize = stylizeWithColor;\n  return formatValue(ctx, obj, ctx.depth);\n}\nexports.inspect = inspect;\n\n\n// http://en.wikipedia.org/wiki/ANSI_escape_code#graphics\ninspect.colors = {\n  'bold' : [1, 22],\n  'italic' : [3, 23],\n  'underline' : [4, 24],\n  'inverse' : [7, 27],\n  'white' : [37, 39],\n  'grey' : [90, 39],\n  'black' : [30, 39],\n  'blue' : [34, 39],\n  'cyan' : [36, 39],\n  'green' : [32, 39],\n  'magenta' : [35, 39],\n  'red' : [31, 39],\n  'yellow' : [33, 39]\n};\n\n// Don't use 'blue' not visible on cmd.exe\ninspect.styles = {\n  'special': 'cyan',\n  'number': 'yellow',\n  'boolean': 'yellow',\n  'undefined': 'grey',\n  'null': 'bold',\n  'string': 'green',\n  'date': 'magenta',\n  // \"name\": intentionally not styling\n  'regexp': 'red'\n};\n\n\nfunction stylizeWithColor(str, styleType) {\n  var style = inspect.styles[styleType];\n\n  if (style) {\n    return '\\u001b[' + inspect.colors[style][0] + 'm' + str +\n           '\\u001b[' + inspect.colors[style][1] + 'm';\n  } else {\n    return str;\n  }\n}\n\n\nfunction stylizeNoColor(str, styleType) {\n  return str;\n}\n\n\nfunction arrayToHash(array) {\n  var hash = {};\n\n  array.forEach(function(val, idx) {\n    hash[val] = true;\n  });\n\n  return hash;\n}\n\n\nfunction formatValue(ctx, value, recurseTimes) {\n  // Provide a hook for user-specified inspect functions.\n  // Check that value is an object with an inspect function on it\n  if (ctx.customInspect &&\n      value &&\n      isFunction(value.inspect) &&\n      // Filter out the util module, it's inspect function is special\n      value.inspect !== exports.inspect &&\n      // Also filter out any prototype objects using the circular check.\n      !(value.constructor && value.constructor.prototype === value)) {\n    var ret = value.inspect(recurseTimes, ctx);\n    if (!isString(ret)) {\n      ret = formatValue(ctx, ret, recurseTimes);\n    }\n    return ret;\n  }\n\n  // Primitive types cannot have properties\n  var primitive = formatPrimitive(ctx, value);\n  if (primitive) {\n    return primitive;\n  }\n\n  // Look up the keys of the object.\n  var keys = Object.keys(value);\n  var visibleKeys = arrayToHash(keys);\n\n  if (ctx.showHidden) {\n    keys = Object.getOwnPropertyNames(value);\n  }\n\n  // IE doesn't make error fields non-enumerable\n  // http://msdn.microsoft.com/en-us/library/ie/dww52sbt(v=vs.94).aspx\n  if (isError(value)\n      && (keys.indexOf('message') >= 0 || keys.indexOf('description') >= 0)) {\n    return formatError(value);\n  }\n\n  // Some type of object without properties can be shortcutted.\n  if (keys.length === 0) {\n    if (isFunction(value)) {\n      var name = value.name ? ': ' + value.name : '';\n      return ctx.stylize('[Function' + name + ']', 'special');\n    }\n    if (isRegExp(value)) {\n      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n    }\n    if (isDate(value)) {\n      return ctx.stylize(Date.prototype.toString.call(value), 'date');\n    }\n    if (isError(value)) {\n      return formatError(value);\n    }\n  }\n\n  var base = '', array = false, braces = ['{', '}'];\n\n  // Make Array say that they are Array\n  if (isArray(value)) {\n    array = true;\n    braces = ['[', ']'];\n  }\n\n  // Make functions say that they are functions\n  if (isFunction(value)) {\n    var n = value.name ? ': ' + value.name : '';\n    base = ' [Function' + n + ']';\n  }\n\n  // Make RegExps say that they are RegExps\n  if (isRegExp(value)) {\n    base = ' ' + RegExp.prototype.toString.call(value);\n  }\n\n  // Make dates with properties first say the date\n  if (isDate(value)) {\n    base = ' ' + Date.prototype.toUTCString.call(value);\n  }\n\n  // Make error with message first say the error\n  if (isError(value)) {\n    base = ' ' + formatError(value);\n  }\n\n  if (keys.length === 0 && (!array || value.length == 0)) {\n    return braces[0] + base + braces[1];\n  }\n\n  if (recurseTimes < 0) {\n    if (isRegExp(value)) {\n      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n    } else {\n      return ctx.stylize('[Object]', 'special');\n    }\n  }\n\n  ctx.seen.push(value);\n\n  var output;\n  if (array) {\n    output = formatArray(ctx, value, recurseTimes, visibleKeys, keys);\n  } else {\n    output = keys.map(function(key) {\n      return formatProperty(ctx, value, recurseTimes, visibleKeys, key, array);\n    });\n  }\n\n  ctx.seen.pop();\n\n  return reduceToSingleString(output, base, braces);\n}\n\n\nfunction formatPrimitive(ctx, value) {\n  if (isUndefined(value))\n    return ctx.stylize('undefined', 'undefined');\n  if (isString(value)) {\n    var simple = '\\'' + JSON.stringify(value).replace(/^\"|\"$/g, '')\n                                             .replace(/'/g, \"\\\\'\")\n                                             .replace(/\\\\\"/g, '\"') + '\\'';\n    return ctx.stylize(simple, 'string');\n  }\n  if (isNumber(value))\n    return ctx.stylize('' + value, 'number');\n  if (isBoolean(value))\n    return ctx.stylize('' + value, 'boolean');\n  // For some reason typeof null is \"object\", so special case here.\n  if (isNull(value))\n    return ctx.stylize('null', 'null');\n}\n\n\nfunction formatError(value) {\n  return '[' + Error.prototype.toString.call(value) + ']';\n}\n\n\nfunction formatArray(ctx, value, recurseTimes, visibleKeys, keys) {\n  var output = [];\n  for (var i = 0, l = value.length; i < l; ++i) {\n    if (hasOwnProperty(value, String(i))) {\n      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n          String(i), true));\n    } else {\n      output.push('');\n    }\n  }\n  keys.forEach(function(key) {\n    if (!key.match(/^\\d+$/)) {\n      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n          key, true));\n    }\n  });\n  return output;\n}\n\n\nfunction formatProperty(ctx, value, recurseTimes, visibleKeys, key, array) {\n  var name, str, desc;\n  desc = Object.getOwnPropertyDescriptor(value, key) || { value: value[key] };\n  if (desc.get) {\n    if (desc.set) {\n      str = ctx.stylize('[Getter/Setter]', 'special');\n    } else {\n      str = ctx.stylize('[Getter]', 'special');\n    }\n  } else {\n    if (desc.set) {\n      str = ctx.stylize('[Setter]', 'special');\n    }\n  }\n  if (!hasOwnProperty(visibleKeys, key)) {\n    name = '[' + key + ']';\n  }\n  if (!str) {\n    if (ctx.seen.indexOf(desc.value) < 0) {\n      if (isNull(recurseTimes)) {\n        str = formatValue(ctx, desc.value, null);\n      } else {\n        str = formatValue(ctx, desc.value, recurseTimes - 1);\n      }\n      if (str.indexOf('\\n') > -1) {\n        if (array) {\n          str = str.split('\\n').map(function(line) {\n            return '  ' + line;\n          }).join('\\n').substr(2);\n        } else {\n          str = '\\n' + str.split('\\n').map(function(line) {\n            return '   ' + line;\n          }).join('\\n');\n        }\n      }\n    } else {\n      str = ctx.stylize('[Circular]', 'special');\n    }\n  }\n  if (isUndefined(name)) {\n    if (array && key.match(/^\\d+$/)) {\n      return str;\n    }\n    name = JSON.stringify('' + key);\n    if (name.match(/^\"([a-zA-Z_][a-zA-Z_0-9]*)\"$/)) {\n      name = name.substr(1, name.length - 2);\n      name = ctx.stylize(name, 'name');\n    } else {\n      name = name.replace(/'/g, \"\\\\'\")\n                 .replace(/\\\\\"/g, '\"')\n                 .replace(/(^\"|\"$)/g, \"'\");\n      name = ctx.stylize(name, 'string');\n    }\n  }\n\n  return name + ': ' + str;\n}\n\n\nfunction reduceToSingleString(output, base, braces) {\n  var numLinesEst = 0;\n  var length = output.reduce(function(prev, cur) {\n    numLinesEst++;\n    if (cur.indexOf('\\n') >= 0) numLinesEst++;\n    return prev + cur.replace(/\\u001b\\[\\d\\d?m/g, '').length + 1;\n  }, 0);\n\n  if (length > 60) {\n    return braces[0] +\n           (base === '' ? '' : base + '\\n ') +\n           ' ' +\n           output.join(',\\n  ') +\n           ' ' +\n           braces[1];\n  }\n\n  return braces[0] + base + ' ' + output.join(', ') + ' ' + braces[1];\n}\n\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\nfunction isArray(ar) {\n  return Array.isArray(ar);\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return isObject(re) && objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return isObject(d) && objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return isObject(e) &&\n      (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = __webpack_require__(/*! ./support/isBuffer */ \"./node_modules/util/support/isBufferBrowser.js\");\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n\n\nfunction pad(n) {\n  return n < 10 ? '0' + n.toString(10) : n.toString(10);\n}\n\n\nvar months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',\n              'Oct', 'Nov', 'Dec'];\n\n// 26 Feb 16:19:34\nfunction timestamp() {\n  var d = new Date();\n  var time = [pad(d.getHours()),\n              pad(d.getMinutes()),\n              pad(d.getSeconds())].join(':');\n  return [d.getDate(), months[d.getMonth()], time].join(' ');\n}\n\n\n// log is just a thin wrapper to console.log that prepends a timestamp\nexports.log = function() {\n  console.log('%s - %s', timestamp(), exports.format.apply(exports, arguments));\n};\n\n\n/**\n * Inherit the prototype methods from one constructor into another.\n *\n * The Function.prototype.inherits from lang.js rewritten as a standalone\n * function (not on Function.prototype). NOTE: If this file is to be loaded\n * during bootstrapping this function needs to be rewritten using some native\n * functions as prototype setup using normal JavaScript does not work as\n * expected during bootstrapping (see mirror.js in r114903).\n *\n * @param {function} ctor Constructor function which needs to inherit the\n *     prototype.\n * @param {function} superCtor Constructor function to inherit prototype from.\n */\nexports.inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits.js\");\n\nexports._extend = function(origin, add) {\n  // Don't do anything if add isn't an object\n  if (!add || !isObject(add)) return origin;\n\n  var keys = Object.keys(add);\n  var i = keys.length;\n  while (i--) {\n    origin[keys[i]] = add[keys[i]];\n  }\n  return origin;\n};\n\nfunction hasOwnProperty(obj, prop) {\n  return Object.prototype.hasOwnProperty.call(obj, prop);\n}\n\nvar kCustomPromisifiedSymbol = typeof Symbol !== 'undefined' ? Symbol('util.promisify.custom') : undefined;\n\nexports.promisify = function promisify(original) {\n  if (typeof original !== 'function')\n    throw new TypeError('The \"original\" argument must be of type Function');\n\n  if (kCustomPromisifiedSymbol && original[kCustomPromisifiedSymbol]) {\n    var fn = original[kCustomPromisifiedSymbol];\n    if (typeof fn !== 'function') {\n      throw new TypeError('The \"util.promisify.custom\" argument must be of type Function');\n    }\n    Object.defineProperty(fn, kCustomPromisifiedSymbol, {\n      value: fn, enumerable: false, writable: false, configurable: true\n    });\n    return fn;\n  }\n\n  function fn() {\n    var promiseResolve, promiseReject;\n    var promise = new Promise(function (resolve, reject) {\n      promiseResolve = resolve;\n      promiseReject = reject;\n    });\n\n    var args = [];\n    for (var i = 0; i < arguments.length; i++) {\n      args.push(arguments[i]);\n    }\n    args.push(function (err, value) {\n      if (err) {\n        promiseReject(err);\n      } else {\n        promiseResolve(value);\n      }\n    });\n\n    try {\n      original.apply(this, args);\n    } catch (err) {\n      promiseReject(err);\n    }\n\n    return promise;\n  }\n\n  Object.setPrototypeOf(fn, Object.getPrototypeOf(original));\n\n  if (kCustomPromisifiedSymbol) Object.defineProperty(fn, kCustomPromisifiedSymbol, {\n    value: fn, enumerable: false, writable: false, configurable: true\n  });\n  return Object.defineProperties(\n    fn,\n    getOwnPropertyDescriptors(original)\n  );\n}\n\nexports.promisify.custom = kCustomPromisifiedSymbol\n\nfunction callbackifyOnRejected(reason, cb) {\n  // `!reason` guard inspired by bluebird (Ref: https://goo.gl/t5IS6M).\n  // Because `null` is a special error value in callbacks which means \"no error\n  // occurred\", we error-wrap so the callback consumer can distinguish between\n  // \"the promise rejected with null\" or \"the promise fulfilled with undefined\".\n  if (!reason) {\n    var newReason = new Error('Promise was rejected with a falsy value');\n    newReason.reason = reason;\n    reason = newReason;\n  }\n  return cb(reason);\n}\n\nfunction callbackify(original) {\n  if (typeof original !== 'function') {\n    throw new TypeError('The \"original\" argument must be of type Function');\n  }\n\n  // We DO NOT return the promise as it gives the user a false sense that\n  // the promise is actually somehow related to the callback's execution\n  // and that the callback throwing will reject the promise.\n  function callbackified() {\n    var args = [];\n    for (var i = 0; i < arguments.length; i++) {\n      args.push(arguments[i]);\n    }\n\n    var maybeCb = args.pop();\n    if (typeof maybeCb !== 'function') {\n      throw new TypeError('The last argument must be of type Function');\n    }\n    var self = this;\n    var cb = function() {\n      return maybeCb.apply(self, arguments);\n    };\n    // In true node style we process the callback on `nextTick` with all the\n    // implications (stack, `uncaughtException`, `async_hooks`)\n    original.apply(this, args)\n      .then(function(ret) { process.nextTick(cb, null, ret) },\n            function(rej) { process.nextTick(callbackifyOnRejected, rej, cb) });\n  }\n\n  Object.setPrototypeOf(callbackified, Object.getPrototypeOf(original));\n  Object.defineProperties(callbackified,\n                          getOwnPropertyDescriptors(original));\n  return callbackified;\n}\nexports.callbackify = callbackify;\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../process/browser.js */ \"./node_modules/process/browser.js\")))\n\n//# sourceURL=webpack:///./node_modules/util/util.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/amd-define.js":
/*!***************************************!*\
  !*** (webpack)/buildin/amd-define.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = function() {\n\tthrow new Error(\"define cannot be used indirect\");\n};\n\n\n//# sourceURL=webpack:///(webpack)/buildin/amd-define.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/amd-options.js":
/*!****************************************!*\
  !*** (webpack)/buildin/amd-options.js ***!
  \****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* WEBPACK VAR INJECTION */(function(__webpack_amd_options__) {/* globals __webpack_amd_options__ */\nmodule.exports = __webpack_amd_options__;\n\n/* WEBPACK VAR INJECTION */}.call(this, {}))\n\n//# sourceURL=webpack:///(webpack)/buildin/amd-options.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/global.js":
/*!***********************************!*\
  !*** (webpack)/buildin/global.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("var g;\n\n// This works in non-strict mode\ng = (function() {\n\treturn this;\n})();\n\ntry {\n\t// This works if eval is allowed (see CSP)\n\tg = g || new Function(\"return this\")();\n} catch (e) {\n\t// This works if the window reference is available\n\tif (typeof window === \"object\") g = window;\n}\n\n// g can still be undefined, but nothing to do about it...\n// We return undefined, instead of nothing here, so it's\n// easier to handle this case. if(!global) { ...}\n\nmodule.exports = g;\n\n\n//# sourceURL=webpack:///(webpack)/buildin/global.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/module.js":
/*!***********************************!*\
  !*** (webpack)/buildin/module.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = function(module) {\n\tif (!module.webpackPolyfill) {\n\t\tmodule.deprecate = function() {};\n\t\tmodule.paths = [];\n\t\t// module.parent = undefined by default\n\t\tif (!module.children) module.children = [];\n\t\tObject.defineProperty(module, \"loaded\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.l;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"id\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.i;\n\t\t\t}\n\t\t});\n\t\tmodule.webpackPolyfill = 1;\n\t}\n\treturn module;\n};\n\n\n//# sourceURL=webpack:///(webpack)/buildin/module.js?");

/***/ }),

/***/ "./node_modules/xtend/immutable.js":
/*!*****************************************!*\
  !*** ./node_modules/xtend/immutable.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = extend\n\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\n\nfunction extend() {\n    var target = {}\n\n    for (var i = 0; i < arguments.length; i++) {\n        var source = arguments[i]\n\n        for (var key in source) {\n            if (hasOwnProperty.call(source, key)) {\n                target[key] = source[key]\n            }\n        }\n    }\n\n    return target\n}\n\n\n//# sourceURL=webpack:///./node_modules/xtend/immutable.js?");

/***/ }),

/***/ "./src/game.ts":
/*!*********************!*\
  !*** ./src/game.ts ***!
  \*********************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Game = void 0;\nvar utils_1 = __webpack_require__(/*! ./utils */ \"./src/utils.ts\");\nvar Game = (function () {\n    function Game(siblingEl) {\n        var _this = this;\n        this.siblingEl = siblingEl;\n        this.canvas = document.createElement(\"canvas\");\n        this.context = this.canvas.getContext(\"2d\");\n        this.siblingEl.parentElement.appendChild(this.canvas);\n        this.siblingEl.addEventListener(\"resize\", function () { _this.resizeCanvas(); });\n        window.addEventListener(\"resize\", function () { _this.resizeCanvas(); });\n        this.resizeCanvas();\n        this.loadImage();\n        this.canvas.classList.add(\"spooky\");\n        if (utils_1.DEBUG) {\n            this.canvas.style.backgroundColor = \"rgba(0,255,0,0.2)\";\n        }\n        else {\n            this.canvas.style.backgroundColor = \"transparent\";\n        }\n    }\n    ;\n    Game.prototype.loadImage = function () {\n        var _this = this;\n        var image = document.createElement(\"img\");\n        image.src = \"images/spooky.svg\";\n        image.onload = function () {\n            _this.spookyImage = image;\n            _this.setupEyes();\n        };\n        return { image: image, is_loaded: false };\n    };\n    Game.prototype.start = function () {\n        var _this = this;\n        var lastUpdate = Date.now();\n        var cb = function () {\n            var delta = Date.now() - lastUpdate;\n            lastUpdate = Date.now();\n            _this.update(delta);\n            _this.draw();\n            window.requestAnimationFrame(cb);\n        };\n        window.requestAnimationFrame(cb);\n    };\n    Game.prototype.handleFace = function (bounds, landmarks, expressions) {\n        this.nose = this.getCenter(landmarks.getNose());\n    };\n    Game.prototype.update = function (delta) {\n        this.moveEyeTowardsPoint(delta, this.leftEyePosition, this.leftEyeTarget);\n        this.moveEyeTowardsPoint(delta, this.rightEyePosition, this.rightEyeTarget);\n    };\n    Game.prototype.moveEyeTowardsPoint = function (delta, eyePosition, target) {\n        var velocity = 1;\n        var dx = target.x - eyePosition.x;\n        var dy = target.y - eyePosition.y;\n        var angle = Math.atan2(dy, dx);\n        var xVelocity = velocity * Math.cos(angle);\n        var yVelocity = velocity * Math.sin(angle);\n        eyePosition.x += xVelocity;\n        eyePosition.y += yVelocity;\n    };\n    Game.prototype.draw = function () {\n        this.clear();\n        if (this.spookyImage) {\n            var canvasWidth = this.canvas.width;\n            var canvasHeight = this.canvas.height;\n            this.context.drawImage(this.spookyImage, 0, 0, canvasWidth, canvasHeight);\n            this.drawEye(this.leftEyePosition);\n            this.drawEye(this.rightEyePosition);\n            this.leftEyeTarget = this.findEyeTarget(this.getLeftEyeConfig(true));\n            this.rightEyeTarget = this.findEyeTarget(this.getRightEyeConfig(true));\n        }\n    };\n    Game.prototype.getLeftEyeConfig = function (includeOffset) {\n        return { xOffset: -165, yOffset: -135, includeOffset: includeOffset };\n    };\n    Game.prototype.getRightEyeConfig = function (includeOffset) {\n        return { xOffset: 140, yOffset: -100, includeOffset: includeOffset };\n    };\n    Game.prototype.drawEye = function (position) {\n        utils_1.drawPoint(this.context, position, \"black\", position.radius);\n    };\n    Game.prototype.findEyeTarget = function (_a) {\n        var xOffset = _a.xOffset, yOffset = _a.yOffset, includeOffset = _a.includeOffset;\n        var pupilRadius = 30;\n        var eyeRadius = 80;\n        var canvasWidth = this.canvas.width;\n        var canvasHeight = this.canvas.height;\n        var imageWidth = this.spookyImage.width;\n        var imageHeight = this.spookyImage.height;\n        var scale = 0;\n        var imageRatio = imageHeight / imageWidth;\n        var canvasRatio = canvasHeight / canvasWidth;\n        if (imageRatio > canvasRatio) {\n            scale = canvasHeight / imageHeight;\n        }\n        else {\n            scale = canvasWidth / imageWidth;\n        }\n        pupilRadius *= scale;\n        eyeRadius *= scale;\n        var imageCenter = { x: canvasWidth / 2, y: canvasHeight / 2 };\n        var eyeCenter = {\n            x: imageCenter.x + (xOffset * scale),\n            y: imageCenter.y + (yOffset * scale)\n        };\n        var pupilCenter = { x: eyeCenter.x, y: eyeCenter.y };\n        if (this.nose && includeOffset) {\n            var eyeSize = 2 * (eyeRadius - pupilRadius);\n            var nosePosition = {\n                x: ((this.nose.x - canvasWidth / 2) / canvasWidth) * eyeSize,\n                y: ((this.nose.y - canvasHeight / 2) / canvasHeight) * eyeSize,\n            };\n            pupilCenter.y += nosePosition.y;\n            pupilCenter.x -= nosePosition.x;\n        }\n        if (utils_1.DEBUG) {\n            utils_1.drawPoint(this.context, { x: eyeCenter.x, y: eyeCenter.y }, \"rgba(255,0,0,0.8)\", eyeRadius);\n        }\n        return {\n            x: pupilCenter.x,\n            y: pupilCenter.y,\n            radius: pupilRadius\n        };\n    };\n    Game.prototype.resizeCanvas = function () {\n        this.canvas.width = this.siblingEl.clientWidth;\n        this.canvas.height = this.siblingEl.clientHeight;\n        this.setupEyes();\n    };\n    Game.prototype.setupEyes = function () {\n        if (this.spookyImage) {\n            this.leftEyePosition = this.findEyeTarget(this.getLeftEyeConfig(false));\n            this.rightEyePosition = this.findEyeTarget(this.getRightEyeConfig(false));\n            this.leftEyeTarget = this.findEyeTarget(this.getLeftEyeConfig(false));\n            this.rightEyeTarget = this.findEyeTarget(this.getRightEyeConfig(false));\n        }\n    };\n    Game.prototype.getCenter = function (points) {\n        var center = { x: 0, y: 0 };\n        for (var _i = 0, points_1 = points; _i < points_1.length; _i++) {\n            var point = points_1[_i];\n            center.x += point.x;\n            center.y += point.y;\n        }\n        center.x /= points.length;\n        center.y /= points.length;\n        return center;\n    };\n    Game.prototype.clear = function () {\n        this.context.clearRect(0, 0, this.canvas.width, this.canvas.height);\n    };\n    return Game;\n}());\nexports.Game = Game;\n\n\n//# sourceURL=webpack:///./src/game.ts?");

/***/ }),

/***/ "./src/index.ts":
/*!**********************!*\
  !*** ./src/index.ts ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.init = void 0;\nvar faceapi = __importStar(__webpack_require__(/*! face-api.js */ \"./node_modules/face-api.js/build/commonjs/index.js\"));\nvar game_1 = __webpack_require__(/*! ./game */ \"./src/game.ts\");\nfunction init() {\n    return __awaiter(this, void 0, void 0, function () {\n        var messageEl, stream, e_1, videoEl, videoCanvas, videoGroup, game;\n        var _this = this;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    messageEl = document.getElementById(\"message\");\n                    insertLoadingText(messageEl);\n                    return [4, Promise.all([\n                            faceapi.nets.tinyFaceDetector.loadFromUri(\"./models\"),\n                            faceapi.nets.faceLandmark68Net.loadFromUri(\"./models\"),\n                            faceapi.nets.faceRecognitionNet.loadFromUri(\"./models\"),\n                            faceapi.nets.faceExpressionNet.loadFromUri(\"./models\"),\n                        ])];\n                case 1:\n                    _a.sent();\n                    stream = null;\n                    _a.label = 2;\n                case 2:\n                    _a.trys.push([2, 4, , 5]);\n                    return [4, navigator.mediaDevices.getUserMedia({\n                            video: true\n                        })];\n                case 3:\n                    stream = _a.sent();\n                    return [3, 5];\n                case 4:\n                    e_1 = _a.sent();\n                    insertErrorText(messageEl, \"Can't fetch your webcam :(\");\n                    return [2];\n                case 5:\n                    messageEl.style.display = \"none\";\n                    videoEl = document.getElementById('video');\n                    videoEl.srcObject = stream;\n                    videoCanvas = null;\n                    videoGroup = document.getElementsByClassName(\"videoGroup\")[0];\n                    game = new game_1.Game(videoEl);\n                    videoEl.addEventListener('play', function () {\n                        videoCanvas = faceapi.createCanvasFromMedia(videoEl);\n                        videoGroup.append(videoCanvas);\n                        game.start();\n                        var rect = videoEl.getBoundingClientRect();\n                        var displayValues = {\n                            width: 0,\n                            height: 0\n                        };\n                        var resize = function () {\n                            rect = videoEl.getBoundingClientRect();\n                            displayValues = {\n                                width: rect.width,\n                                height: rect.height\n                            };\n                            faceapi.matchDimensions(videoCanvas, displayValues);\n                        };\n                        resize();\n                        videoEl.addEventListener(\"resize\", resize);\n                        window.addEventListener(\"resize\", resize);\n                        setInterval(function () { return __awaiter(_this, void 0, void 0, function () {\n                            var detections, i;\n                            return __generator(this, function (_a) {\n                                switch (_a.label) {\n                                    case 0: return [4, faceapi.detectAllFaces(videoEl, new faceapi.TinyFaceDetectorOptions())\n                                            .withFaceLandmarks()\n                                            .withFaceExpressions()\n                                            .withFaceDescriptors()];\n                                    case 1:\n                                        detections = _a.sent();\n                                        detections = faceapi.resizeResults(detections, displayValues);\n                                        videoCanvas\n                                            .getContext('2d')\n                                            .clearRect(0, 0, videoCanvas.width, videoCanvas.height);\n                                        for (i = 0; i < detections.length; i++) {\n                                            game.handleFace(detections[i].detection.box, detections[i].landmarks, detections[i].expressions);\n                                        }\n                                        faceapi.draw.drawDetections(videoCanvas, detections);\n                                        return [2];\n                                }\n                            });\n                        }); }, 100);\n                    });\n                    return [2];\n            }\n        });\n    });\n}\nexports.init = init;\nfunction insertLoadingText(container) {\n    var text = \"loading...\";\n    removeChildren(container);\n    container.classList.add(\"loading\");\n    for (var _i = 0, text_1 = text; _i < text_1.length; _i++) {\n        var letter = text_1[_i];\n        var element = document.createElement(\"span\");\n        element.textContent = letter;\n        element.classList.add(\"loading__letter\");\n        container.appendChild(element);\n    }\n}\nfunction insertErrorText(container, message) {\n    removeChildren(container);\n    container.classList.remove(\"loading\");\n    container.classList.add(\"error\");\n    removeChildren(container);\n    container.textContent = message;\n}\nfunction removeChildren(container) {\n    while (container.firstChild) {\n        container.removeChild(container.firstChild);\n    }\n}\nif (!window.did_load) {\n    window.did_load = true;\n    init();\n}\n\n\n//# sourceURL=webpack:///./src/index.ts?");

/***/ }),

/***/ "./src/utils.ts":
/*!**********************!*\
  !*** ./src/utils.ts ***!
  \**********************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.drawRect = exports.drawPoint = exports.getDistance = exports.DEBUG = void 0;\nexports.DEBUG = false;\nfunction getDistance(p1, p2) {\n    return Math.sqrt((Math.pow((p2.x - p1.x), 2)) + (Math.pow((p2.y - p1.y), 2)));\n}\nexports.getDistance = getDistance;\nfunction drawPoint(context, center, color, radius) {\n    context.save();\n    context.beginPath();\n    context.fillStyle = color;\n    context.arc(center.x, center.y, radius, 0, 2 * Math.PI);\n    context.closePath();\n    context.fill();\n    context.restore();\n}\nexports.drawPoint = drawPoint;\nfunction drawRect(context, rect, color, opacity) {\n    if (opacity === void 0) { opacity = 1.0; }\n    context.save();\n    context.beginPath();\n    context.globalAlpha = opacity;\n    context.fillStyle = color;\n    context.fillRect(rect.x, rect.y, rect.width, rect.height);\n    context.closePath();\n    context.fill();\n    context.restore();\n}\nexports.drawRect = drawRect;\n\n\n//# sourceURL=webpack:///./src/utils.ts?");

/***/ }),

/***/ 0:
/*!************************!*\
  !*** crypto (ignored) ***!
  \************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* (ignored) */\n\n//# sourceURL=webpack:///crypto_(ignored)?");

/***/ })

/******/ });